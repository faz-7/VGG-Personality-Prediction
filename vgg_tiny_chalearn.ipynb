{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbtgzgwkuLC"
      },
      "source": [
        "# prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwwT8hGQj63N",
        "outputId": "aca72206-5021-4af6-f7c9-1cfa8da46cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepPersonality'...\n",
            "remote: Enumerating objects: 5721, done.\u001b[K\n",
            "remote: Counting objects: 100% (737/737), done.\u001b[K\n",
            "remote: Compressing objects: 100% (398/398), done.\u001b[K\n",
            "remote: Total 5721 (delta 528), reused 500 (delta 335), pack-reused 4984 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5721/5721), 7.89 MiB | 14.63 MiB/s, done.\n",
            "Resolving deltas: 100% (4217/4217), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/liaorongfan/DeepPersonality.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J_5QJvz5kLwK",
        "outputId": "95534f72-513e-459e-d99b-9ce0a5b5a96d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DeepPersonality'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DeepPersonality\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKZ5JoDVkOWE",
        "outputId": "45158947-74b4-469b-b840-28ef1d5de333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.9.0/index.html\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.13)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "WO7wFWi4ubE-",
        "outputId": "8431e0ce-3a20-4f6c-8cd4-a052cdb43dbb"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3rBwKQAkSJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6073c113-d64a-416c-cc48-8c0e23052b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1eANtFzA75Mqv01nW45exfauAIMLNO70J\n",
            "From (redirected): https://drive.google.com/uc?id=1eANtFzA75Mqv01nW45exfauAIMLNO70J&confirm=t&uuid=9ef1be08-482d-4e3d-b53e-256c490d4c7a\n",
            "To: /content/DeepPersonality/ChaLearn2016_tiny_processed.zip\n",
            "100% 1.59G/1.59G [00:26<00:00, 59.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1eANtFzA75Mqv01nW45exfauAIMLNO70J --output ChaLearn2016_tiny_processed.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17GdySUakT0X",
        "outputId": "d07aa58f-34e4-4ed9-ed0b-f24c011ebf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/9hqH1PJ6cG8.001/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/C_NtwmmF2Ys.000/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/jDdRrqRcSzM.002/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/L_gmlaz-0s4.003/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/98fnGDVky00.005/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/DnTtbAR_Qyw.004/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/yftfxiDNXko.002/frame_229.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/eI_7SimPnnQ.001/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/WT1YjeADatU.001/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/bt-ev53zZWE.004/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/vrMlwwTLWIE.005/frame_458.jpg  \n",
            "   creating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/\n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_1.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_2.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_3.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_4.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_5.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_6.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_7.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_8.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_9.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_10.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_11.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_12.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_13.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_14.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_15.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_16.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_17.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_18.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_19.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_20.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_21.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_22.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_23.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_24.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_25.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_26.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_27.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_28.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_29.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_30.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_31.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_32.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_33.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_34.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_35.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_36.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_37.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_38.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_39.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_40.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_41.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_42.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_43.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_44.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_45.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_46.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_47.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_48.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_49.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_50.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_51.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_52.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_53.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_54.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_55.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_56.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_57.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_58.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_59.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_60.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_61.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_62.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_63.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_64.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_65.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_66.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_67.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_68.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_69.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_70.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_71.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_72.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_73.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_74.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_75.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_76.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_77.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_78.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_79.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_80.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_81.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_82.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_83.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_84.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_85.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_86.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_87.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_88.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_89.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_90.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_91.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_92.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_93.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_94.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_95.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_96.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_97.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_98.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_99.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_100.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_101.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_102.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_103.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_104.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_105.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_106.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_107.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_108.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_109.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_110.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_111.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_112.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_113.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_114.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_115.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_116.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_117.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_118.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_119.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_120.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_121.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_122.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_123.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_124.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_125.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_126.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_127.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_128.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_129.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_130.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_131.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_132.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_133.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_134.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_135.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_136.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_137.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_138.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_139.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_140.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_141.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_142.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_143.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_144.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_145.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_146.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_147.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_148.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_149.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_150.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_151.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_152.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_153.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_154.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_155.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_156.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_157.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_158.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_159.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_160.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_161.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_162.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_163.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_164.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_165.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_166.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_167.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_168.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_169.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_170.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_171.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_172.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_173.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_174.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_175.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_176.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_177.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_178.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_179.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_180.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_181.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_182.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_183.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_184.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_185.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_186.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_187.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_188.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_189.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_190.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_191.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_192.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_193.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_194.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_195.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_196.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_197.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_198.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_199.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_200.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_201.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_202.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_203.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_204.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_205.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_206.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_207.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_208.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_209.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_210.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_211.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_212.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_213.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_214.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_215.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_216.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_217.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_218.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_219.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_220.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_221.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_222.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_223.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_224.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_225.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_226.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_227.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_228.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_229.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_230.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_231.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_232.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_233.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_234.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_235.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_236.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_237.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_238.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_239.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_240.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_241.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_242.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_243.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_244.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_245.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_246.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_247.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_248.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_249.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_250.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_251.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_252.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_253.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_254.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_255.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_256.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_257.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_258.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_259.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_260.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_261.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_262.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_263.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_264.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_265.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_266.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_267.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_268.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_269.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_270.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_271.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_272.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_273.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_274.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_275.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_276.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_277.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_278.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_279.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_280.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_281.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_282.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_283.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_284.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_285.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_286.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_287.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_288.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_289.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_290.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_291.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_292.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_293.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_294.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_295.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_296.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_297.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_298.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_299.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_300.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_301.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_302.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_303.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_304.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_305.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_306.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_307.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_308.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_309.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_310.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_311.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_312.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_313.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_314.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_315.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_316.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_317.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_318.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_319.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_320.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_321.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_322.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_323.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_324.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_325.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_326.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_327.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_328.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_329.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_330.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_331.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_332.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_333.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_334.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_335.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_336.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_337.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_338.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_339.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_340.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_341.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_342.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_343.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_344.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_345.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_346.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_347.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_348.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_349.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_350.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_351.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_352.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_353.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_354.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_355.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_356.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_357.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_358.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_359.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_360.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_361.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_362.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_363.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_364.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_365.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_366.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_367.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_368.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_369.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_370.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_371.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_372.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_373.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_374.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_375.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_376.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_377.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_378.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_379.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_380.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_381.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_382.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_383.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_384.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_385.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_386.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_387.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_388.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_389.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_390.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_391.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_392.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_393.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_394.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_395.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_396.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_397.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_398.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_399.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_400.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_401.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_402.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_403.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_404.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_405.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_406.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_407.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_408.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_409.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_410.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_411.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_412.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_413.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_414.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_415.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_416.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_417.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_418.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_419.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_420.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_421.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_422.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_423.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_424.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_425.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_426.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_427.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_428.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_429.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_430.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_431.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_432.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_433.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_434.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_435.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_436.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_437.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_438.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_439.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_440.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_441.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_442.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_443.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_444.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_445.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_446.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_447.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_448.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_449.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_450.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_451.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_452.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_453.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_454.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_455.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_456.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_457.jpg  \n",
            "  inflating: datasets/ChaLearn2016_tiny/train_data/dd0z9mErfSo.003/frame_458.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip ChaLearn2016_tiny_processed.zip -d datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZxcXDMYk56d"
      },
      "source": [
        "# library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Uj8Dalk8qY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL1EEhH8lLWl",
        "outputId": "f5bda8fc-dde0-4445-8558-512063071af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchaudio\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqpE4ztylqwz"
      },
      "source": [
        "# vggish for extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW3e_YFhlvfd",
        "outputId": "33b22bf3-1173-436a-e9eb-04197d00f69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvggish\n",
            "  Downloading torchvggish-0.2.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvggish) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchvggish) (2.4.1+cu121)\n",
            "Collecting resampy (from torchvggish)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy->torchvggish) (0.60.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchvggish) (2024.6.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy->torchvggish) (0.43.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchvggish) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchvggish) (1.3.0)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torchvggish\n",
            "  Building wheel for torchvggish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchvggish: filename=torchvggish-0.2-py3-none-any.whl size=10534 sha256=60f45a5957b63ac3d2694e7b485a3d4db111588822bef5da65c0a734114bfbf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/92/3f/652f4935ffcb94cccc2754b4bec8a88c561e360cec6da24c22\n",
            "Successfully built torchvggish\n",
            "Installing collected packages: resampy, torchvggish\n",
            "Successfully installed resampy-0.4.3 torchvggish-0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvggish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOyQHdkhpF7U"
      },
      "source": [
        "# padd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqtYtyZZpC29"
      },
      "outputs": [],
      "source": [
        "def pad_features(features, desired_length=64):\n",
        "    current_length = features.shape[2]  # Current length\n",
        "    if current_length < desired_length:\n",
        "        # Pad with zeros\n",
        "        padding = torch.zeros((15, 1, 96, desired_length - current_length))\n",
        "        features = torch.cat((features, padding), dim=2)  # Concatenate along the last dimension\n",
        "    elif current_length > desired_length:\n",
        "        # Truncate\n",
        "        features = features[:, :, :, :desired_length]\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-xe-UemnehP"
      },
      "source": [
        "# Audio data class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUplj4dcl291"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pickle\n",
        "from torchvggish import vggish, vggish_input\n",
        "\n",
        "\n",
        "class AudioFeaturesDataset(Dataset):\n",
        "    def __init__(self, audio_path, annotation_path):\n",
        "        self.audio_files = []\n",
        "        self.labels = []\n",
        "\n",
        "        self.mp4_to_index = {}\n",
        "        for i, audio_file in enumerate(self.audio_files):\n",
        "               file_name = os.path.basename(audio_file).replace('.wav', '.mp4')\n",
        "               self.mp4_to_index[file_name] = i\n",
        "\n",
        "\n",
        "        # Load audio files\n",
        "        for file in os.listdir(audio_path):\n",
        "            if file.endswith('.wav'):\n",
        "                self.audio_files.append(os.path.join(audio_path, file))\n",
        "\n",
        "        # Load annotations\n",
        "        with open(annotation_path, 'rb') as f:\n",
        "            annotations = pickle.load(f, encoding='latin1')\n",
        "\n",
        "        # Extract labels for each file\n",
        "        for audio_file in self.audio_files:\n",
        "            file_name = os.path.basename(audio_file).replace('.wav', '.mp4')\n",
        "            label = []\n",
        "\n",
        "            # Extract labels for all Big-Five personality traits\n",
        "            for trait in annotations.keys():\n",
        "                if trait != \"interview\":\n",
        "                    trait_dict = annotations[trait]\n",
        "                    if file_name in trait_dict:\n",
        "                        label.append(trait_dict[file_name])\n",
        "                    else:\n",
        "                        label.append(-1.0)  # Default value if label is not found\n",
        "\n",
        "            self.labels.append(torch.tensor(label, dtype=torch.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_files[idx]\n",
        "\n",
        "        # Extract features using VGGish\n",
        "        features = vggish_input.wavfile_to_examples(audio_path)\n",
        "        features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n",
        "        # output shape of features: [15, 1, 96, 64]\n",
        "\n",
        "\n",
        "        # Reshape to desired format: [1, 96, 15 * 64] --> [audio_channel=1, audio_width=96, audio_height=960]\n",
        "        # num_frames, channel, width, height = features.shape\n",
        "        # features = features.view(1, width, num_frames * height)  # Shape: [1, 96, 960]\n",
        "\n",
        "        # Pad or truncate features to desired length\n",
        "        features = pad_features(features)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return features, label\n",
        "\n",
        "\n",
        "    def get_data_by_mp4_name(self, mp4_name):\n",
        "           if mp4_name in self.mp4_to_index:\n",
        "               index = self.mp4_to_index[mp4_name]\n",
        "               return self.__getitem__(index)  # Return features and label\n",
        "           else:\n",
        "               return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCbipWsPo42t"
      },
      "source": [
        "## path data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd_StfiHo32H"
      },
      "outputs": [],
      "source": [
        "train_audio_path = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/voice_data/voice_raw/train_data'\n",
        "valid_audio_path = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/voice_data/voice_raw/valid_data'\n",
        "test_audio_path = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/voice_data/voice_raw/test_data'\n",
        "labels_path_train = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/annotation/annotation_training.pkl'\n",
        "labels_path_valid = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/annotation/annotation_validation.pkl'\n",
        "labels_path_test = '/content/DeepPersonality/datasets/ChaLearn2016_tiny/annotation/annotation_test.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NrcvAHDpLzf"
      },
      "source": [
        "## data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RADojvwpPIj"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = AudioFeaturesDataset(train_audio_path, labels_path_train)\n",
        "valid_dataset = AudioFeaturesDataset(valid_audio_path, labels_path_valid)\n",
        "test_dataset = AudioFeaturesDataset(test_audio_path, labels_path_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcff5w5tY_iZ"
      },
      "source": [
        "## check the length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6SPMPshZDOR",
        "outputId": "66f5e07d-f41f-45ba-84ad-e02de72fcd94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length: 64.0\n",
            "Minimum length: 64\n",
            "Maximum length: 64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = []\n",
        "\n",
        "for idx in range(len(train_dataset)):\n",
        "    features, label = train_dataset[idx]\n",
        "    feature_length = features.shape[-1]\n",
        "    lengths.append(feature_length)\n",
        "\n",
        "mean_length = np.mean(lengths)\n",
        "min_length = np.min(lengths)\n",
        "max_length = np.max(lengths)\n",
        "\n",
        "print(f\"Average length: {mean_length}\")\n",
        "print(f\"Minimum length: {min_length}\")\n",
        "print(f\"Maximum length: {max_length}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdhbdMJRYnTq"
      },
      "source": [
        "## check shape and eaquality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKTxZ2YkmSKl",
        "outputId": "c86f3ed7-f1af-4a37-fe75-d8ff9a65dada"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-ddeab408b034>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([15, 1, 96, 64]), torch.Size([15, 1, 96, 64]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][0].shape, train_dataset[20][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UkHZONetNjq",
        "outputId": "c0a6ca83-42e2-4fed-a3ca-28afeab9f362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-ddeab408b034>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are the tensors completely equal? False\n"
          ]
        }
      ],
      "source": [
        "tensor1 = train_dataset[0][0]\n",
        "tensor2 = train_dataset[20][0]\n",
        "\n",
        "are_equal = torch.equal(tensor1, tensor2)\n",
        "\n",
        "print(f\"Are the tensors completely equal? {are_equal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCpJX5aSXGsl"
      },
      "source": [
        "# plot density of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MDMDmywXKMO"
      },
      "outputs": [],
      "source": [
        "def plotLabelsDensity(filePath):\n",
        "    gt = pickle.load(open(filePath, \"rb\" ), encoding='latin1')\n",
        "\n",
        "    neuroticism = list(gt['neuroticism'].values())\n",
        "    extraversion = list(gt['extraversion'].values())\n",
        "    agreeableness = list(gt['agreeableness'].values())\n",
        "    conscientiousness = list(gt['conscientiousness'].values())\n",
        "    openness = list(gt['openness'].values())\n",
        "\n",
        "    df = pd.DataFrame({'neuroticism': neuroticism,'extraversion': extraversion,'agreeableness':agreeableness,'conscientiousness':conscientiousness,'openness':openness})\n",
        "    df.plot(kind='density',xlim=(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "via3iipBX07u",
        "outputId": "25420706-9639-43f6-aa10-eb0fde1e3f41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plotLabelsDensity(labels_path_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "1b0_pwXUX6P2",
        "outputId": "70124c6c-f0b2-476d-90d4-954d48421867"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plotLabelsDensity(labels_path_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "P0YsIHkPX-Gq",
        "outputId": "3a284d90-5c56-472e-c53f-06f6406159e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADs1UlEQVR4nOzdd1xV9f/A8de57L03CCiiuHDvlVtzp5WZKytNzcxKs76p2dCGldWvYcNtWaZW7omKe4IDUZAhG2TPy733/P64cpUEBGSJn+fjcR9d7j3nc973euO++ay3JMuyjCAIgiAIwmNIUdsBCIIgCIIg1BaRCAmCIAiC8NgSiZAgCIIgCI8tkQgJgiAIgvDYEomQIAiCIAiPLZEICYIgCILw2BKJkCAIgiAIjy2RCAmCIAiC8NjSr+0AappGoyEuLg4LCwskSartcARBEARBKAdZlsnKysLV1RWFour6cR67RCguLg4PD4/aDkMQBEEQhEq4desW7u7uVdbeY5cIWVhYANo30tLSspajEQRBEAShPDIzM/Hw8NB9j1eVxy4RKhoOs7S0FImQIAiCIDxiqnpai5gsLQiCIAjCY0skQoIgCIIgPLZEIiQIgiAIwmPrsZsjVB6yLKNSqVCr1bUdiiCUi56eHvr6+mJLCEEQhAoSidB/KJVK4uPjyc3Nre1QBKFCTE1NcXFxwdDQsLZDEQRBeGSIROgeGo2GiIgI9PT0cHV1xdDQUPyFLdR5siyjVCpJTk4mIiKCxo0bV+lmY4IgCPWZSITuoVQq0Wg0eHh4YGpqWtvhCEK5mZiYYGBgQFRUFEqlEmNj49oOSRAE4ZEg/mwsgfhrWngUic+tIAhCxYnfnIIgCIIgPLZqNRH6/vvvadWqlW6X5y5durBr164yz/nzzz9p2rQpxsbGtGzZkp07d9ZQtIIgCIIg1De1mgi5u7uzbNkyzp07x9mzZ+nTpw8jRozgypUrJR5//Phxxo0bx9SpU7lw4QIjR45k5MiRXL58uYYjFx5WQEAAkiSRnp5eruN79+7NnDlzqjUmQRAE4fEjybIs13YQ97K1teWzzz5j6tSp9z33zDPPkJOTw/bt23WPde7cmdatW/PDDz+Uq/3MzEysrKzIyMi4r9ZYfn4+EREReHt7i8mmVah37960bt2ar776SveYUqkkNTUVJyencq3MS01NxcDAoMqL7dUn4vMrCEJ9Vtb398OoM6vG1Go1f/75Jzk5OXTp0qXEY06cOMHcuXOLPTZw4EC2bdtWarsFBQUUFBTofs7MzKySeAVtMlPZPWsMDQ1xdnYu9/G2traVuo4gVKecwhyCkoIITQsloyADAHcLd5rbNaepbVOx/YYgPAJqfbL0pUuXMDc3x8jIiOnTp7N161aaNWtW4rEJCQk4OTkVe8zJyYmEhIRS21+6dClWVla6m4eHR4Xik2WZXKWqVm4V6azr3bs3s2fPZt68edja2uLs7MzixYt1z6enp/Piiy/i4OCApaUlffr0ISgoSPf85MmTGTlyZLE258yZQ+/evYtdY9asWcyZMwd7e3sGDhwIwOHDh+nYsSNGRka4uLjw9ttvo1KpdO0ePnyYFStWIEkSkiQRGRlZ4tDYsWPH6N27N6amptjY2DBw4EDS0tJ01753aOy7776jcePGGBsb4+TkxJgxY4rF+eqrrzJnzhxsbGxwcnLip59+IicnhylTpmBhYYGPj88D56MJQmmCk4N58/Cb9N7Um2n7p/HFuS/45fIv/HL5F94/8T5Pb3+a4duG80foH6g0qtoOVxCEMtR6j1CTJk24ePEiGRkZbN68mUmTJnH48OFSk6GKWrBgQbFepMzMzAolQ3mFapot3FMlsVTU1SUDMTUs/z/RmjVrmDt3LqdOneLEiRNMnjyZbt260b9/f8aOHYuJiQm7du3CysqKH3/8kb59+3L9+vUK9basWbOGV155hWPHjgEQGxvLkCFDmDx5MmvXruXatWu89NJLGBsbs3jxYlasWMH169dp0aIFS5YsAcDBwYHIyMhi7V68eJG+ffvywgsvsGLFCvT19Tl06FCJZU7Onj3L7NmzWbduHV27diU1NZWjR4/eF+e8efM4ffo0mzZt4pVXXmHr1q2MGjWKd955hy+//JIJEyYQHR0t9owSyu1W5i2Wnl7K0di7nzc3czda2LfAwcQBjawhIiOC80nnicyM5IOTH/Dbtd9Y2mMpTW2b1mLkgiCUptYTIUNDQ3x8fABo164dZ86cYcWKFfz444/3Hevs7ExiYmKxxxITE8scYjEyMsLIyKhqg66jWrVqxaJFiwBo3Lgx3377LQcOHMDExITTp0+TlJSkey8+//xztm3bxubNm3n55ZfLfY3GjRvz6aef6n5+99138fDw4Ntvv0WSJJo2bUpcXBzz589n4cKFWFlZYWhoiKmpaZn/Tp9++int27fnu+++0z3WvHnzEo+Njo7GzMyMoUOHYmFhgaenJ23atCl2jL+/P//73/8AbTK8bNky7O3teemllwBYuHAh33//PcHBwXTu3Lncr194PMmyzIaQDXx1/isK1AXoSXoMazSMZ5s+SzPbZvcNgWUrs/k7/G++D/qesPQwnt/5PIu6LGJYo2G19AoEQShNrSdC/6XRaIrN6blXly5dOHDgQLEhkn379pU6p6gqmBjocXXJwGpr/0HXrohWrVoV+9nFxYWkpCSCgoLIzs7Gzs6u2PN5eXmEh4dX6Brt2rUr9nNISAhdunQp9kXQrVs3srOziYmJoUGDBuVq9+LFi4wdO7Zcx/bv3x9PT08aNmzIoEGDGDRoEKNGjSrWs3Pve6Gnp4ednR0tW7bUPVY0xJqUlFSuawqPr2xlNguPL2Rf1D4AOrt05t1O7+Jl5VXqOeaG5oz3G8+T3k/yTuA7HI09yjuB75BbmMszTZ+pocgFQSiPWk2EFixYwODBg2nQoAFZWVls3LiRgIAA9uzRDkVNnDgRNzc3li5dCsBrr71Gr169WL58OU8++SS///47Z8+eZeXKldUWoyRJFRqeqk0GBgbFfpYkCY1GQ3Z2Ni4uLgQEBNx3jrW1NaDdlfi/c5IKCwvvO97MzKzK4r2XiYlJuY+1sLDg/PnzBAQEsHfvXhYuXMjixYs5c+aM7vWU9F7c+1hR4qbRaB4+eKHeisuOY9q+aURmRqKv0Oet9m8xrum4ck+Ctja25tu+37L87HLWXl3Lh6c+xFDPkFGNR1Vz5IIglFetTpZOSkpi4sSJNGnShL59+3LmzBn27NlD//79Ae0QSHx8vO74rl27snHjRlauXIm/vz+bN29m27ZttGjRorZewiOhbdu2JCQkoK+vj4+PT7Gbvb09oJ23c+97Ddpemgfx8/PjxIkTxZKoY8eOYWFhgbu7O6Ad/ixprs+9WrVqxYEDB8r9mvT19enXrx+ffvopwcHBREZGcvDgwXKfLwgPEp4ezoRdE4jMjMTJ1Ik1g9bwnN9zFV4JppAUvNn+TSY3nwzAkhNLOJNwphoiFgShMmq1q+OXX34p8/mSejDGjh1b7iEUQatfv3506dKFkSNH8umnn+Lr60tcXBw7duxg1KhRtG/fnj59+vDZZ5+xdu1aunTpwvr167l8+fJ9c2/+a8aMGXz11Ve8+uqrzJo1i9DQUBYtWsTcuXN1ta+8vLw4deoUkZGRmJublzg5e8GCBbRs2ZIZM2Ywffp0DA0NOXToEGPHjtUla0W2b9/OzZs36dmzJzY2NuzcuRONRkOTJk2q7k0THmsht0N4ed/LpBek08iqET/2/xEnM6cHn1gKSZKY224uCTkJ7I7czdyAufw57E+czcq/hYQgCNWj1pfPC9VPkiR27txJz549mTJlCr6+vjz77LNERUXp5soMHDiQ9957j3nz5tGhQweysrKYOHHiA9t2c3Nj586dnD59Gn9/f6ZPn87UqVN1E5UB3nzzTfT09GjWrBkODg5ER0ff146vry979+4lKCiIjh070qVLF/7++2/09e/P1a2trdmyZQt9+vTBz8+PH374gd9++63UydWCUBE3M24ybd800gvSaWnfktWDVj9UElREkiSWdFuCn60f6QXp/C/wf2hkMTQrCLWtzu0sXd3EztJCfSU+vw8vPjueibsnkpCTgJ+tH78O/BVzQ/MqvUZkRiRPb3+aPFUeb7Z/k0nNJ1Vp+4JQX1XXztKiR0gQBAHIUmYxff90EnIS8Lby5of+P1R5EgTgZeXFWx3eAuDbC98SkxVT5dcQBKH8RCIkCMJjT61RM//IfG5m3MTR1JGV/Vdia1x9ZV3GNB5DR+eO5Kvz+fjUxxXaRV4QhKolEiFBEB57Ky6s4GjsUYz0jPi6z9fVPolZkiTe7fwu+gp9jsYe5eAtseJREGqLSIQEQXis7Yncw6rLqwD4oNsHNLermUn3Da0a6pbUf3XuK1GTTBBqiUiEBEF4bMVmx/L+8fcBmNJiCoO9B9fo9ae2mIqNkQ2RmZFsDdtao9cWBEFLJEKCIDyWCjWFzDsyj6zCLFo5tOLVNq/WeAzmhuZM858GwPcXvye3MLfGYxCEx51IhARBeCx9f/F7gpODsTCw4NOen2KgMHjwSdVgrO9Y3MzdSM5LZn3I+lqJQRAeZyIREgThsXM55TK/XNbubL+o6yLczN1qLRZDPUNdb9TqK6vJVmbXWiyC8DgSiZBQb/Tu3Zs5c+bUdhhCHadUK3nv2HtoZA2DvQcz0GtgbYfEYO/BeFt5k6XMYlPoptoORxAeKyIREggICECSJNLT02s7lIeyZcsWPvjgg9oOQ6jjVgavJCw9DFtjWxZ0XFDb4QDawqwvtnwRgLVX15Kvyq/liATh8SESIaHclEplnb62ra0tFhYWNRCN8Ki6kXaDXy5ph8Te6fQONsY2tRzRXYO9B+Nm7kZqfipbbmyp7XAE4bEhEqF6QqPRsHTpUry9vTExMcHf35/NmzcjyzL9+vVj4MCBut1rU1NTcXd3Z+HChURGRvLEE08AYGNjgyRJTJ48GdAONc2aNYs5c+Zgb2/PwIHaIYQvvviCli1bYmZmhoeHBzNmzCA7WzuvITMzExMTE3bt2lUsvq1bt2JhYUFurnZVzK1bt3j66aextrbG1taWESNGEBkZqTt+8uTJjBw5ko8++ghXV1ddZfnvvvuOxo0bY2xsjJOTE2PGjNGd89+hsbS0NCZOnIiNjQ2mpqYMHjyYGzdu6J5fvXo11tbW7NmzBz8/P8zNzRk0aBDx8fFV8C8i1DWyLPPxqY9RySqe8HiCAZ4DajukYgwUBkxpPgWAVVdWUagurOWIBOHxIBKhB5FlUObUzq0C2+4vXbqUtWvX8sMPP3DlyhVef/11nn/+eY4cOcKaNWs4c+YMX3/9NQDTp0/Hzc2NhQsX4uHhwV9//QVAaGgo8fHxrFixQtfumjVrMDQ05NixY/zwww8AKBQKvv76a65cucKaNWs4ePAg8+bNA8DS0pKhQ4eycePGYvFt2LCBkSNHYmpqSmFhIQMHDsTCwoKjR49y7NgxXRJyb8/PgQMHCA0NZd++fWzfvp2zZ88ye/ZslixZQmhoKLt376Znz56lvieTJ0/m7Nmz/PPPP5w4cQJZlhkyZAiFhXe/YHJzc/n8889Zt24dR44cITo6mjfffLPc77vw6NgduZuziWcx0jNifsf5SJJU2yHdZ2Tjkdib2JOQk8DuyN21HY4gPBb0azuAOq8wFz52rZ1rvxMHhmYPPKygoICPP/6Y/fv306VLFwAaNmxIYGAgP/74Ixs3buTHH39k4sSJJCQksHPnTi5cuIC+vvaf39ZWW1PJ0dERa2vrYm03btyYTz/9tNhj9/a6eHl58eGHHzJ9+nS+++47AMaPH8+ECRPIzc3F1NSUzMxMduzYwdat2g3jNm3ahEaj4eeff9Z9Ga1atQpra2sCAgIYMED7l7qZmRk///wzhoaGgHYOkJmZGUOHDsXCwgJPT0/atGlT4nty48YN/vnnH44dO0bXrl0BbTLm4eHBtm3bGDt2LACFhYX88MMPNGrUCIBZs2axZMmSB77nwqMlpzCHz898DsCLLV+s1VViZTHSM2Jc03F8c+Eb1oesZ2jDoXUyYROE+kT0CNUDYWFh5Obm0r9/f8zNzXW3tWvXEh4eDsDYsWMZNWoUy5Yt4/PPP6dx48blartdu3b3PbZ//3769u2Lm5sbFhYWTJgwgdu3b+uGvYYMGYKBgQH//PMPAH/99ReWlpb069cPgKCgIMLCwrCwsNDFamtrS35+vi5egJYtW+qSIID+/fvj6elJw4YNmTBhAhs2bNBd879CQkLQ19enU6dOusfs7Oxo0qQJISEhusdMTU11SRCAi4sLSUlJ5XpvhEfHT8E/kZSXhLu5O1NaTKntcMo0xncMRnpGXL19lYvJF2s7HEGo90SP0IMYmGp7Zmrr2uVQND9nx44duLkV/0vXyMgI0A4BnTt3Dj09vWLzZB7EzKx4j1RkZCRDhw7llVde4aOPPsLW1pbAwECmTp2KUqnE1NQUQ0NDxowZw8aNG3n22WfZuHEjzzzzjK4HKjs7m3bt2rFhw4b7rufg4FDqtS0sLDh//jwBAQHs3buXhQsXsnjxYs6cOXNfT1Z5GRgU30RPkiRRCbyeSchJ0G1U+FaHtzDSM6rliMpma2zLkw2fZMuNLay/up42jiX3egqCUDVEIvQgklSu4ana1KxZM4yMjIiOjqZXr14lHvPGG2+gUCjYtWsXQ4YM4cknn6RPnz4Aul4XtVr9wGudO3cOjUbD8uXLUSi0HYp//PHHfceNHz+e/v37c+XKFQ4ePMiHH36oe65t27Zs2rQJR0dHLC0tK/Ra9fX16devH/369WPRokVYW1tz8OBBRo8eXew4Pz8/VCoVp06d0g2N3b59m9DQUJo1a1ahawqPtu8ufkeBuoC2jm15wuOJ2g6nXMb7jWfLjS0ciD5AfHY8LuYutR2SINRbYmisHrCwsODNN9/k9ddfZ82aNYSHh3P+/Hm++eYb1qxZw44dO/j111/ZsGED/fv356233mLSpEmkpaUB4OnpiSRJbN++neTkZF0PU0l8fHwoLCzkm2++4ebNm6xbt043ifpePXv2xNnZmfHjx+Pt7V1siGr8+PHY29szYsQIjh49SkREBAEBAcyePZuYmJhSr719+3a+/vprLl68SFRUFGvXrkWj0ehWlN2rcePGjBgxgpdeeonAwECCgoJ4/vnncXNzY8SIERV5e4VHWFhaGH+H/w3A6+1ef2Tm2/ja+NLRuSNqWc1vob/VdjiCUK+JRKie+OCDD3jvvfdYunQpfn5+DBo0iB07duDl5cXUqVNZvHgxbdu2BeD999/HycmJ6dOnA+Dm5sb777/P22+/jZOTE7NmzSr1Ov7+/nzxxRd88skntGjRgg0bNrB06dL7jpMkiXHjxhEUFMT48eOLPWdqasqRI0do0KABo0ePxs/Pj6lTp5Kfn19mD5G1tTVbtmyhT58++Pn58cMPP/Dbb7/RvHnzEo9ftWoV7dq1Y+jQoXTp0gVZltm5c+d9w2FC/bXi/Ao0soZ+DfrR2rF1bYdTIc/7PQ/AX9f/EsVYBaEaSfJjNiEiMzMTKysrMjIy7vvSzc/PJyIiAm9vb4yNjWspQkGoHPH5Le5S8iWe2/kcepIeW0dsxdvKu7ZDqhC1Rs3QrUOJyY7hvc7v8XSTp2s7JEGoVWV9fz8M0SMkCEK99H3Q9wAMbTj0kUuCAPQUeoxrOg6AP0L/EJP4BaGaiERIEIR653LKZY7GHkVP0uPlVi/XdjiVNsJnBEZ6RoSmhRKUHFTb4QhCvSQSIUEQ6p0fgrQT+J9s+CQNLBvUcjSVZ2VkxUAvbWmbP6//WcvRCEL9JBIhQRDqlSu3r3A45jAKSfFI9wYVeabJMwDsjthNen567QYjCPWQSIQEQahXVl1eBWiruXtaetZyNA+vpX1Lmto2RalR6rYCEASh6ohESBCEeiMmK4Z9UfsAeKHFC7UcTdWQJEm3YuzP63+ikTW1HJEg1C8iERIEod5YH7Iejayhq2tXfG18azucKvOk95OYGZgRlRnF6YTTtR2OINQrIhESBKFeyCjIYMuNLQBMaj6plqOpWqYGpgxtOBTQLqUXBKHqiERIEIR64c/rf5KnysPXxpcuLl1qO5wqVzQ8djD6IEm5SbUcjSDUHyIREuqEyMhIJEni4sWLpR4TEBCAJEmkp6fXWFzCo0GpVrIxZCOg7Q16VGqKVYSvjS9tHNugltW6ni9BEB6eSIQEQXjk7YzYSXJeMo4mjgz2Glzb4VSbsb5jAdh8fTMqjaqWoxGE+kEkQkKpZFlGpRK/bIW6TZZlNoRsAOA5v+cw0Ku/RXUHeA3A2siaxNxEjsYcre1wBKFeEIlQPbJ79266d++OtbU1dnZ2DB06lPDwcN3zx48fp3Xr1hgbG9O+fXu2bdtWbDiqaOhp165dtGvXDiMjIwIDA9FoNCxduhRvb29MTEzw9/dn8+bNxa59+fJlBg8ejLm5OU5OTkyYMIGUlJRyx1bk2rVrdO3aFWNjY1q0aMHhw4fLfM2BgYH06NEDExMTPDw8mD17Njk5Obrnvby8+Pjjj3nhhRewsLCgQYMGrFy5slgbt27d4umnn8ba2hpbW1tGjBhBZGSk7vmAgAA6duyImZkZ1tbWdOvWjaioKACCgoJ44oknsLCwwNLSknbt2nH27Nmy/6GEKhWcEsy11GsYKgx5qvFTtR1OtTLSM2Kkz0gA/rguJk0LQlUQidADyLJMbmFurdwqWmQxJyeHuXPncvbsWQ4cOIBCoWDUqFFoNBoyMzMZNmwYLVu25Pz583zwwQfMnz+/xHbefvttli1bRkhICK1atWLp0qWsXbuWH374gStXrvD666/z/PPP65KU9PR0+vTpQ5s2bTh79iy7d+8mMTGRp59+ulyx3eutt97ijTfe4MKFC3Tp0oVhw4Zx+/btEuMMDw9n0KBBPPXUUwQHB7Np0yYCAwOZNWtWseOWL19O+/btuXDhAjNmzOCVV14hNDQUgMLCQgYOHIiFhQVHjx7l2LFjmJubM2jQIJRKJSqVipEjR9KrVy+Cg4M5ceIEL7/8sm4Oyvjx43F3d+fMmTOcO3eOt99+GwOD+tsjURcVraIa5D0Ia2Pr2g2mBhQNjx2LPcatrFu1HI0gPPok+TEraZyZmYmVlRUZGRlYWloWey4/P5+IiAi8vb0xNjYGILcwl04bO9VGqJx67hSmBqaVPj8lJQUHBwcuXbpEYGAg//vf/4iJidG9tp9//pmXXnqJCxcu0Lp1awICAnjiiSfYtm0bI0aMAKCgoABbW1v2799Ply53V+K8+OKL5ObmsnHjRj788EOOHj3Knj17dM/HxMTg4eFBaGgovr737+dyb2wtWrQgMjISb29vli1bpkvQVCoV3t7evPrqq8ybN08XX1paGtbW1rz44ovo6enx448/6toNDAykV69e5OTkYGxsjJeXFz169GDdunWANrF1dnbm/fffZ/r06axfv54PP/yQkJAQXXKjVCqxtrZm27ZttG/fHjs7OwICAujVq9d9r8PS0pJvvvmGSZNqf7l2SZ/f+i49P52+f/ZFqVGyYcgGWjm0qu2QKkxVqCb+RgaxN9K4HZNNelIeBbmFaNQyhib6mFsb4dDAAldfazyb26FvqMe0fdM4HnecKc2nMLf93Np+CYJQI8r6/n4Y+lXWklDrbty4wcKFCzl16hQpKSm63pbo6GhCQ0Np1apVsS/Ijh07lthO+/btdffDwsLIzc2lf//+xY5RKpW0adMG0A4PHTp0CHNz8/vaCg8Px9fXt8zYWrRooTv+3mRLX1+f9u3bExISUmKcQUFBBAcHs2HDBt1jsiyj0WiIiIjAz88PgFat7n45SpKEs7MzSUlJujbCwsKwsLAo1nZ+fj7h4eEMGDCAyZMnM3DgQPr370+/fv14+umncXFxAWDu3Lm8+OKLrFu3jn79+jF27FgaNWpUYrxC1fs7/G+UGiV+tn60tG9Z2+GUm0Yjc+tqKjfOJHIzKJnCfHWJxxXkqsi6nU98eAbBh2IwMNajSSdnRrd4huNxx9kStoUZrWdgrP94JL6CUB1EIvQAJvomnHruVK1duyKGDRuGp6cnP/30E66urmg0Glq0aIFSqaxQO2ZmZrr72dnZAOzYsQM3N7dixxkZGemOGTZsGJ988sl9bRUlDFUV272ys7OZNm0as2fPvu+5Bg3uVhz/71CVJEm6RCw7O5t27doVS6aKODg4ALBq1Spmz57N7t272bRpE//73//Yt28fnTt3ZvHixTz33HPs2LGDXbt2sWjRIn7//XdGjRpV6dcllI9G1rApdBOg3WPnUVgyr8xXEXI8nuCDt8hMydc9bmZthHsTG5y8LbF2MsXEwhA9fYmCXBUZyXkkRmQSEZRMdloBlw/Hojgq0ddjHIed/mJP5B5G+IyoxVclCI82kQg9gCRJDzU8VVNu375NaGgoP/30Ez169AC0w0RFmjRpwvr16ykoKNAlMGfOnHlgu82aNcPIyIjo6OgSh4YA2rZty19//YWXlxf6+vd/pB4U271OnjxJz549Ae3Q2Llz5+6b83Pvda9evYqPj88DX0dp2rZty6ZNm3B0dCyzq7VNmza0adOGBQsW0KVLFzZu3Ejnzp0B8PX1xdfXl9dff51x48axatUqkQjVgJNxJ7mVdQtzA3OGeA+p7XDKlJmSR3BADCGBcSjv9P4Ymenj29GZxu2dcPa2RFKUnMg5N7SiSSdnejzdmJjraZzbFUVsaBqNozrjnNCYHQYHRSIkCA9BTJauJ2xsbLCzs2PlypWEhYVx8OBB5s69O3fgueeeQ6PR8PLLLxMSEsKePXv4/PPPAcr8S9rCwoI333yT119/nTVr1hAeHs758+f55ptvWLNmDQAzZ84kNTWVcePGcebMGcLDw9mzZw9TpkxBrVY/MLZ7/d///R9bt27l2rVrzJw5k7S0NF54oeTimfPnz+f48ePMmjWLixcvcuPGDf7+++9SE6eSjB8/Hnt7e0aMGMHRo0eJiIggICCA2bNnExMTQ0REBAsWLODEiRNERUWxd+9ebty4gZ+fH3l5ecyaNYuAgACioqI4duwYZ86c0Q3JCdWrqDdoeKPhdfKPFVmWiQ/PYPfKS6x/7wRB+2+hzFdj7WRKr+eaMGlpN3o+44tLI6tSk6B7SQoJj6a2jHy9DU/OaIWpjQEWBXa0OP4ke7aL+mOCUFmiR6ieUCgU/P7778yePZsWLVrQpEkTvv76a3r37g1oJ/X++++/vPLKK7Ru3ZqWLVuycOFCnnvuuQdOrP3ggw9wcHBg6dKl3Lx5E2tra9q2bcs777wDgKurK8eOHWP+/PkMGDCAgoICPD09GTRoEAqFAkmSyoztXsuWLWPZsmVcvHgRHx8f/vnnH+zt7UuMq1WrVhw+fJh3332XHj16IMsyjRo14plnnin3+2ZqasqRI0eYP38+o0ePJisrCzc3N/r27YulpSV5eXlcu3aNNWvWcPv2bVxcXJg5cybTpk1DpVJx+/ZtJk6cSGJiIvb29owePZr333+/3NcXKiclL4XDMdpVi0WlJ+oKlVLN9TOJXD4cS3J0lu5x96Y2+Pf1wLO5XbkSn7J4tbJnfOMurPjyD0yjnQnbno1Z/g26jfZ56LYF4XEjVo3d43FbdbNhwwamTJlCRkYGJiYVm48k1D2P0+d31eVVfHHuC1o5tGLDkPvnd9U0WSOTEJFJ2NlEQk8nUJCj3YhUT1+Bb0cn/Pt6YOd2/2KCh3Uh8QJf/LKaztHaobGmnZ3pM9FPJENCvSRWjQkPbe3atTRs2BA3NzeCgoKYP38+Tz/9tEiChEeKLMtsC9sGoNtcsDYUFqiJD0/n1tVUws4nkZ1aoHvOws6YFj3d8Ovmgom5YbXF0NqxNQUt4zlguI6+4c9z7WQCCn0Fvcc3eSQmjwtCXSASocdIQkICCxcuJCEhARcXF8aOHctHH31U22EJQoVcSrnEzYybGOsZM8hrUJW2LcsyyVkFXE/MJiYtl9s5SnKVKlDLmObLWBTImORqkFMKuB2dhUZ9t0PdwFiPhv4ONO7ghEczWxQ10CsjSRLPNn2WRamLsDaxov3l4VwNjMPYTJ8uoyq/iEAQHie1mggtXbqULVu2cO3aNUxMTOjatSuffPIJTZo0KfWc1atXM2XKlGKPGRkZkZ+fX8oZQpF58+Yxb9682g5DEB5KUW9QX8++WBhalH1wOeQp1ewLSeTQtSROhN8mKz0fB7UCR7UCB7WEg1qBrUYCJLKArHvOVRkrsPW2pGNXNxr526NvqPfQ8VTUYO/BfH72c86YH2DYkOHE7YDze6KxcjClWXfXGo9HEB41tZoIHT58mJkzZ9KhQwdUKhXvvPMOAwYM4OrVq8X2svkvS0tLXYkEKHvVkyAI9Ue+Kp/dEbuBhxsWk2WZ0xGp/H7mFoHBCTjngqdKwSiVHuZyyUPFan2JHBOJBEnDzUIlt/Q1pCtkiM/BamcKo+LdmNLNC0+70n93VQcTfRPG+I5h1eVV/GOwjleefI8zOyIJ2BiKtbMprj7WNRqPIDxqajUR2r17d7GfV69ejaOjI+fOndPtJVOSot2BBUF4vByIPkBWYRauZq50dC55Z/SyaDQye68msvJQGPkR2TRX6jFJZYDE3T+mJAmsnUyxdzfHzt0cOzdz7N3NMbM20v3RlZlfyOmbqRy5kcyuywkkZxWw+ngka05EMqCZEzN6++DvYV1VL/uBnmv6HOuurONs4llMn8ylcaIjN84msffnKzzzbgdMLKpvnpIgPOrq1ByhjIwMAGxtbcs8Ljs7G09PTzQaDW3btuXjjz+mefPmJR5bUFBAQcHdSYyZmZlVF7AgCDWqaFhsuM9wFFLFtkE7Hp7CR/9exTAql075BljId5MDp4aWePjZ4tHUBgdPSwweMMRlaWxAv2ZO9GvmxKJhzQkMS+HXwAgOX09mz5VE9lxJZJi/K/MGNsHDtvr3OHI2c2ag90B23NzBuqvr+OD5j0i+lU16Yi77V19l6Ex/sZJMEEpRZ5bPazQahg8fTnp6eqm7DgOcOHGCGzdu0KpVKzIyMvj88885cuQIV65cwd3d/b7jFy9eXOK+LmL5vFDf1PfPb0JOAgM2D0BGZtfIHbijgPRoyEsDtRLUKjAyB1N7sHACKw+QJKJu5/DhjhCuBCczINcAB402gTKxMqRlTzeadHLG0r5qVk5eT8zi+4Bwtl2MRZbBUE/Byz0bMquPD8YG1Tt/6Ortqzyz/Rn0JX12PbULg3Rz/lx2FnWhhs4jG9JukFe1Xl8Qqlt1LZ+vM4nQK6+8wq5duwgMDCwxoSlNYWEhfn5+jBs3jg8++OC+50vqEfLw8BCJkFDv1OvPrzKHX48u4suYPbTT6LP61i3QFJZ5imxkSbxpE7aluHM9awCN8p1QIGFkpk/n4Q3x6+qKnkH1bK5/OTaDj3eGcDz8NgANHcz45KlWdPAqu7f7Yb2w5wXOJJzRVaW/eiyOQ+uuoVBIjH2nA/buVb+XkSDUlOpKhOpEiY1Zs2axfft2Dh06VKEkCLQFNdu0aUNYWFiJzxsZGWFpaVnsJgjCI0Cjget74M/J8JkPO8L/BeDJ1ERtEqTQBxsvcO8Ant3Buxe4tgGrBsgKA6SCTBxTL+Kd2ZjG+c4okPD1SuX5t5vSopd7tSVBAC3crNjwYid+eL4tDhZG3EzOYewPJ1jy71UKVCVXmq8KE5tNBGDz9c3kFObg19UFb397NBqZg2tD0Kg11XZtQXhU1eocIVmWefXVV9m6dSsBAQF4e3tXuA21Ws2lS5cYMqRuF118XEVGRuLt7c2FCxdo3bp1tV5r8eLFbNu2jYsXL1brdYRqpiqAixvh5HeQch2AGwYGXDcyRB+JAU8sA68eYN0AFPcPN+0Ijufdv87jURDNEzn2GBXaoYeSnpYraZZ/AH62hM6vQLfXwLD6VnhJksSgFi50aWjPRzuv8sfZGH49FsGpiNt8M64NDR2qvnemp3tPvCy9iMyMZPP1zUxqPole45oQdyOd5OgsLu6/RduBnlV+XUF4lNVqj9DMmTNZv349GzduxMLCgoSEBBISEsjLy9MdM3HiRBYsWKD7ecmSJezdu5ebN29y/vx5nn/+eaKionjxxRdr4yUID+Dh4UF8fDwtWrSo0nYlSWLbtm3FHnvzzTc5cOBAlV5HqEGyDFe2wbcdYPscbRJkZAmdZ7Cz+0sAdPfohVXbiWDrfV8SVKBSs+jvy8zceJ6sfOis8sOo0A4DYz2GvepPs3FPgVMLKMiEw5/A/3WGG/uq/WVZmRrw6Rh/fpnUHhtTA67EZTL0m0C2XYit8mspJAWTm08GYM2VNRSoCzCzNqLbmMYAnP43grSEnCq/riA8ymo1Efr+++/JyMigd+/euLi46G6bNm3SHRMdHU18fLzu57S0NF566SX8/PwYMmQImZmZHD9+nGbNmtXGSxAeQE9PD2dnZ/T1q7/z0dzcHDs7u2q/jlANUsJg1RD4cxKkR4G5MwxcCnOvohn4ETuTzwPwZMMnSzw9NUfJ8z+fYs2JKCQZZpvZYJ2twcBYjxFz2uDW3AXajIdpR2Hsau1E6oxo2DAG9rwL6rLnG1WFvn5O7HqtJ10a2pGrVDNn00U+3H4VVRUPVw1vNBwXMxeS85LZcmMLAE27ONOgmS1qlYajm65TR6aGCkKdUKuJkCzLJd4mT56sOyYgIIDVq1frfv7yyy+JioqioKCAhIQEduzYQZs2bWo++DpGo9Hw6aef4uPjg5GREQ0aNNCVz7h06RJ9+vTBxMQEOzs7Xn75ZbKzs3XnTp48mZEjR/L555/j4uKCnZ0dM2fOpLDw7pfDd999R+PGjTE2NsbJyYkxY8aU69qRkZFIklRsuOry5csMHjwYc3NznJycmDBhAikpKbrne/fuzezZs5k3bx62trY4OzuzePFi3fNeXl4AjBo1CkmSdD8vXry42PCbRqNhyZIluLu7Y2RkROvWrYvtXRUQEIAkSaSnp+seu3jxIpIkERkZCUBUVBTDhg3DxsYGMzMzmjdvzs6dO4udf+DAAdq3b4+pqSldu3YtttknwN9//03btm0xNjamYcOGvP/++6hU2qKcsiyzePFiGjRogJGREa6ursyePbtc73u9oNHAye/hh+4QfRz0TaDX2zD7PHSZAUYWBCUHEZcTh6m+Kb3de9/XxM3kbEZ/d4wzkWlYGOuzrGkD9OPyUehJDJneEieve+YFKhTQfBTMOAmdpmsfO/EtrBmuXX1WzZytjFn/YidmPaEtf/FzYASTV50hLUdZZdcw0DPghRYvAPDr5V8pVBciSRI9x/mi0Je4FZJGRFDKA1oRhMdHnZgsXZfJsowmN7dWbhX5q23BggUsW7aM9957j6tXr7Jx40acnJzIyclh4MCB2NjYcObMGf7880/279/PrFmzip1/6NAhwsPDOXToEGvWrGH16tW6BPTs2bPMnj2bJUuWEBoayu7du4tteFnatUuSnp5Onz59aNOmDWfPnmX37t0kJiby9NNPFztuzZo1mJmZcerUKT799FOWLFnCvn3aYYwzZ84AsGrVKuLj43U//9eKFStYvnw5n3/+OcHBwQwcOJDhw4dz48aNcr+vM2fOpKCggCNHjnDp0iU++eQTzM2Lz+149913Wb58OWfPnkVfX58XXnhB99zRo0eZOHEir732GlevXuXHH39k9erVukTxr7/+4ssvv+THH3/kxo0bbNu2jZYtW5brfX/k5aTA+lGw+21Q5UHD3jDrDDyxoNjcnR03dwDQz7MfxvrFV8Odi0pl9PfHibydi7uNCSv7NyfldDIAT0xoinvTUlZpGZnD4E/gmQ3a4bfo4/DrIMiIqZaXei89hcSbA5vw3fi2mBrqERiWwvD/CyQ0IevBJ5fTqMajcDBxICEngb/D/wbAysGU1v0aAHBs8w1UhdU3aVsQHinyYyYjI0MG5IyMjPuey8vLk69evSrn5eXpHlPn5MhXmzStlZs6J6dcrykzM1M2MjKSf/rpp/ueW7lypWxjYyNnZ2frHtuxY4esUCjkhIQEWZZledKkSbKnp6esUql0x4wdO1Z+5plnZFmW5b/++ku2tLSUMzMzK3RtWZbliIgIGZAvXLggy7Isf/DBB/KAAQOKHXPr1i0ZkENDQ2VZluVevXrJ3bt3L3ZMhw4d5Pnz5+t+BuStW7cWO2bRokWyv7+/7mdXV1f5o48+uq+dGTNmyLIsy4cOHZIBOS0tTff8hQsXZECOiIiQZVmWW7ZsKS9evLjE11Z0/v79+3WP7dixQwZ0n6G+ffvKH3/8cbHz1q1bJ7u4uMiyLMvLly+XfX19ZaVSeV/7Zb3vJSnp81tnxZyT5eXNZHmRpSx/6CzLp3+SZY3mvsOUaqXc/bfucovVLeRjMceKPXc8LEX2e2+X7Dl/uzz820A5OjZT/vmNI/K30w7Ih9aHlD+WhMuy/HlTbSxf+ctyRtxDvrjyC4nPkHt8clD2nL9dbrFwt3wsLLnK2l57Za3cYnULeeDmgbJSrf18FeQVyqvmHZW/nXZAPrsrosquJQg1oazv74cheoTqgZCQEAoKCujbt2+Jz/n7+xer3datWzc0Gk2xIZzmzZujp3d38qmLiwtJSUkA9O/fH09PTxo2bMiECRPYsGEDubm5D7x2SYKCgjh06BDm5ua6W9OmTQEIDw/XHdeqVati590bT3lkZmYSFxdHt27dij3erVs3QkJCyt3O7Nmz+fDDD+nWrRuLFi0iODj4vmPujdXFxQVAF2tQUBBLliwp9npfeukl4uPjyc3NZezYseTl5dGwYUNeeukltm7dqhs2K+t9f6QF/6ntfcmMAdtG8NJB6PCitrbFf5yIO0F6QTp2xnZ0dLlbUiPwRgpTVp8mV6mmR2N7fnuxE5f/jSQ/uxA7d3O6P924/PE4NYepe8HaE9IiYO1wyLldFa/0gZo6W/LPrG509LIlq0DFpF9P8/fFqplEPcZ3DLbGtsRmx7LzpnY419BYny6jtcNyZ3dFkZNRUFYTgvBYqFMlNuoiycSEJufP1dq1y8OknMeVxcDAoPi1JQmNRjuJ08LCgvPnzxMQEMDevXtZuHAhixcv5syZMxW+dnZ2NsOGDeOTTz6577miJOJB8VQVhUL7d4B8zxDkvfOiAF588UUGDhzIjh072Lt3L0uXLmX58uW8+uqrJcZaVIuqKNbs7Gzef/99Ro8efd/1jY2N8fDwIDQ0lP3797Nv3z5mzJjBZ599xuHDh8t8362travsfagxsgyBX8CBJdqfmwyBUT+AsVWpp+yJ3APAAK8B6Cu0v66O3khm6pqzKFUa+jR15LvxbbkVlMLNC8koFBL9JvuhX9FdnK09YNK/sGqwdrXapvEw8W/QN6rUS72XKi2N7IDD5AQGUnDzJqqEBNDTQ8/cHKOmTTFt24Zfhw9g/iEjdlyK57XfL5KQkc/LPRs+VEFpE30TJjWfxJfnvuT7oO8Z4j0EAz0DfDs6EXwohqTITM7tiqLns74P/RoF4VEmeoQeQJIkFKamtXIr7y/Bxo0bY2JiUuLScT8/P4KCgsjJubtk9tixYygUCpo0aVLu90FfX59+/frx6aefEhwcTGRkJAcPHizz2iVp27YtV65cwcvLCx8fn2K3e3utHsTAwAC1uvQ5DpaWlri6unLs2LFijx87dky3wtDBwQGg2KrEkvYg8vDwYPr06WzZsoU33niDn376qdxxtm3bltDQ0Pteq4+Pjy4RMzExYdiwYXz99dcEBARw4sQJLl26BJT+vj9yNGrY8cbdJKjLLO38nDKSIKVayaHoQwAM9BoIwMVb6Uxbdw6lSsPA5k788Hw7FGqZwD+0877aDvbE3t2icjHaeMKErWBkBdEn4J/Z2uStkgpuRhD3zruE9epN/IIFZO7YQUFICOq0NNQpKSgjI8navZvEj5dyq19f3j6xijmNtAnc0l3X+GhHyEOv7nq2ybPYm9gTmx3LH9f/ALS/07qMbAjAlaOxZKbkldWEINR7okeoHjA2Nmb+/PnMmzcPQ0NDunXrRnJyMleuXGH8+PEsWrSISZMmsXjxYpKTk3n11VeZMGFCqROa/2v79u3cvHmTnj17YmNjw86dO9FoNDRp0qTMa0+dOvW+tmbOnMlPP/3EuHHjdKvCwsLC+P333/n555+LDc+VxcvLiwMHDtCtWzeMjIywsbG575i33nqLRYsW0ahRI1q3bs2qVau4ePEiGzZsAMDHxwcPDw8WL17MRx99xPXr11m+fHmxNubMmcPgwYPx9fUlLS2NQ4cO4efnV64YARYuXMjQoUNp0KABY8aMQaFQEBQUxOXLl/nwww9ZvXo1arWaTp06YWpqyvr16zExMcHT07PM9/2RolbB3zMgeBMgwaCl2g0NH+Bk/EmyCrNwMHGgjWMbwpOzmbLq7nDYN+PaYqiv4MS/N8nNVGLlYEL7h62n5dAEnl4N68dA8O/g3h46vlShJtTZ2aR88y2pGzbAnWFOo6ZNMX+iNyatWmHg6gqyjOr2bfIvXyH70CHyLl4ke/9+Bh44gH+PQcyw6MbPgREUqDS8P7w5ikoWTDU1MOUV/1f44OQHrAxeyUifkZgZmOHe1Bb3pjbEXEvj9PYI+k0W248Ijy+RCNUT7733Hvr6+ixcuJC4uDhcXFyYPn06pqam7Nmzh9dee40OHTpgamrKU089xRdffFHutq2trdmyZQuLFy8mPz+fxo0b89tvv9G8efMyr12Sol6a+fPnM2DAAAoKCvD09GTQoEG6HpLyWL58OXPnzuWnn37Czc1Nt9z9XrNnzyYjI4M33niDpKQkmjVrxj///EPjxtr5IwYGBvz222+88sortGrVig4dOvDhhx8yduxYXRtqtZqZM2cSExODpaUlgwYN4ssvvyx3nAMHDmT79u0sWbKETz75BAMDA5o2barbANTa2pply5Yxd+5c1Go1LVu25N9//8XOzu6B7/sjQV0IW16GK1tA0oPRK6Fl+bYAKBoW6+fZj+QsJRN/OU1abiH+7lb88Hw7DPUVZCTncvHALQC6j21cNWUzGvWBAR/Anne0N/cO4Nq6XKfmnjtH3Lz5FMZq5/mY9+qF/SvTMSllV3Xzbt2wn/YyBTdukPzt/5G1Zw/OR3bxm/153m7+NOtOglKl4ePRLdGrZDI0qvEo1l5dS1RmFGuvrOWV1toktPOIRmy+dpbQUwm0GdAAO1dRh0x4PNWZoqs1payibfW6aKVQ79W5z69KCZunwLXtoDCAsavAb1i5Ti1UF9Lrj15kKbP4oe/PfPq3iqBb6Xjbm7F5ehfszLVzd/b8dJmwc0k0aGbL0Ff9H2pOTTGyDL8/B6E7wbYhTD8GhqZlHC6TunoNSZ99BhoNBq6uOL+/GPMePSp02ZxTp4l/5x0KY2PR6BuwotVo9jbowKg2bnw2phX6epVL9PZE7uHNw29iqm/KztE7sTPRbjy664dL3LyYTKM2Dgya1rJSbQtCTanXRVcFQahn1IV3kyA9I3h2Q7mTIIAT8SfIUmZhZ2zHthOGBN1Kx8rEgNVTOuiSoJSYbMLOaVfndRntU3VJEGhXsI38DixcIfUmHPqo1EM1BQXEL3iHpE8+AY0Gy+HD8P7n7wonQQBmnTri/fffWPTvh0JVyOvnN/Hc9f1sPR/DW5uD0Wgq93frAM8BtLBrQa4ql5XBK3WPdxymre8YfiGZ1DhRekN4PIlESBCEqqXRwLYZd5Ogcb+B78AKNbE3ci8AHkad+PNcHAoJvhnXBk+7uxPqT/97EwCfdo7Yu1fDsI6JDQxbob1/4v8g+tR9h6gzM4me8gIZ27aBQoHTOwtw/eQT9MwrH4+euRluK1ZgN30aABOu7uaFkJ1sPR/Don+uVGoCtSRJzGk3B4A/Qv/gZrr2vbNzM6dha+2igXN7IisdsyA8ykQiJAhC1ZFl2PkGXPoDFPrw9BrwKd8eU0UK1YUcvKVdGXfqkjsAbw9uSk9fB90xydFZRASlIEnQYah31cX/X74DwP85QIa/Z0Lh3RVWqpQUoiZOIu/8eRQWFnj8tBLbiROrpGdKUihwnDMHx/nzARh7/RDP3jjAupNRfLYn9AFnl6yTSyd6e/RGJav49MynuoSq3WBtNfobpxPJSK4H+1QJQgWJREgQhKohy7BvIZz9FZBg1I/QZHCFmzkZf5IsZRaS2gJljhfD/F15qUfDYsec3xsFgE97J2xdyr/tQqUM+lhbBPb2DTjyGQCFcXFEjX+egmvX0LO3x3P9Osz/s3lnVbCbMhmnd94BYNLV3QyMPMV3AeH8fPRmpdp7q/1bGCgMOBZ3jCMxRwBw9LSkQXM7ZBnO74mustgF4VEhEiFBEKrG0c/h+Nfa+8NWlHt12H8VDYsVZDanga05S0e3LNbLkpGcR/iduUFtB3o+XMzlYWIDT97ZVuH4NxRcOELk+OdRRkVh4OqK1/p1GFfjlga2EydgN007TPZa0F90jr/MRztD2HMlocJtNbBswIRmEwD49MynKNXaYq/t7/QKXTsRT1ZqfhVFLgiPBpEICYLw8E7+AAc/1N4f+DG0m1SpZgo1heyO3A+AnNWKr8e1wdyo+C4fQfujkWVo0Ny2euYGlaTpk9CoD/kpGqKmzkQVH49hw4Z4btyAoZdXtV/eYc5rWI8dgyRreOfCb3hkJDDn94sEx6RXuK2XW72MvYk90VnRrA9ZD4CLjzWuja3RqGUuHar+wrOCUJeIREgQhIdzYQPs1s5lofcC6DKz0k39G3qEfHU2GpU5r3YbQGsP62LP5+cUEnJcuxN4mwE10BtURJLIdZlA1EF71LkqjBt54Ll+HQbOzjV0eQnnRYsw7dIZA2UBS8+vQ5GTzdQ1Z4lLr9jO0GYGZsxpOweAH4N+JDk3GYA2/bWV6a8ExqHMV1Vp/IJQl4lESBCEyruyDf6Zpb3fZRb0ml/ppjQamS+P/wWAHW2Z0fv+GljXTsSjKtRg526Om691pa9VUVmHDhH9xhI0hQpM7Ato8EQK+pY1uwGhpK+P2xdfYODqim16Iu9f+YOUzDxmbDiPUlWxOnzDGg2jlX0rclW5fHFOu7mqZws7rJ1MUeapdMmmIDwORCIkCELl3NgHf70IsgbaToQBH5ZYQb68fjsdRSoXAHi961P37aQsa2QuH9Hu2Nyyl1vV7htUhvRt24iZ9SpyQQHmPbvR4EkFetnhcH5NjVz/Xvo2Nrh98zWSkRHNoy4xIeIwF2+l8/HOkAq1o5AUvNPpHSQktt/czrnEc0gKCf++HgAEH7xV6T2LBOFRIxIhQRAqLjIQNj0PmkJoPhqGfvVQSVBCRj7LDu5BoZ+NoWTKUN/7NyOMCU0jIykPA2M9GncoX528hyHLMrd/+YX4txeAWo3ViBG4/9/3KPre6fU6/AkUZFd7HP9l0rw5zgvfA+DZK7vxTYtm9fFI/g2Kq1A7ze2b85TvUwB8fOpjVBoVTTo7Y2SmT2ZKPhFByVUeuyDURSIREgShYmLPwcZnQZUPvoO09cMU5SuWWxJZlvnftksUGF0CoI9nLwz0DO477vJhbW9Q007OGBpXb5lETX4+cfPnk/TZ5wDYTpqEy9KPkQwMoN1ksPGGnGQ4+V21xlEaq9GjsRg0CEmt5qOrf2KsKuDtv4K5mVyxxOy1Nq9hZWTF9bTrbArdhIGhHi16ugEQtP9WdYQuCHWOSIQEQSi/xKuw/ilQZoFXDxi7GkpIWipi9+UE9ockYmB5BYC+nn3uOyY7rYCI4BQAmvdye6jrPYgyJoao8c+T+c+/oKeH07vv4vj2fKSiosB6BtDnf9r7x76GnJRqjackkiTh8v5i9J2dMU+O573I3eQo1bzxZxAqdfnnC1kbWzO7zWwA/u/C/3E77zYte7uj0JOID88gMSKzul6CINQZIhGqJwoKCpg9ezaOjo4YGxvTvXt3zpw5A0BAQACSJLFjxw5atWqFsbExnTt35vLly8XaCAwMpEePHpiYmODh4cHs2bPJyblbf8jLy4uPP/6YF154AQsLCxo0aMDKlXfrFkVGRiJJElu2bOGJJ57A1NQUf39/Tpw4UaHrfPfddzRu3BhjY2OcnJwYM+bufjSbN2+mZcuWmJiYYGdnR79+/YqdK1Sj2+GwbiTkpYFbe23pDAOTh2oyT6nmwx0hKAyTUBimYKAwoLtr9/uOuxoYi6yRcfGxqrYq6bJGQ9qffxIxfAT5V66gZ21Ng19+wXbC8/fPR2o+GpxbaRPCo8urJZ4H0bOywvWTT0CSaHv5KD1Tr3MhOp2VFdxs8anGT+Fn60dWYRZfnf8KMysj3dBj0AGxwaJQ/4lE6AFkWaawQF0rt4rUFJo3bx5//fUXa9as4fz58/j4+DBw4EBSU1N1x7z11lssX76cM2fO4ODgwLBhwygsLAQgPDycQYMG8dRTTxEcHMymTZsIDAxk1qxZxa6zfPly2rdvz4ULF5gxYwavvPIKoaHFt/x/9913efPNN7l48SK+vr6MGzcOlUpVruucPXuW2bNns2TJEkJDQ9m9ezc9e/YEID4+nnHjxvHCCy8QEhJCQEAAo0ePrlTtJaGCMmJh7UjITgTH5jD+TzCyeOhmvw8IIzY9D1uH64C2DIS5YfFER9bIXDuh3TywaNimquVdvEjUuOdIeG8hmtxcTNq3w/uvzZh17lTyCQoF9FusvX/mF8is2PycqmLWqSO2k7R7Nr15eSumhfl8ue861xLK35Ojp9DjnU7a3au3hW3jYtJF3aTp8PPJ5GQUVH3gglCHSPJj9i2SmZmJlZUVGRkZWFpaFnsuPz+fiIgIvL29MTY2BqCwQM3K1w7XRqi8vKIXBkYPnnuRk5ODjY0Nq1ev5rnnngOgsLAQLy8v5syZQ4cOHXjiiSf4/fffeeaZZwBITU3F3d2d1atX8/TTT/Piiy+ip6fHjz/+qGs3MDCQXr16kZOTg7GxMV5eXvTo0YN169YB2iTR2dmZ999/n+nTpxMZGYm3tzc///wzU6dOBeDq1as0b96ckJAQmjZt+sDr7Ny5kylTphATE4OFRfEv2vPnz9OuXTsiIyPx9KzBPWQeESV9fqtEZjysGQq3w8C2EUzZBRYPP1k56nYO/b88glKloVm7VdzKDWVRl0WM8S2+I3Xs9TS2fXEBQyMFTz9jgpSZjiY3F8nIEIWpKXpWVhi4uaHv4HB3+KocNPn5ZB8+QtrGjeSe0hZUlUxNcZg5E9vJk5D0HvD/nizDqsEQfQI6ToMhn1b4PagKmrw8bo4YSWF0NEFt+vC25xD8XCz5e2Y3DPXL/368d+w9toVtw8/Wj9+e/I1tn18k4WYGHYd50+HJaqznJgjlVNb398Oo3hmHQo0IDw+nsLCQbvfUOjIwMKBjx46EhITQoUMHALp06aJ73tbWliZNmhASol12GxQURHBwMBs2bNAdI8syGo2GiIgI/Pz8AGjVqpXueUmScHZ2JikpqVg89x7j4uICQFJSEk2bNn3gdfr374+npycNGzZk0KBBDBo0iFGjRumG2fr27UvLli0ZOHAgAwYMYMyYMdjY2Dz0eyiU4t4kyMoDJv5dJUkQwAfbr6JUaejooyAkNxQJid4evXXPy7JM7okTXNh0E3DFLvIocS9sLLU9ydAQA1dXDDw8MHB2Rt/JCX0nR/RtbYsaRJ2RgTImhvzgS+RduIAm906RUX19rIYPx+G11zBwcizfC5Ak6P02rB0B51ZD9zlg6VqZt+KhKExMcPngA6InTcL/wkG62jbjOF78dPQmM5/wKXc7c9rO4UDUAUJSQ/jrxl/49+pJws0MrhyNo90gTxR6YgBBqJ9EIvQA+oYKXl7Rq9auXVOys7OZNm0as2fPvu+5Bg0a6O4bGBSfGCtJEhpN8cmZ9x5TNLei6JgHXcfQ0JDz588TEBDA3r17WbhwIYsXL+bMmTNYW1uzb98+jh8/zt69e/nmm2949913OXXqFN7e4i/WKlcsCWoAk7eDtUeVNH3kejL7Q5LQV0h0908k5Cr4O/hjb2KPLMtk7thJyv/9H3lRMcR0XQr64Jx0BgMPD/SdHFGYmCIrlWhyc1GnpVEYH4+sVKKMjEQZGVnuOPRdXbAaMgSb557DwLUSSYx3L2jQRdsrFPhVrfUKmXXqiPWzz5D++ybmXdnK2A6v8s3BGwz3d8XD1rRcbdiZ2DGzzUyWnV7G1xe+5u+h/TCxMCAnvYDI4Ns0bONQza9CEGqHSIQeQJKkcg1P1aZGjRphaGjIsWPHdENGhYWFnDlzhjlz5uiOO3nypC6pSUtL4/r167qenrZt23L16lV8fMr/F2RllOc6+vr69OvXj379+rFo0SKsra05ePAgo0ePRpIkunXrRrdu3Vi4cCGenp5s3bqVuXPnVmvcj52SkiCbqhmOVGtklu66BsDELl5cStsKQJ8GfSgICyPu3XfJDwoG4LZHN9T6JpibQ6f9v6NnVvKXuqxSUZiQSGHMLQpjYihMSESVlIQqMRF1erruOIWFBQYuLhg1bYJpmzYYNW1aoeG0+0iStqzI2uG12isE4PjGG2QdOIBRQiyzU8+w3KEL7/97lZ8ntS93G880eYYtN7ZwPe063176hgHdnuf87iguHY4RiZBQb4lEqB4wMzPjlVde4a233sLW1pYGDRrw6aefkpuby9SpUwkKCgJgyZIl2NnZ4eTkxLvvvou9vT0jR44EYP78+XTu3JlZs2bx4osvYmZmxtWrV9m3bx/ffvttlcX6oOts376dmzdv0rNnT2xsbNi5cycajYYmTZpw6tQpDhw4wIABA3B0dOTUqVMkJyfrkjmhimTGw+onITW8ypMggG0XYgmJz8TCWJ/J3R0Z8e9ZkGV6nM4lYsUY5IICFKam2L38EjfyOkBoBk17eZWaBIG2/IShuxuG7tW7tL5E3j2hQVeIPg6BX8KQz2o+BkDPwgKnefOIe2se/c5uZ+MTfuwPgUPXkniiafmG+/QV+rzT6R0m757MX9f/YmjXUbAHYq6lkZaQg42zWTW/CkGoeWLQt55YtmwZTz31FBMmTKBt27aEhYWxZ8+eYvNnli1bxmuvvUa7du1ISEjg33//xdDQENDO6zl8+DDXr1+nR48etGnThoULF+JameGCMjzoOtbW1mzZsoU+ffrg5+fHDz/8wG+//Ubz5s2xtLTkyJEjDBkyBF9fX/73v/+xfPlyBg8eXKUxPtbuTYKsqz4Jyi9Us3yvdpXhjN4+BKedRKMuZG6ABYWffotcUIBZ9+403LULk3FTiLmeAUCTTjVT3LRSiuYKgbZXKCO21kKxHDoU0/btoaCAD2L3AfDRzpAK7S3UzqkdQxsORUbmi+uf4NnCDkBX3kQQ6huxauwe1bbqppYFBATwxBNPkJaWhrW1dW2HI1STh/78ZsTCmmF3k6BJVZsEAfx4OJylu67hYmXMoTd7s+jwW7T8ajftwmSQJBzffAPbKVOQFAqCDtwi8M8bODe05Kl55R/eqRWyDKuGaHuFanEFGUB+6HUiRo8GtZplvadz2NqHD0e24PnO5f+3TM5NZti2YeQU5vCO68ek/mWGoYk+k5d1q/NTBYT6q7pWjYkeIUEQIP0WrB5SrUlQeq6S/zsUBsDc/r4o1AW0XbGPdmEyspEh7t98jd3Uqbo5O2HnEgHwaV/9dcUemiRB7zs1yM6thqyEWgvFuIkvts8/D8BrIf9goFbx5b7rZOUXlrsNB1MHXvF/BYAfbn+Ohb0RyjwVN84kVkvMglCbRCIkCI+7tChtEpQWCTZeMHlnlSdBAP93KIzMfBVNnS0Y5e9C6OxptLqhQqkPHt9/j0W/frpjs1LzSbiZCRL4tC3ncvba5t0LPDqBukBbeqMW2b86Cz0He0wS45iceIbbOUpWH4usUBvP+T2Hl6UXqQWpZDXW7jB96XCM2MBUqHdEIvQY6N27N7Isi2Ex4X6pEdo5QenRYNtQmwRV0RL5e8Wm57HmeBQA8wc1IeWTT9A/cpZCPTg0uysWXbsWOz7snHZvKlcfa8ysjao8nmohSdBrnvb+2V8hO6ns46uRnrk5jnNeB2DElT2YK3P56ehNMivQK2SgMODVNq8C8Jv8A3oGEim3skX9MaHeEYmQIDyubodrk6CMW2Dno02CrKpn1dW3B8NQqjV0bmiL/9n9pK1fr318mIIm/cfcd3xRIuTT7hHpDSrSqC+4tQNVHhz/plZDsRo5AqMmTdDLyeaVW4fJzFexKjCyQm309+xPC7sWZEip5Hlq/02uiEnTQj0jEiFBeByl3NAmQZmxYN9EmwRZulTLpW6l5vLn2VsAvOWuJHHZMgDWP6HgdDMDuroW7w3KTMkjKTITSYJGj8qwWBFJgl535gqd+blWKtPrQtHTw/GttwB44uphXHJS+DnwJhl55e8VkiSJOe3mALDLVLur941zSeTnlL8NQajrRCJUAjEGLjyKyv25LeoJyooHx2YweUeVlc0oyTcHb6DSyAxy0cdy2UJQqUjr2ox/Okn4O/hjZWRV7HjdsJivDaaWhtUWV7VpPABc/KEwF078X62GYt69G2bduyOpVcwK30dWvopfAyMq1EYnl050celCvOlNCm2yUBdquHYivpoiFoSaJxKhexSVhsgtqj8kCI+Qos/tf8ugFJN+S1sbKzsRnFrApH/BvPp2DI66ncNf52NRyBpmHVuDKikJw0aN+G20DUgSvTzuL19TlAg1bv+I9QYVubdX6PRKyE2t1XAc33oTJIm2N8/RNDWSXwMjKtQrBDCj9QyQ4JTNbgCuHI0TfzAK9YbYWfoeenp6WFtb64qImpqa6mplCUJdJcsyubm5JCUlYW1tjV5pVdOzk7RJUMYtsGsME7aBmX21xvb1gTDUGpm3006jF3wBhakp9l98wvHTEwHo6daz2PGZKXkkR2chSdCw9SNc0qHJEHBqCYmX4OT30OfdWgvFuEkTrEaPIuOvLbx6fRczbabz2+lopvdqVO42Wju2prNLZ86pz9D11ijSE3OJDU3DvaltNUYuCDVDJEL/4eys3cH2vxXVBaGus7a21n1+75OXButG3S2bMXFbtfYEAdxMzmbrhRh80mPoeUxbT8zpvfe4YJqMUqPE1cyVRtbFv4wjgrRzalx8rDGxeASHxYpIEvR6C/6YCKd+hC4zwcS61sJxmD2bzO07aJgQTrukUFYfM+GFbt4Y6pd/UGBaq2lMiZ9CqN1p/BK6cvlInEiEhHpBJEL/IUkSLi4uODo6UlgoJgQKjwYDA4PSe4IK8+G3cZB4GcydtEmQlXu1x/T1gRsYFCp5P3gTklqNxcCBWI0cwZGTHwDQ073nfT2uNy8mA494b1CRpsPAwQ+SQ7RDZEVL62uBgZMTNs89R+qqVUwN3cMMxybsuBTHqDbl/xy0d25Pe6f2XM45il9CVyIuJpOTUYCZ1SOyvYEglEIkQqXQ09Mr/YtFEB4Vsgz/zILoE2BkBRO2gl35h0QqKywpi7+D4ph2dSe2qfHoOzrivHgRAEdijgDaROheeVlK4sPSAfBuXb1DdjVCodD2Cm1+QTtputN0MK66sgAVZffSi6Rv2oR36i26xF/hpyNWjGztVqHh/2n+03gp8SWSLKJwzPIk5Hg87Qd7VV/QglADxGRpQajPApbCpT9BoQ/PrAWn5jVy2RUHwmiaEsnwm8cAcPn4Y/RtbLiedp3E3ESM9Yzp4Nyh2DkRwSnIMth7mGNpZ1IjcVa7ZiPB3hfy0+HMT7Uair6tLTaTtHOzJl3bzbW4dE6E365QG52cO+Fn68clJ20ye+VoLBqNmDQtPNpEIiQI9dWlzXD4E+39oV9Cw941ctkbiVnsvhDNnIt/ICFjNXo05t27AXd7gzq5dMJYv3hh2Ij6NCxWRKEHPd7U3j/+LRRk12o4dlOmoLC0xDMzgR6xQfx09GaFzpckiQnNJnDTNogC/VyyUwuIvlKxZEoQ6hqRCAlCfZQUAv9oyyPQ7TVoO7HGLv1dQDhjrx+kQVYSenZ2OM17S/fc4ZjDwP3DYsp8FbdC0oB6lggBtHhKW74kLxXO/lKroehZWmL3whQAJoTs4XBIAjeTK5acDfIahJ2FDdccTgFip2nh0ScSIUGob/IzYdME7YZ+3r2g76Iau3T07VwuHD3Ps6EHAHD+37vo3alxl5afRnByMHB/IhR9JRW1SoOVgwm2rmY1Fm+N0NO/2yt07GtQ1u4+ZbYTJqBnY4NbTgp9bp3nt9PRFTrfQM+A55o+x1Un7bBn5OXbZN7Oq45QBaFGiERIEOqTosnRt2+ApRuM+VU7PFNDvj90g1fP/4GBrMb8iSewGDRI91xgbCAyMr42vjibFV/mf+9qsXq5d1erp8HaE3JT4NyqWg1FYWaG3YtTAXjm+gE2n4kmv1BdoTbG+I5BaZFNjFUoyHA1MK46QhWEGlGridDSpUvp0KEDFhYWODo6MnLkSEJDQx943p9//knTpk0xNjamZcuW7Ny5swaiFYRHwIX1cPVvUBjA2DXVvmHivRIy8snb/AfNUqOQTUxxXrSwWFJzNOYoAL3ci+8mrVZpiLqk3T+oYZt6NixWRM8AeryhvX9sBRTWbg+KzbPPorC2xj0nhVZhZ9l1uWIlM6yMrBjWcJiuV+jqsXjUak11hCoI1a5WE6HDhw8zc+ZMTp48yb59+ygsLGTAgAHk5OSUes7x48cZN24cU6dO5cKFC4wcOZKRI0dy+fLlGoxcEOqg1AjY/bb2ft/3wKND2cdXsXX/nGbC5R0AOL/1Bgb3bO6o0qgIjAsE7h8WiwlNQ5mvxtTKECev2lteXu38x4GVh7a8yfm1tRqKwswMu8mTAHg2dD8bT0RWuI2nmzxNpM0lcg0yyctUEnGx9grMCsLDqNVEaPfu3UyePJnmzZvj7+/P6tWriY6O5ty5c6Wes2LFCgYNGsRbb72Fn58fH3zwAW3btuXbb7+twcgFoY7RqGHrdFBmg2c36DKrRi+fkpWP068rMFUVUNi0BTbPPlvs+YtJF8lSZmFtZE1L+5bFnisaFvP2d0BS1MNhsSL6htD9de39wC+1G13WIpvx45HMzfHKSsTwxFFCE7IqdH4T2ya0cGpBiOMJAC6LSdPCI6pOzRHKyMgAwNa29G3bT5w4Qb9+/Yo9NnDgQE6cOFHi8QUFBWRmZha7CUK9c/xruHUSDC1g5Pc1Oi8IYPc36+kQfxWVQh/fzz5GUhT/1XIkVrtsvrtbd/TuiU2jkXVlNRr614NNFB+kzfNg4QpZ8XBxfa2Gomdhgd3ECQCMu76fjScjK9zG075PE+J0AhkNsaFppCWU3psvCHVVnUmENBoNc+bMoVu3brRo0aLU4xISEnBycir2mJOTEwkJCSUev3TpUqysrHQ3Dw+PKo1bEGrd7XA4tFR7f/AysPGs0cunxSfjs+lHALLHPo9x48b3HXPkVsm7SSdGaIdVDE30cWtiU/3B1jZ9o7u9Qke/qP1eoQkTkE1MaJQRR+SOfeQpKzZpeqDXQCQLFVE2VwG4IiZNC4+gOpMIzZw5k8uXL/P7779XabsLFiwgIyNDd7t161aVti8ItUqWYfvroC6Ahk9A6/E1HsL5txdjVZBNvI0rHRfMue/52OxYwjPC0ZP06OratdhzRZsoerawQ68CBUAfaW0nalf0ZcbW/m7TNjbYPfccACMv72ZPBSdNG+sbM6LRCN2k6WvH41FVMJkShNpWJ37zzJo1i+3bt3Po0CHc3csuAujs7ExiYmKxxxITE0utum1kZISlpWWxmyDUG8F/QMRh0DeGoV9oq57XoJSAI7ieOogGicLX30bP+P4CnEW7Sbd2bI2VkVWx5yKCtcNi3o/DsFgRA2PovUB7/+hyyM+o1XDsXpiC2sCQpmm3OLdlT4XPf6rxU9yyDiHLKJWCXBVh55OqIUpBqD61mgjJssysWbPYunUrBw8exNvb+4HndOnShQMHDhR7bN++fXTp0qW6whSEuik3Ffbc+ULtNU+7e3EN0uTmcut/CwEIaNaLvk/1LfG40oqspiXkkJ6Yi0JPwrO5XfUGW9f4jwP7JpCXpl1OX4v07ewwHvUUAC0PbSEuvWJL+31sfGhm34yrjscBsdO08Oip1URo5syZrF+/no0bN2JhYUFCQgIJCQnk5d39H3HixIksWLBA9/Nrr73G7t27Wb58OdeuXWPx4sWcPXuWWbNqdpWMINS6Qx9D7m1w8IMur9b45eO/+hrjlESSTKxxnPMa+nr3/zrJLczldPxpAHq6FU+EilaLuTe1wdBEv/oDrkv09KHfnR2/T3wHmRUbkqpqnjOnoVbo0fL2TQ78deDBJ/zH8EbDueZ4Eo2kJuFmJikxFVuBJgi1qVYToe+//56MjAx69+6Ni4uL7rZp0ybdMdHR0cTH3/0l0bVrVzZu3MjKlSvx9/dn8+bNbNu2rcwJ1oJQ7yRdg7O/au8P+VS7NLsG5V26RMa6dQBs6DqOEV19SzzudMJplBolrmauNLJuVOy5otVi3v71dBPFB2kyBDw6gSrvbnHcWmLg5ERmd+1qXP0/NiDLFasoP8R7CIXGedy0DQLg8hExaVp4dNT60FhJt8mTJ+uOCQgIYPXq1cXOGzt2LKGhoRQUFHD58mWGDBlSs4ELQm3b+y7Iamg6FLx7Pvj4KiQXFhL37v+QZA2H3NvQ9blhGJYy0fneYbF7d5nOySggMVK7lYV3q8doftC9JAn6LdbeP78WUm7Uajh+r88AoFVUEBeOBVXoXGtja3q799ZNmr5+KgFlvqrKYxSE6lAnJksLglABN/ZB2H5tGY3+S2r88rd/+RXl9etkGJryR6cxPNOhQYnHybJc6vygyOAUkMHRyxIz6/snWD82PLuC7yBtUrtvYa2GYuPnS2TTdiiQifmh4qvZhjcaTpxlGJmmKRQWqLl+OvHBJwlCHSASIUF4lKhVsOdd7f3O08GuUdnHV7GC8HBSvvsOgB9bjmB0n5aYGJa8eeP1tOsk5iZirGdMB+fi5T7uDos9pr1B9+q/BBT6ELoTwg/Waii2U7XFWL3OHyY7tmLzlrq7d8fG2IZLjtrkN/hQTIWH2AShNohESBAeJcGbICUUTGyh51s1emm5sJC4+W8jK5WccWzCSe8OTOhc+uaNRb1BnV06Y6xvrHtcma/i1rVUQCRCADg0gQ4vae/vXqBNdmtJhyd7c92xEQYaNZe/Xlmhcw0UBgzwGkCowyk0+irS4nO4FZJaTZEKQtURiZAgPCpUSji8THu/++tgbFX28VUs5aefyL98mTwjU1a0eZpnOjbAxqz0SdpFiVAP9x7FHo++kopGJWPpYIKti1m1xvzI6D1fm9wm3zMJvhYoFBIpQ8cCYLz7b9RZFVv9NchrEEr9fK47aVcKBh0QG9gKdZ9IhAThUXF+DaRHg7kzdHypRi+dd+UKKd99D8A3LUaSbmbN1O6l7/uVlp9GULJ2wu1/5wdFBGuXzTf0ty82gfqxZmIDfe4MeR76SLtHVC3p+OxwoiycMCrII3HDbxU6t61TWxxNHTnvuB/QJr2p8aL+mFC3iURIEB4Fylw48rn2fs83wcCkxi6tKSgg/u23QaUi3K8jh9zb8GRLFzxsTUs9JzA2EBmZJjZNcDa7u+u7Wq0h6tJt4DFeNl+atpPBsTnkp0PA0loLo4WHNYfbDAQgZfUaNEpluc9VSAoGeQ0i0/g2ue7aydLBB0WvkFC3iURIEB4FZ36G7ASwagBtJ9XopZO/WkHBjTAkG1vea/gkSBIv9yx7F+ujMUeB+3uD4m+kU5CrwtjcAOdGNTu0V+fp6cOgOwnQmV8gPrhWwpAkCcdRw0kxtsIgPZXMf/6p0PmDvQcDcMR2GwChJxPIzy6s6jAFocqIREgQ6rr8TAj8Unu/9/wa3Twxa/9+UletAuDI8JdIMzCjR2N7WriVnsSoNCoC4wKBEobF7qwW82plj0IhhsXu07AXNB+lXU6//XXQaGoljGHtPNnaSDu3K+mnX5ArEEdzu+a4m7sTaXoVQycNqkINVwJF2Q2h7hKJkCDUdad/hLxUsGsMrZ6tscsqo6KIe1tb3sZ0/PN8masd4npQb9DFpItkKbOwNrKmpX1L3eOyLHMzSDs/6LHdRLE8Bi4FQwuIPQvnV9dKCD6O5kR0HkCWgQnqqEiyAwLKfa4kSQzyHgQS3PLSzhO7dCgGtap2kjpBeBCRCAlCXVaQra1FBdBrvnb4pAZo8vKImf0amuxsTNq25d9Oo8krVNPMxZLuPmUnMUditavFurt1R09xd4+hlJhsslML0DdQ4NHMtlrjf6RZukCf/2nv718M2bVTzX1gx4bs8uoMQOqq1RU6t5+ntlzHXv3NmFoakJOhJOycqEov1E0iERKEuuz8Gm1vkG1DaDG6Ri4pyzIJi9+nIDQUPTs77D/7nFWnYgCY1qvhA1d6lTY/qGhYzKOZLQalbMIo3NHhRXDxh/wM2Pu/WglhmL8r/zbshkpSkHvmDHmXr5T73Ga2zXAxcyFHk41ZG+38oKADt8QGi0KdJBIhQairVAVw/Bvt/W5zQFEzyUP6H3+S8fffoFDg9sUXbLul5HaOEjdrE55s6VLmubHZsYSlh6En6dHVtWux5yKKhsXEJooPpqcPQ78EJO0mmjcP13gIbtYmeDX15rBbawDdXLHykCSJvg36AnDJ4Qj6BgqSo7OIvZ5eDZEKwsMRiZAg1FUXN0BWPFi6gf+4Grlk3qXLJH74IQCOc1/HuEMHfj56E4AXe3ijr1f2r4yiTRRbO7bGyujuhOrM23mk3MpGksCrpUiEysWtnbZnCODf2aCs+f14hrd2ZatPLwAyd++mMK78VeWLhscOJO+lSVcnAM7viar6IAXhIYlESBDqIrUKAr/S3u86u0ZWiqnS0oh97TXkwkLM+/XFdupU9l5JIPJ2LtamBjzTweOBbRyO0fZc3DcsdlE7LObcyAoTi5pb9fbI67sQLN0hLRIOflTjlx/S0oUIGzcu2jcCtZrU9RvKfW5rh9bYGtuSpcxC9r+NpJC4dTWV5OiK7VYtCNVNJEKCUBdd/gvSo8DUHtpOrPbLyRoNcfPmUxgXh4FnA1yXavez+eGItjdoYmdPTA3LnqidW5jL6XhtaYXe7r2LPRd+QTtRtlEbxyqOvJ4ztoRhX2nvn/wObp2p0cvbmxvRuaEdW+70CqX/8Qfq7Oxynaun0KNPgz4ABGYcwqed9t/+/F7RKyTULSIREoS6RqOBwC+097vMAMPSd3CuKinff0/O0aNIxsa4f/01ehYWnI5IJehWOkb6CiZ29XpgGyfjT1KoKcTd3B1vq7vlN3IyCogPzwCgYRuxm3SFNe5/Z2hUhr9naueO1aDBLV0469SUJBtnNNnZpG/eXO5z+zW4MzwWfYDW/d0BCD+XREZybrXEKgiVIRIhQahrwvZpi28aWd6dI1KNso8GkvLt/wHgvHgRxk2aAPDjnd6gMe3csTc3emA7RcNivTx6FVtZdvNCMsjg5G2Jha1xaacLZRn4MZg5QkooHP60Zi/d3AkUCn7z7A5A2tp1yCpVuc7t6NwRCwMLbuffJtb4Jg2a2yHLcGGfKLsh1B0iERKEuqZopVi7SdVeYb4wNpa4N98EWcb6mWewHjkSgNCELA5eS0KS4KUeZW+gCKCRNbqJ0v+dHySGxaqAqS08uVx7P/BLiA+qsUs7WhjTwcuWgx7tKLSwojAujqx9+8p1roGeAT09tJ+H/VH7aTuwAQDXjseTm1n+GmaCUJ1EIiQIdUl8EEQeBUkPOk2v1ktplEpi5ryOOiMD4xYtcHpnge65lXd6gwY1d8bL3uyBbYXcDiElLwVTfVM6OHXQPZ6bqSTuzpLpRm3FsNhDaTYcmo3Ult/YNhPUNVe/a0gLZ5R6Bhxtpp0rdHvV6nLvCVQ0PHYw+iAuPlY4eVuiVmkIEsVYhTpCJEKCUJec0A5R0XwUWLlX66USly4l/9Il9KyscPvqKxRG2uGv+Iw8/gnS1oZ6UDmNIkXDYt3cumGgZ6B7PCIoGVkGhwYWWNqbVPEreAwN+QxMbCHxEhxdXmOXHXxn/6iVtm3A0JD84GDyzp8v17ldXbtioDAgJjuGyMxI2g70BODy4ViUeeUbYhOE6iQSIUGoKzJitavFALrOqt5L/f036b/9DpKE6+efYejupntu1bFICtUynbxtadPAplztBdwKAEoYFjt/Z1hM9AZVDXNHbTIEcOQzSLhUI5d1sjSmvacNGUYWJHXWrgRLXb26XOeaGpjS0bkjoE2YvVvZY+NsijJPxeUjohirUPtEIiQIdcXpH0GjAs/u4Nqm2i6TH3qd+EWLAbCfMQPzHj10z2XmF7LxVDQA03s1Kld7iTmJhKSGICHRw+1uW/nZhcSEpgNiflCVavEUNB2q/axse6XGhsiKeoU2eWknTWftP4AyqnxL4YsS5IBbAUgKiTYDtHOFgg7cQlWorvpgBaECRCIkCHVBQTacXa2932VmtV1GnZ1N7OzZyPn5mHXvjv2MV4o9v/FUNNkFKnydzOndpHy9OEdjtbXFWjq0xM7ETvd4RHAyskbGzs0ca6fq3wLgsSFJ2vIbJrbaHqEaGiIb1MIZgF1Zxhh06w6yTOqateU6t7dHbwAuJl8koyAD347OmNsYkZup5NqJhOoKWRDKRSRCglAXXFgPBRlg2wh8B1XLJWRZJmHhIpRRUei7uOD62adIenfrlxWo1PwaGAHAyz0bPbC4apHDt+4sm3fvVezx8PPa2mJiWKwa/HeILD642i/pZm1Caw9rZBkudxsKQPrWrajT0x94rqu5K41tGqORNRyNPYqevoLW/bS9Qhf2RqFRa6ozdEEok0iEBKG2adTaXYNBu4Gionr+t0zfvJnMnTtBTw+3L5ajb1N8/s/fF+JIyirA2dKY4f6u5WozX5XPyfiTQPFEKD+7kFtXUwFo1FYMi1WLFk+B37A7Q2QzamSIrKjo7qZCR4yaNkXOyyNt0x/lOrfo83HklnabhWbdXTE2MyAzJZ+wO3PJBKE2iERIEGrbte3achomtuD/XLVcIv/6dRI/+hgAx9fnYNqm+BwkjUZm5Z3iqi9098JQv3y/Gk4nnCZfnY+zmTO+Nr66x8POJ6HRyNi5m2Pr8uDl90IlSBI8+UWNriIrGh47FZmK4bjnAUhbvx5Z+eA9gYoSocDYQAo1hRgY6dGqj3Zl5Pnd0eVeji8IVa1SidDNmzerOg5BeHwd/1b73w5Tq6WchiY3l9i5c3XzgmxfeOG+Yw5eSyIsKRsLI33GdWxQ7raLNlHs5V58N+kbZxIB8O3g9JDRC2Wq4SEyD1tTWrlboZHhqHtr9B0dUSUnk7Fj5wPPbWnfEhsjG7IKs7iYdFH7WG93DIz0uB2bTdTl29UauyCUplKJkI+PD0888QTr168nPz+/qmMShMfHrdMQcxr0DKHDS9VyicSly1CGhaPv4IDrJ8uQShh6+/FIOADjO3tiYWxw3/MlkWW5xGrzWan5xIWlA9BYJELV779DZKrq3bF5cAvt8NjOaynYTND2CqWuWvXAHh09hR493LWrCou2WzA2M6B5T+3WDed3i2KsQu2oVCJ0/vx5WrVqxdy5c3F2dmbatGmcPn26qmMThPrvxJ3eoJZPg0XVJw3ZR4+S/uef2v2CPvsMfTu7+445F5XGmcg0DPUUTOnmVe62r6ddJyEnAWM9Y90+MQBhZ5NABhcfK1FbrCbU8BDZkJba4bHj4beRho5CMjWl4Pp1ck+ceOC5unlCd3oSAVr39UChLxEfnqFLoAWhJlUqEWrdujUrVqwgLi6OX3/9lfj4eLp3706LFi344osvSE5Oruo4BaH+SYuEkH+196thybw6M5P4/70HgO3ECZh17lTicSvv9AaNbOOKk2X5E5dDtw4B0NmlM8b6d8+7cfbOsFhH50rFLVTCvUNkRz+v1iEyTzszmrtaotbIHIjJw3r0aEBbduNBurp2RV+hT2RmJJEZkQCYWRvRtLO2l0n0Cgm14aEmS+vr6zN69Gj+/PNPPvnkE8LCwnjzzTfx8PBg4sSJxMfHV1WcglD/nPweZA006gNOzaq8+cSPl6JKTMTQ0xOHOXNKPOZmcjZ7r2oTl/KW0yhyMPogAH0a9NE9lpaQQ3J0FgqFJJbN17QaHCIbcmf12I5L8dhOmggKBTlHj1IQFlbmeeaG5rpadEXDqgBtBjRAkiDq8m1SYrKqLW5BKMlDJUJnz55lxowZuLi48MUXX/Dmm28SHh7Ovn37iIuLY8SIEVUVpyDUL3npcH6d9n6Xqi+nkX34MBnbtoFCgcvSpShMSq7z9dPRCGQZ+vk54eNoUe7247LjCEkNQSEp6OVxd9n89dPapMrdzxYTc8OHeg1CBdXgENngO6vHjoWlkGfnjEXfO2U3yrHBYtHn5d5EyNrRlEbttNssiF4hoaZVKhH64osvaNmyJV27diUuLo61a9cSFRXFhx9+iLe3Nz169GD16tWcL2dRPkF47JxbDYU54NhM2yNUhTR5eSQs+QAA20mTMG1bcrmOpKx8/jofA8C0XhXrDSoaFmvj2AZbY1sAZI3MtZPaXuCmXcSwWK0wd4QnP9fer8YhsoYO5jR1tkClkdkXkojt5MkAZPzzD6rU1DLPLZpYfyHxAlnKu70/RcVYw84lkZ6UWy1xC0JJKpUIff/99zz33HNERUWxbds2hg4diuI/K1EcHR355ZdfqiRIQahX1IVw6kft/S4ztX/JV6GUH3+kMDYWfRcXHGaVPvdozfFIlCoNbRtY096zfMVVixyIPgBAH4+7SVzM9TSyUwswNNHH29++csELD6/56BoZIisaHtt5KR6Ttm0xbtECuaCAtN9/L/M8DwsPvK28Uckqjscd1z3u4GFBg+Z2yDJc2BddLTELQkkqlQjt27eP+fPn4+LiUuxxWZaJjtZ+gA0NDZk0adLDRygI9c2VrZAVB2aO0HJslTZdcPMmt3/5FQDnd99BYVbyZobZBSrWndAOQUzrVf5yGgDp+emcSzwHFJ8fdO24tjeocQcn9A30SjxXqAE1NERWtHrs6I1ksgpU2N75fZ+28Tc0D9hgsaebtlfo3tVjAO0GaXuFrp2IJye9oKpDFoQSVSoRatSoESkpKfc9npqaire390MHJQj1lizD8W+09zu+DPpGVdi0rB0SKyzEvFcvzPv2LfXYTWdukZmvoqG9Gf39KrZsPyAmAI2soYlNE9wttDsDF+SpuHlBu1rUr4tLWacLNaEGhsh8HC1o7GhOoVrmQEgiloMGou/khDolhcwHbLBYNDwWGBuIRr5bZ8y1sTUujazQqGSCDtyq8pgFoSSVSoRK2zgrOzsbY2Oxb4gglCoyEBKCQd8E2t+/w/PDyD5wgNyTJ5GMjHB673+l9vIUqjX8cqecxks9G6JQVGxormi1WN8GdxOtsLOJqAo12Dib4uhV/knXQjVqPhr8ht8ZInulWobIBuuGxxKQDAyweX48AKmrV5e5wWIbpzaYG5iTmp/KlZQrxZ5re6dX6PKRWPJzqr9+miDoV+TguXPnAiBJEgsXLsTU9G45ALVazalTp2jdunWVBigI9UrRBoqtx4HZ/ZsbVpasVJL0mbYHwPaFKRi6u5d67PbgOOIy8rE3N2JUG7cKXSe3MFc3r6PYsNiJBACadnWp0DCbUI0kCZ5crk2+Ey9rh8ieWFCll3iypQtfH7jB4evJZOUXYvP006R89z0FoaHknjqFWefOJZ5noDCgi2sX9kXt40jsEVo6tNQ959nCDjs3M27H5nD5cAzth4hRBqF6VahH6MKFC1y4cAFZlrl06ZLu5wsXLnDt2jX8/f1ZvXp1NYUqCI+45OtwfTcgQeeq3UAxbdMfKKOi0LOzw27qi6UeJ8syPx7W9gZN6eaFcQXn8pyIO0GBugA3czddkdXU+BwSbmYgSdCkk1gtVqf8d4gs8UrZx1eQr5M5DR3MUKo0HLyWhJ6VFdajRgGQunpNmecWDY/9d56QJEm6FWRBB2MoVKqrNGZB+K8K9QgdOqRdMjtlyhRWrFiBpaVltQQlCPXSye+0/20yGOx9qqxZdWYmKf/3fwA4vPoqeualV3s/ciOFawlZmBrq8Xwnzwpfa3/0fkDbG1TU83PlSCwAXq3sMbOqujlPQhVpPhoub4Fr22HHGzBlV5WtVJQkiSEtXPj2UBi7LiUworUbthMnkPbbb2QHBFBwMwKjhiX36HR36w7A1dtXSc5NxsH07gacPu0cOfn3TbJu53P9VALNe1Ss51IQKqJSc4RWrVolkiBBqIicFAj6TXu/istp3F65EnV6OoaNGmE95qkyj/3xsLacxriODbAyLV9x1SIF6gLd/kEDPAcAUKhUc+2kdlisRU/xZVUnSRIMWgYGphB94u7nsIoULaM/FJpEToEKQy8vzHv3BiB1XekbLNqb2NPcrjmgnTR9L4WeglZPaId3gw7GPLCgqyA8jHInQqNHjyYzM1N3v6ybIAj/ceYXUOWDS2vw7FZlzaqSk0ldvwEAxzffQNIvvZP3UkwGx8Nvo6+QeKF7xeddHIs9Rk5hDk6mTrRyaAXAjTOJKPNUWNob4+FnW7kXIVQ/aw/oNV97f+97kJdWZU37uVjgZWdKgUrDodAkgLsbLG7dhjo9vdRzSxseA/Dr5oqBkR5p8Tnculr2Jo2C8DDKnQhZWVnpusKtrKzKvAmCcI/CfDi9Unu/y6wq3UDx9s8/I+fnY+Lvr/srvDQ/3imuOtzfFTfrkktulGVP5B4ABngNQCFpf3UUDYs17+GGVMHVZ0IN6zwDHJpCbgoc+KDKmpUkSbd6bNclbe+gaccOGPn5Iefnk7bpj1LPLUqETsSfoFBdfIWYkYk+ft207QYdFEvphepT7jlCq1atKvG+IAgPEPy79svH0h2aj6yyZgsTE0n7TbuLr/3sV8tcrRV9O5edl7QbHr5UweKqAPmqfAJuBQAw0GsgAElRmSRFZaHQl/DrKvYOqvP0DbWryFY/CWd/hTbjwa1dlTQ9pIUL3weEc/BaEnlKNSaGethOmkj82wtI27ABuymTkQzvrz3XzK4ZdsZ23M6/zfmk83Ry6VTs+VZPeBB8KIboK6mkxudg61L6/DdBqKxKzRHKy8sjN/duLZioqCi++uor9u7dW2WBCUK9oNHACe1EZjq/AnoVm5dTlts/rkRWKjFp1w6zrl3LPPaXwJtoZOjl64CfS8Xn9x2LPUauKhcXMxda2WuHxS7f6Q1q1MYREwtRYPWR4NUdWj0LyLDzLe3nswq0cLPEw9aEvEI1AXeGx6yGDEHfwQFVUhKZe/aUeJ5CUugmTZc0PGblYEJDf+0katErJFSXSiVCI0aMYO1a7SS49PR0OnbsyPLlyxkxYgTff/99uds5cuQIw4YNw9XVFUmS2LZtW5nHBwQEIEnSfbeEhITKvAxBqH439kLKdTCyhLYTq6zZwvh40v/8EwCH2bPL7A1KzVGy6az2S6SixVWLFA2LDfQaiCRJ5GUpuX5KW2m+RS8xSfqR0n8JGJpD7Dm4vLlKmixaPQaw87L297FkaIjN+OcASF1V+gaLZc0TAvDvq500HXoygfxsscGiUPUqlQidP3+eHj16ALB582acnZ2Jiopi7dq1fP311+VuJycnB39/f/7vztLf8goNDSU+Pl53c3R0rND5glBjijZQbDcJjKtupeXtX35FLizEtGNHzDp1LPPYtSciyS/U0NLNii4NK76JY54qj4CYAODusNjlI7GoVRocPS1waSTmBT5SLJygh3ZzXPYvBmXVVHovmid0ICSR/ELt3j/WzzyDZGRE/tWr5J09W+J5XVy7oC/pE5kZya3M+3t9XHyscWhggbpQw5XA2CqJVRDuValEKDc3FwsL7Tb6e/fuZfTo0SgUCjp37kxUVFS52xk8eDAffvgho+5swFVejo6OODs7624KRaVehiBUr7gLEHkUFPrQaXqVNatKSyN9s/YveftXym43T6lmra64asNK7fp8NOYoeao83MzdaG7XHHWhhkuHtV9I/v08xE7Sj6LOM8GqAWTG3q1995D83a1wszYhV6nm8HVt3Tl9GxusRo4E4PaakjdYtDC0oK1TWwCOxN7fKyRJEq36aHuFLh+JRaMRS+mFqlWpDMLHx4dt27Zx69Yt9uzZw4AB2j1FkpKSamR/odatW+Pi4kL//v05duxYmccWFBSQmZlZ7CYINeL4nd6g5qPBqvSSFxWVtm49cn4+xi1aYFpKCYMim8/dIjVHSQNbUwY1r9yuz/euFpMkietnEsnLVGJuY0SjtqI39pFkYAz939feP/YVZMY9dJOSJDG4hfYztuvOxHwA20naIeHsAwdRlvKH8oOGx3zaOWJkpk92agFRl28/dKyCcK9KJUILFy7kzTffxMvLi06dOtGlSxdA2zvUpk2bKg3wXi4uLvzwww/89ddf/PXXX3h4eNC7d2/Onz9f6jlLly4ttrTfw8Oj2uITBJ30W3Blq/Z+11lV1qwmJ4fUDdp9g+xeeqnM3hiVWsPKO8VVX+zhjb5exf93z1ZmczjmMKAdFpPlu1XBW/Z2R68SbQp1RPNR4NEZCnPhwJIqabJoeGx/SBIFKu3wmFHDhpj17AGyTOq69SWe18NdO9XiTMIZcgvvH6rTN9CjWVdXAC4fjqmSWAWhSKV+i40ZM4bo6GjOnj3L7t27dY/37duXL7/8ssqC+68mTZowbdo02rVrR9euXfn111/p2rVrmddcsGABGRkZututW2LlgVADTv0Ashq8e4KLf5U1m/bnn2gyMjD08sKiX98yj91xKZ5bqXnYmRkytl3l/gDYF7WPAnUBDa0a0sy2GTHX0rgdm42+oYJm3V0r1aZQR0gSDPpYez/oN4i7+NBNtvGwxsXKmOwCFUevp+get7uzwWL6li2oS+iV97b0xt3cnUJNISfjT5bYdvOeriBB9JVUMpKrZl6TIEAlEyEAZ2dn2rRpU2x+TseOHWnatGmVBFZeHTt2JCwsrNTnjYyMsLS0LHYThGqVnwHn7syH6Dq7ypqVlUpSV60GwO7FqUh6pRdMlWWZH+4UV53c1QsTw4oVVy3yT/g/AAxrNAxJkji3Wzu04dfVFWOzqtsKQKglbu2g5Vjt/YMfPnRzCoXEoDvDYzvvGR4z7dIFI19f5Nxc3WrHe0mS9MDhMSsHUxo00+5efvnIww/lCUKRSiVCOTk5vPfee3Tt2hUfHx8aNmxY7FaTLl68iIuL2MxNqEPOrQFllnYXX59+VdZsxr/bUSUmou/oiOXw4WUee/h6MiHxmZga6jGhS8WLqwLEZsdyNvEsEhJDGw4l4WYGsaFpKBQSbQY0qFSbQh3Ue4F2Qn/YPog6/tDNPXlneGzv1burxyRJ0s0VSl2/AVmluu+8okToaOzRUpfat+ilnWsXcjwOlahKL1SRClWfL/Liiy9y+PBhJkyYgIuLS6VXjWRnZxfrzYmIiODixYvY2trSoEEDFixYQGxsrG7Poq+++gpvb2+aN29Ofn4+P//8MwcPHhQbOQp1h0oJJ+/spVWF5TRkjYbbv/wCgO2kSShK2KX3Xj/cKa76XMcGWJtWbrPD7eHbAejo0hFnM2d27A4GwLezMxa2xpVqU6iD7BpBmwlwbpV2rtBDVqdv28AGVytj4jLyCQhNYtCd/YUshw4l6YsvUcXHk7V3L5ZDhhQ7r71ze0z0TUjKTSI0LZSmtvePLni2sMPc1ojs1ALCzifRtLP4I1h4eJVKhHbt2sWOHTvo1u3hikeePXuWJ554Qvfz3LnavS0mTZrE6tWriY+PJzo6Wve8UqnkjTfeIDY2FlNTU1q1asX+/fuLtSEIterKVsiKAzNHaPV0lTWbExiI8uZNFObmWD9TdrsXotM4eTMVAz2JqT0qXlwVtENr/978F4DhjYaTEpNNZHAKSNBuYOV6mIQ6rNc87Tyh6BNwYx/4Dqh0UwqFxDB/V348cpN/g+J1iZDCyAibceNI+fZbbq9eg8XgwcX+iDbSM6KTcycCYgI4EnOkxERIoZBo0dONk9tucikgViRCQpWo1NCYjY0NtrYPX2m6d+/eyLJ832316tUArF69moCAAN3x8+bNIywsjLy8PG7fvs2hQ4dEEiTUHbIMJ+7sydLpZdA3qrKmU9doe0Wtx4xBz9y8zGOLeoNGtHbDxarixVUBglOCicqMwkTfhH4N+nF+dyQAPm0dsXYyrVSbQh1m6QodX9LeP7DkoUtvDPPXTqTfH5JIdsHdYTCbcc8iGRqSHxxM3oWL951XtHqstHlCoJ2fptCTSIrMJCUm66HiFASoZCL0wQcfsHDhwmL1xgThsRdxGBIugb4JtJ9aZc0W3LhBzrFjoFBg8/z4Mo8NS8pm71Vt6YvplSynAfBvuLY3qG+DvuQny9w4p60f1XaQ6A2qt7rP1ZaCSbwEV7c+VFPNXS1paG9GgUrDvqt3SyDp29lhOXwYAKklbLBYNE8oODmYtPy0Ets2tTTE298egKvH4ks8RhAqolKJ0PLly9mzZw9OTk60bNmStm3bFrsJwmOpaAPFNs+D6cP3mBYp2nvFom9fDN3L3phx5ZFwZBn6N3PCx9GiUtdTqpXsjtRuizGs0TBOb78JMjRs44CDR+XaFB4BprbQ9VXt/YBloKn8ZGRJknS9Qv8GFU9WbCdqJ01n7duHMqb4nkDOZs742vgiIxMYG1hq+37dtG1fP5WAqlBMmhYeTqXmCI28s2W6IAh3JIVoV90gaavMVxFVWhoZf/8N3N2htzTxGXlsvaAtfTG9V6NKX/NA9AEyCjJwNHWkUWFzNp8/BxJ0HFq5+UbCI6TTdDjxf9pCwVf/hhajK93UMH9XVhy4wZHryaTlKLEx007aN/b1xaxrV3KOHydt3XqcFrxd7Lye7j25nnadozFHGdZoWIlte/jZYm5jRHZaATcvJuPboXK7pgsCVDIRWrRoUVXHIQiPtqLiqn5Dtatwqkj6H38iFxRg3KwZJu3alXnsr4ERFKplOnrZ0s7TptLX/PO6dp+Xpxo/xdkd2n2DGrd3ws6t7LlJQj1gbKlN5AOWwpHPodlIqGQtRx9Hc5q5WHI1PpPdVxIY1/Hulgu2UyaTc/w46Zs3Y//qrGLz3nq69+TnSz8TGBeISqNCX3H/15RCIdG0qwtnd0QScixeJELCQ6n0horp6en8/PPPLFiwgNTUVEBblT42VlQHFh4zWYkQ/If2fpdXq6xZubCQtDvlNGwnTSxzm4qM3EI2ntKusHyld+UTsciMSM4knEEhKehlMIjI4BQk0Rv0eOk0DQwtIOkKXN/1UE0Nb60dwvrnYvENEM26d8ewUSM0OTm6AsJFWtm3wsrIiixlFsHJwaW27dfFBSSIuZZGRnLeQ8UpPN4qlQgFBwfj6+vLJ598wueff056ejoAW7ZsYcGCBVUZnyDUfadXgloJ7h2hQacqazZzz15USUnoOdhjMXhwmceuPRFJjlJNU2cLejdxqPQ1/7rxFwDd3boTvj8DgCZdXMRKsceJic3dFWSHP9Wuhqykoa20y9tPRtwmKTNf97gkSbq5Qmnr1iOr787z0VPo0c1VuzVLWavHLO1N8Giq7fm8dkJMmhYqr1KJ0Ny5c5k8eTI3btzA2PjuxmpDhgzhyJHSP7iCUO8oc+DMz9r7XauwN0iWdatqbMaNK3MDxewCFb8ciwC0vUGV3eBUqVbyd5h2PtIQozHcCklDoSfRYYhXpdoTHmFdZoKBKcRfhLD9lW7G3caUdp42yDJsDy6erFiNGI6etTWFsbFk7T9Q7DlduY3Ysr9PiiZNhxyPR6OpfMImPN4qlQidOXOGadOm3fe4m5sbCQkJJZwhCPXUhfWQnw42XtD0ySprNu/iRfIvXUIyNMTmmWfKPHb9ySjScwvxtjdjaKvKF0LdH7WftII0HE0cyT5iBkCzbq5Y2lduLyLhEWZmD+1f0N5/yF6h4XdWj/19sfi0CYWxMdbjngUg9c7ecUW6u3VHISm4kXaD+OzSe3sa+jtgbGZATnoB0VduVzpG4fFWqUTIyMiIzBIqCF+/fh0Hh8p3ywvCI0WtujtJuuuroKhcYdOSpN1ZMm85dCj6dnalHpenVPPzUW1x1Rm9G6GnqHxphN+u/QbAaCaTEp2NgbEeHcTcoMdX19mgbwwxpyGy9KXsDzK0lQv6ComgmAzCkrKLPWczbhwYGJB34QJ5wXfnA1kZWeHv4A9oa4+VRs9AQZNO2onSIcfF8JhQOZVKhIYPH86SJUsoLCwEtOO90dHRzJ8/n6eeeqpKAxSEOuvqNkiPBlM7aF32RocVUZiYSOad+nm2D9hAcePpaFKylbjbmDCyjVulr3kl5QoXky9iJJtgck67aWL7wV6YWlauTplQD1g4affEAjj+daWbsTM3opev9g/krReK7xtk4OiI1ZPantTU1cU3WHxQNfoift2085Aig1LIzVRWOk7h8VXpDRWzs7NxcHAgLy+PXr164ePjg4WFBR999FFVxygIdY8sw7EV2vsdp4FB1Q0fpf3+O6hUmLRvh3GzZqUel1+o5sc75TRm9PbBQK/Si0DZEKJdnTY690XyMlRY2BnTqk/ZmzcKj4EuMwEJbuzV7pVVSaPbaj9L2y7E3TeXx3byJAAy9+yhMO7u6rIebtpyG6fiT5Gvyv//9u46vqr6f+D469xcd8OaDUYOGF2CKC0iCKKEKCYmJhbWV/2ZKIKoiIiihGIgiNIh3d0rxrrr9vn9cWCIG7Ld3RHb5/l43McO9577Pp9xFu996s2l+DZyIyDCA5tN5thWMTVDqDm7fnJ6enqycuVKli1bxieffMIjjzzC8uXLWb9+Pa6uro5uoyBce06vg4z9yoTS8ytsHMBmNFKwUFmK7zNm7H+eu3hnKlnFRoI9nRje3v7eoJzyHP5I+gMXkwfeR5oA0GVYNBqt44b6hOuUTxTEndvU8PzO6Xa4MS4AdycNaQXlbEvMu+g1p2bNcOnUCaxW8s5tFwEQ6x1LoEsgBquBHRk7/jN+83O9Qke2pCPXYj6T0DDVOBGy2WzMmTOHwYMH88ADD/DZZ5+xadMmzp49K74AhYbj/FBB27EOLadR9McfWPPy0AQF4d73xkueZ7LY+Gyd0hv0YK9o9Br7k5bFxxZjsVnolz0GmxmCojxo0j7A7nhCPdPtceXj/oVQZN88HCetumIp/ZLdZyq9fr5XqGDRYmylpYAy5aK6w2NNEgLRaFXkp5eSlSQKsQo1U6NESJZlbrnlFiZOnEhaWhqtWrWiRYsWJCcnc/fddzNs2LC6aqcgXDvS98OpNSCpoMvDDgsry3LFJGnv0aORNJfe+H3J7jOcLTTg765nVIdQu69ptBpZeGwhvqWNCEyJBaDbiBi7l+AL9VDjBAjrAjYzbP/c7jDD2irDY38czKDcdHF9MLdevdBFRGArLqZgyYWCr+eHxzambfzPP7T1zhqi2irzkI5sPnvJ8wShKjVKhObOncuGDRtYvXo1e/bs4YcffmDBggXs27ePVatWsWbNGubNm1dXbRWEa8P53qAWw5Rl8w5SvmcvhkOHkHQ6vEbefsnzLFYbM8/1Bj3QMwqnWgxh/XryV3LLc7khdSQgEdMhkKAoT7vjCfVU18eUjzvmgNG+HpeEcG9CfZwpMVr46/DFc3kklQrvccpQcN6331ZssNgpuBM6lY60kjROF57+z/hxXZUepxM7s7CYRCFWofpqlAj98MMPvPDCC/Tu3bvSa3369OH5559n/j/GeAWh3ilIgYNLlOPzvxwcJP+7c0vmhwxG433pWmG/7D1LSl4ZPq467uwUdsnzLsdis/D1wa8Jz2+Jf34Eao2KzrdG2R1PqMdi+4NvDBgLYbd9f+yqVBLD4pW5bOeLA/+T1623ovL0xJySQsnatQC4aF3oENQBuPzwWKNYb9x9nTCVWzi9N9uuNgoNU40Sof3799O/f/9Lvj5gwAD27dtX60YJwjVry0yQrRB1A4TEOyzsxUvmx1zyPJPFxserjwNwX48oXHR21U0GYGXySs4WpdMtRRnSbtM3FA9fsXmiUAWVCro+ohxvnQU2+3pchp1bPbbheDZZxRevBFO5uOA9ciQAed9cSLZ6NFaGxy6XCEkqiWZdzk2aFnsKCTVQo0QoLy+PwMDAS74eGBhIfn5+rRslCNeksjzYfW6vE0f3Bv1zyXxc3CXPW7wrldS8cvzc9IzvGm739WRZ5qsDX9E8sxse5X44u2tp38/+eEID0HoUOPtAYQocs68Ya6SfK23DvLDJlQuxAnjfdSdoNJTt2IHh8GHgwn5Ce7L2UGSqvJHvPzXrrGyueOZYPkU5ohCrUD01SoSsViua/5jAqVarsVgstW6UIFyTdnwF5jIIbAXRfRwWtrpL5g1mK9NXnwRgUu/oWvUGbUrbRFJWKh3OKMVcO90Shc7Z/nhCA6B1hvZ3K8fbZtkdZvi5XqHFO89UmgCtDQrCo18/gIpae6HuoUR6RmKVrWw+u/k/Y3v4OdOoqTfIcFTsKSRUU41+8smyzN13341er6/ydaPR6JBGCcI1x1x+YcVMt8fBgauqqrtk/vttKWQUGQjxdKrV3CCArw5+Rbu0m9FbXPAJca2YaCoI/6nDRGUj0aSNkHEQglrWOMSQNiG88fthjmUWsze1gLZhF8+H87l7PEXLllG4/A/8n3oKbUAAPRv1JLEwkY1nNtI/4tLTM0CZNJ12LJ+jW9LpMDACqRZlZ4SGoUY9QuPHjycgIABPT88qHwEBAYwbN66u2ioIV8++H6A0GzzDoMWtDgtb3SXzZSYLM9cpvUGP3hhTq32DdmXu4mRSCi0zlLkX3UY0QVWLXamFBsSzETS/RTm2cym9p7OWga2UxHvRztRKrzu3aoVzu3ZgNpP/g1L/7vzw2Ka0Tdhk23/Gj2rrj85JTXGugbQTBXa1UWhYatQj9PXXX9dVOwTh2mWzwubpynGXh0GtdVjo6i6Zn7s5iZwSE2E+Loxob3/pC1mW+XTPp3ROvgW1rCGshS9hzS9d1FUQKun0IBz6GfYvgr6v2bWh6MiEUH7ek8bSfem8PLh5pWFen3HjSNu9m4IFC/F74AHaBrbFTetGniGPQzmHaOXf6pKxtTo1TToEcnjjWY5sPkvjppdegSkIYGeJDUFoUI7+DnmnwclL2UnagaqzZL7IYObz9coeKk/0jalVTbFtGds4e7yAyPzWSCroNryJ3bGEBiq0EwS3AYvhwuKBGuoc5UO4rwslRgvL9lde4eXe90a0ISFY8/MpXLoUrUpLl5AuAKw7s+6y8c8P9Z7enY2xXMxbFf6bSIQE4b9cVFz1PtC7OSx0dZfMz96YSGG5mSYBbgyNt7+mmCzLfLr7U7ok3wpAix6N8AkRtQGFGpIkpVcIYPtssNY80ZAkiZEJyo7oVQ2PSRoN3mOVPzry581DlmV6hyr7161JWXPZ+IERHngHuWAx2zi5M7PG7RMaFpEICcJ/Sd4MabtArVeqzDtQ/vc/XHbJfH6piTmbEgGYfFMs6lpM/NyUtonywzr8S0PROqnoODjS7lhCA9fiNnDxg6IzcGyZXSFGtG+MSoIdSfmcyi6p9LrXiOGoXFwwnjhJ6d+b6RXaC42k4WTBSRILE/8ztiRJxHUNAcSeQsLliURIEP7L+d6g+DvBzd9hYW1lZcreQSjzIS5l+pqTlBgtNA/2oH+LILuvJ8syn+38nE4pgwFIGBiJs7vO7nhCA6d1goR7lOOt9i2lD/RwondTpbjvoh2Ve4XU7u54Dh8OQN68b/DQedApuBMAq1NWXzZ+bKdAJJVEZmIReemldrVRaBhEIiQIl5J1BE78CUjQ9VGHhi5Y8jO2wkK0YWG431j1kvmU3DK+3ZoEwPMDmqGqRW/QmtQ16A4G42r2wtVXR+ve9k+4FgRASYRUGkjZrBQitsPIcwWDf9p9BrO18mown7FjQJIo3bAR46lT3BiufK+sTr58IuTqqSe8pbIQ4OgW0SskXJpIhAThUs6vFIsbAr7RDgsrW60Vm8X53D0eSV31Uvh3/zyK2SrTI8aPnrH290aZbWY++/tL4s8qm0B2vy0WTS0KtQoCAB7B0HyocrzjS7tC9GkWgJ+bnpwSE2uOZlV6XRcWhlsf5es2b9639A7tjYTEwdyDpJdcPrk5P2n62NYMbFUkWoIAIhEShKoVpML+hcpxt8cdGrp41WrMqamoPT3xGjasynP2phbw+/50JAmmDLh0yY3qWHJ8CSGH26C16fGPdCO6neOG+IQGruP9ysf9i5USNDWkVasY3l5ZAPD9tpQqz/EZrwwdF/76K14GNW0D2gJKL+flhLfyxdldS1mRiZRDNW+f0DCIREgQqrLlU7BZIKIHNE5waOi8c/txed05GpVz5SKnsizz1vIjANzWtjHNQzzsvlapuZTvNy2habYyt6LnyKZIDtwVW2jgQjtBUCuwlMPe+XaFuLOjskv6hhPZpOSWVXrdpUMH9M3jkA0GChYtpm94XwBWJa+6bGy1WkVsR2VunZg0LVyKSIQE4d9Kc2DXuf1Rejzl0NBlu/dQvncvklaLz513VnnO6iNZbE/MQ69R8dTNsbW63tcHvqbFcWVoITrBn6BIz1rFE4SLSNKFXqEds+2qSh/u60rPWH9kGeZvT67iElLFgoL8+fPpE6zsMr07aze55bmXjX9+eCxpfw7lxaYat0+o/0QiJAj/tvUz5S/ckLYQdYNDQ5/vDfIYegsa/8pDVBarjbf/UHqD7ukeSYhX5R6j6soqy2LNpu00KopBUst0HSY2TxTqQMsRymaj+Ulw8vK9NFUZ2zkcUFaPGcyVkymPgQNR+/thycrCbdMBmvs2xybbWJe67rKxfRu5ERDujs0mc3y72FNIqEwkQoLwT4ZC2H5u4mePpxxaXNWUkkLxKuUXhe/dd1d5zqKdZziVXYq3i5aHbqjdBO0Zu2fQLlEpUBl/YzgevvYnVYJwSToXaHdux/XtX9gVok+zAEI8ncgvM/PHwcpDWCqdDu/RowGlKv1NYcrw2MqUldWKf75X6Mjms5Uq3guCSIQE4Z92fAXGQvBrCk0HOTR03txvQJZx7dUTfZPKvTOlRgsfrToOwGM3xuDhZH9NsxP5Jzi2ORPv8iA0LhLt+4fbHUsQLivhXkBSeoRyT9X47WqVxOhzc4W+21r1pGnvO+5A0ukwHDxI73wlsdmWvo0iU9Fl4zdJCEStUZGbVkp2SnGN2yfUbyIREoTzzOWwdaZy3P1JUDnu28OSm0vBkiUA+E6YUOU5M9aeJLvYSLivC3d1ql3iMm3rJ7RPHQBAlyFN0Ls4rlCsIFTiEwmx/ZTjHbPtCjGqYygalcSu5HwOn62c3Gh8fPAcegsA+p9WEu0ZjcVmYX3q+svGdnLVEhXvB8BRMWla+BeRCAnCeXu+g9Js8AyDViMcGjrvm3nIBgNOrVrh0qlTpdeTc0uZvVEpG/DiwDh0Gvu/Nbemb6V8pwsuZndc/bS06GF/fTJBqLaO9ykf98wHY+WSGZcT4O5Ev3O7p3+3rfKkaaCi/ljxqlUMcu4AwMrk6g6PKSU3ju/IxFLFPCSh4RKJkCAAWM0Xyml0ewzUjutBsRYWkj9fWVrs9+ADVS5ff3PZEUxWGz1i/LipeaDd17LJNj7d9Dmt05UClT2GN0Vdi6RKEKotqg/4RCtDywcW2RVizLlJ07/sSaPYYK70ulNsLK5du4LNRo8tyhDXprRN1Roea9TMGzdvPcYyC4n7cuxqn1A/iZ+QggBw4EcoTAVXf2h76Urw9sibPx9baSn6mBjceveu9PqG49msPJyJWiXxyuDmtdrnZ9npZXjvj0Fr0+Ef6UpUvNg8UbhCVKoLvULbvwQ7JiV3jvKhSYAbZSYrS3anVXmOz93jAZCWrqKFUyRmm7laFelVKolmXc5PmhbDY8IFIhESBJsNNn2oHHd+GLSOW11lKy0l/5t5APg+8ADSv+Ydma02Xv/9MADju0QQE+hu97WMViPfbFhI0+yOAPQc2UxsnihcWW1Gg9YVsg5D8t81frskSRVL6b/ZnITNVjmZcu3eHV1kJLbSUu46rQx3rUhcUa345xOh1CN5FOcZatw+oX4SiZAgHPkVco6D3hM63OvQ0PkLFmItLEQXHo7HgP6VXp+3JZmTWSX4uup4vG9Mra41/8h8mhztgoSKyHa+YvNE4cpz9oLWI5VjO5fSj2jfGHcnDadzSll/PLvS65JKVVF2I2blMSSbzNb0reQZLl9Cw9PfmZAYL5CV+mOCACIREho6mw3W/Z9y3PkhcHJc8mAzGsmdq2yg6Hv/fZWKq+aUGJl2brn80/2a4uls/7ykAkMBy9atI7QwDlQy3YbVbkdqQbDb+eGxI79DYdXDW//FVa9hVIJSlX7O34lVnuM5dCgqT0/ksxkMy2iMVbZWq+QGQFy3c8NjW9LFnkICIBIhoaE78itkH1F6gzo/5NDQBYt/xJqdgyY4GM8hQyq9/v6fxyg2WGgR4sHIcz/47fX53s9pc+pmAFr3DsXTX2yeKFwlgS0gvDvIVtj1tV0hxneNQCXBxhM5nMisvO+PytkZ75FKz9PAHUpV+T8S/6hW7Oi2AWid1BRll5N+ssCu9gn1i0iEhIbr371Bzl6OC20wkPv55wD43jcRSae76PV9qQUs3JkKwKu3tECtsn8uT2pRKrs3nca3PAS1E3QYGGl/wwXBEc73Cu2aCxZjjd8e6uNSsXry681JVZ7jPeYu0GjwOJxKZIbMrsxdZJZevoSGVq+mSfsAAA5tOlvjtgn1j0iEhIarDnuD8n9YgCU7G01IMF4jLt6TyGK18cLPB5BlGNa2ER0ifGp1rY+3T6d9sjL/qPPgJji5is0Thaus2SBwD1H25Tr8q10h7ummJPRLdp+hoKxysVRtYCAe/ZWv+7H7vZCR+Sv5r2rFPr+31sldWZQViUKsDZ1IhISG6Z+9QV0edmxvUGkpuV8oE0X9H34Y1b96g77dmsyhs0V4OGl4YWBcra61L3sfOVttuJo9cfZW06pX41rFEwSHUGsh4R7l2M5J0x0jfWge7IHBbOOH7alVnnN+0nTzffl4F8vVXj0WGOFBQIQHNovM4b9Fr1BDd1UToQ0bNjBkyBBCQkKQJIlffvnlsu9Zt24d7dq1Q6/X06RJE+bOnVvn7RTqocO/XOgN6vSgQ0PnfTcfa34+2rAwPIcOvei1zCIDH/ylTJB+tn8z/N31dl9HlmU+2TST+LM3AtBjeDPUWvG3jXCNaD8eVFo4swPSdtf47ZIkcU93pVdo3pYkzFZbpXOcW7XCuV07VBYb/XbL7M/Zz5niM9WK3/oGpVfo0IY0bFXEFhqOq/pTs7S0lDZt2jBjxoxqnZ+YmMigQYPo3bs3e/fu5YknnmDixIn8+eefddxSoV6x2WD9+d6gSQ7tDbIWF5M7Zw4A/o9MQtJePEz1+u+HKTFaiA/14s5zRSbttTplNU57GqO16fEJc66Y9yAI1wS3AGgxTDm2s/7YkDbB+LnpSC80sOJg1cvdfcYrGywO2KdCa5ZZkVS9XqHo9gE4u2spyTeSuF/sNN2QXdVEaMCAAbz55psMGzasWufPmjWLyMhIPvjgA+Li4njkkUcYMWIEH330UR23VKhXDv8C2UeVpfKdHnBo6Ly532ArLEQXHY3HoIur1687lsWy/emoJPjfsJaoajFB2mwzM3vDtzTL6gJAr5FxYvNE4drT8X7l44EfoTS3xm/Xa9QVZTe+2HC6yuXu7jf2QRsSgnOphZ6HZH4/9Xu1lsVrtGqad1M2ZDywrnq9SEL9dF31o2/ZsoW+ffte9Fy/fv3YsmXLJd9jNBopKiq66CE0YFYLrP2fctzZsb1Blrw88s4N1fo/+shF+wYZzFZe+fUQABO6RdIipHb7FS0+tpiwQwmoUBHexpuQJl61iicIdaJxAgTHg9UIe761K8S4LhE4aVUcSCtky6nKyZSk0VQUYx20Q+ZUwUkO5x6uVuwWPRshSZB2rIDcszUvFCvUD9dVIpSRkUFg4MUFKQMDAykqKqK8vLzK97z99tt4enpWPEJDa7dfi3Cd2/Mt5J4EFz9lkrQD5cz8TKkp1jwO95tvvui1mWtPkpJXRpCHE0/eVLvNDotNxSxZ9yfhBS1AJdP9tqa1iicIdUaSLvQK7fgKbDWv+u7jqqvYYPHzDaerPMdrxHBULi40zpFpkyjz26nfqhXb3ceJyHP1+A6uq/nmj0L9cF0lQvaYMmUKhYWFFY/U1KpXHwgNgKkM1r2jHPd8BvT21/WqFDo5mfwFCwAIfOaZi2qKncgs5rP1pwCYOqQ5bnpNra4158AcWp1QJki36NkIr0CXWsUThDrV8jZw9oHCFDhu33zOiT2iUEmw/ng2R9Ir9+qr3d3xHD4cgIE7ZP5I/AOztXL1+qq0ukFZaXl0WwaG0uq9R6hfrqtEKCgoiMzMizfMyszMxMPDA2fnqnfS1ev1eHh4XPQQGqhts6AkA7zCIGGCQ0NnfTQNLBZce/TAtUuXiuetNplnftyP2SpzY7MA+rcMqtV1Mkoz2LzuEH5ljVHpodPgqFq2XBDqmNYZ2inL3O1dSh/q48LAVkppjC8u0SvkM3YMSBJtT8u4pOWxMW1jtWI3ivXCt5ErFqOVQxtFr1BDdF0lQl26dGH16tUXPbdy5Uq6/OMXjyBUqSwPNk1Tjnu/CBr7l63/W/m+fRSvWAGSRMDTT1302tzNSexNLcBdr+HNYS1rPaF5+o4ZtEvuB0CngVE4u+ku8w5BuAYk3AOSCk6vhezjdoV4oGc0AL/tO8uZ/LJKr+vCwnC7sQ+glN1YemppteJKkkT8TcoKzv1rzmAx13z4Tri+XdVEqKSkhL1797J3715AWR6/d+9eUlJSAGVYa9y4cRXnP/jgg5w+fZpnn32Wo0ePMnPmTBYtWsSTTz55NZovXE82fQTGQghoAa1ud1hYWZbJfO89ADxvvRWnphfm66TklvH+n8cAmDIwjmDP2tX/Opp3lNTNpbiZvNF7qmjdR8x3E64T3uEQO0A5tnMpfavGnnRr4ovVJjNnU1KV5/ic+33R66DMzuNrKTAUVCt2TEIgbt56yopMHN92+TIdQv1yVROhnTt30rZtW9q2bQvA5MmTadu2La+88goA6enpFUkRQGRkJMuWLWPlypW0adOGDz74gNmzZ9OvX7+r0n7hOlGQeqFLvu9UUKn/+/waKFmzhvKdu5D0evwff6zieVmWeX7JfsrNVjpH+XBHh9olLbIs8/GmT2mbpqya7HFbMzRax30eglDnztcf2/s9GCsXUq2O+8/1Ci3YkVJl2Q2XDh3QN49DZ4E+u8zV3lNIrVHR5kble3TPyhRkm6hK35Bc1UTohhtuQJblSo/zu0XPnTuXdevWVXrPnj17MBqNnDp1irvvvvuKt1u4zqyaChaDUhE75ubLn19NNpOJzP97F1D+EtUGXZj/s2hnKptP5eKkVfHOba1rtWcQwN9n/0baFYDO6oRXYz2xHQIv/yZBuJZE3QC+MWAqhn0L7ArRM8aPuGAPykxW5lZRjFWSJHwnKPP/+u+08cfR6tc5a949BJ2zhoLMMrHBYgNzXc0REoQaS9kKB38CJOj/lrKc10Hy583DnJKC2t8P3wcubMyYWWTgzWVHAHjqpqZE+LnW6jpWm5XP1s0hLlOZC3fDyOZItUysBOGK++dS+u1fQjU2PawcQuLhG5ReoTmbEik2VF7l5dG/P6qgQLzKwGfdfhILE6sVW+ekoWVPpezGnr9SLnO2UJ+IREiov2w2+OM55bjdWAhu47DQ5qwscmZ+BkDA5KdQuynJjizLvPjzQYoNFtqEelXUSqqN3079RsjBeFSoadzKk0ax3rWOKQhXRZs7QOcGOccgcYNdIQa2CibK35Uig4VvtyZXel3SavE/1ys0eJuN3078Uu3Yrfs0RqWRyDhdSPrJArvaJ1x/RCIk1F/7foD0vaBzhz4vOzR09ocfYSsrw6l1azyH3lLx/E+701h1JBOtWuLd4a1R17LnpsxcxsLVS4nIbwkqmZ7Dm9W26YJw9Th5KMkQ2L2UXq2SeKR3EwBmb0ykzGSpdI7XiBFY3VwIyYfk3xdjsVU+pyqunnqadVKGuHf+UTnJEuonkQgJ9ZOxGFa/phz3ekYpAOkg5fv2UfjLLwAEvfhCxeaJaQXlvPabUkbjyZtiaRpU+w0bvzk0j2YnegHQvEcI3kG1G2YThKuuw7lJ08eWKwsZ7HBLmxDCfV3IKzXx/bbKw1gqV1f87rwTgF4b8tl0pnp7CgG06x+OpJJIOZRLxulCu9onXF9EIiTUTxs/gJJM8I6ETg86LKxss5Hx1luAslzeuY0y3GazyTyzeB/FRgvtwrwq9jypjZzyHDas2Yt/aSiSTqbz4NrHFISrLqAZRPYE2QY759gVQqNWVcwV+nzDaQxV7P3jN3YcVo2K2LPw9x/Vv46nvwtNOyu9Qjt+r978IuH6JhIhof7JOgKbpyvH/d5y6OaJhb/9hmHfflQuLvhPvrB/1Tdbkth8KhdnrZoPRsbXekgM4LOdnxOfdBMAnQZG4+wuNk8U6onzk6Z3fwNmg10hhrVtTCMvZ7KLjSzcUblnSePvj3aQ8v0T9vsuMkurvz9QwoAIVCqJlMN5oleoARCJkFC/2Gzw+5Ngs0DTQdBsoMNCW4uLyfrgAwB8H3oQbYAy3HYyq4R3/jgKwAuD4ois5SoxgNMFpzm1MQ83kzc6T6lijxNBqBdiB4BnKJTlwn77ltLrNCoe7KWUmJm1/hRGS+VeoYgHHkeWIOGEzF/ra9Ir5EzTLkqv0PalVZf0EOoPkQgJ9cve+ZCyBbSuMOD/HBo6++NPsGbnoAsPx2f8eADMVhuTF+3FaLHRM9afMZ3CHHKtT/6eSZszSmHVXsPjxOaJQv2i1kDnh5Xjvz+xqyo9wO0JoQR66EkvNLCoil4hfVQkpZ2aA2CZ/xM22Vbt2Od7hVKP5HNWrCCr10QiJNQfpTmw8tzqsN5TwMtxvSjlhw6R//33AARNfQWVThmmmrn2FPvPFOLhpOHd4a1rXUsMYEfGDkzbPdDZnPBsrCMmQWyeKNRD7caBkxfknYKjy+wK4aRVM+ncCrLpa05SbqqcUDWZ9AwA7feWsv3gn9WO7eHnTLNuSqHX7UvFXKH6TCRCQv2x8hUoz4fAVtDpIYeFla1WMl59DWw2PAYNwrVrVwB2JefxyZoTALxxa0uCPJ1qfS2bbGPG2tkVmyf2GdVCbJ4o1E96twtlN/6eZtcGiwB3dAijkZczWcVGvt2aVOl17w6dyWnih9YKSV/NqFHshAERqNQSacfyST2cZ1f7hGufSISE+uHUWmVYDAmGTFO63h2kYNEiDAcOoHJzI/B5ZYPGwnIzj/2wF6tNZljbRgyNb+SQa/2R+AeB+1qhQk2jlh6ExIjNE4V6rOMDoHGCtF2Q/LddIXQaFY/3jQHgs3Wnqtxt2m/iRACarD1Fbu6Zasd293GiZS/le3vzzydFDbJ6SiRCwvXPWAy/Paocd5gIjRMcFtqSk0PWhx8B4P/EE2j8/ZFlmReWHCCtoJxwXxdeH9rCIdcyWo0s+Ot3wgqag0rmhtubOySuIFyz3Pwh/i7leNM0u8Pc1rYRUf6u5JeZq6xM3+yWseT463E1ws4v3qpR7A4DI9E5a8hJLeH49gy72yhcu0QiJFz//noZClPBKxz6vurQ0JnvvoutuBinFi3wHq3siLtwRyrLDqSjUUl8ckdb3J20DrnW/IPf0+xoTwBa9WmEV6CLQ+IKwjWt6yMgqeDkSsg4aFcIjVrFk31jAZi98XSlyvSSSoVhZD8APH/egNVorHZsJzct7fuHA7D119NYqpiHJFzfRCIkXN9OrYVdXyvHQ2co8w4cpHTrVop+WwqSRNCrryKp1ZzMKubVpcru0c/0a0qbUC+HXCunPIdNfx7CyxCIysVG50FNHBJXEK55PlHQfKhyvPkTu8MMahVMXLAHxUYLs9ZXXvLe5Z7nyXOX8CyysnfetBrFbt27MW7eekryjexfW/2hNeH6IBIh4fplKPrHkNh9ENnDYaFtJhMZr70OgPfoO3Bu1RKD2coj3+/BYLbRI8aP+3pEOex6n26eRcvkGwDoeVscOmfHzXEShGtet8eVjwd+hAL7Kr+rVBJP3aT0Cs3dnEhW0cUbNbq5epM6uB0A5nkLkS3Vqz8GoNGp6TxU+X7ftSIZQ0nleUjC9UskQsL1668X62xILPeLLzElJqL288P/iScAeGv5EY5mFOPrquODkW1QOWg116GcQ2SvB73VBddgNXFdQxwSVxCuGyFtIbIXyNYLu8Lb4ca4ANqFeWEw2/jgr+OVXk+4fwpFzuCZXU7qrwtrFDu2YxB+oW6Yyi1sF6U36hWRCAnXp8O/we55gOTwITHjiRPkfP45AEEvTEHt4cFv+84yb4tSjfr9kW0IcK/9UnkAWZb5eOXnxGV1BuDmuxyXYAnCdaXHZOXjrm+g2L5JyZIk8eKgOAAW7UrlSHrRRa83CW7Bvt7K/mKZs2Yi26q/waKkkug2QlmddnBDGrlpJXa1Ubj2iERIuP4Upl0YEuv2uEOHxGSrlfSXXgazGbfevXEfMIATmcU8/9N+ACb1jqZ3U8dVsl966nf8d7dEQkVoW09Cmng5LLYgXFcie0FoJ7Aa4e+P7Q7TPtyHQa2CkWWlF1f+1/5EERMeokwHbql5FK5ZXaPYjZt6E93OH9kms3Hh8UqxheuTSISE64vNCj8/AIYCCI6H3i86NHz+/O8p37cPlasrQVNfocxk5aH5uykzWeka7cvkm5o67Fql5lIWr1hBSHET0NjofbtjluELwnVJkqCXsk8XO+dAcfWLpP7bc/2boVOr2Hgih3XHsy96rXeLwWzqqNQDTJr+QY2Tma7Dm6DRqkg7XsDJXVl2t1G4dohESLi+bP4EkjYqtcSGfwUax1VkN6elkTVtGgABTz+FJjCQ55cc4GRWCYEeej4Z3dYhVeXP+3LXbFoc7wNAu5vDcfdxzHCbIFy3ovtAowSwGGq1gizM14XxXZUl728tO4LFemEITKvS4jLmDkwa0B9Lpmzb9hrF9vB1pt255fSbfzqJ2SiW01/vRCIkXD/SdsGaN5XjAf8Hfo5bYi7LMumvvoZcVoZzQnu8Ro1i3pZklu47i0YlMePOdvi56R12vVMFpzi8Mht3kzdaT0jo77gVaIJw3ZIkuOF55XjnHCjJ/u/z/8MjvWPwctFyIquEBf8qyHpLh7GsbaP8+kuZ8VGNY7e9KQx3HydK8o3s/jPZ7jYK1waRCAnXB2Mx/HQf2CzQ/FZoO8ah4YuWLqV040YknY7g199g75lC3lx2GIApA+NIiPBx2LVsso13/5xGy7O9AOg7uhVanaguLwgANOkLIe3AXAZb7F9B5umi5fEblcnNH608TmH5hSXvga6B5N3WE4sK2LGP8v37axRbo1PT7XblD7E9f6VQmF1udzuFq08kQsK1T5aVydF5p8CjsVJLzAFV3s+z5OWR+dbbAPg9/DCFfsE8+N0uzFaZQa2CuadbhMOuBfDj8Z/w3dUStawmuLkbUfH+Do0vCNe1f84V2j4bSnPsDjWmczhR/q7klpr4aOXFy+kHd53AxhbKz5HMz2bWOHZUvD+Nm3ljtdjYtPiE3W0Urj6RCAnXvu1fwKGfQaWB2+eCs2MLkWb+7y2sBQXomzXDddx47v92F5lFRmIC3HhneCskByZdOeU5/PLHahoVxYBapu+drRwWWxDqjdh+yt5C5lLY+KHdYbRqFa/doixCmLcliUNnCyte6xDUgV03hWEDyteux3DkSI1iS5JEj5GxqFQSSftzSDpgf8ImXF0iERKubak74M9zK8Nu/h+EdnBo+OK1aylatgxUKoLeeJ0Xfz/K3tQCPJ21zB6f4LA6Yue9u+kD4k8pNY86DIzEw8/ZofEFoV6QJOjzsnK8YzYU2l/WokeMP4NaBWOT4ZVfD2E7V0FekiRu7DGOzc2VP3SyZ9S8V8gnxJU2Nyr7Em1ceFzUIbtOiURIuHaV5sLiu8FmVuYFdXrAoeGtBQVkvDIVAJ/x4/m+wJUlu9NQn5scHe7r6tDrrUpeRdHfOlzNnjj7qml/c4RD4wtCvRLdB8K7K/sKrf+/WoV6aXAcLjo1u5Lz+XH3haTq1ia3sqKXOzagZNWqGvcKASQMisDNW09RjoFdK8TE6euRSISEa5PNBkvug6Iz4BMNt0x36LwggIz/vYUlOxtdZCRHB97JW8uVH4IvDoyje4yfQ6+VU57DJ399QYsMZfPHm+5qhVorvv0E4ZIkCW481yu0Zz7knLQ7VLCnc8XE6Xf+OFpRnd5F60LnriPYEqf8bMmZWfNeIZ2Thu63K7F3/5VMQWaZ3e0Urg7xk1i4Nm18H06tBo0zjPoWnDwcGr5o5UqKli4FlQr5uVd49KdD2GQYmdCYCQ6eHC3LMq9tfo02x/qhQkVkWz9CmztuFZog1FthnSGmn1KDbN1btQp1T/dIYgLcyCs18d6fxyqeH91sNEu6a7ABxStXYTh6tMaxo9r6E9bCB5tFZoPYcfq6IxIh4dpzai2sPfdDb/CHEOjYHZcteXlkTH0VAJdxdzNxRzlFBgvtw71549aWDp0cDfDrqV/J3mkhqCQStU6i58hYh8YXhHqtz0vKx4M/QXrNlrn/k1at4vWhLQH4fnsKu5LzAGjs3pim7W680Ctkx1whSZLoMSoWtUZF6uE8Tu22f/8j4coTiZBwbSk6Cz9NBGRoNw7i73RoeFmWyXjtdax5eWibxPC0SweScsto5OXMZ2Paodc4dj+ftJI0PtnwGZ2ShwDQdVgMbt5iB2lBqLbg1tDiNuV41au1CtUl2pfh7Rojy/Dsj/sxmJXJzWOaj+HH7qpzvUIr7eoV8gpwoV2/MAA2LT6ByWCpVVuFK0ckQsK1w2qGxROgLAeCWsGAdx1+iaLlyyn+80/QaJjXaxw7zpbi4aThm3s6OKyi/Hkmq4mn1j5FwvHB6GxOBEZ60KpXI4deQxAahD4vKdtnnFoNJ2tWKPXfXh4ch5+bnlPZpUxfo+z/0y6gHR6xzWvVKwTQrl84Hn5OlBYY2fF7Yq3aKVw5IhESrh2rXoXUraD3gJHzQOvYpeWW7GwyX38DgCN9bmNerjNatcQX4xJoEuDu0GsBvL/zfQzHdYQXtECllugzNg7JgbXKBKHB8I2GDvcpx3+9rBRftpOXi443b1WG22etP83BtEIkSWJM8zH81E2FTbK/V0ijU9PzDqUw8741Z8hNK7G7ncKVIxIh4dpw+DfY8qlyfOtM8HFs7S1Zlkl/+RWshYWUhkXzjFN7AN4b0YbOUb4OvRbAisQVLDnwK90ThwOQMDACnxDHLscXhAal17Pg5AlZh2DPd7UK1b9lMANbBWG1yTz7437MVhv9I/pTHurHlma16xUKb+lLVLw/sk1m/Q/HxMTp64BIhISrL/cU/DpJOe7yCMQNcfglChYupGTdOmSNlmea3IpVpebpm2O5ta3jh6oSCxOZunkqXZOH4WxxxyfElXb9wh1+HUFoUFx8oOezyvHa/4Gxdr0tr93SEi8XLYfTi/hiw2l0ah2jmo7ip24q5PO9QnbsKwTQfWQMGp2K9JOFHNuWUat2CnVPJELC1WUqg0XjwFgEYV2g76sOv4Tx1Cky31E2ZPuqxUASPYIZlRDKpN6Oq15/XqGxkEfXPIpvdhhNszuCBL3HNEOtEd9qglBrHe8D7wgoyYS/P65VKH93PVOHNAfg41UnOJJexO1NbyczUMfmc71C2dPsu4a7jxMdBkUCsPmnkxhKzZd5h3A1iZ/OwtUjy7D8acg8CK4BMOJrUDu2pIXNZCLt6WeQDQb2BjZlSUQ3bm4eyP+GOX6ZvNlq5sl1T5Kel0WfxDEAtO7dmKAoT4deRxAaLI0ebnpdOd48HQrTahXu1vhG3NQ8EJPVxhML9uKm8WZg5EAW9lRhU0mUrF9P2e7ddsVuc2Mo3kEulBeb2fbr6Vq1U6hbIhESrp7d82DvfJBUMOIr8Ah2+CWyP5qG8cgRivWuvNt2FF2a+PPJ6LZo1I790pdlmde3vs6OjB3ckDwKZ6M7XoEudL412qHXEYQGL+4WpffYUg5r3qxVKEmSePu2Vvi56TiWWcz7fx5jTPMxZPhIrGut/IzI+vBDu+b5qDUqeo1WJk4f3JhGVnJRrdoq1B2RCAlXx9m9sPwZ5bjPSxDZ0+GXKN28mbyvvwbgg/iRhMWE8cW4BJy0jt0rCGD2gdn8cvIXovPiicpqq1QHGB+HVuf4awlCgyZJSgFmgH0/wJldtQrn56bn3RGtAZi9KZG8PD86BHVgUTewatWU79xF6caNdsVu1NSb2I6BIMP6749VFHwVri0iERKuvPJ8ZV6Q1Qix/aHbkw6/hCU/n9RnngNgWUQX8uM7MffuDrjpNQ6/1jeHvuGTPZ/gbHLn5pRxALTtFy6GxAShrjRuD63vAM4Nr9tstQrXp1kgd3ZSNkN8avE+bm8yhjwPiZXtlT9ksqZNQ7bzGl2HN0HnpCYruZjDm87Wqp1C3RCJkHBl2Wzwy8NQkAxe4TBsFqgcPExls3HqiaeQc3NIdfNnZe87+O7eTni76hx6HYB5h+bx/s73QYbxuc8hl6vxbeRGx3MTJQVBqCM3vQ46dzi7G/Z8W+twLw2KI8LXhfRCA8u2eRLtGc3iTlYszjqMh48oG7HawdVTT6ehynYgW385RVmRqdZtFRxLJELClbX5Yzi2HNR6ZdNEZ2+HX+LUR9OxbduCUaXh234P8O1DPQnwcHxZi+8Of8d7O98D4AHnZyHJHZVaou+EOFFZXhDqmnsg9J6iHK96FcryahXORafho1HxqFUSv+/PoLnrEIpdJFZ00QOQ/fEnyBb7yma07NkIv1A3jGUWtvx8slbtFBxP/LQWrpzkLbBa2dmZge9CSLzDL3Hyz3UYZ38OwOLuo/ng+eF1kgTNPzKf/9uhLMm/L2wSus1Kt3qHQZH4NXb8LtWCIFSh4/3gHwflecreQrXUNsybyTcpRZGXbAjAW+/HovgyLJ6umJKSKPj5Z7viqtQXJk4f3ZLB2RMFtW6r4DgiERKujLI8pZiqbIXWo6DdeIdf4uD+U2Q/9ywqWWZLbBce/2Cyw+uHAfxw9Afe2f4OABOb30fQ1vaYjVaCm3hWFF0UBOEKUGthoNIry845kL6v1iEf6hVNjxg/DGYVlvxuGPQSf/Z0AyDnk+nYysrsihsU5Unz7iEArP/hGFZr7eY1CY4jEiGh7sky/PYoFJ0Bn2gY9IGy8sOBNh/P4Oikx/EyFJPuE8KQOR/WSRK08OhC3tr2FgATWk4gIXkA2cnF6F003HRPC1QOXpYvCMJlRPaAlsNBtsGy2k+cVqkkPhwZj5+bnrOp8ahxYn6zHKzB/liys8n9ao7dsbvcGo2Tq5a8s6UcWHumVu0UHEf81Bbq3o7ZcPR3UOtgxBzQO3boaMXBdNY8/QYtsk9h1DoRP+cz/P28HHoNgEXHFvHmNmXfkrtb3M1w/Tj2rkoFoM+4ONx9HJ94CYJQDTe/CVpXOLMd9n1f63D+7nqmjYpHkp0pz03AopFY3t8HgNw5czBnZtkV18lNS5fblL3Fti9NpCTfWOu2CrV3TSRCM2bMICIiAicnJzp16sT27dsvee7cuXORJOmih5OT+AV0zUrfD3++oBzf9LpD5wXJsszXfyey8J2vGH58DQCN33oDn2axDrvGeT8e/5E3tirzm8Y1H8eDTSax+hulDlHLXo2Iivd3+DUFQagmjxC44Xnl+K+XoCS71iG7x/jxUK9oTHndQFbxbeBJ5FZNkcvLyf7Y/vIecV2CCYrywGy08vePJ2rdTqH2rnoitHDhQiZPnszUqVPZvXs3bdq0oV+/fmRlXTrj9vDwID09veKRnJx8BVssVJuxBH68B6wmZb+gTg86LLTZauPFXw4y/9u/eHz3QgC8770XvyGDHXaN85acWMJrW14DYEzcGJ5q9xSrvzlCebEZ30audBvu+JplgiDUUOeHIaiVsk/ZiucdEnLyTbG0axSFuag1SBJLB/gBUPjzz3YXZJVUEj1HN0WS4OSuLFIO5zqkrYL9rnoi9OGHH3LfffcxYcIEmjdvzqxZs3BxcWHOnEuPw0qSRFBQUMUjMDDwCrZYqLY/noXcE+AeAkNnOmxeUEGZifFztvPH+oO8su1r9DYLrj17EjjZ8Rsz/nziZ17d/CoAd8XdxbMdnmXH8iRSj+Sj0aq4+d6WaMTu0YJw9ak1cMt0pWTPwR/hxMpah9SoVXwyui360t4AzFfvQHNTL5BlMt99167SGwD+oe606t0YgA0LjmM1i4nTV9NVTYRMJhO7du2ib9++Fc+pVCr69u3Lli1bLvm+kpISwsPDCQ0NZejQoRw6dOiS5xqNRoqKii56CFfAwZ8u1BEb/iW4+jok7JH0IobN3MyO45m8smMe/uWF6CIjafTB+0hqxyYkv578lambpyIjM7rZaJ7r8BzJB3LZuSwJgBvGNMMnxNWh1xQEoRZC2io9QwC/P6n0StdSIy9npt02GEtJDDI2ZiZokLRayrZspWT9ervjdhwShYuHjsKscvasFKMaV9NVTYRycnKwWq2VenQCAwPJyMio8j1NmzZlzpw5/Prrr3z33XfYbDa6du3KmTNVz8B/++238fT0rHiEhoY6/PMQ/qU4A5Y9pRz3eBoiutc6pCzLzNuSxNAZf5OYXcIzR3+lWW4SKnd3Gs+cgdrdsROwl55ayst/v4yMzKimo5jScQpFOeWsmnsYgFa9GtG0U5BDrykIggP0fgG8wqAw1SF7CwH0bhrA4LCxAKyUN1F+6y0AZL33PrLZbFdMvbOGbrcrw+o7/0imKKfcIW0Vau6qD43VVJcuXRg3bhzx8fH06tWLJUuW4O/vz+eff17l+VOmTKGwsLDikZqaeoVb3MDIMix9XBmnD2oNvZ6tdciCMhMPfLuLV349hMliY0rBdnqc2AIqFY0+/BB9pGPLWaxIWsFLf7+EjMzI2JG80OkFLGYbf3x+EGOZhaAoD7rdHuPQawqC4CA6Vxj8kXK8bRak1a4o63nvDLoVF1sTJMnKk765qLy9MZ06Rd78+XbHjEkIpFFTb6xmGxsWHrd7qE2onauaCPn5+aFWq8nMzLzo+czMTIKCqvfXtlarpW3btpw8WfW25Xq9Hg8Pj4seQh3a+z0cX6EslR82S9nwrBa2J+Yx8OON/HU4E51axSe+6fRcvxiAwClTcOtR+96mf1qbspYpG6Zgk23cFnMbL3Z+EQmJtfOOkHumBGd3Lf3ua4Vac939DSEIDUeTvtBqpLK30G+PgaX29b3UKompPR4DIMdzG392G6QcT/8U838s7vkvkiTRa3QsKrVE8oFcEvfl1LqdQs1d1Z/mOp2O9u3bs3r16ornbDYbq1evpkuXLtWKYbVaOXDgAMHBwXXVTKG6Cs9cWK1xwxQIbGF3KKtN5uNVJ7jjiy2cLTQQ6efKkk4aYr5Rlq363HMPPmPHOKLVFTanbeap9U9hkS0MjBzIK51fQSWp2Lk8iRM7s1CpJPrf3xI3b71DrysIQh3o/za4+ELmQVj/fw4JOSD6BiLcmiKpzMwIyqAksim20lKy3nvf7pjeQa7E36TsSL9p0QnMRqtD2ipU31X/s3by5Ml8+eWXfPPNNxw5coSHHnqI0tJSJkyYAMC4ceOYMmVKxfmvv/46f/31F6dPn2b37t2MGTOG5ORkJk6ceLU+BQGUIbFfHwFjETTuAF0fsztUemE5d365lY9WHccmw23tGvHTzf5oX5sCFgseAwcQ8PRTDmw87MzYyeNrH8dsM9M3rC//6/4/1Co1J3Zmsn1pIgC97mpKSIzji8QKglAHXP1g8DTleNOHcGZnrUNKksTjCco2IFqfrbwS1QdZkihaupSyHTvsjpswIAI3Hz3FeQZ2/pFU63YKNXPVE6FRo0bx/vvv88orrxAfH8/evXtZsWJFxQTqlJQU0tPTK87Pz8/nvvvuIy4ujoEDB1JUVMTmzZtp3rz51foUBFDq/JxeCxonuPUzZSmrHVYezmTAxxvZlpiHq07NR6Pa8H89Asl95GFspaW4dOhA8DvvIKkc96V7LO8Yj6x5BIPVQI9GPXi357toVBoyk4oqNk1s0zeU5t1CHHZNQRCugOa3QKvblSGynx8Ec+0nJPcJ60O0ZzSS2sCpiBTWx3QFIOONN+2uTq/Vq+kxUtkIdu/KFPIzSmvdTqH6JLmBzc4qKirC09OTwsJCMV/IUfIS4bNuYC6F/u9A54dqHMJgtvLOH0eZuzkJgJaNPJg+uh2hlJM8ZiympCR0TaKJmD8ftaenw5qeUZrBXcvvIqssi/aB7ZnVdxZOGieKcsr56d1dlBWZCG/ly8CHWqNSObY+miAIV0BZHszsAiUZ0HkS9H+r1iGXnlrKC5teQLK5IR+YxDdrpuFsKCXwhSn4jBtnV0xZllk2cz/JB3Jp1NSboU/EIzm4JuP1rq5+f1/1HiHhOmezwa+TlCQovDt0fKDGIU5ll3DbzM0VSdC93SP56aGuhGnMpNw7EVNSEprgYMK++MKhSVCRqYiHVj1EVlkW0Z7RfNz7Y5w0TpSXmFg6fR9lRSZ8G7ly8z0tRBIkCNcrFx9lo0WArTMhcWOtQw6IHECoeyiyqgRro/180WwAANmfTMeSbV95D0mS6DEyFrVWRdqxfE7utG8CtlBzIhESamfbLEj+Wyl4eOsMqMGQlSzLLN6ZypDpmzicXoSPq46v7+7Ay4ObozEYSLn/AYzHjqH28yP86zloQxw3NGWymnhy7ZOcLDiJv7M/M/vOxFPvidloZdmM/RRkluHmo2fwI/HonO0b5hME4RoRezO0GwfIsOR+pZeoFjQqDQ+1UXq+3QI38Wdka455h2IrKSHz7Xfsjuvp70z7/uEAbFp8AmO5fUNtQs2IREiwX84JWK3U4KLfm+AdUe23FhvMPLFwL8/8uJ8yk5UuUb788XgPejcLwGYwcObhhzHs34/a05OwOV+hi6h+7MuRZZmpm6eyPWM7LhoXZvadSYhbCFarjT+/PEhmYhF6Vw1DHo0XK8QEob7o9zb4NoHis8rCjlrOChkYOZBIz0jKrcW0a32I6W2GY5VUFC1fTvHatXbHbXtzGJ4BzpQVmdi+9HSt2ihUj0iEBPtYLcrkQ4sBovtA+wnVfuv+MwUMnr6JX/eeRa2SePrmWL6b2IlADydkk4kzjz1G2fbtqFxdCZ09G6dYx1aTn3d4Hr+f/h2NpOGjGz6imU8zbDaZNd8cIflgLhqtisGT2uATLMpnCEK9oXeDEXOUPc6OLYMds2sVTq1S83AbpZzHWflPnFpGsCS6JwDpr76GtcS+8h4arZqedyg/8w6sPUN2anGt2ilcnkiEBPts/hjSdoLe81yhw8vPoZFlmbl/JzL8s80k55bRyMuZRQ905pE+MahVErLZTNpTT1O6YSOSkxOhn8/CuVVLhzZ7W/o2Ptz1IQDPdHiGro26Ittk1n53lOPbM1GpJPrd15KgKMfNRRIE4RoR3Ab6nuvF/vNFyLx0ncrquDniZmK8Yygxl9C1/SGWtx/MWVdfrJmZZH3wod1xw5r7Et0uAFmGtd8exWYVRVnrkkiEhJrLPARr31aOB7wDno0v+5Yig5lJ3+/m1aWHMVtlbm4eyPLHetA+3AcA2WQibfJkileuRNJqafzpp7gkJDi02ekl6Tyz/hlsso1bom9hdLPRyLLM+gXHObo5HUmCm+5tQURrP4deVxCEa0jnhyDmZrAaYfGEWhVmVUkqJsVPAuDX0wt4bXRTprcdAUDBDz9Qtsv+8h49RsWgd9GQnVLMnpUpdscRLk8kQkLNWEzw8wNgM0PTgdBm9GXfcjCtkCHTN7H8QAZatcQrg5vz+dj2eLoo5Tdkk4kzT06meOUqJJ2OxjM+xa17N4c222Ax8MS6J8g35hPnE8fLnV8GlAmJhzakgQR9JzSnSfsAh15XEIRrjCTB0JngFgQ5x+C32s0X6hPahxa+LSi3lLOrcBGDxt3CivCOACQ+9wI2g8GuuK6eerqPVGoabv89kbyzYm+huiISIaFmNr4PGQfA2VvZtfUyQ2I/bE/htn8MhS1+sCv3dI+s2B/DZjJx5rHHKVm9Gkmvp/GMGbj17OnQJsuyzBtb3+Bw7mG89F5M6z0NnUrPuu+PsX/NGQD6jG1GbEdRTV4QGgQ3fxg5D1QaOPQzbJlhdyhJkpjcfjIAi48t5sbWcGbkRPL07qjOpJD0jv3lN5p2CiK8pS82i8yab49gszWobf+uGJEICdV3dg9sOPdNPehDcA+85Kkmi40Xfz7AlCUHMFls9I0LYNlj3YkP9ao4x2Y0cubRRylZtw5Jryf0s5kOL6IKsODYAn479RsqScX7vd4n0DmIVV8f5vDGsyBB77HNiOsqdo0WhAYlrJOykgxg5Su12l+oY3BHbmh8AxbZwrTd03hjbBd+7D0eAOOC+RT8vdmuuJIkccNdTdE5qclMLGLfqlS72yhcmkiEhOoxG5RVYrIVWgyDlrdd8tScEiNjvtrG/G0pSBI8068pX45LwMtFV3GOzWjkzCOPUrp+Q8XEaNeuXR3e7N2Zu3l3+7sAPNnuSRL8OvDnFwc5sUOZGH3zvS1E6QxBaKg63getRyk/136cAIVpdod6MuFJ1JKatalrOZS3h8dfupuV0Urx8JOTn8VaVGRXXDdvJ7rdrgyRbVt6moLMMrvbKFRNJEJC9ax7C7KPgmsADPzgkqcdTCtk6Kd/sz0xDze9htnjEpjUu8lFW8XbDAbOPPQwpRs3Ijk7E/r557h27uzwJmeVZVVUk+8f0Z87m4xh2Wf7SdyXg1qjYsCDrYhJuHSvliAI9ZwkKUP8ga2gNBt+GGX35OkozyhGxCoTpd/f+T5hvs60evNlzrr64lqYy9bJL9rdzLiuwYQ298FqtrH6myNiFZmDiURIuLyUbfD3J8rxkI/B1bfK05YfSGfErM2kFZQT4evCL5O6cmPcxYmGrbSU1IceonTzZiQXF8K++BzXTh0d3mSz1czkdZPJKc8hxjuG51q+yK8f7SH1cB4avZrBj7QWq8MEQQCdC9wxH1z9lfmPP90LNqtdoR6OfxhXrSuHcw/z++nf6d02kjP3P4MVCZ9Nq9g17ye74kqSRO8xzdA5qck4XciuFcl2xRGqJhIh4b+ZSuGXBwEZ2twJzQZWedrsjad5eP5uDGYbPWP9+XVSd5oEuF90jrWoiJR7J1K2ZSsqFxfCvvwClw4d6qTZ72x/h33Z+3DXufNm3Hss//AwWcnFOLlpGfp4PI2b+dTJdQVBuA55h8PoBaBxguMr4M8X7Arj4+TD/a3vB+CDnR9QZCpi7H23sKfbEADk9/5H0sGTdsV293Gi5+imAOxYlkT6qUK74giViURI+G+rXoO80+AeAv3frvSyzSbz5u+HeXPZEQDGdQnn67s7VCyNP8+Sm0vyuPGU792LytOTsK/n4NK+fZ00ecmJJSw6vggJiZfD3mbzZ2kU5xrw9Hdm+LPtxWaJgiBU1jgBhn2uHG+bBds+tyvM2LixRHpGkmfI45Pdn6BSSQz/5DVSAiNxNZdz5KFHKSy2b55P005BxHYMRLbJrJxzSNQicxCRCAmXlrgBtp/7YTB0Ojh7XfSy0WLlsQV7mL0pEYDn+jfjtVtaoP5XpXZzejrJY8ZiPHpUKaA67xuc27SpkyYfyD7Am1vfBOBh1+dJ+sGGscxCUJQHw59rj1eAS51cVxCEeqDFrdD3VeX4j+fgwI81DqFVa3mp00sALDq2iEM5h3BxdaLVF59SqnMmIjuJXx56AYud83x6jm6Kh58TxbkGNvxwzK4YwsVEIiRUrbwAflaqK9N+AjTpe9HLheVmxn21nd/3p6NVS3w0qg0P3RB90aRoAFNyMsl3jcGUmIgmJJiI777FqWnTOmlybnkuT657EovVwsi8R7CuCsJmkYlu68/QJ9ri7Ka7fBBBEBq2bk9Ah4mArGwee2xFjUN0DO7IoKhByMi8tuU1LDYLIU2jcHpRKe/RceeffP3et3Y1T++s4aZ7WiCpJI5vz+TI5nS74ggXiERIqNofz0HRGfCOhJvfvOilswXl3D5rM9vOrQz7+u6ODGtbucyG4fhxksaMwXz2LLrwcCK++86hVeT/6fzk6PyiIoaffAKfY8py03b9w+l3X0s0OnWdXFcQhHpGkmDAe8qyepsFFo1Tesdr6OmEp3HXuXMk7whzDs4BoOWoIRQOGg5Am/kfs/DXLXY1MSjKk46DIwBY/8MxslNEYdbaEImQUNnhX2H/ApBUcNsXStXmc45mFHHbzM0czywhwF3Pwgc60z2m8uqr8gMHSBk7Dmt2DvqmTQmf/x3akLrZr0eWZd7a/haJSWmMOPA0fjkRaHQqbp7Ygi63RiOpLl8QVhAEoYJKpZThaDpIqUn2w2hl9WwN+Dn7MaXjFAA+2/cZx/KUYaxOb79CYUQs7uZyPP73An9sP21XE9v3jyC8pS9Ws40VXxzAUGq2K44gEiHh34ozYOkTynH3JyH0wtL2LadyuX3WFjKKDET7u7Lk4a60CKk88bh082ZSxt+NtbAQpzatCZ/3DRq/uluqvujYInZuPcqwA5PxMPjh7uPE8Gfbiz2CBEGwn1oDI+ZA1A1gKoFvh9V49+nBUYPpHdobi83CS3+/hNlmRtLpaDf3c8rdvYgoyiD9+efZejK7xs2TVBJ9JzTHw8+JohwDK+ccQhYlOOwiEiHhAlmG3x6F8jwIag29nq94aem+s4yfs51ig4WEcG9+eqgrjb0rTzwuXLqUlPsfwFZWhkvnzoR9NQe1Z92t0tqWtp01iw7S/9h96GxONGrqxe0vJODX2P3ybxYEQfgvWie44wclGTKXwvwRcHJVtd8uSRKvdHkFT70nR/OOMn33dAB0QUHEfj4Ti1pDl7MH+PO5tziSXvOdp51ctQx4sBVqrYqUQ3ls/z2xxjEEkQgJ/7TrazjxF6j1ypCYRplcPHvjaR79YQ8mq43+LYL4bmKni8plnJc752vOPvMsWCx4DBxI6Befo3ZzrbPmnkhNZMXHh2l9tjcArfs0Zshj8WJStCAIjqNzgdELIaYfWAzKMNnRZdV+u5+zH692eRWArw99zYYzynwjt3ZtCZo6FYCRh1bwyatfkJpX82X1fo3dueEuZQHKzuVJHN+eUeMYDZ1IhARF5mFYcW4Tsb5TISAOm03mjX/sEXR31whm3NUOJ+3FE49lm43Mt98h612lppfP+PGEvP8eKl3dJSSHdifz+7uH8SsKw6IxcuN9TekxMha1WnxJC4LgYFonGPUdxN0CVhMsHAs7v6722/uG9+XOZncC8MKmF8goVZIV/5EjcB2tPP/Axm948c3vOZNf82SoWedg4m8KA2D1vCOcPVFQ4xgNmfitISi7Ry++GyzlEH0jdHoIo8XKowv28NW5PYKmDGjG1CHNK+0RZDOZOPv0M+R98w0AAc8+S+CU55FUdfOlZbXa2LTkGOu+OIXO7EyBezqDn21Js/aN6uR6giAIgNJDPuJriL9LKdL6+xOw+nVlSkE1PJXwFC18W1BoLOTJtU9isBgACH1xCtruPdHbLExa+RlPvvcLZwvKa9y8rsOiiWrrj80is3zWflGctQZEIiTA8mch5xi4BcGwzykwWBj71XaWndsj6OM74nmgV+U9giy5uaSMv5ui5ctBqyXkvXfxvWdCnTWzIKuMJe/tYt9fSoXo4yFbGfFMR6LDQuvsmoIgCBXUGhg6A25QVoOx8QNYch9YjJd9q06t471e7+Gp9+Rg7kFe3PQiNtmGpNEQ9clHqFu0wsNcxqQ/pvPgtBWkF9YsGTo/eTogwgNjqYWln+6jrMhkz2fZ4IhEqKHbtwD2fqcslR/xFakmV4Z/tpntiXm46zXMndCRofGVe1sMx46RePvtlO/Zg8rdnbDPZ+E5ZEidNFGWZQ7/fZaF/9tOVlIxRnUZa5t+y7gH+tE0IKZOrikIglAlSYIbnleW16s0cGAxzB0ERZff2DDUPZRpN0xDo9LwV/JfTN+jTJ5WubgQNftzVGHhBJYX8MDy6dz76Zoa9wxpdWoGPdwad18nirLLWTp9r1hWXw0iEWrIso7C75OV417Ps1/TkmEz/+ZUdinBnk4sfqgL3ZpUXvZevHo1SaPvxHI2XdkoceFCXLt2rZMmGkrMrPj8IGu/PYrFaCPN4wSL27zL/cNG0z6wbmqVCYIgXFbbu+CuH8HJE87sgC96QcrWy74tISiB17oqO0zPPjCbbw8rO0xrvL2JnDMbydeXqKJ0Hlg6jXEfr+ZUdkmNmuXioWPIo21wdteSk1rC75/uw2QQNcn+i0iEGqryfFgwWlkSGtmT1f5jGfX5VnJKTMQFe/Dzw91oFuRx0Vtkm42cWbM488ijyGVluHTpTMTCBeijIuukiUkHcljwxjZO781GVtnYGvYry5rPZMqNT3NzxM11ck1BEIRqi+4N96+DgOZQkglzB8P2Ly87b+iW6Ft4OP5hAN7d8S4Lji4AQNe4MRFz5iB5eRFbcIZJKz5h3CdrOHCmZpXmvYNcueXxtuhdNGQmFrF85n4sJqtdn2JDIMlyNWd61RNFRUV4enpSWFiIh4fH5d9QH9ms8P1IOLkK2TOUH+K/4aW/MrDJ0DPWnxl3tsXd6V/V4/PzOfvcc5RuUDYU875zNIFTpiBptVVdoVYMpWY2LTrBsW3KygqLRym/hM8kx+0Mr3d9nWExwxx+TUEQBLsZS+DXSXD4F+XfcbfALZ+As/cl3yLLMh/v/pivDn4FwAudXmB0s9EAGI4eJWn8BOTCAo54h/PWDQ/y3t1d6d00oEbNykwq4tdpezAbrIQ292HAg63QXsflhurq97dIhBqiv16GzZ8ga5yZFvYpHx92BmBUQihvDmuJ9l9L0Mv27CFt8lNY0tOR9HqCXn4JrxEj6qRpp/Zksf6H45QXmZAkyIk5zs9eXyBrbLza9VVubXJrnVxXEAShVmQZtnwKq15VapR5NIbhsyG8y3+8Reb9ne8z7/A8ACa2mshjbR9DkiQMR46QfPcEbIWFHPUO5bUuE3lieAfGd42otHDlv5w9WcDST/ZiMdkIbuLJoElt0DtravvZXhUiEXKQBp8I7fgKlinzgt73eI5Ps9qgkuDFQc25p9vF32CyxULu7NlkfzoDLBZ04eE0+ngaTs2aObxZxXkGNi0+wek9ylbz7gE6NsQsZJttHXq1nvd7vc8NoTc4/LqCIAgOlbYLfrwX8hOVRSi9noMeTysrzqogyzKf7/+cGXtnAEpZjqldpuKkccJw+DDJE+7BVljIGTd/XuxyHzffGM8rg1ug01R/Zkv6qUJlrlC5Bf8w93NziK6/jWdFIuQgDToROroMFo4B2caX6lH8r3Qons5aPr2zLT1i/C861Xg6kbPPP49h/34A3Af0J/iNN1C7uVUV2W5Ws429q1PYuTwJi8mGpJII6qZluvQKOeZsvPRefNz7Y9oFtnPodQVBEOqMsRiWPwP7flD+HdJOWXYf2PySb/n5xM+8tuU1rLKVWO9YPrzhQ8I9wjGePk3KvROxpKeT6+TBS10m4t2qOTPubEeIl3O1m5SdWszST/ZSXmzGO8iFwY+2wcO3+u+/FohEyEEabCKUshV53lAki4GF1t48Z55IkwB3Zo9LIMLvQhkM2WIh79vvyJ42DdloROXuTtDLL+ExZEiNumOr1aRDuWxYeJzCLGWJaFATD9Lid/HV2ZnYZBvNfJoxrfc0GrmJzRIFQbgO7V8Ey54GYyGotNDrWaWYtbrquZVb07fy3IbnyDPk4ap1ZUrHKdwSfQuWrCxSJ96H8cQJyrROvJUwhtORrZh2R1t6xfpXGasq+Rml/PbxXkryjTh76Bj4UCuCIuuuFqSjiUTIQRpkIpS6Hdu3w1CZSlhjjec+81MMjg/lf8Na4aa/0F1btnMnGa+/gfH4cQBcu3Uj+H9vog0KcmhzMpOK2PrLKc4czQfA2UNHVD9XPit7h8N5hwFlVcVLnV/CWXN9/cUiCIJwkaJ0+P1JOP6H8u/AVjB0OoS0rfL0rLIsnln/DLuzdgPQvVF3pnaZir/VhTMPT6Js505sSMyL68/C2D7c3S2S5/o3w7mak6CL8wwsm7Gf3LQS1FoVN46PIyYh0CGfal0TiZCDNLhEKHUHlm+GorGUssXanId5lim3JHB7QuOKHh5zZibZH35E4a+/AqD29MT/qcl43X67Q3uB8jNK2fbbaU7tVuYBqdQSsT382d5oOQsS52OTbXjoPHilyyv0i+jnsOsKgiBcVbIMB39ShsvK8wAJEiZAn5fBxafS6RabhW8OfcPMvTMx2Uw4qZ0Y12IcE2LHUPx/0yhYtAiATcGt+LDdKIKDfXl/ZBvahV16ldo/mQwWVn51iKQDuQB0GBRBwqBIVCrH9vo7mkiEHKQhJUIlR9agXjwGZ5uSBL3t/Srv39WV2EB3QFkSn/vlbPLnz0c2GkGS8Lr9dvyffAKNd/W+oaojN62E3X8mc2JnFrJNBgmiO/iRHLuTb1JnU2wqBqBfRD+eSXiGQNfr468TQRCEGinJhj+nKLtRg7K8vs9L0H4CqCr36JwuOM1rW16r6B3ydfLloTYPceMeK9lvvQNmM+keAbzT9g5O+oTxQK9oHusTU63eIZtNZvNPJ9m3OhWA0Dhv+k5ogYvHtTuJWiRCDtIQEiFZltm1dBZtdr+EFgtbbM3Z1GEGj/Zvg5NWjSU/n/z535M3dy62EmXXUuf27Ql89hmc27RxWBvOHi9gz6oUks/91QEQGOdKStxOfsr9niJTEQDRntE81/E5uoRcepmpIAhCvZG0SanxmHVI+XdQK+j7qlL0+l+98LIsszplNR/t+oiU4hQA/Jz9eFDdh7Yfr8KalYVNUjG/aV8WxN5IsI8bLw+Oo1+LoGr16B/dks76749hMdtw9dRx88SWhMR4OfgTdgyRCDlIfU+EDqXlc/CHlxhV8h0AazXd8LrzK9pGBWM6c4a8r+dS8NNPyAal8rE+Lo6AJ5/AtUcPhwyDGUrNHNuawaGNaeRnnKt+LIFLrIX9jdeyumwZMsqXXIRHBA+1eYh+Ef1QV/HXkCAIQr1ltcDOObD2TTCc2zk6vDvc+DKEda50utlqZvHxxcw5OIfMskwAAizOPL/Om8Y7lATplF8E77YeQYpHED1i/Jg6pAVNAi6/0jc3rYQ/vzxIfkYZkkqi3c1hdBgUiVp7bRWfEImQg9TXRCgpp5TZK7bS7/hUeqgOALC78Tji7noPy9YtFCz+kZJ168BmA8CpeXN875uIe79+SKrafbHbrDbSjhVwfHsGJ3ZlYTUr10Arkx+axCqvheTqLxQk7NaoG3c0vYMejXqIBEgQhIatNAc2fgg7ZoP1XBX7mH5KYddGlbcNMVvNLE9cztcHv+ZU4SmQZbofkrl/pYSTwYpNpeK36B58G3sTRr0zI9o15rG+MTS6zFJ7k8HC+h+OcXybkmT5hLhy4/g4AsKvnd+TIhFykPqWCJ3MKuaLDafJ27OUtzRfEiAVYJL0FMVPQU7RUvDTT1gyMirOd+3eHd+J9+LSqVOteoBsNpmMUwWc2JHFyd2ZGEouFPUrdMtin/86TvjtxKxRvrEjPCK4OeJmhkYPJcwjzP5PWBAEoT4qPAPr34U934F8ri5YRA/o9gQ0qTxkZpNtbM/Yzo/Hf2R1ymo8881MWGWj43HlV3qRmyufNx3IusYd0Gg03NkpjId7RxPg7vSfzTi1O4v1PxyjvNiMpJKI7xtKwsAIdE5XfzdqkQg5SH1IhGw2mb9P5TBnUyJHjh1lqnYeA9Q7sJSryM0Jo7wwivKDRyvOV3t54XnrrXjdPgJ9dLTd1zWUmDm8L4Wje1PJP2EGw4XenHJNCad993HcfzuZbklo1Vra+LehY3BH+ob1pYlXE4fvQyQIglDv5J5SEqKDPyqlOgACWkCHe6H1SNC7V35LeS6/nfqNX0/+ivvuE0xYaSNY2Z2Es77OzIvrwgbfvmi1Tgxv15iJPSKJ9r/0kFl5sYkNC45zclcWAC6eOroOiya2YxDSVVxZJhIhB7meE6HT2SX8vCeNn3adwVCYxX2aZdxlWon1rIqiVGfKsvRw/m5KEi6dOuF1+wjcb7oJla5mKwFkWSYpL4X9B4+TejyX8iQ1zrneSFwYRjOqy0j0OcBJv90YA/OI9YuhuU9zOgR1ID4gXuwBJAiCYK/CM7D1M9g1F0zKohZ0btBqBMSPgcYJVU6sPp5/nBXHfsP4/U/03liImzIdlBR/Fb+0DGddUHfKDc3p26wx93SLoHOU7yWXzSfuy2bTjycpylY2vQ2M9KDT0CgaN/W+Kn/YikTIQa6nRMhksbH/TAFrjmax8nAmJ7JKaEoyE0pX0CtjH4azGgy5Fyc4zm3a4DFoIO79+qMNrF6lYptsI7komYNpRzh5NI28RAPqTHd8ihuhli+ew5PrcpaCwDO4RFkJjwkkzr8ZzXya4efs57DPWxAEQTinPB/2LVAmVuccv/C8Vzi0HK48AltUOXS29/RmTs+eTuQfB3AxnBsyc4bVrTX8EdOUdKk9Ifq2jGrfhBHtGxPoUXnYrKIM0h/JWIzKkF1wE086DIqkcbMrmxCJRMhBruVEKLfEyJH0Ynan5LMtMZddyfkYzFZaWJMYnreeDllHcD5rxFx68VitU6tWuN90Ex4DB6Br3Pg/r2GxWUgqTOJQxhGOH08lJ6UYa5YOn+IQPA2Vt2o3OpUgB5fiE+VMXHworSKa4ap1rSKyIAiCUGdkGZI3Kz1ER5eBufTCa74xENsPYm6GsC6gufgPZFNBPkfmTMPy0zJcci+872gj+DtOw6bQGPJs7UkI7MYtLaO4uUUQPq4XxygtMLLrz2QObzyL1aIsiPEPc6dlr0bEdAhEW82drWtDJEIOcrUTIYPZypn8MlLzyknJKyM1r4yT2SUcSS+isKiIUCmbMDJIKDxGm6xT+GflY81RIdsuZN2SRsK1bQvcBt+O2w03XLLnx2KzcDLvJAcSj3I68Sx5Z0sw56rxKQnGqzzgomGu86zu5biHq4loFkibNk3w9nMTc3sEQRCuJaYyOL5C2a36xF9gNV14TecGUTdAZE8lKQpsUbFZo2yxULR2LWe++RJp1wGkc7/9bRKcDIZ9kSr2BIdw1D2eFr5dGdC0DT1j/WkScOH3QGmBkd1/JnPoHwmR3kVD085BxCQEEhjpUWe/M0Qi5CCX/I+0WaEkU1nKWJ6vPAwF5z4WgcUIFsO5j+VgMWKTwWS1YbbKmKwyZqsNk1XGZDn30WrDbLFhstoqnjNblS8cDTbcKcNdKsPNVoZrQTmaXCvl2TrKsnRYTRdn11pPLa7xTXEbMhrXPv1Rubhc9LrBZORQ4gmOJyVyJjWbkkwTUr4zXmUBaG36Kv8vbK5GXEPUNI7yJTY2jKAIL5xcqy4GKAiCIFyDDIVwag2cWKk8SrMufl3vCaEdIbwLNO4Iwa3ByRNzZhZFK1aQ9dtPcOj4xSG1cCoYTgQ6c9QrgmzvdsTG9aZzdChtQr2IDXTHVGrmyOZ0Dm1MoyjHUPFeNx890e0CiGjlR1CUBxqt43qK6nUiNGPGDN577z0yMjJo06YN06dPp2PHjpc8f/Hixbz88sskJSURExPD//3f/zFw4MBqXaviP/LHJ/Cw5EDRWeVRknlhyWIdkmUwl6ox5Gsx5Gspz9FRnqtFtl7cO6PSq3CJC8O1a1fcBtyOtklTrBYbxbkGUtMySUxJIzM9n5IcE7YCDfoyV1RU/QVnU1nBy4h7kI7GYf5ERzcmMNzzmt5KXRAEQaghmw0y9sHJ1ZCyBVK2wbkSRhfxiYLgNsojqBVmqzelBxLJXr8aw5ZtaErKK73FpIZ0by1nPLxJdwtB698Uz9AofCMb4+EUgCndSsaRAszGC79H1VoVwdGeNGrqTUC4OwFhHji52f/Hdr1NhBYuXMi4ceOYNWsWnTp1Ytq0aSxevJhjx44REFB5yGfz5s307NmTt99+m8GDB/P999/zf//3f+zevZuWLVte9noV/5HPu+Ohv7j7ziKryMWDAtmNQlwplN0okF0pxgUDOoyyFiPKw4wGGQkJGRedGhed5txHFa5aNS46Na4GIy6FJTgVlqDJK0aVnovlTA5yualSuyR3dzRtO0DLTpgbN6XExYeMnHzyc4opzTdhKZRQGf47cbGoTJjcS9D7SPiFuBMV1YiYqHC8A1xQqa+tHUIFQRCEOmazQsYBJSlK3gxn90JhStXnal3BrwmyTywmSwCFmVZSTyRhPJ6Ma3oROst/pwoGtZpCJ09y/eMp9m2JwSUUq9ql0nlOzjLuXmo8/ZzwCXbFt7EXXo29cPNxvuxeRfU2EerUqRMdOnTg008/BcBmsxEaGsqjjz7K888/X+n8UaNGUVpayu+//17xXOfOnYmPj2fWrFmXvd75/8gPnx5JgS6QDNmH9HOPXDxRqdT4uunwddXj66bDz02Pr6sOXzc9vi5afNRWfGQj7jYjHhYjTiWF2HJzMGdlYcnKwpKVjSkjk7KzOVisEhaNs/JQO2PROGHWumFy8sToE4TBzQeDzg2T7ITNpEWSLz+ualYZKXLKwexWht4HvANdadQogOaRTYhuFC52ahYEQRAurSwP0vede+yFzMOQd+rCnkVVkCU9Z9XBHDO6kplvpTTPgL7IjG+xjG8ReFTuQEIGylyCyPNuSqFHFMXuYZS7/PdKZpXViMZSgspShiQbQbKCygZqGTQSBtnApNlPOzwRuqpbRZpMJnbt2sWUKVMqnlOpVPTt25ctW7ZU+Z4tW7YwefLki57r168fv/zyS5XnG41GjEZjxb+LipRCn+qz7QjVORGGhCSBJOehkvOQZBlJBslW+aPNpiJbpSFTpcGm0mKTNNhUykNWNcYmRWBV67E10kGjavwH2IBzQ6vnU6AybRHF+jxKdPmYXcrQeapw89Hj5+9JaEgQsUHRRHn1xknz37uDCoIgCEIlLj4Q3Vt5nGc1Q36Ssjw/+xjknIDck8peRsXpSLKRRpYkGqkBP+VRqJI4ptNxRKfjuFrHWZOOYrMaJwO4lysPt/JM3MszcS/fgHMueGQ4oVI1AnUgNnUAFp0/BucADHpvrBonbGo9JrUe9L5VNr3cVFrl87V1VROhnJwcrFYrgYGBFz0fGBjI0aNHq3xPRkZGledn/KOMxD+9/fbbvPbaa5WeN+mbo9bV7TJws8qISV2OUWPApC7HpDZg0pZhcTKCswXJxYazuwZ3Txe8vT3w9/Um0C0Af5dYGrs3xkN3bS3vFwRBEOohtRb8YpRHs0EXv2Y1Q1GakhQVpELRGSjLw7Msl46lOXQsy4WyXDDlYjWXkaFTk+KiIVWrJVWjIVOj5rBaRa5aTa7aQL4qEVlKUmLLMlorOBvBrVyHd7knHuXuuJk8cTa54WRxRmd1QWt1QiO7IJvr5tO/+sVD6tiUKVMu6kEqKioiNDQUH59DuOjP9apIEqgkZLUK1CpklQpZLSnHGjWoVNi0amRnNTYXDehUSBoJSS2DGlQa0Om0aHUanPQ69M5anF106LWe6NV6dGodHjoPPHQeOGucxXJ0QRAE4fqg1oJ3hPK43Kk2K43MZTQyldLFVAr/fFhNYDNjs5gos5RRai6l1FJGmbmcUms55RYDFtmKWbZikW1YZBtmuRizXKD8GxtSqRG+c/yneFUTIT8/P9RqNZmZmRc9n5mZSVBQUJXvCQoKqtH5er0evb7y8vERrzx8zW2oKAiCIAjXLZVaqYVWRT20ilMAt3OPmioqKuIxFtnbuku6qkuJdDod7du3Z/Xq1RXP2Ww2Vq9eTZcuXap8T5cuXS46H2DlypWXPF8QBEEQBOFSrvrQ2OTJkxk/fjwJCQl07NiRadOmUVpayoQJEwAYN24cjRo14u233wbg8ccfp1evXnzwwQcMGjSIBQsWsHPnTr744our+WkIgiAIgnAduuqJ0KhRo8jOzuaVV14hIyOD+Ph4VqxYUTEhOiUlBZXqQsdV165d+f7773nppZd44YUXiImJ4ZdffqnWHkKCIAiCIAj/dNX3EbrSrnatMUEQBEEQaq6ufn+L7YYFQRAEQWiwRCIkCIIgCEKDJRIhQRAEQRAaLJEICYIgCILQYIlESBAEQRCEBkskQoIgCIIgNFgiERIEQRAEocESiZAgCIIgCA2WSIQEQRAEQWiwrnqJjSvt/EbaRUVFV7klgiAIgiBU1/nf244uiNHgEqHc3FwAQkNDr3JLBEEQBEGoqdzcXDw9PR0Wr8ElQj4+PoBSzNWR/5FCzRUVFREaGkpqaqqo+3YNEPfj2iHuxbVD3ItrR2FhIWFhYRW/xx2lwSVC5yvZe3p6ii/qa4SHh4e4F9cQcT+uHeJeXDvEvbh2nP897rB4Do0mCIIgCIJwHRGJkCAIgiAIDVaDS4T0ej1Tp05Fr9df7aY0eOJeXFvE/bh2iHtx7RD34tpRV/dCkh29Dk0QBEEQBOE60eB6hARBEARBEM4TiZAgCIIgCA2WSIQEQRAEQWiwRCIkCIIgCEKDVS8ToRkzZhAREYGTkxOdOnVi+/bt/3n+4sWLadasGU5OTrRq1Yrly5dfoZbWfzW5F19++SU9evTA29sbb29v+vbte9l7J9RMTb83zluwYAGSJHHrrbfWbQMbkJrei4KCAiZNmkRwcDB6vZ7Y2Fjxs8pBanovpk2bRtOmTXF2diY0NJQnn3wSg8FwhVpbf23YsIEhQ4YQEhKCJEn88ssvl33PunXraNeuHXq9niZNmjB37tyaX1iuZxYsWCDrdDp5zpw58qFDh+T77rtP9vLykjMzM6s8/++//5bVarX87rvvyocPH5ZfeuklWavVygcOHLjCLa9/anov7rzzTnnGjBnynj175CNHjsh333237OnpKZ85c+YKt7x+qun9OC8xMVFu1KiR3KNHD3no0KFXprH1XE3vhdFolBMSEuSBAwfKmzZtkhMTE+V169bJe/fuvcItr39qei/mz58v6/V6ef78+XJiYqL8559/ysHBwfKTTz55hVte/yxfvlx+8cUX5SVLlsiA/PPPP//n+adPn5ZdXFzkyZMny4cPH5anT58uq9VqecWKFTW6br1LhDp27ChPmjSp4t9Wq1UOCQmR33777SrPHzlypDxo0KCLnuvUqZP8wAMP1Gk7G4Ka3ot/s1gssru7u/zNN9/UVRMbFHvuh8Vikbt27SrPnj1bHj9+vEiEHKSm9+Kzzz6To6KiZJPJdKWa2GDU9F5MmjRJ7tOnz0XPTZ48We7WrVudtrOhqU4i9Oyzz8otWrS46LlRo0bJ/fr1q9G16tXQmMlkYteuXfTt27fiOZVKRd++fdmyZUuV79myZctF5wP069fvkucL1WPPvfi3srIyzGazwwvsNUT23o/XX3+dgIAA7r333ivRzAbBnnvx22+/0aVLFyZNmkRgYCAtW7bkrbfewmq1Xqlm10v23IuuXbuya9euiuGz06dPs3z5cgYOHHhF2ixc4Kjf3/Wq6GpOTg5Wq5XAwMCLng8MDOTo0aNVvicjI6PK8zMyMuqsnQ2BPffi35577jlCQkIqfaELNWfP/di0aRNfffUVe/fuvQItbDjsuRenT59mzZo13HXXXSxfvpyTJ0/y8MMPYzabmTp16pVodr1kz7248847ycnJoXv37siyjMVi4cEHH+SFF164Ek0W/uFSv7+LioooLy/H2dm5WnHqVY+QUH+88847LFiwgJ9//hknJ6er3ZwGp7i4mLFjx/Lll1/i5+d3tZvT4NlsNgICAvjiiy9o3749o0aN4sUXX2TWrFlXu2kNzrp163jrrbeYOXMmu3fvZsmSJSxbtow33njjajdNsFO96hHy8/NDrVaTmZl50fOZmZkEBQVV+Z6goKAanS9Ujz334rz333+fd955h1WrVtG6deu6bGaDUdP7cerUKZKSkhgyZEjFczabDQCNRsOxY8eIjo6u20bXU/Z8bwQHB6PValGr1RXPxcXFkZGRgclkQqfT1Wmb6yt77sXLL7/M2LFjmThxIgCtWrWitLSU+++/nxdffBGVSvQvXCmX+v3t4eFR7d4gqGc9Qjqdjvbt27N69eqK52w2G6tXr6ZLly5VvqdLly4XnQ+wcuXKS54vVI899wLg3Xff5Y033mDFihUkJCRciaY2CDW9H82aNePAgQPs3bu34nHLLbfQu3dv9u7dS2ho6JVsfr1iz/dGt27dOHnyZEUyCnD8+HGCg4NFElQL9tyLsrKySsnO+QRVFqU7ryiH/f6u2Tzua9+CBQtkvV4vz507Vz58+LB8//33y15eXnJGRoYsy7I8duxY+fnnn684/++//5Y1Go38/vvvy0eOHJGnTp0qls87SE3vxTvvvCPrdDr5xx9/lNPT0ysexcXFV+tTqFdqej/+Tawac5ya3ouUlBTZ3d1dfuSRR+Rjx47Jv//+uxwQECC/+eabV+tTqDdqei+mTp0qu7u7yz/88IN8+vRp+a+//pKjo6PlkSNHXq1Pod4oLi6W9+zZI+/Zs0cG5A8//FDes2ePnJycLMuyLD///PPy2LFjK84/v3z+mWeekY8cOSLPmDFDLJ8/b/r06XJYWJis0+nkjh07ylu3bq14rVevXvL48eMvOn/RokVybGysrNPp5BYtWsjLli27wi2uv2pyL8LDw2Wg0mPq1KlXvuH1VE2/N/5JJEKOVdN7sXnzZrlTp06yXq+Xo6Ki5P/973+yxWK5wq2un2pyL8xms/zqq6/K0dHRspOTkxwaGio//PDDcn5+/pVveD2zdu3aKn8HnP//Hz9+vNyrV69K74mPj5d1Op0cFRUlf/311zW+riTLoi9PEARBEISGqV7NERIEQRAEQagJkQgJgiAIgtBgiURIEARBEIQGSyRCgiAIgiA0WCIREgRBEAShwRKJkCAIgiAIDZZIhARBEARBaLBEIiQIgiAIQoMlEiFBEARBEBoskQgJgiAIgtBgiURIEARBEIQGSyRCgiAIgiA0WP8PZXmIpU9Pw30AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plotLabelsDensity(labels_path_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP1HB_O1pAc4"
      },
      "source": [
        "# create data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrZzA7hkihi6"
      },
      "outputs": [],
      "source": [
        "def pad_audio(audio, target_length):\n",
        "    \"\"\"Pads audio tensor with zeros to reach target length.\"\"\"\n",
        "    current_length = audio.shape[0]\n",
        "    if current_length < target_length:\n",
        "        pad_shape = (target_length - current_length,) + audio.shape[1:]\n",
        "        padding = torch.zeros(pad_shape, dtype=audio.dtype, device=audio.device)\n",
        "        audio = torch.cat([audio, padding], dim=0)\n",
        "    return audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vePNuiH-ikS4"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function to pad audio tensors.\"\"\"\n",
        "    # Determine maximum audio length\n",
        "    max_length = max([item[0].shape[0] for item in batch])\n",
        "\n",
        "    # Pad audios and stack\n",
        "    audios = [pad_audio(item[0], max_length) for item in batch]\n",
        "    audios = torch.stack(audios)\n",
        "\n",
        "    # Stack labels\n",
        "    labels = torch.stack([item[1] for item in batch])\n",
        "\n",
        "    return audios, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRvIxIlsq3io"
      },
      "outputs": [],
      "source": [
        "training_batch_size = 4\n",
        "training_shuffle = False\n",
        "\n",
        "validation_batch_size = 4\n",
        "validation_shuffle = False\n",
        "\n",
        "test_batch_size = 10\n",
        "test_shuffle = False\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=training_batch_size, shuffle=training_shuffle, collate_fn=custom_collate_fn)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=validation_batch_size, shuffle=validation_shuffle, collate_fn=custom_collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=test_shuffle, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh3Eo6FPsGol"
      },
      "source": [
        "## check representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTGtbsO8rKC3",
        "outputId": "48fcc5b2-81c6-481c-ed5d-198496be479d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-ddeab408b034>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([tensor([[[[[-1.6185, -1.5847, -1.1902,  ..., -3.4072, -3.5870, -3.4306],\n",
              "             [-2.1195, -1.6062, -1.1916,  ..., -3.4606, -3.3710, -3.4906],\n",
              "             [-1.9159, -1.7382, -1.6869,  ..., -2.8378, -2.5718, -3.2384],\n",
              "             ...,\n",
              "             [-1.1377, -2.0529, -0.1281,  ..., -3.0333, -2.6990, -2.2411],\n",
              "             [-0.8143, -1.2311, -0.0753,  ..., -3.2123, -3.2395, -2.2268],\n",
              "             [-0.2991, -1.2939,  0.1386,  ..., -3.1798, -3.2643, -2.3432]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.0626, -0.0465,  0.5948,  ..., -2.8954, -3.1693, -2.4981],\n",
              "             [-0.1258,  0.0101,  0.7601,  ..., -2.8014, -2.8344, -2.4375],\n",
              "             [ 0.0076,  0.2959,  0.8440,  ..., -2.6690, -2.7176, -2.6978],\n",
              "             ...,\n",
              "             [-0.4506,  0.1578,  0.3346,  ..., -3.2503, -3.5987, -4.0602],\n",
              "             [-0.5263,  0.1499,  0.1762,  ..., -2.4552, -2.9378, -2.9855],\n",
              "             [-0.4448, -0.0204, -0.2610,  ..., -3.2503, -3.2236, -3.3454]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.6437, -1.5323, -1.1919,  ..., -3.0040, -2.8772, -2.9258],\n",
              "             [-1.2478, -0.8213, -0.9122,  ..., -3.0097, -3.5606, -2.5734],\n",
              "             [-1.2877, -1.5099, -2.6998,  ..., -3.0141, -2.8173, -2.0559],\n",
              "             ...,\n",
              "             [-0.8125, -0.3137, -0.3071,  ..., -2.9523, -2.9756, -3.6528],\n",
              "             [-0.7716,  0.2673,  0.4758,  ..., -2.9363, -3.3634, -3.7162],\n",
              "             [-0.9339,  0.3521,  0.4159,  ..., -2.9475, -2.7957, -3.2183]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-1.7477, -1.1458, -1.0718,  ..., -2.0545, -1.9274, -2.2207],\n",
              "             [-1.0103, -1.3271, -1.3800,  ..., -1.5735, -1.7993, -2.3970],\n",
              "             [-0.5812, -0.8442, -1.1417,  ..., -2.1493, -2.5166, -2.5762],\n",
              "             ...,\n",
              "             [ 1.1000,  0.7775, -0.0836,  ..., -1.6259, -1.4136, -1.7847],\n",
              "             [ 0.8894,  0.0633,  0.5438,  ..., -1.4402, -1.2733, -1.7050],\n",
              "             [ 0.9482,  0.1719,  0.6047,  ..., -1.6257, -1.6629, -2.1581]]],\n",
              "  \n",
              "  \n",
              "           [[[ 0.8594,  0.5055,  1.1118,  ..., -1.9898, -1.9248, -2.4742],\n",
              "             [ 0.3286, -0.1784,  0.8416,  ..., -2.3397, -2.5108, -2.4239],\n",
              "             [-0.4521, -0.4551,  0.0217,  ..., -2.7245, -3.0702, -2.5902],\n",
              "             ...,\n",
              "             [ 0.3759,  0.4184,  0.5939,  ..., -2.8587, -2.1001, -1.6088],\n",
              "             [ 0.0754,  0.3555,  0.2308,  ..., -2.4965, -2.5489, -2.2640],\n",
              "             [-1.7117, -1.2083, -1.4453,  ..., -2.4874, -2.2881, -2.1050]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.7377, -0.9114, -0.8340,  ..., -2.5084, -2.2838, -1.9535],\n",
              "             [-0.6805, -1.2076, -2.1367,  ..., -2.5694, -2.5644, -2.8087],\n",
              "             [-1.5239, -1.3480, -1.4600,  ..., -2.9374, -2.4074, -2.9047],\n",
              "             ...,\n",
              "             [-0.2287,  0.1126,  0.4197,  ..., -1.7896, -1.9069, -1.6583],\n",
              "             [-0.1170, -0.6324,  0.3650,  ..., -1.6128, -2.3887, -2.2534],\n",
              "             [-0.0589, -0.5288,  0.4014,  ..., -2.3996, -2.0600, -1.4994]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-0.4297, -0.9899,  0.4111,  ...,  0.2982,  1.1835,  0.3098],\n",
              "             [-0.3649, -0.7210,  1.1008,  ...,  0.3129,  1.0047,  0.3497],\n",
              "             [-0.9783, -2.1329,  1.1565,  ...,  0.1143,  0.2023, -0.2500],\n",
              "             ...,\n",
              "             [-1.2379, -1.0791, -0.9386,  ..., -0.1513, -0.9940, -1.0425],\n",
              "             [-2.0462, -1.4929, -1.2431,  ..., -0.3009, -0.5204, -0.5391],\n",
              "             [-0.6061, -0.2453, -0.2317,  ..., -0.2190, -0.3791, -0.4753]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.0117, -1.3001, -0.9273,  ..., -0.2997, -0.5041, -0.5245],\n",
              "             [-1.0251, -1.1662, -1.6203,  ..., -0.3852, -0.4550, -0.4023],\n",
              "             [-0.9059, -1.0033, -1.5315,  ..., -0.4958, -0.3869, -0.8200],\n",
              "             ...,\n",
              "             [-1.2206, -0.8982, -0.7266,  ...,  0.0268,  0.2760, -0.3405],\n",
              "             [-0.4413, -0.7464, -0.8701,  ..., -0.0459, -0.1325, -0.8403],\n",
              "             [ 0.1083, -0.4135, -0.9967,  ...,  0.0913,  0.0677, -0.7284]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.4748, -0.6562, -1.1529,  ...,  0.1113,  0.0877, -1.2227],\n",
              "             [-0.1930, -0.5974, -0.5870,  ...,  0.1863,  0.0136, -0.9497],\n",
              "             [-0.1710, -0.6986, -2.0354,  ..., -0.2668, -0.4564, -1.1815],\n",
              "             ...,\n",
              "             [ 2.0539,  1.9695,  1.0811,  ...,  0.9557,  0.0984,  0.2156],\n",
              "             [ 1.8512,  1.8332,  0.9890,  ...,  0.3088,  0.5220,  0.2469],\n",
              "             [ 1.7146,  1.6418,  0.7720,  ...,  0.3595,  0.8046,  0.3063]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-1.1302, -0.1538,  0.0602,  ...,  1.0908,  1.2463,  1.1112],\n",
              "             [-0.9227, -0.4041, -0.4514,  ...,  1.1915,  1.2847,  0.7636],\n",
              "             [ 0.4223,  1.0883,  1.3629,  ...,  1.0857,  0.6917,  0.8430],\n",
              "             ...,\n",
              "             [ 2.1466,  1.5587,  0.3013,  ..., -1.1308, -0.6084, -0.6562],\n",
              "             [ 2.0516,  1.5952, -0.0608,  ..., -1.3250, -0.6661, -1.0746],\n",
              "             [ 1.7426,  0.5687,  0.7286,  ..., -0.3594, -0.4194, -0.8708]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.7229,  1.1992,  0.8335,  ..., -0.5146, -0.5022, -0.4043],\n",
              "             [ 1.4558,  0.2236,  0.5393,  ..., -0.4765, -0.3575, -0.9614],\n",
              "             [ 1.3934,  0.0403,  0.8419,  ..., -0.0834, -0.5557, -1.2644],\n",
              "             ...,\n",
              "             [-1.0004, -1.5567, -0.7329,  ...,  0.0705, -0.2210, -0.4851],\n",
              "             [-0.3805, -0.7225, -1.1175,  ...,  0.7634,  0.5964,  0.4306],\n",
              "             [-0.7554, -0.5700, -0.4954,  ...,  1.1948,  0.9522,  0.9274]]],\n",
              "  \n",
              "  \n",
              "           [[[ 0.8296,  1.3727,  1.7042,  ...,  0.9389,  0.9833,  1.0085],\n",
              "             [ 1.5533,  2.1899,  2.5849,  ...,  0.0590, -0.1392,  0.1777],\n",
              "             [ 0.5631,  0.2951,  1.4189,  ..., -0.4781, -0.4682, -0.5128],\n",
              "             ...,\n",
              "             [-1.7841, -2.0348, -1.7029,  ...,  0.6240,  1.0457,  0.8150],\n",
              "             [-1.6169, -1.3446, -1.9190,  ...,  0.7427,  0.0943,  0.2250],\n",
              "             [-1.3287, -1.4321, -2.2305,  ...,  0.8831,  0.7209,  0.3149]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-2.0067, -0.6726, -0.0514,  ..., -2.8497, -2.9083, -3.2057],\n",
              "             [-1.8316, -0.5434,  0.0970,  ..., -3.1450, -3.6215, -3.6890],\n",
              "             [-2.2260, -0.3387,  0.1320,  ..., -3.2317, -3.5672, -3.3622],\n",
              "             ...,\n",
              "             [-2.5390, -2.5609, -2.5947,  ..., -1.5151, -2.0872, -2.4051],\n",
              "             [-3.0797, -2.7356, -3.1169,  ..., -1.3853, -1.7116, -2.3992],\n",
              "             [-2.8733, -3.0609, -3.7647,  ..., -1.2334, -1.2342, -2.5255]]],\n",
              "  \n",
              "  \n",
              "           [[[-2.9354, -2.8878, -3.5547,  ..., -1.3584, -1.4493, -2.1463],\n",
              "             [-2.5933, -3.0292, -3.1522,  ..., -1.7223, -1.8107, -1.9868],\n",
              "             [-3.8056, -3.1750, -3.0089,  ..., -1.8111, -1.8371, -2.1170],\n",
              "             ...,\n",
              "             [-1.5649, -0.1683,  0.3413,  ..., -3.9739, -3.9101, -4.1892],\n",
              "             [-1.8862, -0.5014,  0.0356,  ..., -3.8540, -3.7023, -4.0231],\n",
              "             [-1.6379, -1.6305, -0.7571,  ..., -3.8728, -4.0145, -4.1731]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.0526, -1.0456, -1.0766,  ..., -3.6081, -3.8904, -3.9403],\n",
              "             [-1.7657, -1.3865, -1.1199,  ..., -3.7592, -3.8354, -3.7848],\n",
              "             [-2.1921, -1.7912, -1.6577,  ..., -3.2030, -3.5523, -4.0099],\n",
              "             ...,\n",
              "             [-2.9672, -3.0794, -3.5603,  ..., -0.5786, -0.4945, -0.5048],\n",
              "             [-3.4722, -3.5390, -3.4488,  ..., -0.5057,  0.0285, -0.5930],\n",
              "             [-3.1556, -3.7075, -3.1519,  ...,  0.1962,  0.5474, -0.0226]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-0.1389,  0.3731,  0.1251,  ..., -3.7824, -3.2438, -2.6609],\n",
              "             [-0.2530,  0.2639,  0.0138,  ..., -3.4046, -3.1266, -2.9011],\n",
              "             [-0.1853,  0.2634, -0.0242,  ..., -3.1272, -3.1659, -3.5899],\n",
              "             ...,\n",
              "             [-2.6867, -2.0462, -0.8079,  ..., -2.5017, -3.3915, -3.4819],\n",
              "             [-2.4201, -1.4561, -0.7627,  ..., -2.5814, -3.5678, -4.1038],\n",
              "             [-3.2369, -2.0764, -0.9688,  ..., -2.9221, -3.8217, -4.1549]]],\n",
              "  \n",
              "  \n",
              "           [[[-3.5003, -1.8371, -0.8553,  ..., -2.9689, -4.0268, -4.1108],\n",
              "             [-2.7415, -1.7997, -0.8898,  ..., -3.1837, -3.8612, -3.8635],\n",
              "             [-2.9303, -1.6053, -0.9068,  ..., -3.3083, -3.5019, -3.7558],\n",
              "             ...,\n",
              "             [-1.0600, -0.0458,  0.1025,  ..., -3.5015, -3.1520, -3.3011],\n",
              "             [-0.6849, -0.0376, -0.1886,  ..., -3.0035, -2.8869, -3.2425],\n",
              "             [-1.0207, -0.0368,  0.0654,  ..., -3.5793, -3.0067, -3.0950]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.5169,  0.1127,  0.0143,  ..., -3.8250, -3.3466, -3.5399],\n",
              "             [-0.6447,  0.1187,  0.1041,  ..., -3.7407, -3.6461, -3.6909],\n",
              "             [-0.6026,  0.1273,  0.0694,  ..., -3.7527, -3.8125, -3.5926],\n",
              "             ...,\n",
              "             [-2.5861, -1.8025, -0.7476,  ..., -3.0146, -2.6172, -2.8996],\n",
              "             [-2.2322, -1.5492, -0.8722,  ..., -2.5637, -2.1955, -2.7475],\n",
              "             [-4.3763, -3.7686, -2.0335,  ..., -2.8736, -2.1879, -2.4776]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-1.0468, -0.9843, -0.5584,  ..., -2.7159, -2.8236, -2.8887],\n",
              "             [-2.4708, -1.3800, -0.6147,  ..., -2.9054, -2.9996, -3.1238],\n",
              "             [-1.2375, -1.2741, -0.7263,  ..., -2.6500, -2.8702, -3.1439],\n",
              "             ...,\n",
              "             [-1.5120, -1.0256, -0.3610,  ..., -2.4836, -2.3585, -2.7130],\n",
              "             [-1.9608, -0.9287, -0.2421,  ..., -2.4562, -2.6781, -2.4705],\n",
              "             [-1.4924, -1.2096, -0.2732,  ..., -2.4386, -2.6894, -2.4916]]],\n",
              "  \n",
              "  \n",
              "           [[[-2.7164, -0.7141, -0.1507,  ..., -2.7552, -2.2773, -1.6681],\n",
              "             [-2.6472, -1.1017, -0.2175,  ..., -2.7193, -2.0767, -1.7469],\n",
              "             [-1.5384, -0.8383, -0.2110,  ..., -2.2298, -1.6715, -1.7778],\n",
              "             ...,\n",
              "             [-2.5735, -1.8249, -1.0902,  ..., -2.1837, -2.0658, -2.1664],\n",
              "             [-2.4186, -1.5693, -0.7616,  ..., -2.1160, -1.5228, -1.2331],\n",
              "             [-2.1927, -1.2906, -0.8778,  ..., -2.0962, -1.8650, -2.1559]]],\n",
              "  \n",
              "  \n",
              "           [[[-2.0415, -1.0079, -0.4267,  ..., -2.6754, -2.6427, -2.8513],\n",
              "             [-0.9371, -0.2536,  0.1129,  ..., -2.3398, -2.6871, -2.3311],\n",
              "             [-1.0237, -0.3289, -0.0921,  ..., -1.3429, -1.6179, -1.8320],\n",
              "             ...,\n",
              "             [-1.5963, -0.9757, -0.5392,  ..., -3.2675, -3.4235, -3.9629],\n",
              "             [-1.8632, -1.0442, -0.4449,  ..., -2.6801, -2.2962, -2.4645],\n",
              "             [-1.3072, -1.8152, -0.7979,  ..., -2.1987, -2.0855, -2.7447]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-1.9740, -0.1087,  0.2788,  ..., -3.2467, -3.2835, -3.4979],\n",
              "             [-1.5874, -0.0831,  0.2690,  ..., -3.4930, -3.5973, -3.7945],\n",
              "             [-1.1988, -0.0705,  0.2096,  ..., -3.3392, -3.4356, -3.8303],\n",
              "             ...,\n",
              "             [-4.0396, -0.1288,  0.5049,  ..., -3.5794, -2.9293, -3.1961],\n",
              "             [-3.0562, -0.1474,  0.4389,  ..., -3.1368, -3.2400, -3.2865],\n",
              "             [-1.3920, -0.2644,  0.3565,  ..., -2.9444, -3.2032, -3.4840]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.2497, -0.8967,  0.0686,  ..., -2.2579, -2.9613, -3.0588],\n",
              "             [-2.0250, -1.9120, -0.5404,  ..., -2.3633, -2.8456, -3.3923],\n",
              "             [-2.3788, -1.1856, -0.8592,  ..., -2.5273, -2.6700, -3.1807],\n",
              "             ...,\n",
              "             [-2.1303,  0.4827,  1.1064,  ..., -2.2994, -2.5603, -3.1285],\n",
              "             [-0.7769,  0.7042,  1.1554,  ..., -2.5727, -2.7308, -2.9238],\n",
              "             [-0.2442,  0.7590,  1.0758,  ..., -2.4880, -3.2473, -3.1972]]],\n",
              "  \n",
              "  \n",
              "           [[[-0.2295,  0.5458,  0.6984,  ..., -2.9139, -3.2376, -3.1266],\n",
              "             [-1.6353, -0.2302,  0.6353,  ..., -2.5781, -2.5608, -2.6792],\n",
              "             [-1.7422, -0.2055,  0.7517,  ..., -2.3974, -3.4695, -3.8553],\n",
              "             ...,\n",
              "             [-1.4795, -0.1585,  0.4817,  ..., -1.9485, -1.8037, -1.7489],\n",
              "             [-1.2035,  0.0521,  0.8250,  ..., -1.3978, -1.4988, -2.1488],\n",
              "             [-1.7039, -0.1367,  0.6347,  ..., -1.2439, -1.4084, -1.1715]]]]]),\n",
              "  tensor([[0.3738, 0.4062, 0.3297, 0.2233, 0.4889],\n",
              "          [0.5607, 0.5938, 0.6374, 0.4951, 0.6667],\n",
              "          [0.6542, 0.5417, 0.5714, 0.6214, 0.6444],\n",
              "          [0.7570, 0.8854, 0.7143, 0.7670, 0.9444]])],\n",
              " [tensor([[[[[ 1.7576e+00,  1.7459e+00,  9.3987e-01,  ..., -1.1442e+00,\n",
              "              -1.2300e+00, -1.4519e+00],\n",
              "             [ 4.5712e-01,  1.5692e+00,  1.7540e+00,  ..., -1.1279e+00,\n",
              "              -1.5979e+00, -1.4633e+00],\n",
              "             [ 1.1796e+00,  1.7576e+00,  1.3994e+00,  ..., -8.7559e-01,\n",
              "              -1.2188e+00, -1.7138e+00],\n",
              "             ...,\n",
              "             [ 1.8978e+00,  2.0397e+00,  1.5576e+00,  ..., -2.4203e-01,\n",
              "               2.7382e-02, -8.5376e-01],\n",
              "             [ 1.7041e+00,  1.6195e+00,  9.9312e-01,  ..., -7.2450e-01,\n",
              "              -1.0292e-01, -1.0278e+00],\n",
              "             [ 2.1187e+00,  1.9149e+00,  1.1180e+00,  ..., -4.1849e-01,\n",
              "              -1.5222e-01, -6.0168e-01]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.9334e+00,  1.4330e+00, -3.9555e-02,  ..., -2.8356e-01,\n",
              "              -1.8065e-01, -8.6015e-01],\n",
              "             [ 1.7417e+00,  1.5033e+00,  7.8110e-01,  ..., -4.9023e-01,\n",
              "              -6.0162e-01, -1.1895e+00],\n",
              "             [ 8.5452e-01,  9.6090e-01,  2.2857e-01,  ..., -4.1408e-01,\n",
              "              -5.9722e-01, -2.6730e+00],\n",
              "             ...,\n",
              "             [ 6.1301e-01,  6.1620e-01,  5.3856e-01,  ..., -6.3753e-02,\n",
              "              -5.5096e-01, -6.0515e-01],\n",
              "             [ 2.0631e+00,  2.1110e+00,  1.9581e+00,  ..., -1.5374e-01,\n",
              "              -4.3928e-01, -5.5556e-01],\n",
              "             [ 2.3087e+00,  2.1870e+00,  1.2977e+00,  ..., -4.3342e-01,\n",
              "              -4.0403e-01, -1.0136e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.1969e+00,  1.1858e+00,  1.1229e+00,  ..., -5.9780e-01,\n",
              "              -5.9105e-01, -8.0726e-01],\n",
              "             [ 5.9568e-01, -3.9444e-02,  5.1107e-01,  ..., -4.7120e-01,\n",
              "              -2.4082e-01, -1.2400e+00],\n",
              "             [ 2.9071e-01,  4.5372e-01,  1.2956e+00,  ..., -3.2927e-01,\n",
              "              -4.4448e-01, -1.2819e+00],\n",
              "             ...,\n",
              "             [ 4.2998e-01,  9.8766e-02, -2.2965e-01,  ..., -6.8432e-01,\n",
              "              -1.1747e+00, -1.3087e+00],\n",
              "             [ 1.9501e+00,  1.6006e+00,  1.2583e+00,  ..., -2.3193e-01,\n",
              "              -5.6073e-01, -1.1063e+00],\n",
              "             [ 2.7413e+00,  2.7603e+00,  2.1388e+00,  ..., -2.7493e-01,\n",
              "               1.9579e-01, -5.3190e-01]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[ 1.6291e+00,  1.0988e+00,  5.2984e-01,  ..., -1.8618e+00,\n",
              "              -9.7484e-01, -1.6182e+00],\n",
              "             [ 1.3750e+00,  1.1382e+00,  8.1733e-01,  ..., -1.4535e+00,\n",
              "              -7.3194e-01, -1.7317e+00],\n",
              "             [ 9.5162e-02,  2.3085e-01,  3.1045e-01,  ..., -1.1564e+00,\n",
              "              -1.0066e+00, -1.3446e+00],\n",
              "             ...,\n",
              "             [ 5.7864e-01,  5.1816e-01,  6.6681e-01,  ..., -1.3953e+00,\n",
              "              -1.5073e+00, -2.3251e+00],\n",
              "             [ 7.2555e-01,  1.0338e+00,  1.1164e+00,  ..., -1.5231e+00,\n",
              "              -1.6768e+00, -2.2848e+00],\n",
              "             [ 9.1771e-01,  9.6892e-01, -2.4246e-02,  ..., -1.2733e+00,\n",
              "              -1.5620e+00, -2.5545e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.2022e+00,  1.5668e+00,  1.2811e+00,  ..., -1.0937e+00,\n",
              "              -1.6034e+00, -2.5463e+00],\n",
              "             [ 3.8930e-02,  8.6955e-01,  5.1990e-01,  ..., -9.8539e-01,\n",
              "              -7.6406e-01, -1.8219e+00],\n",
              "             [ 1.6002e+00,  1.3996e+00,  9.3704e-01,  ..., -1.2099e+00,\n",
              "              -1.1954e+00, -2.0094e+00],\n",
              "             ...,\n",
              "             [ 8.9159e-01,  1.2687e+00,  9.8776e-01,  ..., -5.9097e-01,\n",
              "              -3.4440e-01, -1.2829e+00],\n",
              "             [ 3.8296e-01,  1.1878e+00,  1.5637e+00,  ..., -7.1217e-01,\n",
              "              -2.4799e-01, -1.3094e+00],\n",
              "             [ 1.5773e+00,  1.0938e+00,  9.4050e-01,  ..., -9.5353e-01,\n",
              "              -5.7862e-01, -1.5273e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.3582e+00,  8.0837e-01, -2.4785e-01,  ..., -7.4243e-01,\n",
              "              -6.0684e-01, -1.8830e+00],\n",
              "             [ 5.2400e-01,  3.2765e-01,  1.7401e-01,  ..., -5.7557e-01,\n",
              "              -9.0040e-01, -2.3801e+00],\n",
              "             [ 1.2584e+00,  9.8167e-01,  5.3426e-01,  ..., -1.1318e-01,\n",
              "              -3.4846e-01, -2.7417e+00],\n",
              "             ...,\n",
              "             [ 1.5564e+00,  8.6478e-01,  1.9434e+00,  ..., -1.2900e+00,\n",
              "              -9.7507e-01, -1.7790e+00],\n",
              "             [ 1.7003e+00,  5.6387e-01,  2.0512e+00,  ..., -1.2053e+00,\n",
              "              -1.1321e+00, -1.6818e+00],\n",
              "             [ 1.9095e+00,  1.1467e+00,  2.1341e+00,  ..., -1.3761e+00,\n",
              "              -1.4248e+00, -1.1546e+00]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-9.5323e-02,  6.5158e-01,  7.3376e-01,  ..., -2.1012e+00,\n",
              "              -3.3414e+00, -2.8492e+00],\n",
              "             [-4.5558e-01,  4.4882e-01,  6.5677e-01,  ..., -2.2511e+00,\n",
              "              -3.7249e+00, -2.7788e+00],\n",
              "             [-6.0922e-01,  1.7891e-01,  2.3598e-01,  ..., -2.1235e+00,\n",
              "              -3.4508e+00, -2.9235e+00],\n",
              "             ...,\n",
              "             [ 1.5053e-01,  1.3702e+00,  1.6226e+00,  ..., -2.4971e+00,\n",
              "              -2.4251e+00, -2.7135e+00],\n",
              "             [ 7.4034e-01,  1.2789e+00,  1.1315e+00,  ..., -2.0145e+00,\n",
              "              -1.8521e+00, -1.9078e+00],\n",
              "             [ 7.9210e-01,  9.0406e-01,  1.7386e-01,  ..., -1.6044e+00,\n",
              "              -1.2867e+00, -1.8433e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 7.6752e-01,  8.3117e-01,  1.3562e-01,  ..., -9.0980e-01,\n",
              "              -5.3994e-01, -7.3767e-01],\n",
              "             [ 2.8339e-01,  2.5959e-01,  1.1778e-01,  ..., -8.1161e-01,\n",
              "              -6.4411e-01, -7.7489e-01],\n",
              "             [-1.7260e-01, -6.0725e-02, -5.6340e-02,  ..., -1.6187e+00,\n",
              "              -1.5709e+00, -1.6524e+00],\n",
              "             ...,\n",
              "             [-6.8342e-02,  6.2623e-01,  5.7877e-01,  ..., -3.7405e+00,\n",
              "              -2.9685e+00, -2.3660e+00],\n",
              "             [-1.2523e+00, -1.4482e-01,  1.1243e-01,  ..., -4.2260e+00,\n",
              "              -3.7805e+00, -3.1184e+00],\n",
              "             [-2.0424e+00, -1.1761e+00, -3.9033e-01,  ..., -4.2173e+00,\n",
              "              -3.9161e+00, -3.3777e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.3356e+00, -4.6994e-01, -1.8441e-01,  ..., -4.1670e+00,\n",
              "              -4.0865e+00, -4.0746e+00],\n",
              "             [-2.7372e+00, -5.7690e-01, -2.2091e-01,  ..., -4.0662e+00,\n",
              "              -3.5663e+00, -3.1172e+00],\n",
              "             [-1.5224e+00, -8.9279e-01, -6.3587e-01,  ..., -3.3876e+00,\n",
              "              -2.1686e+00, -1.4818e+00],\n",
              "             ...,\n",
              "             [ 7.4596e-01,  6.5714e-01, -2.6614e-01,  ..., -3.9147e+00,\n",
              "              -3.2042e+00, -2.7799e+00],\n",
              "             [ 8.0898e-01,  6.0164e-01, -9.4572e-01,  ..., -3.5407e+00,\n",
              "              -3.0000e+00, -2.7345e+00],\n",
              "             [ 7.0850e-01,  6.0271e-01, -2.8079e-01,  ..., -3.6647e+00,\n",
              "              -2.4804e+00, -2.5133e+00]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[ 3.5733e-01, -2.9563e-01,  8.5732e-03,  ..., -3.6216e+00,\n",
              "              -3.5935e+00, -3.5661e+00],\n",
              "             [ 3.3643e-01,  2.7432e-01, -1.0489e-01,  ..., -4.0620e+00,\n",
              "              -3.6409e+00, -3.5430e+00],\n",
              "             [ 6.5797e-01,  2.2024e-01, -6.0214e-01,  ..., -4.0244e+00,\n",
              "              -3.8835e+00, -3.8105e+00],\n",
              "             ...,\n",
              "             [ 9.9232e-01,  2.6975e-01,  4.3008e-01,  ..., -4.1295e+00,\n",
              "              -4.2241e+00, -3.4185e+00],\n",
              "             [ 1.1523e+00,  2.7860e-01,  8.6224e-01,  ..., -4.2793e+00,\n",
              "              -4.3270e+00, -3.2979e+00],\n",
              "             [ 1.1871e+00,  1.0523e-01,  1.4085e+00,  ..., -4.2893e+00,\n",
              "              -4.3520e+00, -3.2627e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.2261e+00, -1.0717e+00,  1.5740e+00,  ..., -4.3177e+00,\n",
              "              -4.0817e+00, -3.3966e+00],\n",
              "             [ 1.2285e+00,  1.9633e-01,  1.4651e+00,  ..., -4.0419e+00,\n",
              "              -3.5608e+00, -2.7747e+00],\n",
              "             [ 1.2401e+00,  5.6374e-01,  1.4247e+00,  ..., -3.9932e+00,\n",
              "              -3.3359e+00, -2.9303e+00],\n",
              "             ...,\n",
              "             [ 2.5127e-01, -1.0265e+00, -4.5806e-01,  ..., -3.3706e+00,\n",
              "              -2.9305e+00, -3.4979e+00],\n",
              "             [ 5.6754e-01, -6.3808e-01,  1.9747e-01,  ..., -3.5085e+00,\n",
              "              -3.0839e+00, -3.2876e+00],\n",
              "             [ 6.2392e-01, -5.4074e-01,  2.7912e-01,  ..., -3.4859e+00,\n",
              "              -2.7842e+00, -2.3315e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.8117e-01, -6.8810e-01,  3.5255e-01,  ..., -3.5191e+00,\n",
              "              -2.7828e+00, -2.3342e+00],\n",
              "             [-2.2066e-03, -4.0258e-01,  4.8302e-01,  ..., -3.3528e+00,\n",
              "              -2.6849e+00, -2.2783e+00],\n",
              "             [ 1.8349e-01, -2.6109e-01,  6.4053e-01,  ..., -3.4974e+00,\n",
              "              -3.2451e+00, -2.4279e+00],\n",
              "             ...,\n",
              "             [-1.5996e+00, -2.3967e+00, -2.1970e+00,  ..., -4.2612e+00,\n",
              "              -4.0512e+00, -4.1814e+00],\n",
              "             [-1.3140e+00, -1.9571e+00, -2.4407e+00,  ..., -2.3333e+00,\n",
              "              -6.7868e-01, -4.1947e-01],\n",
              "             [-1.1768e+00, -2.0447e+00, -1.7895e+00,  ..., -1.7053e+00,\n",
              "              -5.0068e-01, -2.4969e-01]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-1.0401e+00, -4.5384e-01, -6.5487e-01,  ..., -2.6028e+00,\n",
              "              -2.9035e+00, -3.6702e+00],\n",
              "             [-4.6392e-01,  7.8796e-02,  3.0233e-01,  ..., -2.8939e+00,\n",
              "              -2.8184e+00, -3.2002e+00],\n",
              "             [-2.1756e-01,  3.1654e-02,  4.2394e-02,  ..., -3.1305e+00,\n",
              "              -2.9415e+00, -3.2737e+00],\n",
              "             ...,\n",
              "             [-1.4042e+00, -1.0062e+00, -9.6395e-01,  ..., -2.4812e+00,\n",
              "              -2.7966e+00, -2.8921e+00],\n",
              "             [-9.1798e-01, -6.5832e-01, -4.7323e-01,  ..., -2.5536e+00,\n",
              "              -2.3062e+00, -2.5898e+00],\n",
              "             [-1.3014e+00, -2.2462e+00, -1.2265e+00,  ..., -2.6292e+00,\n",
              "              -2.3015e+00, -2.6245e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[-3.9146e-01, -2.6531e-01, -6.0931e-01,  ..., -2.5237e+00,\n",
              "              -2.7406e+00, -2.9566e+00],\n",
              "             [-1.1391e+00, -2.9880e-01, -2.1062e-01,  ..., -2.4189e+00,\n",
              "              -2.3971e+00, -3.0539e+00],\n",
              "             [-6.1963e-01, -1.2826e+00, -2.1535e+00,  ..., -2.5843e+00,\n",
              "              -2.3693e+00, -3.2770e+00],\n",
              "             ...,\n",
              "             [ 1.0505e+00,  1.0492e+00,  1.6984e-01,  ..., -1.6718e+00,\n",
              "              -2.0179e+00, -1.9224e+00],\n",
              "             [ 1.1419e+00,  1.1628e+00,  3.5071e-01,  ..., -1.8888e+00,\n",
              "              -2.2661e+00, -2.3399e+00],\n",
              "             [ 1.1982e+00,  1.1949e+00,  4.6775e-01,  ..., -1.8318e+00,\n",
              "              -1.8251e+00, -2.0964e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 1.1338e+00,  1.0809e+00,  4.7257e-01,  ..., -1.4585e+00,\n",
              "              -1.7555e+00, -2.1519e+00],\n",
              "             [ 5.8342e-01,  2.2807e-01, -1.3348e-01,  ..., -1.5549e+00,\n",
              "              -1.5314e+00, -2.0016e+00],\n",
              "             [ 4.6466e-02, -3.1281e-01, -1.1483e+00,  ..., -7.6511e-01,\n",
              "              -1.1887e+00, -1.0954e+00],\n",
              "             ...,\n",
              "             [-9.8834e-02, -3.5442e-01,  3.3993e-01,  ..., -1.8111e+00,\n",
              "              -1.8927e+00, -1.6217e+00],\n",
              "             [-1.0190e+00, -3.7897e-01,  4.9308e-01,  ..., -1.8578e+00,\n",
              "              -1.8534e+00, -1.5668e+00],\n",
              "             [-9.5720e-01, -6.2303e-01,  2.9569e-01,  ..., -1.8448e+00,\n",
              "              -1.5350e+00, -1.7937e+00]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-1.1413e+00, -4.1315e-01, -3.1070e-02,  ..., -1.6096e+00,\n",
              "              -2.0753e+00, -2.1572e+00],\n",
              "             [-4.3140e-01, -6.1704e-02,  1.9997e-01,  ..., -1.8185e+00,\n",
              "              -2.1108e+00, -2.3127e+00],\n",
              "             [-1.0844e+00, -1.0661e+00, -1.4301e-01,  ..., -2.8750e+00,\n",
              "              -2.5296e+00, -2.4749e+00],\n",
              "             ...,\n",
              "             [ 1.8690e-02,  3.1810e-01,  7.5600e-01,  ..., -2.9185e+00,\n",
              "              -2.8374e+00, -3.0310e+00],\n",
              "             [-3.6304e-01, -7.8687e-01,  2.4878e-01,  ..., -2.6376e+00,\n",
              "              -2.5845e+00, -2.9363e+00],\n",
              "             [-1.0761e+00,  5.5681e-01,  9.1094e-01,  ..., -2.7539e+00,\n",
              "              -2.7828e+00, -2.9593e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[ 5.9952e-01,  1.0717e+00,  1.0894e+00,  ..., -2.8188e+00,\n",
              "              -2.9970e+00, -3.0347e+00],\n",
              "             [-6.7164e-01,  4.3241e-01,  1.8352e-01,  ..., -2.8110e+00,\n",
              "              -2.9884e+00, -2.9218e+00],\n",
              "             [-4.1550e-01,  2.3353e-01,  5.4204e-01,  ..., -2.4906e+00,\n",
              "              -2.7280e+00, -2.4156e+00],\n",
              "             ...,\n",
              "             [ 4.6012e-01,  5.4978e-01, -1.3135e-01,  ..., -1.7390e+00,\n",
              "              -1.3401e+00, -1.8261e+00],\n",
              "             [-1.6840e-01,  5.0715e-01,  8.2864e-01,  ..., -1.4552e+00,\n",
              "              -1.1243e+00, -2.3641e+00],\n",
              "             [ 1.4058e+00,  1.5335e+00,  1.3360e+00,  ..., -5.2954e-01,\n",
              "              -8.2072e-01, -7.4406e-01]]],\n",
              "  \n",
              "  \n",
              "           [[[ 6.7030e-01,  1.2032e+00,  2.0665e+00,  ..., -1.2046e+00,\n",
              "              -1.3451e+00, -1.1911e+00],\n",
              "             [ 6.0511e-02,  2.5643e-01,  1.2723e+00,  ..., -1.4880e+00,\n",
              "              -1.5113e+00, -1.6640e+00],\n",
              "             [ 2.5253e-01,  8.3586e-01,  1.4802e+00,  ..., -1.3389e+00,\n",
              "              -1.1705e+00, -1.2927e+00],\n",
              "             ...,\n",
              "             [-1.8269e+00,  4.1572e-01,  8.4013e-01,  ..., -2.8952e+00,\n",
              "              -2.4219e+00, -2.5825e+00],\n",
              "             [ 2.9396e-01,  9.9038e-01,  1.0826e+00,  ..., -2.8320e+00,\n",
              "              -2.3917e+00, -2.5732e+00],\n",
              "             [-8.3073e-02,  9.4146e-01,  1.0103e+00,  ..., -2.5784e+00,\n",
              "              -2.1659e+00, -2.3995e+00]]]],\n",
              "  \n",
              "  \n",
              "  \n",
              "          [[[[-3.2547e+00, -2.1043e+00, -2.5061e+00,  ..., -3.3608e+00,\n",
              "              -3.6331e+00, -3.8417e+00],\n",
              "             [-2.3624e+00, -2.1021e+00, -1.2741e+00,  ..., -3.3008e+00,\n",
              "              -3.6696e+00, -3.8208e+00],\n",
              "             [-1.7936e+00, -1.7612e+00, -1.0897e+00,  ..., -3.3128e+00,\n",
              "              -3.5954e+00, -3.6339e+00],\n",
              "             ...,\n",
              "             [-1.6531e+00, -1.0632e+00, -8.6869e-02,  ..., -2.7074e+00,\n",
              "              -2.7807e+00, -3.2705e+00],\n",
              "             [-2.2582e+00, -2.8501e-01,  8.1355e-01,  ..., -3.1184e+00,\n",
              "              -2.9318e+00, -3.4544e+00],\n",
              "             [-1.9406e+00, -3.1492e-01,  8.6669e-01,  ..., -2.7720e+00,\n",
              "              -3.2934e+00, -3.5893e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.6698e+00,  1.2102e-01,  9.8359e-01,  ..., -2.9332e+00,\n",
              "              -2.9132e+00, -3.4995e+00],\n",
              "             [-2.0078e+00, -3.4569e-01,  6.7439e-01,  ..., -3.0127e+00,\n",
              "              -2.7774e+00, -3.3201e+00],\n",
              "             [-2.2184e+00, -5.3854e-01,  1.8132e-01,  ..., -2.8298e+00,\n",
              "              -2.7608e+00, -3.6049e+00],\n",
              "             ...,\n",
              "             [-3.6437e+00, -1.1553e+00,  3.1557e-01,  ..., -3.5643e+00,\n",
              "              -3.5279e+00, -3.7691e+00],\n",
              "             [-2.4055e+00, -2.2465e+00,  1.3467e-01,  ..., -3.4816e+00,\n",
              "              -3.6650e+00, -3.8782e+00],\n",
              "             [-2.0554e+00, -2.2870e+00, -4.7210e-01,  ..., -3.7458e+00,\n",
              "              -4.0442e+00, -3.9845e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[-3.2903e+00, -1.7808e+00, -9.7270e-01,  ..., -3.7564e+00,\n",
              "              -4.5042e+00, -3.7546e+00],\n",
              "             [-2.6345e+00, -1.9710e+00, -7.8443e-01,  ..., -3.5447e+00,\n",
              "              -4.5614e+00, -3.8386e+00],\n",
              "             [-2.4439e+00, -2.7630e+00, -1.2505e+00,  ..., -3.4248e+00,\n",
              "              -3.9881e+00, -3.7962e+00],\n",
              "             ...,\n",
              "             [-2.8361e+00, -2.8990e+00, -3.3177e+00,  ..., -3.2404e+00,\n",
              "              -3.3515e+00, -3.7036e+00],\n",
              "             [-3.0553e+00, -3.0127e+00, -3.0007e+00,  ..., -3.3386e+00,\n",
              "              -3.6445e+00, -3.7210e+00],\n",
              "             [-3.1849e+00, -3.0086e+00, -3.0470e+00,  ..., -3.4134e+00,\n",
              "              -3.7608e+00, -3.5784e+00]]],\n",
              "  \n",
              "  \n",
              "           ...,\n",
              "  \n",
              "  \n",
              "           [[[-2.7002e+00, -1.6600e+00, -1.2567e+00,  ..., -3.7778e+00,\n",
              "              -3.5557e+00, -3.7132e+00],\n",
              "             [-3.6489e+00, -2.4630e+00, -1.8172e+00,  ..., -3.6567e+00,\n",
              "              -3.3100e+00, -3.7441e+00],\n",
              "             [-3.0499e+00, -2.2917e+00, -2.0500e+00,  ..., -3.2938e+00,\n",
              "              -3.2457e+00, -3.3198e+00],\n",
              "             ...,\n",
              "             [-3.6444e-01,  7.8163e-01,  1.0069e+00,  ..., -3.1666e+00,\n",
              "              -3.7052e+00, -3.7783e+00],\n",
              "             [-2.5467e-01,  7.2218e-01,  1.0043e+00,  ..., -3.3155e+00,\n",
              "              -3.3303e+00, -3.4053e+00],\n",
              "             [-2.9279e+00,  8.9110e-02,  7.9496e-01,  ..., -3.4154e+00,\n",
              "              -3.3553e+00, -3.6463e+00]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.4267e+00,  1.2601e-01,  9.0878e-01,  ..., -3.3108e+00,\n",
              "              -3.3348e+00, -3.5058e+00],\n",
              "             [-1.5695e+00,  1.5827e-01,  1.1002e+00,  ..., -3.4411e+00,\n",
              "              -3.4247e+00, -3.8480e+00],\n",
              "             [-6.5222e-01, -1.4741e+00,  8.1543e-01,  ..., -3.5362e+00,\n",
              "              -3.6514e+00, -3.6608e+00],\n",
              "             ...,\n",
              "             [-2.5202e+00, -1.9337e+00, -1.6001e+00,  ...,  4.8543e-01,\n",
              "               2.6561e-01,  3.6728e-02],\n",
              "             [-1.2267e+00, -7.1455e-01, -2.2697e-01,  ...,  9.2726e-02,\n",
              "              -9.4538e-02,  4.1859e-02],\n",
              "             [-2.1764e+00,  2.2649e-01,  9.9012e-01,  ..., -8.5956e-01,\n",
              "              -4.3060e-01, -6.6950e-01]]],\n",
              "  \n",
              "  \n",
              "           [[[-1.4302e-01,  1.0218e+00,  1.5339e+00,  ..., -9.0657e-01,\n",
              "              -1.0644e+00, -1.0818e+00],\n",
              "             [-7.3265e-01,  9.0495e-01,  1.4816e+00,  ..., -9.9727e-01,\n",
              "              -1.4929e+00, -1.9066e+00],\n",
              "             [-1.6761e-01,  1.0195e+00,  1.3677e+00,  ..., -1.0252e+00,\n",
              "              -1.4416e+00, -1.9971e+00],\n",
              "             ...,\n",
              "             [-8.6833e-02,  8.6703e-01,  9.1486e-01,  ..., -3.7590e+00,\n",
              "              -3.3871e+00, -3.3637e+00],\n",
              "             [ 1.2693e-01,  1.0085e+00,  1.1633e+00,  ..., -3.7432e+00,\n",
              "              -2.9277e+00, -3.5191e+00],\n",
              "             [-4.8462e-01,  8.5063e-01,  1.1415e+00,  ..., -3.4576e+00,\n",
              "              -2.9104e+00, -3.4846e+00]]]]]),\n",
              "  tensor([[0.3271, 0.3750, 0.3187, 0.2718, 0.6111],\n",
              "          [0.4486, 0.5625, 0.4835, 0.5631, 0.5000],\n",
              "          [0.5514, 0.4896, 0.5824, 0.4369, 0.5667],\n",
              "          [0.4579, 0.4271, 0.6484, 0.5437, 0.6333]])])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a batch of data from the dataloader\n",
        "data = iter(train_dataloader)\n",
        "\n",
        "# Access the shape of the first element in the first batch\n",
        "next(data), next(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeiSEXHkuFSE",
        "outputId": "a9719062-cf97-47b0-ed06-eef7eb9ad801"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 15, 1, 96, 64])\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the DataLoader to access the data\n",
        "for batch_idx, data in enumerate(test_dataloader):\n",
        "    if batch_idx == 0:  # Access the first batch\n",
        "        # Get the shape of the desired element in the batch\n",
        "        shape = data[0].shape  # Assuming you want the shape of the first element in the batch\n",
        "        print(shape)\n",
        "        break  # Stop after processing the first batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5IkiIrVsK1o"
      },
      "source": [
        "# define Vgg model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vBp-sMusSo3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch import flatten\n",
        "\n",
        "class Vgg(nn.Module):\n",
        "    def __init__(self, numChannels=1, classes=5):\n",
        "      super(Vgg, self).__init__()\n",
        "\n",
        "      self.conv1 = Conv2d(in_channels=numChannels, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu1 = ReLU()\n",
        "      self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "\n",
        "      self.conv2 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu2 = ReLU()\n",
        "      self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "\n",
        "      self.conv3 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu3 = ReLU()\n",
        "      self.conv4 = Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu4 = ReLU()\n",
        "      self.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "\n",
        "      self.conv5 = Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu5 = ReLU()\n",
        "      self.conv6 = Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu6 = ReLU()\n",
        "      self.maxpool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "\n",
        "      # self.conv7 = Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "      # self.relu7 = ReLU()\n",
        "      # self.conv8 = Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "      # self.relu8 = ReLU()\n",
        "      # self.maxpool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "\n",
        "      # initialize first (and only) set of FC => RELU layers\n",
        "      self.fc1 = Linear(in_features=512 * 6 * 4, out_features=4096)\n",
        "      self.relu9 = ReLU()\n",
        "\n",
        "      self.fc2 = Linear(in_features=4096, out_features=4096)\n",
        "      self.relu10 = ReLU()\n",
        "\n",
        "      self.fc3 = Linear(in_features=4096, out_features=128)\n",
        "      self.relu11 = ReLU()\n",
        "\n",
        "      self.fc4 = Linear(in_features=128, out_features=classes)\n",
        "      self.sigmoid = Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      print(\"input: \", x.shape)\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      print(\"after conv1: \", x.shape)\n",
        "      x = self.relu1(x)\n",
        "      x = self.maxpool1(x)\n",
        "      print(\"after maxpool1: \", x.shape)\n",
        "\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      print(\"after conv2: \", x.shape)\n",
        "      x = self.relu2(x)\n",
        "      x = self.maxpool2(x)\n",
        "      print(\"after maxpool2: \", x.shape)\n",
        "\n",
        "      x = self.conv3(x)\n",
        "      print(\"after conv3: \", x.shape)\n",
        "      x = self.relu3(x)\n",
        "      x = self.conv4(x)\n",
        "      print(\"after conv4: \", x.shape)\n",
        "      x = self.relu4(x)\n",
        "      x = self.maxpool3(x)\n",
        "      print(\"after maxpool3: \", x.shape)\n",
        "\n",
        "      x = self.conv5(x)\n",
        "      print(\"after conv5: \", x.shape)\n",
        "      x = self.relu5(x)\n",
        "      x = self.conv6(x)\n",
        "      print(\"after conv6: \", x.shape)\n",
        "      x = self.relu6(x)\n",
        "      x = self.maxpool4(x)\n",
        "      print(\"after maxpool4: \", x.shape)\n",
        "\n",
        "\n",
        "      # x = self.conv7(x)\n",
        "      # x = self.relu7(x)\n",
        "      # x = self.conv8(x)\n",
        "      # x = self.relu8(x)\n",
        "      # x = self.maxpool5(x)\n",
        "      # print(\"after conv7 , conv8: \", x.shape)\n",
        "\n",
        "      x = x.view(x.size(0), -1)\n",
        "      print(\"after flatten: \", x.shape)\n",
        "\n",
        "      x = self.fc1(x)\n",
        "      print(\"after fc1: \", x.shape)\n",
        "      x = self.relu9(x)\n",
        "\n",
        "      x = self.fc2(x)\n",
        "      print(\"after fc2: \", x.shape)\n",
        "\n",
        "      x = self.fc3(x)\n",
        "      print(\"after fc3: \", x.shape)\n",
        "      x = self.relu11(x)\n",
        "\n",
        "      x = self.fc4(x)\n",
        "      print(\"after fc3: \", x.shape)\n",
        "      output = self.sigmoid(x)\n",
        "\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdmpJ-2jsjb1"
      },
      "outputs": [],
      "source": [
        "num_classes = 5  # 5 personality traits\n",
        "\n",
        "model = Vgg(\n",
        "    classes=num_classes,\n",
        ")\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion1 = nn.L1Loss()\n",
        "criterion2 = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKN9ORW4sut5"
      },
      "source": [
        "# set hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9yxRADKsoC7"
      },
      "outputs": [],
      "source": [
        "start_epoch = 0\n",
        "n_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISitUl9Hs8rC"
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "           \"meanLossTraining\":[], \"meanAccuracyTraining\":[], \"meanLossValidation\":[],\n",
        "           \"meanAccuracyValidation\":[], \"meanLossTest\":[], \"meanAccuracyTest\":[],\n",
        "           \"meanR2Training\": [], \"meanR2Validation\": [], \"meanR2Test\": [],\n",
        "           \"meanCCCTraining\": [], \"meanCCCValidation\": [], \"meanCCCTest\": [],\n",
        "           \"meanPCCTraining\": [], \"meanPCCValidation\": [], \"meanPCCTest\": [],\n",
        "\n",
        "           \"O_AccuracyTraining\":-1, \"C_AccuracyTraining\":-1, \"E_AccuracyTraining\":-1, \"A_AccuracyTraining\":-1, \"N_AccuracyTraining\":-1,\n",
        "           \"O_AccuracyValidation\":-1, \"C_AccuracyValidation\":-1, \"E_AccuracyValidation\":-1, \"A_AccuracyValidation\":-1, \"N_AccuracyValidation\":-1,\n",
        "           \"O_AccuracyTest\":-1, \"C_AccuracyTest\":-1, \"E_AccuracyTest\":-1, \"A_AccuracyTest\":-1, \"N_AccuracyTest\":-1,\n",
        "\n",
        "           \"O_R2Training\":-1, \"C_R2Training\":-1, \"E_R2Training\":-1, \"A_R2Training\":-1, \"N_R2Training\":-1,\n",
        "           \"O_R2Validation\":-1, \"C_R2Validation\":-1, \"E_R2Validation\":-1, \"A_R2Validation\":-1, \"N_R2Validation\":-1,\n",
        "           \"O_R2Test\":-1, \"C_R2Test\":-1, \"E_R2Test\":-1, \"A_R2Test\":-1, \"N_R2Test\":-1,\n",
        "\n",
        "           \"O_CCCTraining\":-1, \"C_CCCTraining\":-1, \"E_CCCTraining\":-1, \"A_CCCTraining\":-1, \"N_CCCTraining\":-1,\n",
        "           \"O_CCCValidation\":-1, \"C_CCCValidation\":-1, \"E_CCCValidation\":-1, \"A_CCCValidation\":-1, \"N_CCCValidation\":-1,\n",
        "           \"O_CCCTest\":-1, \"C_CCCTest\":-1, \"E_CCCTest\":-1, \"A_CCCTest\":-1, \"N_CCCTest\":-1,\n",
        "\n",
        "           \"O_PCCTraining\":-1, \"C_PCCTraining\":-1, \"E_PCCTraining\":-1, \"A_PCCTraining\":-1, \"N_PCCTraining\":-1,\n",
        "           \"O_PCCValidation\":-1, \"C_PCCValidation\":-1, \"E_PCCValidation\":-1, \"A_PCCValidation\":-1, \"N_PCCValidation\":-1,\n",
        "           \"O_PCCTest\":-1, \"C_PCCTest\":-1, \"E_PCCTest\":-1, \"A_PCCTest\":-1, \"N_PCCTest\":-1\n",
        "           }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4_1M8q-tEcz"
      },
      "source": [
        "### count parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIN5gljitG2j"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9vMiwD2tJ5K"
      },
      "source": [
        "### set model and dataset Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opQgNNbutOqP",
        "outputId": "e94efde2-5441-482a-c414-0059e3bb90c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        }
      ],
      "source": [
        "data = next(iter(train_dataloader))\n",
        "audioFrameNum, audioChannelNum, audioHeight, audioWidth = data[0][0].shape\n",
        "audioSegmentNum = 1\n",
        "\n",
        "modality = \"Audio\"\n",
        "preTrainedModel = \"No\"\n",
        "datasetName = \"Tiny chalearn\"\n",
        "weights = None\n",
        "\n",
        "modelName = model.__class__.__name__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCjdBR4rttHu"
      },
      "outputs": [],
      "source": [
        "modelInfo = {\n",
        "    \"modality\": modality,\n",
        "    \"model\": model.__class__.__name__,\n",
        "    \"parametersNum\": count_parameters(model),\n",
        "    \"weights\": weights,\n",
        "    \"dataset\": datasetName,\n",
        "    \"feature\": {\n",
        "        \"audio\": {\n",
        "            \"audioSegmentNum\": audioSegmentNum,\n",
        "            \"audioWidth\": audioWidth,\n",
        "            \"audioHeight\": audioHeight,\n",
        "            \"audioChannelNum\": audioChannelNum\n",
        "        },\n",
        "    },\n",
        "    \"hyperparameters\": {\n",
        "        \"EpochNum\": n_epochs,\n",
        "        \"batchSizeTraining\": training_batch_size,\n",
        "        \"batchSizeValidation\": validation_batch_size,\n",
        "        \"batchSizeTest\": test_batch_size,\n",
        "        \"trainingShuffle\": False,\n",
        "        \"validationShuffle\": False,\n",
        "        \"testShuffle\": False,\n",
        "        \"optimizer\": optimizer.__class__.__name__,\n",
        "        \"learningRate\": optimizer.param_groups[0]['lr'],\n",
        "        \"lossFunctionTraining\": criterion2.__class__.__name__,\n",
        "        \"lossFunctionEvaluation\": {\n",
        "            \"Training\": criterion1.__class__.__name__,\n",
        "            \"Validation\": criterion1.__class__.__name__,\n",
        "            \"Test\": criterion1.__class__.__name__\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "torchInfo = {\n",
        "    \"torchVersion\": torch.__version__,\n",
        "    \"torchDevice\": {\n",
        "        \"type\": device,\n",
        "        \"cudaVersion\": torch.version.cuda if torch.cuda.is_available() else None,\n",
        "        \"GPUName\": torch.cuda.get_device_name(torch.cuda.current_device()) if torch.cuda.is_available() else None\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myc8oFRht3bp"
      },
      "source": [
        "# define metric method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHZynYqtuAPt"
      },
      "source": [
        "## pcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTPvbDhht91b"
      },
      "outputs": [],
      "source": [
        "def pearson_correlation_coefficient(y_true, y_pred):\n",
        "  return np.corrcoef(y_true, y_pred)[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpZ9H4VHuCon"
      },
      "source": [
        "## ccc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bm7qfyjuDzr"
      },
      "outputs": [],
      "source": [
        "def concordance_correlation_coefficient(y_true, y_pred):\n",
        "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
        "\n",
        "    # Raw data\n",
        "    dct = {\n",
        "        'y_true': y_true,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "    df = pd.DataFrame(dct)\n",
        "\n",
        "    # Remove NaNs\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Pearson product-moment correlation coefficients\n",
        "    y_true = df['y_true']\n",
        "    y_pred = df['y_pred']\n",
        "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
        "\n",
        "    # Means\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "\n",
        "    # Population variances\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "\n",
        "    # Population standard deviations\n",
        "    sd_true = np.std(y_true)\n",
        "    sd_pred = np.std(y_pred)\n",
        "\n",
        "    # Calculate CCC\n",
        "    numerator = 2 * cor * sd_true * sd_pred\n",
        "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
        "\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCKQS8T4uK2w"
      },
      "source": [
        "# Create row in csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHzBEcsjuNnO"
      },
      "outputs": [],
      "source": [
        "def createRow(modelInfo, history, epoch, elapsedTime, torchInfo):\n",
        "\n",
        "    new_row = {\"modality\": modelInfo[\"modality\"],\n",
        "               \"model\":  modelInfo[\"model\"],\n",
        "               \"parametersNum\": modelInfo[\"parametersNum\"],\n",
        "\n",
        "               \"meanAccuracyTraining\": history[\"meanAccuracyTraining\"][epoch],\n",
        "               \"meanAccuracyValidation\": history[\"meanAccuracyValidation\"][epoch],\n",
        "               \"meanAccuracyTest\": history[\"meanAccuracyTest\"][epoch],\n",
        "\n",
        "               \"meanR2Training\": history[\"meanR2Training\"][epoch],\n",
        "               \"meanR2Validation\": history[\"meanR2Validation\"][epoch],\n",
        "               \"meanR2Test\": history[\"meanR2Test\"][epoch],\n",
        "\n",
        "               \"meanCCCTraining\": history[\"meanCCCTraining\"][epoch],\n",
        "               \"meanCCCValidation\": history[\"meanCCCValidation\"][epoch],\n",
        "               \"meanCCCTest\": history[\"meanCCCTest\"][epoch],\n",
        "\n",
        "               \"meanLossTraining\": history[\"meanLossTraining\"][epoch],\n",
        "               \"meanLossValidation\": history[\"meanLossValidation\"][epoch],\n",
        "               \"meanLossTest\": history[\"meanLossTest\"][epoch],\n",
        "               \"elapsedTime\": elapsedTime,\n",
        "               \"weights\": modelInfo[\"weights\"],\n",
        "               \"dataset\": modelInfo[\"dataset\"],\n",
        "\n",
        "               \"audioSegmentNum\": modelInfo[\"feature\"][\"audio\"][\"audioSegmentNum\"],\n",
        "               \"audioWidth\": modelInfo[\"feature\"][\"audio\"][\"audioWidth\"],\n",
        "               \"audioHeight\": modelInfo[\"feature\"][\"audio\"][\"audioHeight\"],\n",
        "               \"audioChannelNum\": modelInfo[\"feature\"][\"audio\"][\"audioChannelNum\"],\n",
        "\n",
        "               \"EpochNum\": modelInfo[\"hyperparameters\"][\"EpochNum\"],\n",
        "               \"batchSizeTraining\": modelInfo[\"hyperparameters\"][\"batchSizeTraining\"],\n",
        "               \"trainingShuffle\": modelInfo[\"hyperparameters\"][\"trainingShuffle\"],\n",
        "               \"batchSizeValidation\": modelInfo[\"hyperparameters\"][\"batchSizeValidation\"],\n",
        "               \"validationShuffle\": modelInfo[\"hyperparameters\"][\"validationShuffle\"],\n",
        "               \"batchSizeTest\": modelInfo[\"hyperparameters\"][\"batchSizeTest\"],\n",
        "               \"testShuffle\": modelInfo[\"hyperparameters\"][\"testShuffle\"],\n",
        "               \"optimizer\": modelInfo[\"hyperparameters\"][\"optimizer\"],\n",
        "               \"learningRate\": modelInfo[\"hyperparameters\"][\"learningRate\"],\n",
        "               \"lossFunctionEvaluationTraining\": modelInfo[\"hyperparameters\"][\"lossFunctionEvaluation\"][\"Training\"],\n",
        "               \"lossFunctionEvaluationValidation\": modelInfo[\"hyperparameters\"][\"lossFunctionEvaluation\"][\"Validation\"],\n",
        "               \"lossFunctionEvaluationTest\": modelInfo[\"hyperparameters\"][\"lossFunctionEvaluation\"][\"Test\"],\n",
        "               \"lossFunctionTraining\": modelInfo[\"hyperparameters\"][\"lossFunctionTraining\"],\n",
        "\n",
        "               \"torchVersion\": torchInfo[\"torchVersion\"],\n",
        "               \"torchDevice\": torchInfo[\"torchDevice\"][\"type\"],\n",
        "               \"torchCudaVersion\": torchInfo[\"torchDevice\"][\"cudaVersion\"],\n",
        "               \"GPUName\": torchInfo[\"torchDevice\"][\"GPUName\"],\n",
        "\n",
        "                \"O_AccuracyTraining\": history[\"O_AccuracyTraining\"],\n",
        "                \"C_AccuracyTraining\": history[\"C_AccuracyTraining\"],\n",
        "                \"E_AccuracyTraining\": history[\"E_AccuracyTraining\"],\n",
        "                \"A_AccuracyTraining\": history[\"A_AccuracyTraining\"],\n",
        "                \"N_AccuracyTraining\": history[\"N_AccuracyTraining\"],\n",
        "\n",
        "                \"O_AccuracyValidation\": history[\"O_AccuracyValidation\"],\n",
        "                \"C_AccuracyValidation\": history[\"C_AccuracyValidation\"],\n",
        "                \"E_AccuracyValidation\": history[\"E_AccuracyValidation\"],\n",
        "                \"A_AccuracyValidation\": history[\"A_AccuracyValidation\"],\n",
        "                \"N_AccuracyValidation\": history[\"N_AccuracyValidation\"],\n",
        "\n",
        "                \"O_AccuracyTest\": history[\"O_AccuracyTest\"],\n",
        "                \"C_AccuracyTest\": history[\"C_AccuracyTest\"],\n",
        "                \"E_AccuracyTest\": history[\"E_AccuracyTest\"],\n",
        "                \"A_AccuracyTest\": history[\"A_AccuracyTest\"],\n",
        "                \"N_AccuracyTest\": history[\"N_AccuracyTest\"],\n",
        "\n",
        "                \"O_R2Training\": history[\"O_R2Training\"],\n",
        "                \"C_R2Training\": history[\"C_R2Training\"],\n",
        "                \"E_R2Training\": history[\"E_R2Training\"],\n",
        "                \"A_R2Training\": history[\"A_R2Training\"],\n",
        "                \"N_R2Training\": history[\"N_R2Training\"],\n",
        "\n",
        "                \"O_R2Validation\": history[\"O_R2Validation\"],\n",
        "                \"C_R2Validation\": history[\"C_R2Validation\"],\n",
        "                \"E_R2Validation\": history[\"E_R2Validation\"],\n",
        "                \"A_R2Validation\": history[\"A_R2Validation\"],\n",
        "                \"N_R2Validation\": history[\"N_R2Validation\"],\n",
        "\n",
        "                \"O_R2Test\": history[\"O_R2Test\"],\n",
        "                \"C_R2Test\": history[\"C_R2Test\"],\n",
        "                \"E_R2Test\": history[\"E_R2Test\"],\n",
        "                \"A_R2Test\": history[\"A_R2Test\"],\n",
        "                \"N_R2Test\": history[\"N_R2Test\"],\n",
        "\n",
        "\n",
        "                \"O_CCCTraining\": history[\"O_CCCTraining\"],\n",
        "                \"C_CCCTraining\": history[\"C_CCCTraining\"],\n",
        "                \"E_CCCTraining\": history[\"E_CCCTraining\"],\n",
        "                \"A_CCCTraining\": history[\"A_CCCTraining\"],\n",
        "                \"N_CCCTraining\": history[\"N_CCCTraining\"],\n",
        "\n",
        "                \"O_CCCValidation\": history[\"O_CCCValidation\"],\n",
        "                \"C_CCCValidation\": history[\"C_CCCValidation\"],\n",
        "                \"E_CCCValidation\": history[\"E_CCCValidation\"],\n",
        "                \"A_CCCValidation\": history[\"A_CCCValidation\"],\n",
        "                \"N_CCCValidation\": history[\"N_CCCValidation\"],\n",
        "\n",
        "                \"O_CCCTest\": history[\"O_CCCTest\"],\n",
        "                \"C_CCCTest\": history[\"C_CCCTest\"],\n",
        "                \"E_CCCTest\": history[\"E_CCCTest\"],\n",
        "                \"A_CCCTest\": history[\"A_CCCTest\"],\n",
        "                \"N_CCCTest\": history[\"N_CCCTest\"]\n",
        "\n",
        "               }\n",
        "    return new_row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0cuA1TouXFn"
      },
      "source": [
        "# Evaluate metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTZmlFj2uZ9H"
      },
      "outputs": [],
      "source": [
        "def check_data(y_true, y_pred):\n",
        "    print(f\"y_true: {y_true}\")\n",
        "    print(f\"y_pred: {y_pred}\")\n",
        "    print(f\"Stddev y_true: {np.std(y_true)}\")\n",
        "    print(f\"Stddev y_pred: {np.std(y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE8FObcOucdZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score\n",
        "\n",
        "def evaluationMetrics(y_true, y_pred, wantedMetrics, phase):\n",
        "    yt = np.array([np.array(item) for sublist in y_true for item in sublist])\n",
        "    yp = np.array([np.array(item) for sublist in y_pred for item in sublist])\n",
        "\n",
        "    accuracy = []\n",
        "    r2Score = []\n",
        "    concordanceCC = []\n",
        "    label_name = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
        "\n",
        "    for metric in wantedMetrics[phase].keys():\n",
        "        for i in range(len(label_name)):\n",
        "            # yt[:, i], yp[:, i] = preprocess_data(yt[:, i], yp[:, i])\n",
        "\n",
        "            if metric == \"mae\":\n",
        "                print(\"for mae:\")\n",
        "                check_data(yt[:,i], yp[:,i])\n",
        "                wantedMetrics[phase][metric].append(mean_absolute_error(yt[:,i], yp[:,i]))\n",
        "\n",
        "            elif metric == \"r2\":\n",
        "                print(\"for r2:\")\n",
        "                check_data(yt[:,i], yp[:,i])\n",
        "                wantedMetrics[phase][metric].append(r2_score(yt[:,i], yp[:,i]))\n",
        "\n",
        "            elif metric == \"accuracy\":\n",
        "                print(\"for accuracy:\")\n",
        "                check_data(yt[:,i], yp[:,i])\n",
        "                wantedMetrics[phase][metric].append(1 - mean_absolute_error(yt[:,i], yp[:,i]))\n",
        "\n",
        "            elif metric == \"ccc\":\n",
        "                print(\"for ccc:\")\n",
        "                check_data(yt[:,i], yp[:,i])\n",
        "                wantedMetrics[phase][metric].append(concordance_correlation_coefficient(yt[:,i], yp[:,i]))\n",
        "\n",
        "            elif metric == \"pcc\":\n",
        "                print(\"for pcc:\")\n",
        "                check_data(yt[:,i], yp[:,i])\n",
        "                wantedMetrics[phase][metric].append(pearson_correlation_coefficient(yt[:,i], yp[:,i]))\n",
        "\n",
        "    return wantedMetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZInPaNQgumiN"
      },
      "source": [
        "# train func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcHWAEJBuoGf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "def trainAudioModel(model, criterion, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    training_losses = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        audios, labels = batch\n",
        "        audios = audios.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Pad the audio sequences in the batch\n",
        "        audios = torch.nn.utils.rnn.pad_sequence(audios, batch_first=True)\n",
        "\n",
        "\n",
        "        Total = training_batch_size * audioFrameNum\n",
        "        audios = audios.reshape(Total, audioChannelNum, audioWidth, audioHeight)\n",
        "\n",
        "\n",
        "        # # Cast audios to float\n",
        "        # audios = audios.float()\n",
        "\n",
        "        # # Cast labels to float\n",
        "        # labels = labels.float()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(audios)\n",
        "\n",
        "\n",
        "        outputs = outputs.reshape(Total//audioFrameNum, audioFrameNum, -1)\n",
        "        outputs = outputs.mean(dim=1)\n",
        "\n",
        "\n",
        "        print(\"Predicted Labels:\", outputs.detach().cpu().numpy())\n",
        "        print(\"True Labels:\", labels.detach().cpu().numpy())\n",
        "\n",
        "        # print(f\"Shape of outputs: {outputs.shape}\")\n",
        "        # print(f\"Shape of labels: {labels.shape}\")\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        training_losses.append(loss.item())\n",
        "\n",
        "    return training_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PmBuQC9uyKi"
      },
      "source": [
        "# Evaluate func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuNhg-2xu16Y"
      },
      "outputs": [],
      "source": [
        "def evaluateAudioModel(model, criterion, valid_loader, device):\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            audios, labels = batch\n",
        "            audios = audios.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            audios = torch.nn.utils.rnn.pad_sequence(audios, batch_first=True)\n",
        "\n",
        "\n",
        "            Total = valid_loader.batch_size * audioFrameNum\n",
        "            audios = audios.reshape(Total, audioChannelNum, audioWidth, audioHeight)\n",
        "\n",
        "\n",
        "            # # Cast audios to float\n",
        "            # audios = audios.float()\n",
        "\n",
        "            # # Cast labels to float\n",
        "            # labels = labels.float()\n",
        "\n",
        "\n",
        "            outputs = model(audios)\n",
        "\n",
        "\n",
        "            outputs = outputs.reshape(Total//audioFrameNum, audioFrameNum, -1)\n",
        "            outputs = outputs.mean(dim=1)\n",
        "\n",
        "\n",
        "            print(\"Predicted Labels:\", outputs.detach().cpu().numpy())\n",
        "            print(\"True Labels:\", labels.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.append(outputs.cpu().numpy())\n",
        "            y_true.append(labels.cpu().numpy())\n",
        "\n",
        "    return losses, y_pred, y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8SWhVru7-g"
      },
      "source": [
        "# update history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_NY0J_Ku9oW"
      },
      "outputs": [],
      "source": [
        "def updateHistory(history, phase, accuracy, r2Score, concordanceCC, pearsonCC, losses):\n",
        "    acc = np.array(accuracy).mean()\n",
        "    r2 = np.array(r2Score).mean()\n",
        "    ccc = np.array(concordanceCC).mean()\n",
        "    pcc = np.array(pearsonCC).mean()\n",
        "\n",
        "    labesName = [\"E_\", \"N_\", \"A_\", \"C_\", \"O_\"]\n",
        "\n",
        "    for i in range(len(labesName)):\n",
        "        history[labesName[i]+\"Accuracy\"+phase] = accuracy[i]\n",
        "        history[labesName[i]+\"R2\"+phase] = r2Score[i]\n",
        "        history[labesName[i]+\"CCC\"+phase] = concordanceCC[i]\n",
        "        history[labesName[i]+\"PCC\"+phase] = pearsonCC[i]\n",
        "\n",
        "    history[\"meanLoss\"+phase].append(np.nan_to_num(np.mean(losses)))\n",
        "    history[\"meanAccuracy\"+phase].append(np.nan_to_num(np.mean(acc)))\n",
        "    history[\"meanR2\"+phase].append(np.nan_to_num(np.mean(r2)))\n",
        "    history[\"meanCCC\"+phase].append(np.nan_to_num(np.mean(ccc)))\n",
        "    history[\"meanPCC\"+phase].append(np.nan_to_num(np.mean(pcc)))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szzrt2wyu-rR"
      },
      "source": [
        "# run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpJWgp0VvACA",
        "outputId": "3c758d19-ce9f-4a69-f3b8-4c3a6b43bfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48092368 0.5050882  0.5170719  0.48479745 0.48398757]\n",
            " [0.48087496 0.5051448  0.51706535 0.48482314 0.48403552]\n",
            " [0.4809452  0.5051036  0.5170331  0.48481464 0.48402622]\n",
            " [0.48093164 0.50512147 0.51703596 0.4848293  0.48402503]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48098257 0.5051415  0.5170526  0.4848422  0.48406675]\n",
            " [0.48097295 0.50509447 0.5170761  0.48485842 0.48407388]\n",
            " [0.48084247 0.5051861  0.5171462  0.48487592 0.48404828]\n",
            " [0.48099124 0.5051188  0.5170877  0.48485392 0.48403543]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48099157 0.5051838  0.5170779  0.4848766  0.48419765]\n",
            " [0.48088092 0.50517493 0.5171762  0.48485625 0.4840717 ]\n",
            " [0.48098683 0.5051551  0.51706386 0.4848359  0.48414916]\n",
            " [0.4809721  0.5051686  0.5170454  0.48484948 0.4841885 ]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48097053 0.5051458  0.5171098  0.48486966 0.4841056 ]\n",
            " [0.48098436 0.50517786 0.5170586  0.48486304 0.48424459]\n",
            " [0.4810005  0.50519204 0.51712257 0.4848961  0.4842106 ]\n",
            " [0.4809693  0.5051562  0.5171458  0.48488146 0.4841497 ]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48104706 0.505159   0.51711625 0.4848981  0.48420635]\n",
            " [0.4810264  0.50520915 0.5171521  0.48490965 0.484241  ]\n",
            " [0.48099908 0.5051894  0.51717556 0.48491246 0.48418105]\n",
            " [0.48103535 0.5051841  0.51711625 0.48488218 0.48424748]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4810286  0.505156   0.51715004 0.4848876  0.48421666]\n",
            " [0.4810215  0.5051717  0.5171348  0.48487565 0.48427063]\n",
            " [0.48108953 0.5052027  0.5171491  0.4849263  0.48435035]\n",
            " [0.48104155 0.5051792  0.51712924 0.48488367 0.48426116]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4810418  0.50517607 0.5171993  0.48492733 0.48423603]\n",
            " [0.48113817 0.50525236 0.5171063  0.48490375 0.48434496]\n",
            " [0.48102328 0.50516725 0.5172111  0.48493618 0.48423883]\n",
            " [0.4810521  0.5052087  0.51715505 0.48491195 0.48427   ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48103258 0.50522417 0.51717085 0.48494264 0.48433134]\n",
            " [0.4810655  0.5052325  0.5171343  0.4849567  0.48435748]\n",
            " [0.481055   0.50518084 0.5171196  0.4849273  0.48430267]\n",
            " [0.48103812 0.505156   0.51716083 0.4849447  0.48427075]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48108798 0.50521106 0.5171364  0.48496535 0.48437077]\n",
            " [0.48102942 0.50521225 0.51717734 0.48495656 0.484357  ]\n",
            " [0.48096615 0.5052822  0.5172164  0.4849686  0.4843225 ]\n",
            " [0.48102188 0.50515544 0.51721156 0.4849851  0.48427674]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48101726 0.50514495 0.5171855  0.48495987 0.48426983]\n",
            " [0.48109677 0.50522256 0.51712185 0.4849496  0.48438025]\n",
            " [0.48109424 0.50517625 0.51710796 0.4849694  0.48433077]\n",
            " [0.4809945  0.5051992  0.5171907  0.48494184 0.4842962 ]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48113    0.5052601  0.5171985  0.48499995 0.4843922 ]\n",
            " [0.48123237 0.5053015  0.51713717 0.48498157 0.48449522]\n",
            " [0.48102868 0.505273   0.5172562  0.48504323 0.4843647 ]\n",
            " [0.4811308  0.5052711  0.51718533 0.4850366  0.48441768]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48114377 0.5052841  0.5171713  0.48503324 0.48442677]\n",
            " [0.48112717 0.50528836 0.5172166  0.48506147 0.48445696]\n",
            " [0.48112774 0.5053201  0.51720643 0.48507127 0.4845105 ]\n",
            " [0.48121047 0.5052916  0.5171863  0.4850261  0.48444882]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812104  0.50531995 0.517203   0.48509118 0.48451543]\n",
            " [0.48107222 0.5053622  0.517291   0.4850637  0.48449236]\n",
            " [0.48118022 0.5053028  0.5172371  0.4850857  0.48447067]\n",
            " [0.48107693 0.50526565 0.51731753 0.48509225 0.48442137]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48115224 0.50531423 0.5172572  0.48511755 0.48446563]\n",
            " [0.4811403  0.50530463 0.5172607  0.48511606 0.48445028]\n",
            " [0.48115072 0.50536054 0.51720136 0.4851169  0.48459554]\n",
            " [0.48109064 0.50527614 0.5173184  0.48513204 0.48441598]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4811674  0.5052942  0.5172173  0.48507154 0.48453906]\n",
            " [0.4812048  0.50533104 0.51717484 0.48507005 0.48462984]\n",
            " [0.4811672  0.50528556 0.5172347  0.4850724  0.48452303]\n",
            " [0.48117134 0.505289   0.5172306  0.4850867  0.48451048]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48118582 0.5053369  0.51729614 0.48512045 0.48454893]\n",
            " [0.4811356  0.505393   0.5172901  0.48514473 0.48459494]\n",
            " [0.48120844 0.5053544  0.51725864 0.48514014 0.48459157]\n",
            " [0.48119485 0.50537145 0.51726127 0.48515454 0.48458993]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48121685 0.50536054 0.51724344 0.48512462 0.4845819 ]\n",
            " [0.48120725 0.5053138  0.5172667  0.4851407  0.48458827]\n",
            " [0.48106983 0.5053978  0.5173348  0.48514858 0.48454866]\n",
            " [0.4812255  0.5053361  0.51727706 0.4851337  0.4845469 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48119724 0.5053901  0.5172631  0.4851676  0.48465356]\n",
            " [0.48108175 0.5053736  0.5173591  0.48513794 0.48451516]\n",
            " [0.4811933  0.5053609  0.51724887 0.4851267  0.4846051 ]\n",
            " [0.48117712 0.5053739  0.51723033 0.48514116 0.48464692]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48115927 0.5053294  0.51726437 0.48512763 0.48451862]\n",
            " [0.48117417 0.50536346 0.51721495 0.48512533 0.48466557]\n",
            " [0.48119038 0.5053775  0.5172784  0.48515576 0.48462644]\n",
            " [0.48115876 0.50534105 0.5173014  0.48514047 0.48456427]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48119593 0.5053259  0.51724744 0.48514372 0.4845608 ]\n",
            " [0.4811752  0.5053765  0.51728374 0.4851555  0.48459533]\n",
            " [0.48114786 0.5053549  0.517306   0.48515546 0.48453182]\n",
            " [0.48118427 0.5053519  0.5172484  0.48512974 0.48460433]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48117188 0.50532305 0.5172907  0.48513743 0.4845261 ]\n",
            " [0.48116556 0.50533956 0.5172759  0.48512632 0.48458102]\n",
            " [0.4812343  0.5053724  0.5172907  0.48517948 0.4846636 ]\n",
            " [0.48118615 0.5053475  0.5172705  0.4851358  0.48457313]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48115173 0.5052984  0.51731354 0.4851332  0.48450607]\n",
            " [0.48124984 0.5053771  0.5172224  0.48511457 0.48462158]\n",
            " [0.4811325  0.5052885  0.5173255  0.48514098 0.48450765]\n",
            " [0.48116258 0.50533175 0.51726997 0.48511982 0.48454276]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4811638  0.50537074 0.51730394 0.48513204 0.48457584]\n",
            " [0.48119754 0.50538105 0.5172688  0.48514864 0.4846051 ]\n",
            " [0.48118657 0.50532836 0.5172536  0.48511845 0.48454955]\n",
            " [0.48116985 0.5053021  0.51729333 0.48513344 0.48451453]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812052  0.505347   0.51726127 0.48514047 0.48459837]\n",
            " [0.48114663 0.5053485  0.5173017  0.4851314  0.48458427]\n",
            " [0.48107985 0.5054135  0.5173402  0.4851383  0.4845435 ]\n",
            " [0.4811382  0.5052899  0.51733476 0.4851578  0.48450115]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48114938 0.5053026  0.5173152  0.48514062 0.48450205]\n",
            " [0.48123062 0.5053836  0.5172533  0.4851343  0.48461762]\n",
            " [0.48122734 0.5053359  0.5172389  0.48515263 0.48456618]\n",
            " [0.4811262  0.505357   0.5173206  0.4851226  0.48452836]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48118472 0.50535005 0.51727706 0.485125   0.4845467 ]\n",
            " [0.48128787 0.5053931  0.5172165  0.48510864 0.48465222]\n",
            " [0.48108223 0.5053606  0.51733416 0.48516485 0.48451528]\n",
            " [0.48118603 0.50536156 0.51726395 0.4851622  0.4845727 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4811965  0.50534785 0.5172398  0.48511717 0.48455888]\n",
            " [0.4811795  0.50535196 0.51728505 0.485145   0.48458833]\n",
            " [0.48117986 0.5053836  0.517275   0.4851547  0.48464167]\n",
            " [0.48126358 0.5053556  0.5172549  0.4851103  0.48458114]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812451  0.50535816 0.5172368  0.48513559 0.48460665]\n",
            " [0.48110703 0.50540006 0.5173247  0.48510763 0.48458222]\n",
            " [0.48121488 0.5053408  0.5172709  0.48512986 0.48456132]\n",
            " [0.48111126 0.5053029  0.51735103 0.48513544 0.4845103 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4811761  0.50532806 0.51726806 0.48512965 0.4845327 ]\n",
            " [0.48116413 0.5053184  0.51727164 0.4851281  0.48451725]\n",
            " [0.48117453 0.50537425 0.5172124  0.48512888 0.4846636 ]\n",
            " [0.48111406 0.5052897  0.51732916 0.4851438  0.48448175]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48120195 0.5053377  0.51724714 0.4851128  0.4845983 ]\n",
            " [0.48123926 0.5053746  0.51720476 0.48511127 0.48468903]\n",
            " [0.4812016  0.50532866 0.5172643  0.48511326 0.4845817 ]\n",
            " [0.48120567 0.5053323  0.5172604  0.48512766 0.4845693 ]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48118582 0.4811356  0.48120844 0.48119485 0.48121685 0.48120725\n",
            " 0.48106983 0.4812255  0.48119724 0.48108175 0.4811933  0.48117712\n",
            " 0.48115927 0.48117417 0.48119038 0.48115876 0.48119593 0.4811752\n",
            " 0.48114786 0.48118427 0.48117188 0.48116556 0.4812343  0.48118615\n",
            " 0.48115173 0.48124984 0.4811325  0.48116258 0.4811638  0.48119754\n",
            " 0.48118657 0.48116985 0.4812052  0.48114663 0.48107985 0.4811382\n",
            " 0.48114938 0.48123062 0.48122734 0.4811262  0.48118472 0.48128787\n",
            " 0.48108223 0.48118603 0.4811965  0.4811795  0.48117986 0.48126358\n",
            " 0.4812451  0.48110703 0.48121488 0.48111126 0.4811761  0.48116413\n",
            " 0.48117453 0.48111406 0.48120195 0.48123926 0.4812016  0.48120567]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.466629252419807e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5053369  0.505393   0.5053544  0.50537145 0.50536054 0.5053138\n",
            " 0.5053978  0.5053361  0.5053901  0.5053736  0.5053609  0.5053739\n",
            " 0.5053294  0.50536346 0.5053775  0.50534105 0.5053259  0.5053765\n",
            " 0.5053549  0.5053519  0.50532305 0.50533956 0.5053724  0.5053475\n",
            " 0.5052984  0.5053771  0.5052885  0.50533175 0.50537074 0.50538105\n",
            " 0.50532836 0.5053021  0.505347   0.5053485  0.5054135  0.5052899\n",
            " 0.5053026  0.5053836  0.5053359  0.505357   0.50535005 0.5053931\n",
            " 0.5053606  0.50536156 0.50534785 0.50535196 0.5053836  0.5053556\n",
            " 0.50535816 0.50540006 0.5053408  0.5053029  0.50532806 0.5053184\n",
            " 0.50537425 0.5052897  0.5053377  0.5053746  0.50532866 0.5053323 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9348726457101293e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51729614 0.5172901  0.51725864 0.51726127 0.51724344 0.5172667\n",
            " 0.5173348  0.51727706 0.5172631  0.5173591  0.51724887 0.51723033\n",
            " 0.51726437 0.51721495 0.5172784  0.5173014  0.51724744 0.51728374\n",
            " 0.517306   0.5172484  0.5172907  0.5172759  0.5172907  0.5172705\n",
            " 0.51731354 0.5172224  0.5173255  0.51726997 0.51730394 0.5172688\n",
            " 0.5172536  0.51729333 0.51726127 0.5173017  0.5173402  0.51733476\n",
            " 0.5173152  0.5172533  0.5172389  0.5173206  0.51727706 0.5172165\n",
            " 0.51733416 0.51726395 0.5172398  0.51728505 0.517275   0.5172549\n",
            " 0.5172368  0.5173247  0.5172709  0.51735103 0.51726806 0.51727164\n",
            " 0.5172124  0.51732916 0.51724714 0.51720476 0.5172643  0.5172604 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.5842105717165396e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48512045 0.48514473 0.48514014 0.48515454 0.48512462 0.4851407\n",
            " 0.48514858 0.4851337  0.4851676  0.48513794 0.4851267  0.48514116\n",
            " 0.48512763 0.48512533 0.48515576 0.48514047 0.48514372 0.4851555\n",
            " 0.48515546 0.48512974 0.48513743 0.48512632 0.48517948 0.4851358\n",
            " 0.4851332  0.48511457 0.48514098 0.48511982 0.48513204 0.48514864\n",
            " 0.48511845 0.48513344 0.48514047 0.4851314  0.4851383  0.4851578\n",
            " 0.48514062 0.4851343  0.48515263 0.4851226  0.485125   0.48510864\n",
            " 0.48516485 0.4851622  0.48511717 0.485145   0.4851547  0.4851103\n",
            " 0.48513559 0.48510763 0.48512986 0.48513544 0.48512965 0.4851281\n",
            " 0.48512888 0.4851438  0.4851128  0.48511127 0.48511326 0.48512766]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.5500760127906688e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48454893 0.48459494 0.48459157 0.48458993 0.4845819  0.48458827\n",
            " 0.48454866 0.4845469  0.48465356 0.48451516 0.4846051  0.48464692\n",
            " 0.48451862 0.48466557 0.48462644 0.48456427 0.4845608  0.48459533\n",
            " 0.48453182 0.48460433 0.4845261  0.48458102 0.4846636  0.48457313\n",
            " 0.48450607 0.48462158 0.48450765 0.48454276 0.48457584 0.4846051\n",
            " 0.48454955 0.48451453 0.48459837 0.48458427 0.4845435  0.48450115\n",
            " 0.48450205 0.48461762 0.48456618 0.48452836 0.4845467  0.48465222\n",
            " 0.48451528 0.4845727  0.48455888 0.48458833 0.48464167 0.48458114\n",
            " 0.48460665 0.48458222 0.48456132 0.4845103  0.4845327  0.48451725\n",
            " 0.4846636  0.48448175 0.4845983  0.48468903 0.4845817  0.4845693 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 4.777873618877493e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48118582 0.4811356  0.48120844 0.48119485 0.48121685 0.48120725\n",
            " 0.48106983 0.4812255  0.48119724 0.48108175 0.4811933  0.48117712\n",
            " 0.48115927 0.48117417 0.48119038 0.48115876 0.48119593 0.4811752\n",
            " 0.48114786 0.48118427 0.48117188 0.48116556 0.4812343  0.48118615\n",
            " 0.48115173 0.48124984 0.4811325  0.48116258 0.4811638  0.48119754\n",
            " 0.48118657 0.48116985 0.4812052  0.48114663 0.48107985 0.4811382\n",
            " 0.48114938 0.48123062 0.48122734 0.4811262  0.48118472 0.48128787\n",
            " 0.48108223 0.48118603 0.4811965  0.4811795  0.48117986 0.48126358\n",
            " 0.4812451  0.48110703 0.48121488 0.48111126 0.4811761  0.48116413\n",
            " 0.48117453 0.48111406 0.48120195 0.48123926 0.4812016  0.48120567]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.466629252419807e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5053369  0.505393   0.5053544  0.50537145 0.50536054 0.5053138\n",
            " 0.5053978  0.5053361  0.5053901  0.5053736  0.5053609  0.5053739\n",
            " 0.5053294  0.50536346 0.5053775  0.50534105 0.5053259  0.5053765\n",
            " 0.5053549  0.5053519  0.50532305 0.50533956 0.5053724  0.5053475\n",
            " 0.5052984  0.5053771  0.5052885  0.50533175 0.50537074 0.50538105\n",
            " 0.50532836 0.5053021  0.505347   0.5053485  0.5054135  0.5052899\n",
            " 0.5053026  0.5053836  0.5053359  0.505357   0.50535005 0.5053931\n",
            " 0.5053606  0.50536156 0.50534785 0.50535196 0.5053836  0.5053556\n",
            " 0.50535816 0.50540006 0.5053408  0.5053029  0.50532806 0.5053184\n",
            " 0.50537425 0.5052897  0.5053377  0.5053746  0.50532866 0.5053323 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9348726457101293e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51729614 0.5172901  0.51725864 0.51726127 0.51724344 0.5172667\n",
            " 0.5173348  0.51727706 0.5172631  0.5173591  0.51724887 0.51723033\n",
            " 0.51726437 0.51721495 0.5172784  0.5173014  0.51724744 0.51728374\n",
            " 0.517306   0.5172484  0.5172907  0.5172759  0.5172907  0.5172705\n",
            " 0.51731354 0.5172224  0.5173255  0.51726997 0.51730394 0.5172688\n",
            " 0.5172536  0.51729333 0.51726127 0.5173017  0.5173402  0.51733476\n",
            " 0.5173152  0.5172533  0.5172389  0.5173206  0.51727706 0.5172165\n",
            " 0.51733416 0.51726395 0.5172398  0.51728505 0.517275   0.5172549\n",
            " 0.5172368  0.5173247  0.5172709  0.51735103 0.51726806 0.51727164\n",
            " 0.5172124  0.51732916 0.51724714 0.51720476 0.5172643  0.5172604 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.5842105717165396e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48512045 0.48514473 0.48514014 0.48515454 0.48512462 0.4851407\n",
            " 0.48514858 0.4851337  0.4851676  0.48513794 0.4851267  0.48514116\n",
            " 0.48512763 0.48512533 0.48515576 0.48514047 0.48514372 0.4851555\n",
            " 0.48515546 0.48512974 0.48513743 0.48512632 0.48517948 0.4851358\n",
            " 0.4851332  0.48511457 0.48514098 0.48511982 0.48513204 0.48514864\n",
            " 0.48511845 0.48513344 0.48514047 0.4851314  0.4851383  0.4851578\n",
            " 0.48514062 0.4851343  0.48515263 0.4851226  0.485125   0.48510864\n",
            " 0.48516485 0.4851622  0.48511717 0.485145   0.4851547  0.4851103\n",
            " 0.48513559 0.48510763 0.48512986 0.48513544 0.48512965 0.4851281\n",
            " 0.48512888 0.4851438  0.4851128  0.48511127 0.48511326 0.48512766]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.5500760127906688e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48454893 0.48459494 0.48459157 0.48458993 0.4845819  0.48458827\n",
            " 0.48454866 0.4845469  0.48465356 0.48451516 0.4846051  0.48464692\n",
            " 0.48451862 0.48466557 0.48462644 0.48456427 0.4845608  0.48459533\n",
            " 0.48453182 0.48460433 0.4845261  0.48458102 0.4846636  0.48457313\n",
            " 0.48450607 0.48462158 0.48450765 0.48454276 0.48457584 0.4846051\n",
            " 0.48454955 0.48451453 0.48459837 0.48458427 0.4845435  0.48450115\n",
            " 0.48450205 0.48461762 0.48456618 0.48452836 0.4845467  0.48465222\n",
            " 0.48451528 0.4845727  0.48455888 0.48458833 0.48464167 0.48458114\n",
            " 0.48460665 0.48458222 0.48456132 0.4845103  0.4845327  0.48451725\n",
            " 0.4846636  0.48448175 0.4845983  0.48468903 0.4845817  0.4845693 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 4.777873618877493e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48118582 0.4811356  0.48120844 0.48119485 0.48121685 0.48120725\n",
            " 0.48106983 0.4812255  0.48119724 0.48108175 0.4811933  0.48117712\n",
            " 0.48115927 0.48117417 0.48119038 0.48115876 0.48119593 0.4811752\n",
            " 0.48114786 0.48118427 0.48117188 0.48116556 0.4812343  0.48118615\n",
            " 0.48115173 0.48124984 0.4811325  0.48116258 0.4811638  0.48119754\n",
            " 0.48118657 0.48116985 0.4812052  0.48114663 0.48107985 0.4811382\n",
            " 0.48114938 0.48123062 0.48122734 0.4811262  0.48118472 0.48128787\n",
            " 0.48108223 0.48118603 0.4811965  0.4811795  0.48117986 0.48126358\n",
            " 0.4812451  0.48110703 0.48121488 0.48111126 0.4811761  0.48116413\n",
            " 0.48117453 0.48111406 0.48120195 0.48123926 0.4812016  0.48120567]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.466629252419807e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5053369  0.505393   0.5053544  0.50537145 0.50536054 0.5053138\n",
            " 0.5053978  0.5053361  0.5053901  0.5053736  0.5053609  0.5053739\n",
            " 0.5053294  0.50536346 0.5053775  0.50534105 0.5053259  0.5053765\n",
            " 0.5053549  0.5053519  0.50532305 0.50533956 0.5053724  0.5053475\n",
            " 0.5052984  0.5053771  0.5052885  0.50533175 0.50537074 0.50538105\n",
            " 0.50532836 0.5053021  0.505347   0.5053485  0.5054135  0.5052899\n",
            " 0.5053026  0.5053836  0.5053359  0.505357   0.50535005 0.5053931\n",
            " 0.5053606  0.50536156 0.50534785 0.50535196 0.5053836  0.5053556\n",
            " 0.50535816 0.50540006 0.5053408  0.5053029  0.50532806 0.5053184\n",
            " 0.50537425 0.5052897  0.5053377  0.5053746  0.50532866 0.5053323 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9348726457101293e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51729614 0.5172901  0.51725864 0.51726127 0.51724344 0.5172667\n",
            " 0.5173348  0.51727706 0.5172631  0.5173591  0.51724887 0.51723033\n",
            " 0.51726437 0.51721495 0.5172784  0.5173014  0.51724744 0.51728374\n",
            " 0.517306   0.5172484  0.5172907  0.5172759  0.5172907  0.5172705\n",
            " 0.51731354 0.5172224  0.5173255  0.51726997 0.51730394 0.5172688\n",
            " 0.5172536  0.51729333 0.51726127 0.5173017  0.5173402  0.51733476\n",
            " 0.5173152  0.5172533  0.5172389  0.5173206  0.51727706 0.5172165\n",
            " 0.51733416 0.51726395 0.5172398  0.51728505 0.517275   0.5172549\n",
            " 0.5172368  0.5173247  0.5172709  0.51735103 0.51726806 0.51727164\n",
            " 0.5172124  0.51732916 0.51724714 0.51720476 0.5172643  0.5172604 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.5842105717165396e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48512045 0.48514473 0.48514014 0.48515454 0.48512462 0.4851407\n",
            " 0.48514858 0.4851337  0.4851676  0.48513794 0.4851267  0.48514116\n",
            " 0.48512763 0.48512533 0.48515576 0.48514047 0.48514372 0.4851555\n",
            " 0.48515546 0.48512974 0.48513743 0.48512632 0.48517948 0.4851358\n",
            " 0.4851332  0.48511457 0.48514098 0.48511982 0.48513204 0.48514864\n",
            " 0.48511845 0.48513344 0.48514047 0.4851314  0.4851383  0.4851578\n",
            " 0.48514062 0.4851343  0.48515263 0.4851226  0.485125   0.48510864\n",
            " 0.48516485 0.4851622  0.48511717 0.485145   0.4851547  0.4851103\n",
            " 0.48513559 0.48510763 0.48512986 0.48513544 0.48512965 0.4851281\n",
            " 0.48512888 0.4851438  0.4851128  0.48511127 0.48511326 0.48512766]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.5500760127906688e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48454893 0.48459494 0.48459157 0.48458993 0.4845819  0.48458827\n",
            " 0.48454866 0.4845469  0.48465356 0.48451516 0.4846051  0.48464692\n",
            " 0.48451862 0.48466557 0.48462644 0.48456427 0.4845608  0.48459533\n",
            " 0.48453182 0.48460433 0.4845261  0.48458102 0.4846636  0.48457313\n",
            " 0.48450607 0.48462158 0.48450765 0.48454276 0.48457584 0.4846051\n",
            " 0.48454955 0.48451453 0.48459837 0.48458427 0.4845435  0.48450115\n",
            " 0.48450205 0.48461762 0.48456618 0.48452836 0.4845467  0.48465222\n",
            " 0.48451528 0.4845727  0.48455888 0.48458833 0.48464167 0.48458114\n",
            " 0.48460665 0.48458222 0.48456132 0.4845103  0.4845327  0.48451725\n",
            " 0.4846636  0.48448175 0.4845983  0.48468903 0.4845817  0.4845693 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 4.777873618877493e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48118582 0.4811356  0.48120844 0.48119485 0.48121685 0.48120725\n",
            " 0.48106983 0.4812255  0.48119724 0.48108175 0.4811933  0.48117712\n",
            " 0.48115927 0.48117417 0.48119038 0.48115876 0.48119593 0.4811752\n",
            " 0.48114786 0.48118427 0.48117188 0.48116556 0.4812343  0.48118615\n",
            " 0.48115173 0.48124984 0.4811325  0.48116258 0.4811638  0.48119754\n",
            " 0.48118657 0.48116985 0.4812052  0.48114663 0.48107985 0.4811382\n",
            " 0.48114938 0.48123062 0.48122734 0.4811262  0.48118472 0.48128787\n",
            " 0.48108223 0.48118603 0.4811965  0.4811795  0.48117986 0.48126358\n",
            " 0.4812451  0.48110703 0.48121488 0.48111126 0.4811761  0.48116413\n",
            " 0.48117453 0.48111406 0.48120195 0.48123926 0.4812016  0.48120567]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.466629252419807e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5053369  0.505393   0.5053544  0.50537145 0.50536054 0.5053138\n",
            " 0.5053978  0.5053361  0.5053901  0.5053736  0.5053609  0.5053739\n",
            " 0.5053294  0.50536346 0.5053775  0.50534105 0.5053259  0.5053765\n",
            " 0.5053549  0.5053519  0.50532305 0.50533956 0.5053724  0.5053475\n",
            " 0.5052984  0.5053771  0.5052885  0.50533175 0.50537074 0.50538105\n",
            " 0.50532836 0.5053021  0.505347   0.5053485  0.5054135  0.5052899\n",
            " 0.5053026  0.5053836  0.5053359  0.505357   0.50535005 0.5053931\n",
            " 0.5053606  0.50536156 0.50534785 0.50535196 0.5053836  0.5053556\n",
            " 0.50535816 0.50540006 0.5053408  0.5053029  0.50532806 0.5053184\n",
            " 0.50537425 0.5052897  0.5053377  0.5053746  0.50532866 0.5053323 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9348726457101293e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51729614 0.5172901  0.51725864 0.51726127 0.51724344 0.5172667\n",
            " 0.5173348  0.51727706 0.5172631  0.5173591  0.51724887 0.51723033\n",
            " 0.51726437 0.51721495 0.5172784  0.5173014  0.51724744 0.51728374\n",
            " 0.517306   0.5172484  0.5172907  0.5172759  0.5172907  0.5172705\n",
            " 0.51731354 0.5172224  0.5173255  0.51726997 0.51730394 0.5172688\n",
            " 0.5172536  0.51729333 0.51726127 0.5173017  0.5173402  0.51733476\n",
            " 0.5173152  0.5172533  0.5172389  0.5173206  0.51727706 0.5172165\n",
            " 0.51733416 0.51726395 0.5172398  0.51728505 0.517275   0.5172549\n",
            " 0.5172368  0.5173247  0.5172709  0.51735103 0.51726806 0.51727164\n",
            " 0.5172124  0.51732916 0.51724714 0.51720476 0.5172643  0.5172604 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.5842105717165396e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48512045 0.48514473 0.48514014 0.48515454 0.48512462 0.4851407\n",
            " 0.48514858 0.4851337  0.4851676  0.48513794 0.4851267  0.48514116\n",
            " 0.48512763 0.48512533 0.48515576 0.48514047 0.48514372 0.4851555\n",
            " 0.48515546 0.48512974 0.48513743 0.48512632 0.48517948 0.4851358\n",
            " 0.4851332  0.48511457 0.48514098 0.48511982 0.48513204 0.48514864\n",
            " 0.48511845 0.48513344 0.48514047 0.4851314  0.4851383  0.4851578\n",
            " 0.48514062 0.4851343  0.48515263 0.4851226  0.485125   0.48510864\n",
            " 0.48516485 0.4851622  0.48511717 0.485145   0.4851547  0.4851103\n",
            " 0.48513559 0.48510763 0.48512986 0.48513544 0.48512965 0.4851281\n",
            " 0.48512888 0.4851438  0.4851128  0.48511127 0.48511326 0.48512766]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.5500760127906688e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48454893 0.48459494 0.48459157 0.48458993 0.4845819  0.48458827\n",
            " 0.48454866 0.4845469  0.48465356 0.48451516 0.4846051  0.48464692\n",
            " 0.48451862 0.48466557 0.48462644 0.48456427 0.4845608  0.48459533\n",
            " 0.48453182 0.48460433 0.4845261  0.48458102 0.4846636  0.48457313\n",
            " 0.48450607 0.48462158 0.48450765 0.48454276 0.48457584 0.4846051\n",
            " 0.48454955 0.48451453 0.48459837 0.48458427 0.4845435  0.48450115\n",
            " 0.48450205 0.48461762 0.48456618 0.48452836 0.4845467  0.48465222\n",
            " 0.48451528 0.4845727  0.48455888 0.48458833 0.48464167 0.48458114\n",
            " 0.48460665 0.48458222 0.48456132 0.4845103  0.4845327  0.48451725\n",
            " 0.4846636  0.48448175 0.4845983  0.48468903 0.4845817  0.4845693 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 4.777873618877493e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48116368 0.50535125 0.5173119  0.48514014 0.484562  ]\n",
            " [0.4811433  0.50532323 0.51733667 0.48516464 0.48451295]\n",
            " [0.48111904 0.5053033  0.51732534 0.48515043 0.48451498]\n",
            " [0.48113164 0.5053882  0.51731396 0.48515627 0.4845512 ]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48115268 0.50533277 0.5172828  0.48514196 0.48451865]\n",
            " [0.4811916  0.50532913 0.51728326 0.4851386  0.484618  ]\n",
            " [0.4812259  0.5053594  0.517244   0.48510265 0.48462826]\n",
            " [0.4811387  0.50531185 0.5173088  0.48516035 0.4844952 ]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812197  0.5053391  0.5172674  0.48510846 0.4845774 ]\n",
            " [0.4812042  0.50535536 0.5172486  0.48512787 0.4845601 ]\n",
            " [0.48122734 0.50536126 0.51723903 0.48511702 0.48458105]\n",
            " [0.4811874  0.50531745 0.51727796 0.48513836 0.48455942]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4811682  0.5054197  0.5172726  0.485141   0.48461378]\n",
            " [0.48118117 0.505349   0.5172862  0.48513195 0.4846388 ]\n",
            " [0.48119256 0.5053232  0.5172717  0.48514616 0.4845169 ]\n",
            " [0.48118436 0.5053194  0.5172864  0.48511592 0.48454392]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48117274 0.5053394  0.517282   0.48513275 0.4845471 ]\n",
            " [0.4812432  0.5053934  0.5172068  0.48513404 0.48466483]\n",
            " [0.48120496 0.5053599  0.5172161  0.48512468 0.4846032 ]\n",
            " [0.48117188 0.5053164  0.5172923  0.48513278 0.48454282]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48116368 0.4811433  0.48111904 0.48113164 0.48115268 0.4811916\n",
            " 0.4812259  0.4811387  0.4812197  0.4812042  0.48122734 0.4811874\n",
            " 0.4811682  0.48118117 0.48119256 0.48118436 0.48117274 0.4812432\n",
            " 0.48120496 0.48117188]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.304791243863292e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50535125 0.50532323 0.5053033  0.5053882  0.50533277 0.50532913\n",
            " 0.5053594  0.50531185 0.5053391  0.50535536 0.50536126 0.50531745\n",
            " 0.5054197  0.505349   0.5053232  0.5053194  0.5053394  0.5053934\n",
            " 0.5053599  0.5053164 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 2.9260543669806793e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5173119  0.51733667 0.51732534 0.51731396 0.5172828  0.51728326\n",
            " 0.517244   0.5173088  0.5172674  0.5172486  0.51723903 0.51727796\n",
            " 0.5172726  0.5172862  0.5172717  0.5172864  0.517282   0.5172068\n",
            " 0.5172161  0.5172923 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.324526915093884e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48514014 0.48516464 0.48515043 0.48515627 0.48514196 0.4851386\n",
            " 0.48510265 0.48516035 0.48510846 0.48512787 0.48511702 0.48513836\n",
            " 0.485141   0.48513195 0.48514616 0.48511592 0.48513275 0.48513404\n",
            " 0.48512468 0.48513278]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5945732229738496e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.484562   0.48451295 0.48451498 0.4845512  0.48451865 0.484618\n",
            " 0.48462826 0.4844952  0.4845774  0.4845601  0.48458105 0.48455942\n",
            " 0.48461378 0.4846388  0.4845169  0.48454392 0.4845471  0.48466483\n",
            " 0.4846032  0.48454282]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 4.604612695402466e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48116368 0.4811433  0.48111904 0.48113164 0.48115268 0.4811916\n",
            " 0.4812259  0.4811387  0.4812197  0.4812042  0.48122734 0.4811874\n",
            " 0.4811682  0.48118117 0.48119256 0.48118436 0.48117274 0.4812432\n",
            " 0.48120496 0.48117188]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.304791243863292e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50535125 0.50532323 0.5053033  0.5053882  0.50533277 0.50532913\n",
            " 0.5053594  0.50531185 0.5053391  0.50535536 0.50536126 0.50531745\n",
            " 0.5054197  0.505349   0.5053232  0.5053194  0.5053394  0.5053934\n",
            " 0.5053599  0.5053164 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 2.9260543669806793e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5173119  0.51733667 0.51732534 0.51731396 0.5172828  0.51728326\n",
            " 0.517244   0.5173088  0.5172674  0.5172486  0.51723903 0.51727796\n",
            " 0.5172726  0.5172862  0.5172717  0.5172864  0.517282   0.5172068\n",
            " 0.5172161  0.5172923 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.324526915093884e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48514014 0.48516464 0.48515043 0.48515627 0.48514196 0.4851386\n",
            " 0.48510265 0.48516035 0.48510846 0.48512787 0.48511702 0.48513836\n",
            " 0.485141   0.48513195 0.48514616 0.48511592 0.48513275 0.48513404\n",
            " 0.48512468 0.48513278]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5945732229738496e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.484562   0.48451295 0.48451498 0.4845512  0.48451865 0.484618\n",
            " 0.48462826 0.4844952  0.4845774  0.4845601  0.48458105 0.48455942\n",
            " 0.48461378 0.4846388  0.4845169  0.48454392 0.4845471  0.48466483\n",
            " 0.4846032  0.48454282]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 4.604612695402466e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48116368 0.4811433  0.48111904 0.48113164 0.48115268 0.4811916\n",
            " 0.4812259  0.4811387  0.4812197  0.4812042  0.48122734 0.4811874\n",
            " 0.4811682  0.48118117 0.48119256 0.48118436 0.48117274 0.4812432\n",
            " 0.48120496 0.48117188]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.304791243863292e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50535125 0.50532323 0.5053033  0.5053882  0.50533277 0.50532913\n",
            " 0.5053594  0.50531185 0.5053391  0.50535536 0.50536126 0.50531745\n",
            " 0.5054197  0.505349   0.5053232  0.5053194  0.5053394  0.5053934\n",
            " 0.5053599  0.5053164 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 2.9260543669806793e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5173119  0.51733667 0.51732534 0.51731396 0.5172828  0.51728326\n",
            " 0.517244   0.5173088  0.5172674  0.5172486  0.51723903 0.51727796\n",
            " 0.5172726  0.5172862  0.5172717  0.5172864  0.517282   0.5172068\n",
            " 0.5172161  0.5172923 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.324526915093884e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48514014 0.48516464 0.48515043 0.48515627 0.48514196 0.4851386\n",
            " 0.48510265 0.48516035 0.48510846 0.48512787 0.48511702 0.48513836\n",
            " 0.485141   0.48513195 0.48514616 0.48511592 0.48513275 0.48513404\n",
            " 0.48512468 0.48513278]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5945732229738496e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.484562   0.48451295 0.48451498 0.4845512  0.48451865 0.484618\n",
            " 0.48462826 0.4844952  0.4845774  0.4845601  0.48458105 0.48455942\n",
            " 0.48461378 0.4846388  0.4845169  0.48454392 0.4845471  0.48466483\n",
            " 0.4846032  0.48454282]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 4.604612695402466e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48116368 0.4811433  0.48111904 0.48113164 0.48115268 0.4811916\n",
            " 0.4812259  0.4811387  0.4812197  0.4812042  0.48122734 0.4811874\n",
            " 0.4811682  0.48118117 0.48119256 0.48118436 0.48117274 0.4812432\n",
            " 0.48120496 0.48117188]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.304791243863292e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50535125 0.50532323 0.5053033  0.5053882  0.50533277 0.50532913\n",
            " 0.5053594  0.50531185 0.5053391  0.50535536 0.50536126 0.50531745\n",
            " 0.5054197  0.505349   0.5053232  0.5053194  0.5053394  0.5053934\n",
            " 0.5053599  0.5053164 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 2.9260543669806793e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5173119  0.51733667 0.51732534 0.51731396 0.5172828  0.51728326\n",
            " 0.517244   0.5173088  0.5172674  0.5172486  0.51723903 0.51727796\n",
            " 0.5172726  0.5172862  0.5172717  0.5172864  0.517282   0.5172068\n",
            " 0.5172161  0.5172923 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.324526915093884e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48514014 0.48516464 0.48515043 0.48515627 0.48514196 0.4851386\n",
            " 0.48510265 0.48516035 0.48510846 0.48512787 0.48511702 0.48513836\n",
            " 0.485141   0.48513195 0.48514616 0.48511592 0.48513275 0.48513404\n",
            " 0.48512468 0.48513278]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5945732229738496e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.484562   0.48451295 0.48451498 0.4845512  0.48451865 0.484618\n",
            " 0.48462826 0.4844952  0.4845774  0.4845601  0.48458105 0.48455942\n",
            " 0.48461378 0.4846388  0.4845169  0.48454392 0.4845471  0.48466483\n",
            " 0.4846032  0.48454282]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 4.604612695402466e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48121685 0.5053614  0.51727116 0.48514992 0.48457205]\n",
            " [0.4812209  0.5053616  0.5172393  0.48511297 0.4845991 ]\n",
            " [0.4812279  0.5053748  0.51724076 0.4851195  0.48460978]\n",
            " [0.4811805  0.50534433 0.5172622  0.48514438 0.48455685]\n",
            " [0.48123816 0.5053723  0.5172288  0.48509157 0.48461923]\n",
            " [0.4811526  0.50532746 0.5173351  0.48514563 0.48453242]\n",
            " [0.48114684 0.5053288  0.5173018  0.48515514 0.4845432 ]\n",
            " [0.48114374 0.5052955  0.5172931  0.48513803 0.4845067 ]\n",
            " [0.48116684 0.50532293 0.5173081  0.48517242 0.4845245 ]\n",
            " [0.48116153 0.5053556  0.517265   0.4851446  0.48460892]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48115072 0.50535834 0.51729923 0.48515844 0.48459893]\n",
            " [0.48116612 0.5053359  0.5173036  0.48515022 0.48454648]\n",
            " [0.4811878  0.50532997 0.5172795  0.4851476  0.48457143]\n",
            " [0.48123294 0.50537044 0.5172345  0.48515737 0.484656  ]\n",
            " [0.48116696 0.505335   0.5172714  0.48513624 0.4845411 ]\n",
            " [0.4812108  0.5053387  0.51725733 0.48512498 0.48459166]\n",
            " [0.4812152  0.505356   0.51725066 0.48513132 0.48464346]\n",
            " [0.4811599  0.5052951  0.51729757 0.4851253  0.48449713]\n",
            " [0.48120052 0.5053817  0.5172474  0.48512918 0.48457912]\n",
            " [0.48113886 0.50538516 0.5172968  0.48514166 0.48458764]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48121685 0.4812209  0.4812279  0.4811805  0.48123816 0.4811526\n",
            " 0.48114684 0.48114374 0.48116684 0.48116153 0.48115072 0.48116612\n",
            " 0.4811878  0.48123294 0.48116696 0.4812108  0.4812152  0.4811599\n",
            " 0.48120052 0.48113886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.225685577490367e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5053614  0.5053616  0.5053748  0.50534433 0.5053723  0.50532746\n",
            " 0.5053288  0.5052955  0.50532293 0.5053556  0.50535834 0.5053359\n",
            " 0.50532997 0.50537044 0.505335   0.5053387  0.505356   0.5052951\n",
            " 0.5053817  0.50538516]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5092043870245107e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51727116 0.5172393  0.51724076 0.5172622  0.5172288  0.5173351\n",
            " 0.5173018  0.5172931  0.5173081  0.517265   0.51729923 0.5173036\n",
            " 0.5172795  0.5172345  0.5172714  0.51725733 0.51725066 0.51729757\n",
            " 0.5172474  0.5172968 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.8578037017723545e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48514992 0.48511297 0.4851195  0.48514438 0.48509157 0.48514563\n",
            " 0.48515514 0.48513803 0.48517242 0.4851446  0.48515844 0.48515022\n",
            " 0.4851476  0.48515737 0.48513624 0.48512498 0.48513132 0.4851253\n",
            " 0.48512918 0.48514166]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7858932551462203e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48457205 0.4845991  0.48460978 0.48455685 0.48461923 0.48453242\n",
            " 0.4845432  0.4845067  0.4845245  0.48460892 0.48459893 0.48454648\n",
            " 0.48457143 0.484656   0.4845411  0.48459166 0.48464346 0.48449713\n",
            " 0.48457912 0.48458764]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.217974856146611e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48121685 0.4812209  0.4812279  0.4811805  0.48123816 0.4811526\n",
            " 0.48114684 0.48114374 0.48116684 0.48116153 0.48115072 0.48116612\n",
            " 0.4811878  0.48123294 0.48116696 0.4812108  0.4812152  0.4811599\n",
            " 0.48120052 0.48113886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.225685577490367e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5053614  0.5053616  0.5053748  0.50534433 0.5053723  0.50532746\n",
            " 0.5053288  0.5052955  0.50532293 0.5053556  0.50535834 0.5053359\n",
            " 0.50532997 0.50537044 0.505335   0.5053387  0.505356   0.5052951\n",
            " 0.5053817  0.50538516]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5092043870245107e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51727116 0.5172393  0.51724076 0.5172622  0.5172288  0.5173351\n",
            " 0.5173018  0.5172931  0.5173081  0.517265   0.51729923 0.5173036\n",
            " 0.5172795  0.5172345  0.5172714  0.51725733 0.51725066 0.51729757\n",
            " 0.5172474  0.5172968 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.8578037017723545e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48514992 0.48511297 0.4851195  0.48514438 0.48509157 0.48514563\n",
            " 0.48515514 0.48513803 0.48517242 0.4851446  0.48515844 0.48515022\n",
            " 0.4851476  0.48515737 0.48513624 0.48512498 0.48513132 0.4851253\n",
            " 0.48512918 0.48514166]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7858932551462203e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48457205 0.4845991  0.48460978 0.48455685 0.48461923 0.48453242\n",
            " 0.4845432  0.4845067  0.4845245  0.48460892 0.48459893 0.48454648\n",
            " 0.48457143 0.484656   0.4845411  0.48459166 0.48464346 0.48449713\n",
            " 0.48457912 0.48458764]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.217974856146611e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48121685 0.4812209  0.4812279  0.4811805  0.48123816 0.4811526\n",
            " 0.48114684 0.48114374 0.48116684 0.48116153 0.48115072 0.48116612\n",
            " 0.4811878  0.48123294 0.48116696 0.4812108  0.4812152  0.4811599\n",
            " 0.48120052 0.48113886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.225685577490367e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5053614  0.5053616  0.5053748  0.50534433 0.5053723  0.50532746\n",
            " 0.5053288  0.5052955  0.50532293 0.5053556  0.50535834 0.5053359\n",
            " 0.50532997 0.50537044 0.505335   0.5053387  0.505356   0.5052951\n",
            " 0.5053817  0.50538516]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5092043870245107e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51727116 0.5172393  0.51724076 0.5172622  0.5172288  0.5173351\n",
            " 0.5173018  0.5172931  0.5173081  0.517265   0.51729923 0.5173036\n",
            " 0.5172795  0.5172345  0.5172714  0.51725733 0.51725066 0.51729757\n",
            " 0.5172474  0.5172968 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.8578037017723545e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48514992 0.48511297 0.4851195  0.48514438 0.48509157 0.48514563\n",
            " 0.48515514 0.48513803 0.48517242 0.4851446  0.48515844 0.48515022\n",
            " 0.4851476  0.48515737 0.48513624 0.48512498 0.48513132 0.4851253\n",
            " 0.48512918 0.48514166]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7858932551462203e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48457205 0.4845991  0.48460978 0.48455685 0.48461923 0.48453242\n",
            " 0.4845432  0.4845067  0.4845245  0.48460892 0.48459893 0.48454648\n",
            " 0.48457143 0.484656   0.4845411  0.48459166 0.48464346 0.48449713\n",
            " 0.48457912 0.48458764]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.217974856146611e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48121685 0.4812209  0.4812279  0.4811805  0.48123816 0.4811526\n",
            " 0.48114684 0.48114374 0.48116684 0.48116153 0.48115072 0.48116612\n",
            " 0.4811878  0.48123294 0.48116696 0.4812108  0.4812152  0.4811599\n",
            " 0.48120052 0.48113886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.225685577490367e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5053614  0.5053616  0.5053748  0.50534433 0.5053723  0.50532746\n",
            " 0.5053288  0.5052955  0.50532293 0.5053556  0.50535834 0.5053359\n",
            " 0.50532997 0.50537044 0.505335   0.5053387  0.505356   0.5052951\n",
            " 0.5053817  0.50538516]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5092043870245107e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51727116 0.5172393  0.51724076 0.5172622  0.5172288  0.5173351\n",
            " 0.5173018  0.5172931  0.5173081  0.517265   0.51729923 0.5173036\n",
            " 0.5172795  0.5172345  0.5172714  0.51725733 0.51725066 0.51729757\n",
            " 0.5172474  0.5172968 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.8578037017723545e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48514992 0.48511297 0.4851195  0.48514438 0.48509157 0.48514563\n",
            " 0.48515514 0.48513803 0.48517242 0.4851446  0.48515844 0.48515022\n",
            " 0.4851476  0.48515737 0.48513624 0.48512498 0.48513132 0.4851253\n",
            " 0.48512918 0.48514166]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7858932551462203e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48457205 0.4845991  0.48460978 0.48455685 0.48461923 0.48453242\n",
            " 0.4845432  0.4845067  0.4845245  0.48460892 0.48459893 0.48454648\n",
            " 0.48457143 0.484656   0.4845411  0.48459166 0.48464346 0.48449713\n",
            " 0.48457912 0.48458764]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.217974856146611e-05\n",
            "Epoch 2/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48118582 0.5053369  0.51729614 0.48512045 0.48454893]\n",
            " [0.4811356  0.505393   0.5172901  0.48514473 0.48459494]\n",
            " [0.48120844 0.5053544  0.51725864 0.48514014 0.48459157]\n",
            " [0.48119485 0.50537145 0.51726127 0.48515454 0.48458993]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812454  0.5053917  0.5172785  0.48516777 0.48463207]\n",
            " [0.48123586 0.50534505 0.51730174 0.4851838  0.48463842]\n",
            " [0.48109764 0.505428   0.51736945 0.48519048 0.48459747]\n",
            " [0.48125398 0.50536704 0.5173119  0.48517644 0.48459673]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48125377 0.5054349  0.5173039  0.48520204 0.4847622 ]\n",
            " [0.48113638 0.5054164  0.5173995  0.4851708  0.48462075]\n",
            " [0.4812499  0.50540537 0.51728976 0.48516098 0.4847136 ]\n",
            " [0.4812339  0.5054187  0.51727146 0.48517558 0.4847561 ]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48123077 0.5053932  0.5173335  0.48519108 0.48466417]\n",
            " [0.48124644 0.5054282  0.51728517 0.48519003 0.484814  ]\n",
            " [0.48126227 0.50544196 0.51734823 0.48521972 0.4847732 ]\n",
            " [0.48123044 0.5054052  0.5173711  0.48520416 0.4847104 ]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48130763 0.50540715 0.5173404  0.48522055 0.48476735]\n",
            " [0.48128742 0.50545824 0.5173767  0.48523262 0.48480204]\n",
            " [0.4812595  0.5054359  0.5173984  0.48523182 0.4847367 ]\n",
            " [0.4812967  0.50543356 0.5173418  0.48520717 0.48481205]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48128805 0.50540376 0.517374   0.4852092  0.48477563]\n",
            " [0.48128274 0.5054208  0.5173595  0.4851985  0.48483175]\n",
            " [0.4813521  0.50545424 0.51737463 0.48525208 0.48491678]\n",
            " [0.48130357 0.50542855 0.5173543  0.4852082  0.48482493]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48130035 0.50542253 0.51742226 0.48524696 0.4847918 ]\n",
            " [0.48140132 0.5055034  0.51733315 0.48523128 0.48491392]\n",
            " [0.48128024 0.50541145 0.5174345  0.48525375 0.48479185]\n",
            " [0.481312   0.5054567  0.5173794  0.48523447 0.48483077]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4812923  0.5054715  0.5173943  0.48526308 0.48488876]\n",
            " [0.48132676 0.50548303 0.5173601  0.48528165 0.48492175]\n",
            " [0.48131508 0.5054295  0.5173445  0.485251   0.4848654 ]\n",
            " [0.48129815 0.5054024  0.51738334 0.48526433 0.48482683]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4813467  0.5054587  0.51736224 0.48528793 0.4849316 ]\n",
            " [0.48128906 0.50546134 0.517402   0.4852793  0.48491767]\n",
            " [0.48121712 0.5055204  0.51744115 0.4852806  0.48486796]\n",
            " [0.48127896 0.5054009  0.5174341  0.48530358 0.4848303 ]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48127574 0.50539136 0.51740825 0.4852795  0.48482534]\n",
            " [0.48135918 0.5054742  0.517348   0.48527643 0.48494747]\n",
            " [0.48135507 0.5054258  0.517333   0.4852937  0.48489374]\n",
            " [0.48125213 0.50544524 0.5174142  0.48526075 0.48485106]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4813894  0.50550807 0.5174231  0.48532242 0.4849525 ]\n",
            " [0.48149583 0.5055542  0.51736414 0.48531002 0.48506516]\n",
            " [0.48128107 0.50551265 0.5174798  0.4853558  0.4849105 ]\n",
            " [0.4813921  0.5055208  0.5174102  0.48536098 0.4849802 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4814045  0.50553286 0.51739633 0.48535722 0.48498982]\n",
            " [0.48138607 0.5055364  0.51744145 0.48538354 0.48501673]\n",
            " [0.48138598 0.5055682  0.51743156 0.48539314 0.4850699 ]\n",
            " [0.4814719  0.50554127 0.51741207 0.48535076 0.48501244]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48147032 0.50557023 0.51742876 0.4854164  0.48508012]\n",
            " [0.48132992 0.5056085  0.5175142  0.4853828  0.4850477 ]\n",
            " [0.4814391  0.50555146 0.51746184 0.48540866 0.48503184]\n",
            " [0.48133096 0.50550836 0.51754016 0.48540735 0.4849706 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48141074 0.5055619  0.5174811  0.48543918 0.4850244 ]\n",
            " [0.48139825 0.50555164 0.51748455 0.48543718 0.4850083 ]\n",
            " [0.48141107 0.5056104  0.51742774 0.4854432  0.48516342]\n",
            " [0.48134413 0.5055181  0.5175407  0.4854465  0.48496404]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4814276  0.505544   0.517443   0.48539686 0.48510438]\n",
            " [0.48146516 0.5055814  0.51740164 0.48539564 0.4851954 ]\n",
            " [0.48142746 0.50553447 0.5174592  0.48539585 0.48508474]\n",
            " [0.48143175 0.50553876 0.51745594 0.4854109  0.48507306]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48144406 0.50558406 0.5175203  0.48544174 0.4851073 ]\n",
            " [0.48139188 0.5056393  0.5175148  0.48546407 0.48515093]\n",
            " [0.48146814 0.5056044  0.51748395 0.48546454 0.48515466]\n",
            " [0.48145416 0.50561976 0.5174867  0.48547783 0.48515177]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4814767  0.50561005 0.5174689  0.485449   0.48514506]\n",
            " [0.48146695 0.5055634  0.5174918  0.48546454 0.4851501 ]\n",
            " [0.48131898 0.50563484 0.51755995 0.4854591  0.48509234]\n",
            " [0.48148456 0.5055841  0.5175013  0.48545587 0.48510692]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48145568 0.5056388  0.5174891  0.4854907  0.48521465]\n",
            " [0.48133138 0.50561047 0.51758444 0.48544875 0.485059  ]\n",
            " [0.4814524  0.50560987 0.5174749  0.48544982 0.48516664]\n",
            " [0.48143637 0.50562304 0.51745576 0.48546582 0.48521224]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48141652 0.50557584 0.517488   0.48544806 0.48507527]\n",
            " [0.48143402 0.5056131  0.5174411  0.48545116 0.48523286]\n",
            " [0.48144904 0.5056259  0.5175041  0.48547783 0.4851865 ]\n",
            " [0.48141706 0.50558853 0.51752657 0.4854614  0.48512226]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48145378 0.5055736  0.5174715  0.48546553 0.48512042]\n",
            " [0.4814337  0.5056246  0.51750803 0.48547715 0.48515424]\n",
            " [0.4814039  0.5055992  0.5175299  0.4854729  0.48508456]\n",
            " [0.48144343 0.5056006  0.5174734  0.48545352 0.48516685]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48142865 0.5055696  0.5175145  0.4854575  0.48508263]\n",
            " [0.4814239  0.50558716 0.5175007  0.4854478  0.48513982]\n",
            " [0.48149413 0.5056233  0.51751614 0.48550445 0.48522863]\n",
            " [0.48144618 0.5055963  0.5174953  0.4854595  0.48513538]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48140782 0.50554377 0.51753676 0.48545185 0.48506   ]\n",
            " [0.4815112  0.5056278  0.5174489  0.48544148 0.48518932]\n",
            " [0.48138672 0.50553125 0.51754916 0.48545715 0.4850585 ]\n",
            " [0.48142046 0.5055793  0.51749396 0.48544148 0.4851019 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48142138 0.5056171  0.5175275  0.48545146 0.48513156]\n",
            " [0.4814568  0.5056306  0.5174945  0.48547235 0.48516753]\n",
            " [0.48144495 0.5055765  0.5174783  0.48544136 0.48511094]\n",
            " [0.4814274  0.5055481  0.51751614 0.4854528  0.48506972]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48146194 0.5055936  0.51748717 0.48546165 0.48515716]\n",
            " [0.48140523 0.50559723 0.517526   0.48545343 0.48514378]\n",
            " [0.48132813 0.50564957 0.51756555 0.4854484  0.48508632]\n",
            " [0.48139322 0.5055338  0.5175576  0.48547482 0.48505262]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48140565 0.5055481  0.51753825 0.48545942 0.48505616]\n",
            " [0.4814909  0.50563395 0.5174797  0.48545974 0.48518285]\n",
            " [0.48148656 0.5055849  0.517464   0.4854762  0.485128  ]\n",
            " [0.48138145 0.5056014  0.51754445 0.48543993 0.48508114]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48144287 0.5055975  0.5175015  0.48544663 0.48510575]\n",
            " [0.4815502  0.50564545 0.51744336 0.48543653 0.4852213 ]\n",
            " [0.4813326  0.50559884 0.51755834 0.48547614 0.48505932]\n",
            " [0.48144618 0.5056108  0.5174888  0.48548582 0.48513418]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48145637 0.5055961  0.5174649  0.48544055 0.48512113]\n",
            " [0.48143739 0.5055994  0.5175099  0.48546642 0.48514712]\n",
            " [0.4814373  0.50563145 0.5174999  0.48547608 0.48520032]\n",
            " [0.48152354 0.5056045  0.5174808  0.48543417 0.4851436 ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48150468 0.50560826 0.51746243 0.48546043 0.48517078]\n",
            " [0.48136422 0.5056461  0.5175478  0.48542625 0.48513696]\n",
            " [0.48147336 0.5055892  0.5174954  0.48545244 0.48512194]\n",
            " [0.4813644  0.50554496 0.5175738  0.48544988 0.48505855]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48143446 0.5055756  0.5174919  0.48545113 0.4850912 ]\n",
            " [0.48142186 0.5055653  0.51749533 0.48544905 0.48507503]\n",
            " [0.4814348  0.505624   0.5174386  0.48545513 0.48523128]\n",
            " [0.48136702 0.50553113 0.5175515  0.4854578  0.48502916]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48146197 0.5055874  0.5174729  0.485438   0.48516345]\n",
            " [0.48149928 0.5056247  0.5174317  0.48543653 0.48525426]\n",
            " [0.48146158 0.5055776  0.51748884 0.48543662 0.48514327]\n",
            " [0.48146597 0.505582   0.5174856  0.48545173 0.48513168]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48144406 0.48139188 0.48146814 0.48145416 0.4814767  0.48146695\n",
            " 0.48131898 0.48148456 0.48145568 0.48133138 0.4814524  0.48143637\n",
            " 0.48141652 0.48143402 0.48144904 0.48141706 0.48145378 0.4814337\n",
            " 0.4814039  0.48144343 0.48142865 0.4814239  0.48149413 0.48144618\n",
            " 0.48140782 0.4815112  0.48138672 0.48142046 0.48142138 0.4814568\n",
            " 0.48144495 0.4814274  0.48146194 0.48140523 0.48132813 0.48139322\n",
            " 0.48140565 0.4814909  0.48148656 0.48138145 0.48144287 0.4815502\n",
            " 0.4813326  0.48144618 0.48145637 0.48143739 0.4814373  0.48152354\n",
            " 0.48150468 0.48136422 0.48147336 0.4813644  0.48143446 0.48142186\n",
            " 0.4814348  0.48136702 0.48146197 0.48149928 0.48146158 0.48146597]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.719789285445586e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50558406 0.5056393  0.5056044  0.50561976 0.50561005 0.5055634\n",
            " 0.50563484 0.5055841  0.5056388  0.50561047 0.50560987 0.50562304\n",
            " 0.50557584 0.5056131  0.5056259  0.50558853 0.5055736  0.5056246\n",
            " 0.5055992  0.5056006  0.5055696  0.50558716 0.5056233  0.5055963\n",
            " 0.50554377 0.5056278  0.50553125 0.5055793  0.5056171  0.5056306\n",
            " 0.5055765  0.5055481  0.5055936  0.50559723 0.50564957 0.5055338\n",
            " 0.5055481  0.50563395 0.5055849  0.5056014  0.5055975  0.50564545\n",
            " 0.50559884 0.5056108  0.5055961  0.5055994  0.50563145 0.5056045\n",
            " 0.50560826 0.5056461  0.5055892  0.50554496 0.5055756  0.5055653\n",
            " 0.505624   0.50553113 0.5055874  0.5056247  0.5055776  0.505582  ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9782373530906625e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5175203  0.5175148  0.51748395 0.5174867  0.5174689  0.5174918\n",
            " 0.51755995 0.5175013  0.5174891  0.51758444 0.5174749  0.51745576\n",
            " 0.517488   0.5174411  0.5175041  0.51752657 0.5174715  0.51750803\n",
            " 0.5175299  0.5174734  0.5175145  0.5175007  0.51751614 0.5174953\n",
            " 0.51753676 0.5174489  0.51754916 0.51749396 0.5175275  0.5174945\n",
            " 0.5174783  0.51751614 0.51748717 0.517526   0.51756555 0.5175576\n",
            " 0.51753825 0.5174797  0.517464   0.51754445 0.5175015  0.51744336\n",
            " 0.51755834 0.5174888  0.5174649  0.5175099  0.5174999  0.5174808\n",
            " 0.51746243 0.5175478  0.5174954  0.5175738  0.5174919  0.51749533\n",
            " 0.5174386  0.5175515  0.5174729  0.5174317  0.51748884 0.5174856 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.513747651595622e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48544174 0.48546407 0.48546454 0.48547783 0.485449   0.48546454\n",
            " 0.4854591  0.48545587 0.4854907  0.48544875 0.48544982 0.48546582\n",
            " 0.48544806 0.48545116 0.48547783 0.4854614  0.48546553 0.48547715\n",
            " 0.4854729  0.48545352 0.4854575  0.4854478  0.48550445 0.4854595\n",
            " 0.48545185 0.48544148 0.48545715 0.48544148 0.48545146 0.48547235\n",
            " 0.48544136 0.4854528  0.48546165 0.48545343 0.4854484  0.48547482\n",
            " 0.48545942 0.48545974 0.4854762  0.48543993 0.48544663 0.48543653\n",
            " 0.48547614 0.48548582 0.48544055 0.48546642 0.48547608 0.48543417\n",
            " 0.48546043 0.48542625 0.48545244 0.48544988 0.48545113 0.48544905\n",
            " 0.48545513 0.4854578  0.485438   0.48543653 0.48543662 0.48545173]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.4914622624928597e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4851073  0.48515093 0.48515466 0.48515177 0.48514506 0.4851501\n",
            " 0.48509234 0.48510692 0.48521465 0.485059   0.48516664 0.48521224\n",
            " 0.48507527 0.48523286 0.4851865  0.48512226 0.48512042 0.48515424\n",
            " 0.48508456 0.48516685 0.48508263 0.48513982 0.48522863 0.48513538\n",
            " 0.48506    0.48518932 0.4850585  0.4851019  0.48513156 0.48516753\n",
            " 0.48511094 0.48506972 0.48515716 0.48514378 0.48508632 0.48505262\n",
            " 0.48505616 0.48518285 0.485128   0.48508114 0.48510575 0.4852213\n",
            " 0.48505932 0.48513418 0.48512113 0.48514712 0.48520032 0.4851436\n",
            " 0.48517078 0.48513696 0.48512194 0.48505855 0.4850912  0.48507503\n",
            " 0.48523128 0.48502916 0.48516345 0.48525426 0.48514327 0.48513168]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.2398430852917954e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48144406 0.48139188 0.48146814 0.48145416 0.4814767  0.48146695\n",
            " 0.48131898 0.48148456 0.48145568 0.48133138 0.4814524  0.48143637\n",
            " 0.48141652 0.48143402 0.48144904 0.48141706 0.48145378 0.4814337\n",
            " 0.4814039  0.48144343 0.48142865 0.4814239  0.48149413 0.48144618\n",
            " 0.48140782 0.4815112  0.48138672 0.48142046 0.48142138 0.4814568\n",
            " 0.48144495 0.4814274  0.48146194 0.48140523 0.48132813 0.48139322\n",
            " 0.48140565 0.4814909  0.48148656 0.48138145 0.48144287 0.4815502\n",
            " 0.4813326  0.48144618 0.48145637 0.48143739 0.4814373  0.48152354\n",
            " 0.48150468 0.48136422 0.48147336 0.4813644  0.48143446 0.48142186\n",
            " 0.4814348  0.48136702 0.48146197 0.48149928 0.48146158 0.48146597]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.719789285445586e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50558406 0.5056393  0.5056044  0.50561976 0.50561005 0.5055634\n",
            " 0.50563484 0.5055841  0.5056388  0.50561047 0.50560987 0.50562304\n",
            " 0.50557584 0.5056131  0.5056259  0.50558853 0.5055736  0.5056246\n",
            " 0.5055992  0.5056006  0.5055696  0.50558716 0.5056233  0.5055963\n",
            " 0.50554377 0.5056278  0.50553125 0.5055793  0.5056171  0.5056306\n",
            " 0.5055765  0.5055481  0.5055936  0.50559723 0.50564957 0.5055338\n",
            " 0.5055481  0.50563395 0.5055849  0.5056014  0.5055975  0.50564545\n",
            " 0.50559884 0.5056108  0.5055961  0.5055994  0.50563145 0.5056045\n",
            " 0.50560826 0.5056461  0.5055892  0.50554496 0.5055756  0.5055653\n",
            " 0.505624   0.50553113 0.5055874  0.5056247  0.5055776  0.505582  ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9782373530906625e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5175203  0.5175148  0.51748395 0.5174867  0.5174689  0.5174918\n",
            " 0.51755995 0.5175013  0.5174891  0.51758444 0.5174749  0.51745576\n",
            " 0.517488   0.5174411  0.5175041  0.51752657 0.5174715  0.51750803\n",
            " 0.5175299  0.5174734  0.5175145  0.5175007  0.51751614 0.5174953\n",
            " 0.51753676 0.5174489  0.51754916 0.51749396 0.5175275  0.5174945\n",
            " 0.5174783  0.51751614 0.51748717 0.517526   0.51756555 0.5175576\n",
            " 0.51753825 0.5174797  0.517464   0.51754445 0.5175015  0.51744336\n",
            " 0.51755834 0.5174888  0.5174649  0.5175099  0.5174999  0.5174808\n",
            " 0.51746243 0.5175478  0.5174954  0.5175738  0.5174919  0.51749533\n",
            " 0.5174386  0.5175515  0.5174729  0.5174317  0.51748884 0.5174856 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.513747651595622e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48544174 0.48546407 0.48546454 0.48547783 0.485449   0.48546454\n",
            " 0.4854591  0.48545587 0.4854907  0.48544875 0.48544982 0.48546582\n",
            " 0.48544806 0.48545116 0.48547783 0.4854614  0.48546553 0.48547715\n",
            " 0.4854729  0.48545352 0.4854575  0.4854478  0.48550445 0.4854595\n",
            " 0.48545185 0.48544148 0.48545715 0.48544148 0.48545146 0.48547235\n",
            " 0.48544136 0.4854528  0.48546165 0.48545343 0.4854484  0.48547482\n",
            " 0.48545942 0.48545974 0.4854762  0.48543993 0.48544663 0.48543653\n",
            " 0.48547614 0.48548582 0.48544055 0.48546642 0.48547608 0.48543417\n",
            " 0.48546043 0.48542625 0.48545244 0.48544988 0.48545113 0.48544905\n",
            " 0.48545513 0.4854578  0.485438   0.48543653 0.48543662 0.48545173]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.4914622624928597e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4851073  0.48515093 0.48515466 0.48515177 0.48514506 0.4851501\n",
            " 0.48509234 0.48510692 0.48521465 0.485059   0.48516664 0.48521224\n",
            " 0.48507527 0.48523286 0.4851865  0.48512226 0.48512042 0.48515424\n",
            " 0.48508456 0.48516685 0.48508263 0.48513982 0.48522863 0.48513538\n",
            " 0.48506    0.48518932 0.4850585  0.4851019  0.48513156 0.48516753\n",
            " 0.48511094 0.48506972 0.48515716 0.48514378 0.48508632 0.48505262\n",
            " 0.48505616 0.48518285 0.485128   0.48508114 0.48510575 0.4852213\n",
            " 0.48505932 0.48513418 0.48512113 0.48514712 0.48520032 0.4851436\n",
            " 0.48517078 0.48513696 0.48512194 0.48505855 0.4850912  0.48507503\n",
            " 0.48523128 0.48502916 0.48516345 0.48525426 0.48514327 0.48513168]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.2398430852917954e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48144406 0.48139188 0.48146814 0.48145416 0.4814767  0.48146695\n",
            " 0.48131898 0.48148456 0.48145568 0.48133138 0.4814524  0.48143637\n",
            " 0.48141652 0.48143402 0.48144904 0.48141706 0.48145378 0.4814337\n",
            " 0.4814039  0.48144343 0.48142865 0.4814239  0.48149413 0.48144618\n",
            " 0.48140782 0.4815112  0.48138672 0.48142046 0.48142138 0.4814568\n",
            " 0.48144495 0.4814274  0.48146194 0.48140523 0.48132813 0.48139322\n",
            " 0.48140565 0.4814909  0.48148656 0.48138145 0.48144287 0.4815502\n",
            " 0.4813326  0.48144618 0.48145637 0.48143739 0.4814373  0.48152354\n",
            " 0.48150468 0.48136422 0.48147336 0.4813644  0.48143446 0.48142186\n",
            " 0.4814348  0.48136702 0.48146197 0.48149928 0.48146158 0.48146597]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.719789285445586e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50558406 0.5056393  0.5056044  0.50561976 0.50561005 0.5055634\n",
            " 0.50563484 0.5055841  0.5056388  0.50561047 0.50560987 0.50562304\n",
            " 0.50557584 0.5056131  0.5056259  0.50558853 0.5055736  0.5056246\n",
            " 0.5055992  0.5056006  0.5055696  0.50558716 0.5056233  0.5055963\n",
            " 0.50554377 0.5056278  0.50553125 0.5055793  0.5056171  0.5056306\n",
            " 0.5055765  0.5055481  0.5055936  0.50559723 0.50564957 0.5055338\n",
            " 0.5055481  0.50563395 0.5055849  0.5056014  0.5055975  0.50564545\n",
            " 0.50559884 0.5056108  0.5055961  0.5055994  0.50563145 0.5056045\n",
            " 0.50560826 0.5056461  0.5055892  0.50554496 0.5055756  0.5055653\n",
            " 0.505624   0.50553113 0.5055874  0.5056247  0.5055776  0.505582  ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9782373530906625e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5175203  0.5175148  0.51748395 0.5174867  0.5174689  0.5174918\n",
            " 0.51755995 0.5175013  0.5174891  0.51758444 0.5174749  0.51745576\n",
            " 0.517488   0.5174411  0.5175041  0.51752657 0.5174715  0.51750803\n",
            " 0.5175299  0.5174734  0.5175145  0.5175007  0.51751614 0.5174953\n",
            " 0.51753676 0.5174489  0.51754916 0.51749396 0.5175275  0.5174945\n",
            " 0.5174783  0.51751614 0.51748717 0.517526   0.51756555 0.5175576\n",
            " 0.51753825 0.5174797  0.517464   0.51754445 0.5175015  0.51744336\n",
            " 0.51755834 0.5174888  0.5174649  0.5175099  0.5174999  0.5174808\n",
            " 0.51746243 0.5175478  0.5174954  0.5175738  0.5174919  0.51749533\n",
            " 0.5174386  0.5175515  0.5174729  0.5174317  0.51748884 0.5174856 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.513747651595622e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48544174 0.48546407 0.48546454 0.48547783 0.485449   0.48546454\n",
            " 0.4854591  0.48545587 0.4854907  0.48544875 0.48544982 0.48546582\n",
            " 0.48544806 0.48545116 0.48547783 0.4854614  0.48546553 0.48547715\n",
            " 0.4854729  0.48545352 0.4854575  0.4854478  0.48550445 0.4854595\n",
            " 0.48545185 0.48544148 0.48545715 0.48544148 0.48545146 0.48547235\n",
            " 0.48544136 0.4854528  0.48546165 0.48545343 0.4854484  0.48547482\n",
            " 0.48545942 0.48545974 0.4854762  0.48543993 0.48544663 0.48543653\n",
            " 0.48547614 0.48548582 0.48544055 0.48546642 0.48547608 0.48543417\n",
            " 0.48546043 0.48542625 0.48545244 0.48544988 0.48545113 0.48544905\n",
            " 0.48545513 0.4854578  0.485438   0.48543653 0.48543662 0.48545173]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.4914622624928597e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4851073  0.48515093 0.48515466 0.48515177 0.48514506 0.4851501\n",
            " 0.48509234 0.48510692 0.48521465 0.485059   0.48516664 0.48521224\n",
            " 0.48507527 0.48523286 0.4851865  0.48512226 0.48512042 0.48515424\n",
            " 0.48508456 0.48516685 0.48508263 0.48513982 0.48522863 0.48513538\n",
            " 0.48506    0.48518932 0.4850585  0.4851019  0.48513156 0.48516753\n",
            " 0.48511094 0.48506972 0.48515716 0.48514378 0.48508632 0.48505262\n",
            " 0.48505616 0.48518285 0.485128   0.48508114 0.48510575 0.4852213\n",
            " 0.48505932 0.48513418 0.48512113 0.48514712 0.48520032 0.4851436\n",
            " 0.48517078 0.48513696 0.48512194 0.48505855 0.4850912  0.48507503\n",
            " 0.48523128 0.48502916 0.48516345 0.48525426 0.48514327 0.48513168]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.2398430852917954e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48144406 0.48139188 0.48146814 0.48145416 0.4814767  0.48146695\n",
            " 0.48131898 0.48148456 0.48145568 0.48133138 0.4814524  0.48143637\n",
            " 0.48141652 0.48143402 0.48144904 0.48141706 0.48145378 0.4814337\n",
            " 0.4814039  0.48144343 0.48142865 0.4814239  0.48149413 0.48144618\n",
            " 0.48140782 0.4815112  0.48138672 0.48142046 0.48142138 0.4814568\n",
            " 0.48144495 0.4814274  0.48146194 0.48140523 0.48132813 0.48139322\n",
            " 0.48140565 0.4814909  0.48148656 0.48138145 0.48144287 0.4815502\n",
            " 0.4813326  0.48144618 0.48145637 0.48143739 0.4814373  0.48152354\n",
            " 0.48150468 0.48136422 0.48147336 0.4813644  0.48143446 0.48142186\n",
            " 0.4814348  0.48136702 0.48146197 0.48149928 0.48146158 0.48146597]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.719789285445586e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50558406 0.5056393  0.5056044  0.50561976 0.50561005 0.5055634\n",
            " 0.50563484 0.5055841  0.5056388  0.50561047 0.50560987 0.50562304\n",
            " 0.50557584 0.5056131  0.5056259  0.50558853 0.5055736  0.5056246\n",
            " 0.5055992  0.5056006  0.5055696  0.50558716 0.5056233  0.5055963\n",
            " 0.50554377 0.5056278  0.50553125 0.5055793  0.5056171  0.5056306\n",
            " 0.5055765  0.5055481  0.5055936  0.50559723 0.50564957 0.5055338\n",
            " 0.5055481  0.50563395 0.5055849  0.5056014  0.5055975  0.50564545\n",
            " 0.50559884 0.5056108  0.5055961  0.5055994  0.50563145 0.5056045\n",
            " 0.50560826 0.5056461  0.5055892  0.50554496 0.5055756  0.5055653\n",
            " 0.505624   0.50553113 0.5055874  0.5056247  0.5055776  0.505582  ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 2.9782373530906625e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5175203  0.5175148  0.51748395 0.5174867  0.5174689  0.5174918\n",
            " 0.51755995 0.5175013  0.5174891  0.51758444 0.5174749  0.51745576\n",
            " 0.517488   0.5174411  0.5175041  0.51752657 0.5174715  0.51750803\n",
            " 0.5175299  0.5174734  0.5175145  0.5175007  0.51751614 0.5174953\n",
            " 0.51753676 0.5174489  0.51754916 0.51749396 0.5175275  0.5174945\n",
            " 0.5174783  0.51751614 0.51748717 0.517526   0.51756555 0.5175576\n",
            " 0.51753825 0.5174797  0.517464   0.51754445 0.5175015  0.51744336\n",
            " 0.51755834 0.5174888  0.5174649  0.5175099  0.5174999  0.5174808\n",
            " 0.51746243 0.5175478  0.5174954  0.5175738  0.5174919  0.51749533\n",
            " 0.5174386  0.5175515  0.5174729  0.5174317  0.51748884 0.5174856 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.513747651595622e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48544174 0.48546407 0.48546454 0.48547783 0.485449   0.48546454\n",
            " 0.4854591  0.48545587 0.4854907  0.48544875 0.48544982 0.48546582\n",
            " 0.48544806 0.48545116 0.48547783 0.4854614  0.48546553 0.48547715\n",
            " 0.4854729  0.48545352 0.4854575  0.4854478  0.48550445 0.4854595\n",
            " 0.48545185 0.48544148 0.48545715 0.48544148 0.48545146 0.48547235\n",
            " 0.48544136 0.4854528  0.48546165 0.48545343 0.4854484  0.48547482\n",
            " 0.48545942 0.48545974 0.4854762  0.48543993 0.48544663 0.48543653\n",
            " 0.48547614 0.48548582 0.48544055 0.48546642 0.48547608 0.48543417\n",
            " 0.48546043 0.48542625 0.48545244 0.48544988 0.48545113 0.48544905\n",
            " 0.48545513 0.4854578  0.485438   0.48543653 0.48543662 0.48545173]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.4914622624928597e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4851073  0.48515093 0.48515466 0.48515177 0.48514506 0.4851501\n",
            " 0.48509234 0.48510692 0.48521465 0.485059   0.48516664 0.48521224\n",
            " 0.48507527 0.48523286 0.4851865  0.48512226 0.48512042 0.48515424\n",
            " 0.48508456 0.48516685 0.48508263 0.48513982 0.48522863 0.48513538\n",
            " 0.48506    0.48518932 0.4850585  0.4851019  0.48513156 0.48516753\n",
            " 0.48511094 0.48506972 0.48515716 0.48514378 0.48508632 0.48505262\n",
            " 0.48505616 0.48518285 0.485128   0.48508114 0.48510575 0.4852213\n",
            " 0.48505932 0.48513418 0.48512113 0.48514712 0.48520032 0.4851436\n",
            " 0.48517078 0.48513696 0.48512194 0.48505855 0.4850912  0.48507503\n",
            " 0.48523128 0.48502916 0.48516345 0.48525426 0.48514327 0.48513168]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.2398430852917954e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48141947 0.50559634 0.5175367  0.48545876 0.48511666]\n",
            " [0.481396   0.5055652  0.51756054 0.48547962 0.48506206]\n",
            " [0.4813736  0.50554633 0.5175482  0.48546627 0.48506534]\n",
            " [0.48138586 0.50563073 0.5175383  0.48547196 0.48510212]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48140925 0.50557816 0.5175058  0.48546037 0.48507258]\n",
            " [0.48145095 0.50557834 0.51750803 0.4854617  0.48517948]\n",
            " [0.4814871  0.50560963 0.51746976 0.48542863 0.4851948 ]\n",
            " [0.48139283 0.5055546  0.5175317  0.48547614 0.48504534]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4814806  0.50558907 0.5174929  0.4854335  0.48514178]\n",
            " [0.48146263 0.50560373 0.5174735  0.48545083 0.4851215 ]\n",
            " [0.4814872  0.50561076 0.51746446 0.48544163 0.48514497]\n",
            " [0.48144534 0.5055653  0.51750255 0.48546043 0.48511884]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48142594 0.50566816 0.5174978  0.48546267 0.485174  ]\n",
            " [0.48144016 0.50559837 0.5175113  0.48545521 0.4852008 ]\n",
            " [0.48144892 0.50556886 0.5174958  0.48546576 0.485073  ]\n",
            " [0.48144186 0.50556713 0.5175104  0.4854376  0.48510283]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4814308  0.505586   0.5175065  0.4854533  0.48510474]\n",
            " [0.48150447 0.505644   0.51743317 0.48546183 0.48523396]\n",
            " [0.4814651  0.50560975 0.5174418  0.48545    0.48516843]\n",
            " [0.48142835 0.50556266 0.51751584 0.48545226 0.48509902]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48141947 0.481396   0.4813736  0.48138586 0.48140925 0.48145095\n",
            " 0.4814871  0.48139283 0.4814806  0.48146263 0.4814872  0.48144534\n",
            " 0.48142594 0.48144016 0.48144892 0.48144186 0.4814308  0.48150447\n",
            " 0.4814651  0.48142835]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.5272791137686e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50559634 0.5055652  0.50554633 0.50563073 0.50557816 0.50557834\n",
            " 0.50560963 0.5055546  0.50558907 0.50560373 0.50561076 0.5055653\n",
            " 0.50566816 0.50559837 0.50556886 0.50556713 0.505586   0.505644\n",
            " 0.50560975 0.50556266]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.0438948670052923e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5175367  0.51756054 0.5175482  0.5175383  0.5175058  0.51750803\n",
            " 0.51746976 0.5175317  0.5174929  0.5174735  0.51746446 0.51750255\n",
            " 0.5174978  0.5175113  0.5174958  0.5175104  0.5175065  0.51743317\n",
            " 0.5174418  0.51751584]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2515199563931674e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48545876 0.48547962 0.48546627 0.48547196 0.48546037 0.4854617\n",
            " 0.48542863 0.48547614 0.4854335  0.48545083 0.48544163 0.48546043\n",
            " 0.48546267 0.48545521 0.48546576 0.4854376  0.4854533  0.48546183\n",
            " 0.48545    0.48545226]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.315007648372557e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48511666 0.48506206 0.48506534 0.48510212 0.48507258 0.48517948\n",
            " 0.4851948  0.48504534 0.48514178 0.4851215  0.48514497 0.48511884\n",
            " 0.485174   0.4852008  0.485073   0.48510283 0.48510474 0.48523396\n",
            " 0.48516843 0.48509902]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.096000313642435e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48141947 0.481396   0.4813736  0.48138586 0.48140925 0.48145095\n",
            " 0.4814871  0.48139283 0.4814806  0.48146263 0.4814872  0.48144534\n",
            " 0.48142594 0.48144016 0.48144892 0.48144186 0.4814308  0.48150447\n",
            " 0.4814651  0.48142835]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.5272791137686e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50559634 0.5055652  0.50554633 0.50563073 0.50557816 0.50557834\n",
            " 0.50560963 0.5055546  0.50558907 0.50560373 0.50561076 0.5055653\n",
            " 0.50566816 0.50559837 0.50556886 0.50556713 0.505586   0.505644\n",
            " 0.50560975 0.50556266]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.0438948670052923e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5175367  0.51756054 0.5175482  0.5175383  0.5175058  0.51750803\n",
            " 0.51746976 0.5175317  0.5174929  0.5174735  0.51746446 0.51750255\n",
            " 0.5174978  0.5175113  0.5174958  0.5175104  0.5175065  0.51743317\n",
            " 0.5174418  0.51751584]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2515199563931674e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48545876 0.48547962 0.48546627 0.48547196 0.48546037 0.4854617\n",
            " 0.48542863 0.48547614 0.4854335  0.48545083 0.48544163 0.48546043\n",
            " 0.48546267 0.48545521 0.48546576 0.4854376  0.4854533  0.48546183\n",
            " 0.48545    0.48545226]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.315007648372557e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48511666 0.48506206 0.48506534 0.48510212 0.48507258 0.48517948\n",
            " 0.4851948  0.48504534 0.48514178 0.4851215  0.48514497 0.48511884\n",
            " 0.485174   0.4852008  0.485073   0.48510283 0.48510474 0.48523396\n",
            " 0.48516843 0.48509902]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.096000313642435e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48141947 0.481396   0.4813736  0.48138586 0.48140925 0.48145095\n",
            " 0.4814871  0.48139283 0.4814806  0.48146263 0.4814872  0.48144534\n",
            " 0.48142594 0.48144016 0.48144892 0.48144186 0.4814308  0.48150447\n",
            " 0.4814651  0.48142835]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.5272791137686e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50559634 0.5055652  0.50554633 0.50563073 0.50557816 0.50557834\n",
            " 0.50560963 0.5055546  0.50558907 0.50560373 0.50561076 0.5055653\n",
            " 0.50566816 0.50559837 0.50556886 0.50556713 0.505586   0.505644\n",
            " 0.50560975 0.50556266]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.0438948670052923e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5175367  0.51756054 0.5175482  0.5175383  0.5175058  0.51750803\n",
            " 0.51746976 0.5175317  0.5174929  0.5174735  0.51746446 0.51750255\n",
            " 0.5174978  0.5175113  0.5174958  0.5175104  0.5175065  0.51743317\n",
            " 0.5174418  0.51751584]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2515199563931674e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48545876 0.48547962 0.48546627 0.48547196 0.48546037 0.4854617\n",
            " 0.48542863 0.48547614 0.4854335  0.48545083 0.48544163 0.48546043\n",
            " 0.48546267 0.48545521 0.48546576 0.4854376  0.4854533  0.48546183\n",
            " 0.48545    0.48545226]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.315007648372557e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48511666 0.48506206 0.48506534 0.48510212 0.48507258 0.48517948\n",
            " 0.4851948  0.48504534 0.48514178 0.4851215  0.48514497 0.48511884\n",
            " 0.485174   0.4852008  0.485073   0.48510283 0.48510474 0.48523396\n",
            " 0.48516843 0.48509902]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.096000313642435e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48141947 0.481396   0.4813736  0.48138586 0.48140925 0.48145095\n",
            " 0.4814871  0.48139283 0.4814806  0.48146263 0.4814872  0.48144534\n",
            " 0.48142594 0.48144016 0.48144892 0.48144186 0.4814308  0.48150447\n",
            " 0.4814651  0.48142835]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.5272791137686e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50559634 0.5055652  0.50554633 0.50563073 0.50557816 0.50557834\n",
            " 0.50560963 0.5055546  0.50558907 0.50560373 0.50561076 0.5055653\n",
            " 0.50566816 0.50559837 0.50556886 0.50556713 0.505586   0.505644\n",
            " 0.50560975 0.50556266]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.0438948670052923e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5175367  0.51756054 0.5175482  0.5175383  0.5175058  0.51750803\n",
            " 0.51746976 0.5175317  0.5174929  0.5174735  0.51746446 0.51750255\n",
            " 0.5174978  0.5175113  0.5174958  0.5175104  0.5175065  0.51743317\n",
            " 0.5174418  0.51751584]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2515199563931674e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48545876 0.48547962 0.48546627 0.48547196 0.48546037 0.4854617\n",
            " 0.48542863 0.48547614 0.4854335  0.48545083 0.48544163 0.48546043\n",
            " 0.48546267 0.48545521 0.48546576 0.4854376  0.4854533  0.48546183\n",
            " 0.48545    0.48545226]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.315007648372557e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48511666 0.48506206 0.48506534 0.48510212 0.48507258 0.48517948\n",
            " 0.4851948  0.48504534 0.48514178 0.4851215  0.48514497 0.48511884\n",
            " 0.485174   0.4852008  0.485073   0.48510283 0.48510474 0.48523396\n",
            " 0.48516843 0.48509902]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.096000313642435e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4814758  0.50560904 0.5174962  0.48547214 0.4851323 ]\n",
            " [0.4814806  0.5056108  0.5174645  0.48543736 0.4851632 ]\n",
            " [0.48148736 0.50562406 0.5174663  0.48544398 0.48517415]\n",
            " [0.4814384  0.5055918  0.517486   0.48546553 0.4851147 ]\n",
            " [0.4815001  0.5056222  0.51745456 0.48541802 0.4851864 ]\n",
            " [0.48140925 0.5055733  0.5175581  0.4854642  0.4850864 ]\n",
            " [0.4814028  0.5055738  0.5175253  0.48547354 0.4850973 ]\n",
            " [0.48140064 0.5055417  0.51751554 0.4854574  0.48506206]\n",
            " [0.4814222  0.50556624 0.5175319  0.48548877 0.48507598]\n",
            " [0.48141947 0.5056036  0.51749057 0.48546717 0.48516896]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4814067  0.5056037  0.51752317 0.48547703 0.48515472]\n",
            " [0.4814239  0.505583   0.5175272  0.48547035 0.48510337]\n",
            " [0.48144588 0.5055778  0.51750404 0.48546964 0.4851308 ]\n",
            " [0.48149377 0.5056222  0.517461   0.4854841  0.4852233 ]\n",
            " [0.48142484 0.50558263 0.51749563 0.4854584  0.48510116]\n",
            " [0.48147064 0.5055881  0.5174827  0.48544893 0.48515466]\n",
            " [0.4814757  0.50560635 0.5174764  0.48545682 0.4852082 ]\n",
            " [0.48141834 0.50554115 0.51752025 0.485445   0.4850525 ]\n",
            " [0.4814596  0.5056304  0.5174724  0.48545307 0.4851418 ]\n",
            " [0.48139203 0.5056274  0.5175227  0.4854574  0.48513928]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4814758  0.4814806  0.48148736 0.4814384  0.4815001  0.48140925\n",
            " 0.4814028  0.48140064 0.4814222  0.48141947 0.4814067  0.4814239\n",
            " 0.48144588 0.48149377 0.48142484 0.48147064 0.4814757  0.48141834\n",
            " 0.4814596  0.48139203]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.4044223866658285e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50560904 0.5056108  0.50562406 0.5055918  0.5056222  0.5055733\n",
            " 0.5055738  0.5055417  0.50556624 0.5056036  0.5056037  0.505583\n",
            " 0.5055778  0.5056222  0.50558263 0.5055881  0.50560635 0.50554115\n",
            " 0.5056304  0.5056274 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5953337171813473e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5174962  0.5174645  0.5174663  0.517486   0.51745456 0.5175581\n",
            " 0.5175253  0.51751554 0.5175319  0.51749057 0.51752317 0.5175272\n",
            " 0.51750404 0.517461   0.51749563 0.5174827  0.5174764  0.51752025\n",
            " 0.5174724  0.5175227 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7729298381018452e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48547214 0.48543736 0.48544398 0.48546553 0.48541802 0.4854642\n",
            " 0.48547354 0.4854574  0.48548877 0.48546717 0.48547703 0.48547035\n",
            " 0.48546964 0.4854841  0.4854584  0.48544893 0.48545682 0.485445\n",
            " 0.48545307 0.4854574 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.6245421647909097e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4851323  0.4851632  0.48517415 0.4851147  0.4851864  0.4850864\n",
            " 0.4850973  0.48506206 0.48507598 0.48516896 0.48515472 0.48510337\n",
            " 0.4851308  0.4852233  0.48510116 0.48515466 0.4852082  0.4850525\n",
            " 0.4851418  0.48513928]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.585540955304168e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4814758  0.4814806  0.48148736 0.4814384  0.4815001  0.48140925\n",
            " 0.4814028  0.48140064 0.4814222  0.48141947 0.4814067  0.4814239\n",
            " 0.48144588 0.48149377 0.48142484 0.48147064 0.4814757  0.48141834\n",
            " 0.4814596  0.48139203]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.4044223866658285e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50560904 0.5056108  0.50562406 0.5055918  0.5056222  0.5055733\n",
            " 0.5055738  0.5055417  0.50556624 0.5056036  0.5056037  0.505583\n",
            " 0.5055778  0.5056222  0.50558263 0.5055881  0.50560635 0.50554115\n",
            " 0.5056304  0.5056274 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5953337171813473e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5174962  0.5174645  0.5174663  0.517486   0.51745456 0.5175581\n",
            " 0.5175253  0.51751554 0.5175319  0.51749057 0.51752317 0.5175272\n",
            " 0.51750404 0.517461   0.51749563 0.5174827  0.5174764  0.51752025\n",
            " 0.5174724  0.5175227 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7729298381018452e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48547214 0.48543736 0.48544398 0.48546553 0.48541802 0.4854642\n",
            " 0.48547354 0.4854574  0.48548877 0.48546717 0.48547703 0.48547035\n",
            " 0.48546964 0.4854841  0.4854584  0.48544893 0.48545682 0.485445\n",
            " 0.48545307 0.4854574 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.6245421647909097e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4851323  0.4851632  0.48517415 0.4851147  0.4851864  0.4850864\n",
            " 0.4850973  0.48506206 0.48507598 0.48516896 0.48515472 0.48510337\n",
            " 0.4851308  0.4852233  0.48510116 0.48515466 0.4852082  0.4850525\n",
            " 0.4851418  0.48513928]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.585540955304168e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4814758  0.4814806  0.48148736 0.4814384  0.4815001  0.48140925\n",
            " 0.4814028  0.48140064 0.4814222  0.48141947 0.4814067  0.4814239\n",
            " 0.48144588 0.48149377 0.48142484 0.48147064 0.4814757  0.48141834\n",
            " 0.4814596  0.48139203]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.4044223866658285e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50560904 0.5056108  0.50562406 0.5055918  0.5056222  0.5055733\n",
            " 0.5055738  0.5055417  0.50556624 0.5056036  0.5056037  0.505583\n",
            " 0.5055778  0.5056222  0.50558263 0.5055881  0.50560635 0.50554115\n",
            " 0.5056304  0.5056274 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5953337171813473e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5174962  0.5174645  0.5174663  0.517486   0.51745456 0.5175581\n",
            " 0.5175253  0.51751554 0.5175319  0.51749057 0.51752317 0.5175272\n",
            " 0.51750404 0.517461   0.51749563 0.5174827  0.5174764  0.51752025\n",
            " 0.5174724  0.5175227 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7729298381018452e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48547214 0.48543736 0.48544398 0.48546553 0.48541802 0.4854642\n",
            " 0.48547354 0.4854574  0.48548877 0.48546717 0.48547703 0.48547035\n",
            " 0.48546964 0.4854841  0.4854584  0.48544893 0.48545682 0.485445\n",
            " 0.48545307 0.4854574 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.6245421647909097e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4851323  0.4851632  0.48517415 0.4851147  0.4851864  0.4850864\n",
            " 0.4850973  0.48506206 0.48507598 0.48516896 0.48515472 0.48510337\n",
            " 0.4851308  0.4852233  0.48510116 0.48515466 0.4852082  0.4850525\n",
            " 0.4851418  0.48513928]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.585540955304168e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4814758  0.4814806  0.48148736 0.4814384  0.4815001  0.48140925\n",
            " 0.4814028  0.48140064 0.4814222  0.48141947 0.4814067  0.4814239\n",
            " 0.48144588 0.48149377 0.48142484 0.48147064 0.4814757  0.48141834\n",
            " 0.4814596  0.48139203]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.4044223866658285e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50560904 0.5056108  0.50562406 0.5055918  0.5056222  0.5055733\n",
            " 0.5055738  0.5055417  0.50556624 0.5056036  0.5056037  0.505583\n",
            " 0.5055778  0.5056222  0.50558263 0.5055881  0.50560635 0.50554115\n",
            " 0.5056304  0.5056274 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.5953337171813473e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5174962  0.5174645  0.5174663  0.517486   0.51745456 0.5175581\n",
            " 0.5175253  0.51751554 0.5175319  0.51749057 0.51752317 0.5175272\n",
            " 0.51750404 0.517461   0.51749563 0.5174827  0.5174764  0.51752025\n",
            " 0.5174724  0.5175227 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7729298381018452e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48547214 0.48543736 0.48544398 0.48546553 0.48541802 0.4854642\n",
            " 0.48547354 0.4854574  0.48548877 0.48546717 0.48547703 0.48547035\n",
            " 0.48546964 0.4854841  0.4854584  0.48544893 0.48545682 0.485445\n",
            " 0.48545307 0.4854574 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.6245421647909097e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4851323  0.4851632  0.48517415 0.4851147  0.4851864  0.4850864\n",
            " 0.4850973  0.48506206 0.48507598 0.48516896 0.48515472 0.48510337\n",
            " 0.4851308  0.4852233  0.48510116 0.48515466 0.4852082  0.4850525\n",
            " 0.4851418  0.48513928]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.585540955304168e-05\n",
            "Epoch 3/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48144406 0.50558406 0.5175203  0.48544174 0.4851073 ]\n",
            " [0.48139188 0.5056393  0.5175148  0.48546407 0.48515093]\n",
            " [0.48146814 0.5056044  0.51748395 0.48546454 0.48515466]\n",
            " [0.48145416 0.50561976 0.5174867  0.48547783 0.48515177]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48150465 0.50564086 0.51750404 0.48549166 0.48519474]\n",
            " [0.48149493 0.50559413 0.5175268  0.48550713 0.4851997 ]\n",
            " [0.48134616 0.5056647  0.5175947  0.48550048 0.48514062]\n",
            " [0.4815123  0.5056147  0.5175363  0.48549822 0.48515633]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4815111  0.5056826  0.5175301  0.48552415 0.4853222 ]\n",
            " [0.48138446 0.50565195 0.51762533 0.48548034 0.48516318]\n",
            " [0.48150796 0.505654   0.5175158  0.48548332 0.48527434]\n",
            " [0.48149246 0.5056673  0.5174969  0.48549968 0.48532072]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48148674 0.5056389  0.5175575  0.48551062 0.48521975]\n",
            " [0.48150522 0.50567704 0.51751137 0.4855149  0.4853802 ]\n",
            " [0.48151928 0.5056894  0.5175742  0.48554054 0.48533168]\n",
            " [0.48148742 0.50565165 0.5175964  0.4855241  0.48526707]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48156375 0.50565356 0.51756465 0.48554102 0.48532534]\n",
            " [0.4815441  0.50570506 0.51760125 0.48555294 0.48535922]\n",
            " [0.48151284 0.5056781  0.5176231  0.4855473  0.4852872 ]\n",
            " [0.48155373 0.5056809  0.5175669  0.48552936 0.4853727 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48154286 0.5056485  0.51759815 0.48552758 0.4853302 ]\n",
            " [0.4815386  0.5056665  0.5175848  0.48551813 0.48538834]\n",
            " [0.48160976 0.50570375 0.51760066 0.4855758  0.48548007]\n",
            " [0.48156166 0.5056761  0.51757926 0.4855306  0.48538557]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48155314 0.50566506 0.5176465  0.48556292 0.48534247]\n",
            " [0.4816605  0.5057528  0.51755977 0.48555657 0.48547956]\n",
            " [0.48153123 0.5056516  0.517659   0.48556736 0.4853396 ]\n",
            " [0.48156762 0.50570244 0.5176037  0.48555437 0.4853877 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4815463  0.5057151  0.5176188  0.48557994 0.48544124]\n",
            " [0.48158333 0.50573075 0.51758605 0.4856033  0.48548153]\n",
            " [0.48157108 0.5056759  0.51756936 0.485572   0.48542425]\n",
            " [0.48155215 0.50564605 0.51760703 0.4855813  0.485379  ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48160028 0.5057031  0.51758844 0.48560664 0.48548722]\n",
            " [0.48154464 0.5057076  0.5176267  0.48559892 0.48547417]\n",
            " [0.48146167 0.50575393 0.51766706 0.48558778 0.48540714]\n",
            " [0.48153    0.50564116 0.5176581  0.48561734 0.48537767]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48152882 0.5056341  0.5176319  0.48559564 0.485376  ]\n",
            " [0.48161632 0.5057225  0.5175746  0.48559928 0.4855094 ]\n",
            " [0.48161134 0.50567263 0.51755834 0.48561487 0.4854524 ]\n",
            " [0.48150343 0.5056863  0.5176388  0.485575   0.48539978]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48164377 0.5057528  0.5176477  0.4856412  0.485508  ]\n",
            " [0.48175383 0.5058037  0.51759136 0.48563445 0.48563012]\n",
            " [0.48152658 0.5057467  0.5177054  0.48566315 0.4854496 ]\n",
            " [0.48164663 0.50576586 0.51763624 0.4856802  0.48553622]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48166004 0.5057779  0.5176221  0.4856774  0.48554784]\n",
            " [0.48163912 0.5057802  0.517667   0.48570114 0.4855707 ]\n",
            " [0.48163867 0.505812   0.5176577  0.48571062 0.48562366]\n",
            " [0.48172536 0.50578445 0.51764    0.48566934 0.48556846]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817244  0.50581646 0.51765525 0.48573682 0.4856388 ]\n",
            " [0.48158044 0.5058493  0.517739   0.4856962  0.48559588]\n",
            " [0.48169175 0.5057957  0.5176872  0.48572662 0.48558676]\n",
            " [0.4815765  0.50574374 0.5177654  0.48571578 0.48551142]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48166177 0.50580394 0.51770675 0.48575515 0.48557612]\n",
            " [0.48164907 0.5057935  0.51770973 0.48575288 0.4855596 ]\n",
            " [0.48166513 0.5058559  0.51765496 0.48576447 0.48572496]\n",
            " [0.48158932 0.5057527  0.51776546 0.48575422 0.48550373]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48168197 0.50578946 0.51766956 0.4857175  0.4856639 ]\n",
            " [0.48171857 0.50582665 0.51762956 0.48571554 0.48575416]\n",
            " [0.48168063 0.5057788  0.5176851  0.48571432 0.48564017]\n",
            " [0.48168555 0.5057838  0.517682   0.4857298  0.48562908]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4816952  0.50582594 0.51774603 0.48575804 0.4856593 ]\n",
            " [0.4816395  0.5058788  0.5177416  0.4857765  0.48569864]\n",
            " [0.4817212  0.5058486  0.51771086 0.48578346 0.48571086]\n",
            " [0.4817065  0.5058628  0.5177136  0.485796   0.48570716]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48173055 0.5058551  0.5176951  0.4857685  0.4857021 ]\n",
            " [0.48171884 0.50580716 0.5177182  0.48578227 0.48570436]\n",
            " [0.4815618  0.505867   0.51778615 0.48576444 0.48562956]\n",
            " [0.48173386 0.5058259  0.51772773 0.48577118 0.48565865]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48170725 0.5058814  0.51771665 0.48580804 0.48576874]\n",
            " [0.48157415 0.5058419  0.51781106 0.48575404 0.48559606]\n",
            " [0.48170322 0.5058533  0.5177025  0.4857664  0.48572028]\n",
            " [0.48168895 0.5058673  0.5176822  0.48578513 0.4857708 ]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48166788 0.50581753 0.517713   0.48576367 0.48562595]\n",
            " [0.4816878  0.50585824 0.5176681  0.485772   0.485794  ]\n",
            " [0.48169944 0.5058686  0.51773137 0.4857934  0.48573866]\n",
            " [0.48166862 0.50583035 0.51775306 0.48577693 0.48567343]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817044  0.5058157  0.51769686 0.48578158 0.48567286]\n",
            " [0.48168525 0.505867   0.517734   0.48579326 0.48570603]\n",
            " [0.48165208 0.5058371  0.5177559  0.48578435 0.48562986]\n",
            " [0.48169485 0.50584394 0.5176996  0.48577118 0.4857219 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48167863 0.50581    0.51774    0.485772   0.48563224]\n",
            " [0.48167473 0.5058289  0.51772726 0.4857635  0.48569146]\n",
            " [0.4817463  0.5058684  0.51774377 0.485824   0.48578665]\n",
            " [0.4816997  0.5058407  0.51772106 0.48577872 0.48569196]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4816561  0.50578207 0.5177622  0.485764   0.48560598]\n",
            " [0.48176602 0.50587386 0.51767635 0.48576325 0.48575062]\n",
            " [0.48163325 0.50576717 0.51777506 0.48576704 0.48560145]\n",
            " [0.48167232 0.5058218  0.51771903 0.48575824 0.48565486]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48167112 0.5058571  0.517753   0.48576492 0.48567978]\n",
            " [0.48170984 0.5058756  0.5177209  0.4857912  0.48572373]\n",
            " [0.481697   0.50581974 0.51770407 0.48575914 0.48566577]\n",
            " [0.48167607 0.5057875  0.5177413  0.4857655  0.48561665]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817121  0.50583524 0.517714   0.4857775  0.48570928]\n",
            " [0.48165664 0.50584006 0.5177518  0.48576966 0.48569602]\n",
            " [0.4815691  0.5058809  0.51779187 0.48575273 0.48562208]\n",
            " [0.4816404  0.5057705  0.51778287 0.4857854  0.48559597]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48165438 0.5057871  0.51776326 0.48577195 0.48560265]\n",
            " [0.4817439  0.50587964 0.51770735 0.4857794  0.48574093]\n",
            " [0.4817378  0.5058279  0.51769084 0.48579335 0.4856819 ]\n",
            " [0.481628   0.5058386  0.51777047 0.4857504  0.4856254 ]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4816946  0.50584024 0.5177266  0.4857636  0.4856589 ]\n",
            " [0.4818053  0.50589305 0.51767117 0.48575878 0.48578355]\n",
            " [0.48157588 0.5058311  0.51778424 0.4857817  0.48559624]\n",
            " [0.48169687 0.50585324 0.5177158  0.4858021  0.48568666]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817097  0.5058397  0.517691   0.48575923 0.48567715]\n",
            " [0.48168853 0.5058418  0.5177356  0.48578238 0.48569912]\n",
            " [0.4816876  0.5058731  0.5177268  0.48579165 0.48575172]\n",
            " [0.48177445 0.50584567 0.51770943 0.48575073 0.4856972 ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48175725 0.5058534  0.51768917 0.48577967 0.4857279 ]\n",
            " [0.48161274 0.50588524 0.51777303 0.48573795 0.48568308]\n",
            " [0.481724   0.5058321  0.5177212  0.48576885 0.48567495]\n",
            " [0.48160833 0.50577915 0.5177994  0.48575696 0.48559782]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48168436 0.5058168  0.5177178  0.48576617 0.48564184]\n",
            " [0.4816717  0.5058064  0.5177207  0.485764   0.4856253 ]\n",
            " [0.4816878  0.5058689  0.51766586 0.48577553 0.48579177]\n",
            " [0.4816114  0.505765   0.51777637 0.4857648  0.48556802]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48171565 0.50583255 0.5176995  0.48575804 0.4857223 ]\n",
            " [0.48175186 0.50586945 0.5176597  0.48575583 0.48581222]\n",
            " [0.4817137  0.50582135 0.517715   0.48575425 0.48569772]\n",
            " [0.48171866 0.50582635 0.51771194 0.48576984 0.48568672]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4816952  0.4816395  0.4817212  0.4817065  0.48173055 0.48171884\n",
            " 0.4815618  0.48173386 0.48170725 0.48157415 0.48170322 0.48168895\n",
            " 0.48166788 0.4816878  0.48169944 0.48166862 0.4817044  0.48168525\n",
            " 0.48165208 0.48169485 0.48167863 0.48167473 0.4817463  0.4816997\n",
            " 0.4816561  0.48176602 0.48163325 0.48167232 0.48167112 0.48170984\n",
            " 0.481697   0.48167607 0.4817121  0.48165664 0.4815691  0.4816404\n",
            " 0.48165438 0.4817439  0.4817378  0.481628   0.4816946  0.4818053\n",
            " 0.48157588 0.48169687 0.4817097  0.48168853 0.4816876  0.48177445\n",
            " 0.48175725 0.48161274 0.481724   0.48160833 0.48168436 0.4816717\n",
            " 0.4816878  0.4816114  0.48171565 0.48175186 0.4817137  0.48171866]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.9830807256512344e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50582594 0.5058788  0.5058486  0.5058628  0.5058551  0.50580716\n",
            " 0.505867   0.5058259  0.5058814  0.5058419  0.5058533  0.5058673\n",
            " 0.50581753 0.50585824 0.5058686  0.50583035 0.5058157  0.505867\n",
            " 0.5058371  0.50584394 0.50581    0.5058289  0.5058684  0.5058407\n",
            " 0.50578207 0.50587386 0.50576717 0.5058218  0.5058571  0.5058756\n",
            " 0.50581974 0.5057875  0.50583524 0.50584006 0.5058809  0.5057705\n",
            " 0.5057871  0.50587964 0.5058279  0.5058386  0.50584024 0.50589305\n",
            " 0.5058311  0.50585324 0.5058397  0.5058418  0.5058731  0.50584567\n",
            " 0.5058534  0.50588524 0.5058321  0.50577915 0.5058168  0.5058064\n",
            " 0.5058689  0.505765   0.50583255 0.50586945 0.50582135 0.50582635]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.100345566053875e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51774603 0.5177416  0.51771086 0.5177136  0.5176951  0.5177182\n",
            " 0.51778615 0.51772773 0.51771665 0.51781106 0.5177025  0.5176822\n",
            " 0.517713   0.5176681  0.51773137 0.51775306 0.51769686 0.517734\n",
            " 0.5177559  0.5176996  0.51774    0.51772726 0.51774377 0.51772106\n",
            " 0.5177622  0.51767635 0.51777506 0.51771903 0.517753   0.5177209\n",
            " 0.51770407 0.5177413  0.517714   0.5177518  0.51779187 0.51778287\n",
            " 0.51776326 0.51770735 0.51769084 0.51777047 0.5177266  0.51767117\n",
            " 0.51778424 0.5177158  0.517691   0.5177356  0.5177268  0.51770943\n",
            " 0.51768917 0.51777303 0.5177212  0.5177994  0.5177178  0.5177207\n",
            " 0.51766586 0.51777637 0.5176995  0.5176597  0.517715   0.51771194]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.472315438557416e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48575804 0.4857765  0.48578346 0.485796   0.4857685  0.48578227\n",
            " 0.48576444 0.48577118 0.48580804 0.48575404 0.4857664  0.48578513\n",
            " 0.48576367 0.485772   0.4857934  0.48577693 0.48578158 0.48579326\n",
            " 0.48578435 0.48577118 0.485772   0.4857635  0.485824   0.48577872\n",
            " 0.485764   0.48576325 0.48576704 0.48575824 0.48576492 0.4857912\n",
            " 0.48575914 0.4857655  0.4857775  0.48576966 0.48575273 0.4857854\n",
            " 0.48577195 0.4857794  0.48579335 0.4857504  0.4857636  0.48575878\n",
            " 0.4857817  0.4858021  0.48575923 0.48578238 0.48579165 0.48575073\n",
            " 0.48577967 0.48573795 0.48576885 0.48575696 0.48576617 0.485764\n",
            " 0.48577553 0.4857648  0.48575804 0.48575583 0.48575425 0.48576984]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.542514110042248e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4856593  0.48569864 0.48571086 0.48570716 0.4857021  0.48570436\n",
            " 0.48562956 0.48565865 0.48576874 0.48559606 0.48572028 0.4857708\n",
            " 0.48562595 0.485794   0.48573866 0.48567343 0.48567286 0.48570603\n",
            " 0.48562986 0.4857219  0.48563224 0.48569146 0.48578665 0.48569196\n",
            " 0.48560598 0.48575062 0.48560145 0.48565486 0.48567978 0.48572373\n",
            " 0.48566577 0.48561665 0.48570928 0.48569602 0.48562208 0.48559597\n",
            " 0.48560265 0.48574093 0.4856819  0.4856254  0.4856589  0.48578355\n",
            " 0.48559624 0.48568666 0.48567715 0.48569912 0.48575172 0.4856972\n",
            " 0.4857279  0.48568308 0.48567495 0.48559782 0.48564184 0.4856253\n",
            " 0.48579177 0.48556802 0.4857223  0.48581222 0.48569772 0.48568672]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.7519122492522e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4816952  0.4816395  0.4817212  0.4817065  0.48173055 0.48171884\n",
            " 0.4815618  0.48173386 0.48170725 0.48157415 0.48170322 0.48168895\n",
            " 0.48166788 0.4816878  0.48169944 0.48166862 0.4817044  0.48168525\n",
            " 0.48165208 0.48169485 0.48167863 0.48167473 0.4817463  0.4816997\n",
            " 0.4816561  0.48176602 0.48163325 0.48167232 0.48167112 0.48170984\n",
            " 0.481697   0.48167607 0.4817121  0.48165664 0.4815691  0.4816404\n",
            " 0.48165438 0.4817439  0.4817378  0.481628   0.4816946  0.4818053\n",
            " 0.48157588 0.48169687 0.4817097  0.48168853 0.4816876  0.48177445\n",
            " 0.48175725 0.48161274 0.481724   0.48160833 0.48168436 0.4816717\n",
            " 0.4816878  0.4816114  0.48171565 0.48175186 0.4817137  0.48171866]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.9830807256512344e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50582594 0.5058788  0.5058486  0.5058628  0.5058551  0.50580716\n",
            " 0.505867   0.5058259  0.5058814  0.5058419  0.5058533  0.5058673\n",
            " 0.50581753 0.50585824 0.5058686  0.50583035 0.5058157  0.505867\n",
            " 0.5058371  0.50584394 0.50581    0.5058289  0.5058684  0.5058407\n",
            " 0.50578207 0.50587386 0.50576717 0.5058218  0.5058571  0.5058756\n",
            " 0.50581974 0.5057875  0.50583524 0.50584006 0.5058809  0.5057705\n",
            " 0.5057871  0.50587964 0.5058279  0.5058386  0.50584024 0.50589305\n",
            " 0.5058311  0.50585324 0.5058397  0.5058418  0.5058731  0.50584567\n",
            " 0.5058534  0.50588524 0.5058321  0.50577915 0.5058168  0.5058064\n",
            " 0.5058689  0.505765   0.50583255 0.50586945 0.50582135 0.50582635]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.100345566053875e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51774603 0.5177416  0.51771086 0.5177136  0.5176951  0.5177182\n",
            " 0.51778615 0.51772773 0.51771665 0.51781106 0.5177025  0.5176822\n",
            " 0.517713   0.5176681  0.51773137 0.51775306 0.51769686 0.517734\n",
            " 0.5177559  0.5176996  0.51774    0.51772726 0.51774377 0.51772106\n",
            " 0.5177622  0.51767635 0.51777506 0.51771903 0.517753   0.5177209\n",
            " 0.51770407 0.5177413  0.517714   0.5177518  0.51779187 0.51778287\n",
            " 0.51776326 0.51770735 0.51769084 0.51777047 0.5177266  0.51767117\n",
            " 0.51778424 0.5177158  0.517691   0.5177356  0.5177268  0.51770943\n",
            " 0.51768917 0.51777303 0.5177212  0.5177994  0.5177178  0.5177207\n",
            " 0.51766586 0.51777637 0.5176995  0.5176597  0.517715   0.51771194]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.472315438557416e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48575804 0.4857765  0.48578346 0.485796   0.4857685  0.48578227\n",
            " 0.48576444 0.48577118 0.48580804 0.48575404 0.4857664  0.48578513\n",
            " 0.48576367 0.485772   0.4857934  0.48577693 0.48578158 0.48579326\n",
            " 0.48578435 0.48577118 0.485772   0.4857635  0.485824   0.48577872\n",
            " 0.485764   0.48576325 0.48576704 0.48575824 0.48576492 0.4857912\n",
            " 0.48575914 0.4857655  0.4857775  0.48576966 0.48575273 0.4857854\n",
            " 0.48577195 0.4857794  0.48579335 0.4857504  0.4857636  0.48575878\n",
            " 0.4857817  0.4858021  0.48575923 0.48578238 0.48579165 0.48575073\n",
            " 0.48577967 0.48573795 0.48576885 0.48575696 0.48576617 0.485764\n",
            " 0.48577553 0.4857648  0.48575804 0.48575583 0.48575425 0.48576984]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.542514110042248e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4856593  0.48569864 0.48571086 0.48570716 0.4857021  0.48570436\n",
            " 0.48562956 0.48565865 0.48576874 0.48559606 0.48572028 0.4857708\n",
            " 0.48562595 0.485794   0.48573866 0.48567343 0.48567286 0.48570603\n",
            " 0.48562986 0.4857219  0.48563224 0.48569146 0.48578665 0.48569196\n",
            " 0.48560598 0.48575062 0.48560145 0.48565486 0.48567978 0.48572373\n",
            " 0.48566577 0.48561665 0.48570928 0.48569602 0.48562208 0.48559597\n",
            " 0.48560265 0.48574093 0.4856819  0.4856254  0.4856589  0.48578355\n",
            " 0.48559624 0.48568666 0.48567715 0.48569912 0.48575172 0.4856972\n",
            " 0.4857279  0.48568308 0.48567495 0.48559782 0.48564184 0.4856253\n",
            " 0.48579177 0.48556802 0.4857223  0.48581222 0.48569772 0.48568672]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.7519122492522e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4816952  0.4816395  0.4817212  0.4817065  0.48173055 0.48171884\n",
            " 0.4815618  0.48173386 0.48170725 0.48157415 0.48170322 0.48168895\n",
            " 0.48166788 0.4816878  0.48169944 0.48166862 0.4817044  0.48168525\n",
            " 0.48165208 0.48169485 0.48167863 0.48167473 0.4817463  0.4816997\n",
            " 0.4816561  0.48176602 0.48163325 0.48167232 0.48167112 0.48170984\n",
            " 0.481697   0.48167607 0.4817121  0.48165664 0.4815691  0.4816404\n",
            " 0.48165438 0.4817439  0.4817378  0.481628   0.4816946  0.4818053\n",
            " 0.48157588 0.48169687 0.4817097  0.48168853 0.4816876  0.48177445\n",
            " 0.48175725 0.48161274 0.481724   0.48160833 0.48168436 0.4816717\n",
            " 0.4816878  0.4816114  0.48171565 0.48175186 0.4817137  0.48171866]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.9830807256512344e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50582594 0.5058788  0.5058486  0.5058628  0.5058551  0.50580716\n",
            " 0.505867   0.5058259  0.5058814  0.5058419  0.5058533  0.5058673\n",
            " 0.50581753 0.50585824 0.5058686  0.50583035 0.5058157  0.505867\n",
            " 0.5058371  0.50584394 0.50581    0.5058289  0.5058684  0.5058407\n",
            " 0.50578207 0.50587386 0.50576717 0.5058218  0.5058571  0.5058756\n",
            " 0.50581974 0.5057875  0.50583524 0.50584006 0.5058809  0.5057705\n",
            " 0.5057871  0.50587964 0.5058279  0.5058386  0.50584024 0.50589305\n",
            " 0.5058311  0.50585324 0.5058397  0.5058418  0.5058731  0.50584567\n",
            " 0.5058534  0.50588524 0.5058321  0.50577915 0.5058168  0.5058064\n",
            " 0.5058689  0.505765   0.50583255 0.50586945 0.50582135 0.50582635]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.100345566053875e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51774603 0.5177416  0.51771086 0.5177136  0.5176951  0.5177182\n",
            " 0.51778615 0.51772773 0.51771665 0.51781106 0.5177025  0.5176822\n",
            " 0.517713   0.5176681  0.51773137 0.51775306 0.51769686 0.517734\n",
            " 0.5177559  0.5176996  0.51774    0.51772726 0.51774377 0.51772106\n",
            " 0.5177622  0.51767635 0.51777506 0.51771903 0.517753   0.5177209\n",
            " 0.51770407 0.5177413  0.517714   0.5177518  0.51779187 0.51778287\n",
            " 0.51776326 0.51770735 0.51769084 0.51777047 0.5177266  0.51767117\n",
            " 0.51778424 0.5177158  0.517691   0.5177356  0.5177268  0.51770943\n",
            " 0.51768917 0.51777303 0.5177212  0.5177994  0.5177178  0.5177207\n",
            " 0.51766586 0.51777637 0.5176995  0.5176597  0.517715   0.51771194]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.472315438557416e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48575804 0.4857765  0.48578346 0.485796   0.4857685  0.48578227\n",
            " 0.48576444 0.48577118 0.48580804 0.48575404 0.4857664  0.48578513\n",
            " 0.48576367 0.485772   0.4857934  0.48577693 0.48578158 0.48579326\n",
            " 0.48578435 0.48577118 0.485772   0.4857635  0.485824   0.48577872\n",
            " 0.485764   0.48576325 0.48576704 0.48575824 0.48576492 0.4857912\n",
            " 0.48575914 0.4857655  0.4857775  0.48576966 0.48575273 0.4857854\n",
            " 0.48577195 0.4857794  0.48579335 0.4857504  0.4857636  0.48575878\n",
            " 0.4857817  0.4858021  0.48575923 0.48578238 0.48579165 0.48575073\n",
            " 0.48577967 0.48573795 0.48576885 0.48575696 0.48576617 0.485764\n",
            " 0.48577553 0.4857648  0.48575804 0.48575583 0.48575425 0.48576984]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.542514110042248e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4856593  0.48569864 0.48571086 0.48570716 0.4857021  0.48570436\n",
            " 0.48562956 0.48565865 0.48576874 0.48559606 0.48572028 0.4857708\n",
            " 0.48562595 0.485794   0.48573866 0.48567343 0.48567286 0.48570603\n",
            " 0.48562986 0.4857219  0.48563224 0.48569146 0.48578665 0.48569196\n",
            " 0.48560598 0.48575062 0.48560145 0.48565486 0.48567978 0.48572373\n",
            " 0.48566577 0.48561665 0.48570928 0.48569602 0.48562208 0.48559597\n",
            " 0.48560265 0.48574093 0.4856819  0.4856254  0.4856589  0.48578355\n",
            " 0.48559624 0.48568666 0.48567715 0.48569912 0.48575172 0.4856972\n",
            " 0.4857279  0.48568308 0.48567495 0.48559782 0.48564184 0.4856253\n",
            " 0.48579177 0.48556802 0.4857223  0.48581222 0.48569772 0.48568672]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.7519122492522e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4816952  0.4816395  0.4817212  0.4817065  0.48173055 0.48171884\n",
            " 0.4815618  0.48173386 0.48170725 0.48157415 0.48170322 0.48168895\n",
            " 0.48166788 0.4816878  0.48169944 0.48166862 0.4817044  0.48168525\n",
            " 0.48165208 0.48169485 0.48167863 0.48167473 0.4817463  0.4816997\n",
            " 0.4816561  0.48176602 0.48163325 0.48167232 0.48167112 0.48170984\n",
            " 0.481697   0.48167607 0.4817121  0.48165664 0.4815691  0.4816404\n",
            " 0.48165438 0.4817439  0.4817378  0.481628   0.4816946  0.4818053\n",
            " 0.48157588 0.48169687 0.4817097  0.48168853 0.4816876  0.48177445\n",
            " 0.48175725 0.48161274 0.481724   0.48160833 0.48168436 0.4816717\n",
            " 0.4816878  0.4816114  0.48171565 0.48175186 0.4817137  0.48171866]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 4.9830807256512344e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50582594 0.5058788  0.5058486  0.5058628  0.5058551  0.50580716\n",
            " 0.505867   0.5058259  0.5058814  0.5058419  0.5058533  0.5058673\n",
            " 0.50581753 0.50585824 0.5058686  0.50583035 0.5058157  0.505867\n",
            " 0.5058371  0.50584394 0.50581    0.5058289  0.5058684  0.5058407\n",
            " 0.50578207 0.50587386 0.50576717 0.5058218  0.5058571  0.5058756\n",
            " 0.50581974 0.5057875  0.50583524 0.50584006 0.5058809  0.5057705\n",
            " 0.5057871  0.50587964 0.5058279  0.5058386  0.50584024 0.50589305\n",
            " 0.5058311  0.50585324 0.5058397  0.5058418  0.5058731  0.50584567\n",
            " 0.5058534  0.50588524 0.5058321  0.50577915 0.5058168  0.5058064\n",
            " 0.5058689  0.505765   0.50583255 0.50586945 0.50582135 0.50582635]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.100345566053875e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51774603 0.5177416  0.51771086 0.5177136  0.5176951  0.5177182\n",
            " 0.51778615 0.51772773 0.51771665 0.51781106 0.5177025  0.5176822\n",
            " 0.517713   0.5176681  0.51773137 0.51775306 0.51769686 0.517734\n",
            " 0.5177559  0.5176996  0.51774    0.51772726 0.51774377 0.51772106\n",
            " 0.5177622  0.51767635 0.51777506 0.51771903 0.517753   0.5177209\n",
            " 0.51770407 0.5177413  0.517714   0.5177518  0.51779187 0.51778287\n",
            " 0.51776326 0.51770735 0.51769084 0.51777047 0.5177266  0.51767117\n",
            " 0.51778424 0.5177158  0.517691   0.5177356  0.5177268  0.51770943\n",
            " 0.51768917 0.51777303 0.5177212  0.5177994  0.5177178  0.5177207\n",
            " 0.51766586 0.51777637 0.5176995  0.5176597  0.517715   0.51771194]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.472315438557416e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48575804 0.4857765  0.48578346 0.485796   0.4857685  0.48578227\n",
            " 0.48576444 0.48577118 0.48580804 0.48575404 0.4857664  0.48578513\n",
            " 0.48576367 0.485772   0.4857934  0.48577693 0.48578158 0.48579326\n",
            " 0.48578435 0.48577118 0.485772   0.4857635  0.485824   0.48577872\n",
            " 0.485764   0.48576325 0.48576704 0.48575824 0.48576492 0.4857912\n",
            " 0.48575914 0.4857655  0.4857775  0.48576966 0.48575273 0.4857854\n",
            " 0.48577195 0.4857794  0.48579335 0.4857504  0.4857636  0.48575878\n",
            " 0.4857817  0.4858021  0.48575923 0.48578238 0.48579165 0.48575073\n",
            " 0.48577967 0.48573795 0.48576885 0.48575696 0.48576617 0.485764\n",
            " 0.48577553 0.4857648  0.48575804 0.48575583 0.48575425 0.48576984]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.542514110042248e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4856593  0.48569864 0.48571086 0.48570716 0.4857021  0.48570436\n",
            " 0.48562956 0.48565865 0.48576874 0.48559606 0.48572028 0.4857708\n",
            " 0.48562595 0.485794   0.48573866 0.48567343 0.48567286 0.48570603\n",
            " 0.48562986 0.4857219  0.48563224 0.48569146 0.48578665 0.48569196\n",
            " 0.48560598 0.48575062 0.48560145 0.48565486 0.48567978 0.48572373\n",
            " 0.48566577 0.48561665 0.48570928 0.48569602 0.48562208 0.48559597\n",
            " 0.48560265 0.48574093 0.4856819  0.4856254  0.4856589  0.48578355\n",
            " 0.48559624 0.48568666 0.48567715 0.48569912 0.48575172 0.4856972\n",
            " 0.4857279  0.48568308 0.48567495 0.48559782 0.48564184 0.4856253\n",
            " 0.48579177 0.48556802 0.4857223  0.48581222 0.48569772 0.48568672]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 5.7519122492522e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48166853 0.50583583 0.5177628  0.48577204 0.48566455]\n",
            " [0.4816409  0.50579995 0.5177868  0.48578823 0.48560315]\n",
            " [0.4816177  0.5057808  0.5177744  0.48577422 0.4856059 ]\n",
            " [0.48163205 0.5058673  0.5177644  0.48578164 0.4856455 ]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4816574  0.50581616 0.5177313  0.4857719  0.48561803]\n",
            " [0.4817027  0.5058221  0.5177341  0.48577878 0.48573345]\n",
            " [0.4817397  0.5058545  0.51769686 0.48574787 0.4857531 ]\n",
            " [0.48163837 0.50579023 0.5177574  0.4857855  0.48558763]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817338  0.5058339  0.5177196  0.4857525  0.48569876]\n",
            " [0.48171464 0.50584686 0.51769966 0.48576856 0.48567638]\n",
            " [0.48174137 0.5058558  0.5176906  0.48576155 0.48570296]\n",
            " [0.4816966  0.50580823 0.5177283  0.4857771  0.48567146]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48167524 0.5059102  0.517725   0.48577747 0.48572588]\n",
            " [0.48169082 0.50584173 0.517738   0.48577183 0.48575467]\n",
            " [0.4816983  0.5058088  0.51772153 0.48577988 0.4856221 ]\n",
            " [0.48169363 0.5058104  0.51773536 0.4857547  0.4856558 ]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48168132 0.5058279  0.5177323  0.48576877 0.48565587]\n",
            " [0.4817587  0.50588983 0.51766056 0.48578387 0.48579618]\n",
            " [0.48171806 0.50585455 0.5176686  0.48576954 0.4857265 ]\n",
            " [0.48167557 0.5058023  0.5177415  0.48576438 0.48564625]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48166853 0.4816409  0.4816177  0.48163205 0.4816574  0.4817027\n",
            " 0.4817397  0.48163837 0.4817338  0.48171464 0.48174137 0.4816966\n",
            " 0.48167524 0.48169082 0.4816983  0.48169363 0.48168132 0.4817587\n",
            " 0.48171806 0.48167557]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.8137208321131766e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50583583 0.50579995 0.5057808  0.5058673  0.50581616 0.5058221\n",
            " 0.5058545  0.50579023 0.5058339  0.50584686 0.5058558  0.50580823\n",
            " 0.5059102  0.50584173 0.5058088  0.5058104  0.5058279  0.50588983\n",
            " 0.50585455 0.5058023 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.226476474083029e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5177628  0.5177868  0.5177744  0.5177644  0.5177313  0.5177341\n",
            " 0.51769686 0.5177574  0.5177196  0.51769966 0.5176906  0.5177283\n",
            " 0.517725   0.517738   0.51772153 0.51773536 0.5177323  0.51766056\n",
            " 0.5176686  0.5177415 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2232044759439304e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48577204 0.48578823 0.48577422 0.48578164 0.4857719  0.48577878\n",
            " 0.48574787 0.4857855  0.4857525  0.48576856 0.48576155 0.4857771\n",
            " 0.48577747 0.48577183 0.48577988 0.4857547  0.48576877 0.48578387\n",
            " 0.48576954 0.48576438]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.0727807421062607e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48566455 0.48560315 0.4856059  0.4856455  0.48561803 0.48573345\n",
            " 0.4857531  0.48558763 0.48569876 0.48567638 0.48570296 0.48567146\n",
            " 0.48572588 0.48575467 0.4856221  0.4856558  0.48565587 0.48579618\n",
            " 0.4857265  0.48564625]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.621691161650233e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48166853 0.4816409  0.4816177  0.48163205 0.4816574  0.4817027\n",
            " 0.4817397  0.48163837 0.4817338  0.48171464 0.48174137 0.4816966\n",
            " 0.48167524 0.48169082 0.4816983  0.48169363 0.48168132 0.4817587\n",
            " 0.48171806 0.48167557]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.8137208321131766e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50583583 0.50579995 0.5057808  0.5058673  0.50581616 0.5058221\n",
            " 0.5058545  0.50579023 0.5058339  0.50584686 0.5058558  0.50580823\n",
            " 0.5059102  0.50584173 0.5058088  0.5058104  0.5058279  0.50588983\n",
            " 0.50585455 0.5058023 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.226476474083029e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5177628  0.5177868  0.5177744  0.5177644  0.5177313  0.5177341\n",
            " 0.51769686 0.5177574  0.5177196  0.51769966 0.5176906  0.5177283\n",
            " 0.517725   0.517738   0.51772153 0.51773536 0.5177323  0.51766056\n",
            " 0.5176686  0.5177415 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2232044759439304e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48577204 0.48578823 0.48577422 0.48578164 0.4857719  0.48577878\n",
            " 0.48574787 0.4857855  0.4857525  0.48576856 0.48576155 0.4857771\n",
            " 0.48577747 0.48577183 0.48577988 0.4857547  0.48576877 0.48578387\n",
            " 0.48576954 0.48576438]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.0727807421062607e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48566455 0.48560315 0.4856059  0.4856455  0.48561803 0.48573345\n",
            " 0.4857531  0.48558763 0.48569876 0.48567638 0.48570296 0.48567146\n",
            " 0.48572588 0.48575467 0.4856221  0.4856558  0.48565587 0.48579618\n",
            " 0.4857265  0.48564625]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.621691161650233e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48166853 0.4816409  0.4816177  0.48163205 0.4816574  0.4817027\n",
            " 0.4817397  0.48163837 0.4817338  0.48171464 0.48174137 0.4816966\n",
            " 0.48167524 0.48169082 0.4816983  0.48169363 0.48168132 0.4817587\n",
            " 0.48171806 0.48167557]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.8137208321131766e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50583583 0.50579995 0.5057808  0.5058673  0.50581616 0.5058221\n",
            " 0.5058545  0.50579023 0.5058339  0.50584686 0.5058558  0.50580823\n",
            " 0.5059102  0.50584173 0.5058088  0.5058104  0.5058279  0.50588983\n",
            " 0.50585455 0.5058023 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.226476474083029e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5177628  0.5177868  0.5177744  0.5177644  0.5177313  0.5177341\n",
            " 0.51769686 0.5177574  0.5177196  0.51769966 0.5176906  0.5177283\n",
            " 0.517725   0.517738   0.51772153 0.51773536 0.5177323  0.51766056\n",
            " 0.5176686  0.5177415 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2232044759439304e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48577204 0.48578823 0.48577422 0.48578164 0.4857719  0.48577878\n",
            " 0.48574787 0.4857855  0.4857525  0.48576856 0.48576155 0.4857771\n",
            " 0.48577747 0.48577183 0.48577988 0.4857547  0.48576877 0.48578387\n",
            " 0.48576954 0.48576438]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.0727807421062607e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48566455 0.48560315 0.4856059  0.4856455  0.48561803 0.48573345\n",
            " 0.4857531  0.48558763 0.48569876 0.48567638 0.48570296 0.48567146\n",
            " 0.48572588 0.48575467 0.4856221  0.4856558  0.48565587 0.48579618\n",
            " 0.4857265  0.48564625]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.621691161650233e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48166853 0.4816409  0.4816177  0.48163205 0.4816574  0.4817027\n",
            " 0.4817397  0.48163837 0.4817338  0.48171464 0.48174137 0.4816966\n",
            " 0.48167524 0.48169082 0.4816983  0.48169363 0.48168132 0.4817587\n",
            " 0.48171806 0.48167557]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 3.8137208321131766e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50583583 0.50579995 0.5057808  0.5058673  0.50581616 0.5058221\n",
            " 0.5058545  0.50579023 0.5058339  0.50584686 0.5058558  0.50580823\n",
            " 0.5059102  0.50584173 0.5058088  0.5058104  0.5058279  0.50588983\n",
            " 0.50585455 0.5058023 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.226476474083029e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5177628  0.5177868  0.5177744  0.5177644  0.5177313  0.5177341\n",
            " 0.51769686 0.5177574  0.5177196  0.51769966 0.5176906  0.5177283\n",
            " 0.517725   0.517738   0.51772153 0.51773536 0.5177323  0.51766056\n",
            " 0.5176686  0.5177415 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.2232044759439304e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48577204 0.48578823 0.48577422 0.48578164 0.4857719  0.48577878\n",
            " 0.48574787 0.4857855  0.4857525  0.48576856 0.48576155 0.4857771\n",
            " 0.48577747 0.48577183 0.48577988 0.4857547  0.48576877 0.48578387\n",
            " 0.48576954 0.48576438]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.0727807421062607e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48566455 0.48560315 0.4856059  0.4856455  0.48561803 0.48573345\n",
            " 0.4857531  0.48558763 0.48569876 0.48567638 0.48570296 0.48567146\n",
            " 0.48572588 0.48575467 0.4856221  0.4856558  0.48565587 0.48579618\n",
            " 0.4857265  0.48564625]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 5.621691161650233e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48172593 0.505851   0.51772344 0.48578802 0.4856847 ]\n",
            " [0.48173296 0.5058549  0.5176909  0.48575592 0.4857201 ]\n",
            " [0.48173627 0.5058668  0.5176939  0.48576033 0.48572877]\n",
            " [0.48168844 0.505833   0.51771164 0.48578036 0.48566464]\n",
            " [0.48175398 0.5058668  0.51768166 0.4857383  0.48574615]\n",
            " [0.48165777 0.50581235 0.51778305 0.4857763  0.48563236]\n",
            " [0.48165074 0.5058123  0.5177506  0.48578557 0.48564342]\n",
            " [0.48165026 0.5057825  0.5177394  0.48577115 0.48561046]\n",
            " [0.48166862 0.5058021  0.51775867 0.48579866 0.48561943]\n",
            " [0.4816703  0.5058459  0.5177178  0.4857838  0.48572162]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4816527  0.5058429  0.5177498  0.485789   0.4857023 ]\n",
            " [0.481673   0.50582296 0.517753   0.48578373 0.48565188]\n",
            " [0.48169717 0.50582063 0.5177295  0.4857862  0.48568326]\n",
            " [0.4817454  0.5058683  0.51768935 0.48580354 0.48578188]\n",
            " [0.4816768  0.50582564 0.51772076 0.48577574 0.48565504]\n",
            " [0.48172218 0.505832   0.5177094  0.4857665  0.48570982]\n",
            " [0.4817295  0.5058516  0.5177035  0.48577687 0.48576614]\n",
            " [0.48166874 0.5057815  0.51774514 0.48575938 0.48560116]\n",
            " [0.48171216 0.50587434 0.51769835 0.48577178 0.48569793]\n",
            " [0.48163894 0.50586474 0.5177496  0.48576805 0.48568445]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48172593 0.48173296 0.48173627 0.48168844 0.48175398 0.48165777\n",
            " 0.48165074 0.48165026 0.48166862 0.4816703  0.4816527  0.481673\n",
            " 0.48169717 0.4817454  0.4816768  0.48172218 0.4817295  0.48166874\n",
            " 0.48171216 0.48163894]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.561182165867649e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.505851   0.5058549  0.5058668  0.505833   0.5058668  0.50581235\n",
            " 0.5058123  0.5057825  0.5058021  0.5058459  0.5058429  0.50582296\n",
            " 0.50582063 0.5058683  0.50582564 0.505832   0.5058516  0.5057815\n",
            " 0.50587434 0.50586474]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.7254349333816208e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51772344 0.5176909  0.5176939  0.51771164 0.51768166 0.51778305\n",
            " 0.5177506  0.5177394  0.51775867 0.5177178  0.5177498  0.517753\n",
            " 0.5177295  0.51768935 0.51772076 0.5177094  0.5177035  0.51774514\n",
            " 0.51769835 0.5177496 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7154561394127086e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48578802 0.48575592 0.48576033 0.48578036 0.4857383  0.4857763\n",
            " 0.48578557 0.48577115 0.48579866 0.4857838  0.485789   0.48578373\n",
            " 0.4857862  0.48580354 0.48577574 0.4857665  0.48577687 0.48575938\n",
            " 0.48577178 0.48576805]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4936509614926763e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4856847  0.4857201  0.48572877 0.48566464 0.48574615 0.48563236\n",
            " 0.48564342 0.48561046 0.48561943 0.48572162 0.4857023  0.48565188\n",
            " 0.48568326 0.48578188 0.48565504 0.48570982 0.48576614 0.48560116\n",
            " 0.48569793 0.48568445]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.953639654559083e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48172593 0.48173296 0.48173627 0.48168844 0.48175398 0.48165777\n",
            " 0.48165074 0.48165026 0.48166862 0.4816703  0.4816527  0.481673\n",
            " 0.48169717 0.4817454  0.4816768  0.48172218 0.4817295  0.48166874\n",
            " 0.48171216 0.48163894]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.561182165867649e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.505851   0.5058549  0.5058668  0.505833   0.5058668  0.50581235\n",
            " 0.5058123  0.5057825  0.5058021  0.5058459  0.5058429  0.50582296\n",
            " 0.50582063 0.5058683  0.50582564 0.505832   0.5058516  0.5057815\n",
            " 0.50587434 0.50586474]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.7254349333816208e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51772344 0.5176909  0.5176939  0.51771164 0.51768166 0.51778305\n",
            " 0.5177506  0.5177394  0.51775867 0.5177178  0.5177498  0.517753\n",
            " 0.5177295  0.51768935 0.51772076 0.5177094  0.5177035  0.51774514\n",
            " 0.51769835 0.5177496 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7154561394127086e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48578802 0.48575592 0.48576033 0.48578036 0.4857383  0.4857763\n",
            " 0.48578557 0.48577115 0.48579866 0.4857838  0.485789   0.48578373\n",
            " 0.4857862  0.48580354 0.48577574 0.4857665  0.48577687 0.48575938\n",
            " 0.48577178 0.48576805]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4936509614926763e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4856847  0.4857201  0.48572877 0.48566464 0.48574615 0.48563236\n",
            " 0.48564342 0.48561046 0.48561943 0.48572162 0.4857023  0.48565188\n",
            " 0.48568326 0.48578188 0.48565504 0.48570982 0.48576614 0.48560116\n",
            " 0.48569793 0.48568445]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.953639654559083e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48172593 0.48173296 0.48173627 0.48168844 0.48175398 0.48165777\n",
            " 0.48165074 0.48165026 0.48166862 0.4816703  0.4816527  0.481673\n",
            " 0.48169717 0.4817454  0.4816768  0.48172218 0.4817295  0.48166874\n",
            " 0.48171216 0.48163894]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.561182165867649e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.505851   0.5058549  0.5058668  0.505833   0.5058668  0.50581235\n",
            " 0.5058123  0.5057825  0.5058021  0.5058459  0.5058429  0.50582296\n",
            " 0.50582063 0.5058683  0.50582564 0.505832   0.5058516  0.5057815\n",
            " 0.50587434 0.50586474]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.7254349333816208e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51772344 0.5176909  0.5176939  0.51771164 0.51768166 0.51778305\n",
            " 0.5177506  0.5177394  0.51775867 0.5177178  0.5177498  0.517753\n",
            " 0.5177295  0.51768935 0.51772076 0.5177094  0.5177035  0.51774514\n",
            " 0.51769835 0.5177496 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7154561394127086e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48578802 0.48575592 0.48576033 0.48578036 0.4857383  0.4857763\n",
            " 0.48578557 0.48577115 0.48579866 0.4857838  0.485789   0.48578373\n",
            " 0.4857862  0.48580354 0.48577574 0.4857665  0.48577687 0.48575938\n",
            " 0.48577178 0.48576805]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4936509614926763e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4856847  0.4857201  0.48572877 0.48566464 0.48574615 0.48563236\n",
            " 0.48564342 0.48561046 0.48561943 0.48572162 0.4857023  0.48565188\n",
            " 0.48568326 0.48578188 0.48565504 0.48570982 0.48576614 0.48560116\n",
            " 0.48569793 0.48568445]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.953639654559083e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48172593 0.48173296 0.48173627 0.48168844 0.48175398 0.48165777\n",
            " 0.48165074 0.48165026 0.48166862 0.4816703  0.4816527  0.481673\n",
            " 0.48169717 0.4817454  0.4816768  0.48172218 0.4817295  0.48166874\n",
            " 0.48171216 0.48163894]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.561182165867649e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.505851   0.5058549  0.5058668  0.505833   0.5058668  0.50581235\n",
            " 0.5058123  0.5057825  0.5058021  0.5058459  0.5058429  0.50582296\n",
            " 0.50582063 0.5058683  0.50582564 0.505832   0.5058516  0.5057815\n",
            " 0.50587434 0.50586474]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.7254349333816208e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51772344 0.5176909  0.5176939  0.51771164 0.51768166 0.51778305\n",
            " 0.5177506  0.5177394  0.51775867 0.5177178  0.5177498  0.517753\n",
            " 0.5177295  0.51768935 0.51772076 0.5177094  0.5177035  0.51774514\n",
            " 0.51769835 0.5177496 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.7154561394127086e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48578802 0.48575592 0.48576033 0.48578036 0.4857383  0.4857763\n",
            " 0.48578557 0.48577115 0.48579866 0.4857838  0.485789   0.48578373\n",
            " 0.4857862  0.48580354 0.48577574 0.4857665  0.48577687 0.48575938\n",
            " 0.48577178 0.48576805]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4936509614926763e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4856847  0.4857201  0.48572877 0.48566464 0.48574615 0.48563236\n",
            " 0.48564342 0.48561046 0.48561943 0.48572162 0.4857023  0.48565188\n",
            " 0.48568326 0.48578188 0.48565504 0.48570982 0.48576614 0.48560116\n",
            " 0.48569793 0.48568445]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 4.953639654559083e-05\n",
            "Epoch 4/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4816952  0.50582594 0.51774603 0.48575804 0.4856593 ]\n",
            " [0.4816395  0.5058788  0.5177416  0.4857765  0.48569864]\n",
            " [0.4817212  0.5058486  0.51771086 0.48578346 0.48571086]\n",
            " [0.4817065  0.5058628  0.5177136  0.485796   0.48570716]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48175782 0.5058854  0.5177304  0.48581058 0.48575112]\n",
            " [0.48174587 0.50583726 0.5177535  0.48582414 0.4857531 ]\n",
            " [0.48158845 0.50589645 0.51782095 0.48580542 0.4856773 ]\n",
            " [0.48176044 0.50585574 0.5177631  0.48581266 0.485707  ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48176154 0.50592434 0.51775795 0.48584062 0.48587516]\n",
            " [0.48162633 0.50588304 0.51785195 0.48578504 0.48569927]\n",
            " [0.48175725 0.50589633 0.517744   0.48579875 0.48582646]\n",
            " [0.48174363 0.5059107  0.5177236  0.48581788 0.48587796]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4817366  0.5058793  0.5177827  0.48582503 0.48576885]\n",
            " [0.4817571  0.505921   0.51773876 0.48583415 0.48593938]\n",
            " [0.48176762 0.5059306  0.5178019  0.48585442 0.48588187]\n",
            " [0.48173717 0.5058922  0.5178232  0.48583815 0.48581648]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48181176 0.5058935  0.5177908  0.4858549  0.48587516]\n",
            " [0.48179293 0.50594544 0.517828   0.4858667  0.48590842]\n",
            " [0.48175874 0.50591415 0.5178497  0.48585692 0.48583022]\n",
            " [0.48180202 0.5059223  0.51779383 0.4858445  0.4859248 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48178968 0.5058864  0.51782465 0.4858394  0.48587662]\n",
            " [0.48178694 0.50590634 0.51781195 0.4858318  0.4859375 ]\n",
            " [0.48185787 0.50594634 0.5178294  0.4858921  0.48603436]\n",
            " [0.48181248 0.5059187  0.5178056  0.48584768 0.48593953]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48179784 0.50590026 0.5178731  0.4858721  0.48588476]\n",
            " [0.4819103  0.5059955  0.51778847 0.4858744  0.48603627]\n",
            " [0.48177493 0.50588506 0.5178855  0.48587483 0.4858795 ]\n",
            " [0.4818153  0.505942   0.5178298  0.48586777 0.48593652]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48179257 0.5059525  0.5178449  0.48589048 0.48598582]\n",
            " [0.48183268 0.50597304 0.51781327 0.4859191  0.486034  ]\n",
            " [0.48181924 0.5059163  0.5177959  0.48588657 0.48597524]\n",
            " [0.48179573 0.5058818  0.5178334  0.4858899  0.485921  ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4818459  0.50594175 0.5178161  0.48591876 0.4860348 ]\n",
            " [0.4817913  0.50594693 0.5178536  0.4859112  0.4860216 ]\n",
            " [0.48169914 0.5059836  0.5178933  0.48588935 0.4859394 ]\n",
            " [0.4817738  0.5058751  0.517884   0.48592502 0.48591736]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48177335 0.5058694  0.5178579  0.4859046  0.48591796]\n",
            " [0.48186424 0.5059654  0.5178031  0.48591495 0.4860626 ]\n",
            " [0.48185712 0.5059118  0.5177863  0.4859276  0.48600096]\n",
            " [0.4817445  0.5059199  0.51786566 0.485881   0.48593867]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48188895 0.5059912  0.5178743  0.4859533  0.48605502]\n",
            " [0.4820015  0.5060465  0.517821   0.48595092 0.48618543]\n",
            " [0.48176527 0.5059764  0.51793146 0.48596507 0.48598194]\n",
            " [0.48188874 0.506003   0.5178655  0.48598975 0.4860807 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48190576 0.5060167  0.5178499  0.4859903  0.48609692]\n",
            " [0.48188454 0.5060183  0.51789397 0.48601237 0.4861168 ]\n",
            " [0.48188162 0.5060485  0.5178863  0.4860202  0.48616788]\n",
            " [0.4819685  0.50602114 0.5178698  0.48597986 0.4861147 ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48196912 0.5060564  0.51788366 0.4860497  0.48618823]\n",
            " [0.48182037 0.50608236 0.5179663  0.48600104 0.48613372]\n",
            " [0.48193255 0.5060322  0.51791525 0.48603532 0.48613045]\n",
            " [0.4818138  0.5059738  0.5179918  0.48601758 0.48604408]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819022  0.5060389  0.51793456 0.4860627  0.48611763]\n",
            " [0.48188934 0.50602806 0.51793736 0.48606014 0.48610064]\n",
            " [0.48190787 0.5060949  0.517884   0.48607683 0.48627576]\n",
            " [0.48182723 0.5059826  0.51799095 0.48605615 0.48603603]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48192695 0.5060289  0.5178976  0.48603058 0.48621422]\n",
            " [0.48196357 0.50606674 0.51785916 0.48602882 0.48630476]\n",
            " [0.4819234  0.5060165  0.5179128  0.48602453 0.48618564]\n",
            " [0.48192933 0.506022   0.5179101  0.4860407  0.48617542]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819359  0.50606084 0.5179738  0.48606616 0.48620132]\n",
            " [0.4818794  0.5061135  0.51796937 0.4860827  0.48623848]\n",
            " [0.48196504 0.50608665 0.51793957 0.486095   0.48625803]\n",
            " [0.4819488  0.50610006 0.51794255 0.4861064  0.48625308]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48197377 0.5060934  0.5179233  0.48607945 0.48624897]\n",
            " [0.4819608  0.5060439  0.51794666 0.48609203 0.48624894]\n",
            " [0.48179904 0.506096   0.5180123  0.48606515 0.48616084]\n",
            " [0.48197138 0.5060595  0.51795715 0.48607704 0.48619905]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48195136 0.5061186  0.51794547 0.48611936 0.4863152 ]\n",
            " [0.4818101  0.50607044 0.5180373  0.48605406 0.48612633]\n",
            " [0.4819451  0.5060906  0.5179324  0.48607588 0.4862651 ]\n",
            " [0.48192957 0.50610447 0.5179108  0.48609507 0.4863182 ]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48191038 0.5060528  0.51793975 0.48607218 0.48616782]\n",
            " [0.48192942 0.5060962  0.51789737 0.48608324 0.4863436 ]\n",
            " [0.48194027 0.50610524 0.51796055 0.4861014  0.48628154]\n",
            " [0.48191026 0.5060657  0.5179813  0.4860847  0.48621514]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819452  0.50605035 0.5179247  0.48608968 0.4862155 ]\n",
            " [0.481927   0.506103   0.517962   0.48610142 0.48624828]\n",
            " [0.48189145 0.5060692  0.51798326 0.48608884 0.4861665 ]\n",
            " [0.48193604 0.5060809  0.5179275  0.48608074 0.48626718]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819192  0.5060438  0.5179676  0.48607874 0.48617244]\n",
            " [0.48191732 0.5060655  0.5179552  0.48607257 0.48623496]\n",
            " [0.4819872  0.5061073  0.5179742  0.48613474 0.48633406]\n",
            " [0.48194417 0.5060792  0.5179485  0.48609084 0.4862397 ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4818952  0.506014   0.5179896  0.48606876 0.48614278]\n",
            " [0.4820092  0.50611234 0.51790637 0.48607594 0.48630095]\n",
            " [0.4818726  0.5059985  0.51800156 0.48607108 0.48613706]\n",
            " [0.48191348 0.5060569  0.51794654 0.4860664  0.4861973 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48191124 0.506091   0.51798016 0.48607075 0.48621863]\n",
            " [0.48195308 0.5061137  0.51794964 0.48610213 0.48627037]\n",
            " [0.48193908 0.50605613 0.5179317  0.48606893 0.48621103]\n",
            " [0.48191425 0.5060196  0.5179687  0.48606977 0.48615336]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48195273 0.506071   0.51794267 0.48608583 0.4862522 ]\n",
            " [0.4818984  0.50607634 0.51797956 0.48607817 0.48623884]\n",
            " [0.48180345 0.50610906 0.518018   0.48605177 0.48615122]\n",
            " [0.48188016 0.50600207 0.5180091  0.48608992 0.4861318 ]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4818946  0.5060197  0.51799    0.48607767 0.4861405 ]\n",
            " [0.48198667 0.50611943 0.51793694 0.48609114 0.48628944]\n",
            " [0.48197877 0.5060643  0.5179198  0.48610246 0.4862259 ]\n",
            " [0.48186445 0.5060698  0.5179978  0.48605293 0.48615998]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819367  0.50607675 0.51795363 0.48607326 0.48620287]\n",
            " [0.48204902 0.50613344 0.5179016  0.48607212 0.48633507]\n",
            " [0.48181245 0.50605994 0.51801026 0.486082   0.48612642]\n",
            " [0.481936   0.50608855 0.5179455  0.48610938 0.48622823]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48195282 0.5060768  0.51791924 0.48606995 0.4862237 ]\n",
            " [0.48193145 0.50607836 0.51796293 0.4860917  0.4862428 ]\n",
            " [0.48192823 0.5061084  0.51795554 0.48609942 0.4862936 ]\n",
            " [0.48201528 0.5060812  0.5179394  0.4860594  0.48624113]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48200026 0.506092   0.51791793 0.48609114 0.48627558]\n",
            " [0.48185137 0.50611746 0.5180004  0.48604172 0.4862196 ]\n",
            " [0.48196334 0.50606745 0.5179494  0.48607633 0.48621708]\n",
            " [0.4818446  0.50600857 0.51802576 0.4860579  0.48612934]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48192376 0.50605106 0.5179457  0.4860729  0.48618227]\n",
            " [0.48191077 0.50604016 0.51794845 0.48607028 0.48616514]\n",
            " [0.48192936 0.50610703 0.51789516 0.48608693 0.48634142]\n",
            " [0.48184842 0.50599444 0.5180019  0.486066   0.48609942]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48195922 0.5060711  0.5179278  0.48607013 0.48627138]\n",
            " [0.48199576 0.5061091  0.5178895  0.4860683  0.48636186]\n",
            " [0.48195508 0.5060581  0.5179431  0.48606348 0.48624197]\n",
            " [0.48196122 0.5060637  0.5179403  0.4860798  0.48623192]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4819359  0.4818794  0.48196504 0.4819488  0.48197377 0.4819608\n",
            " 0.48179904 0.48197138 0.48195136 0.4818101  0.4819451  0.48192957\n",
            " 0.48191038 0.48192942 0.48194027 0.48191026 0.4819452  0.481927\n",
            " 0.48189145 0.48193604 0.4819192  0.48191732 0.4819872  0.48194417\n",
            " 0.4818952  0.4820092  0.4818726  0.48191348 0.48191124 0.48195308\n",
            " 0.48193908 0.48191425 0.48195273 0.4818984  0.48180345 0.48188016\n",
            " 0.4818946  0.48198667 0.48197877 0.48186445 0.4819367  0.48204902\n",
            " 0.48181245 0.481936   0.48195282 0.48193145 0.48192823 0.48201528\n",
            " 0.48200026 0.48185137 0.48196334 0.4818446  0.48192376 0.48191077\n",
            " 0.48192936 0.48184842 0.48195922 0.48199576 0.48195508 0.48196122]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.153514939593151e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50606084 0.5061135  0.50608665 0.50610006 0.5060934  0.5060439\n",
            " 0.506096   0.5060595  0.5061186  0.50607044 0.5060906  0.50610447\n",
            " 0.5060528  0.5060962  0.50610524 0.5060657  0.50605035 0.506103\n",
            " 0.5060692  0.5060809  0.5060438  0.5060655  0.5061073  0.5060792\n",
            " 0.506014   0.50611234 0.5059985  0.5060569  0.506091   0.5061137\n",
            " 0.50605613 0.5060196  0.506071   0.50607634 0.50610906 0.50600207\n",
            " 0.5060197  0.50611943 0.5060643  0.5060698  0.50607675 0.50613344\n",
            " 0.50605994 0.50608855 0.5060768  0.50607836 0.5061084  0.5060812\n",
            " 0.506092   0.50611746 0.50606745 0.50600857 0.50605106 0.50604016\n",
            " 0.50610703 0.50599444 0.5060711  0.5061091  0.5060581  0.5060637 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.2538289815420285e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5179738  0.51796937 0.51793957 0.51794255 0.5179233  0.51794666\n",
            " 0.5180123  0.51795715 0.51794547 0.5180373  0.5179324  0.5179108\n",
            " 0.51793975 0.51789737 0.51796055 0.5179813  0.5179247  0.517962\n",
            " 0.51798326 0.5179275  0.5179676  0.5179552  0.5179742  0.5179485\n",
            " 0.5179896  0.51790637 0.51800156 0.51794654 0.51798016 0.51794964\n",
            " 0.5179317  0.5179687  0.51794267 0.51797956 0.518018   0.5180091\n",
            " 0.51799    0.51793694 0.5179198  0.5179978  0.51795363 0.5179016\n",
            " 0.51801026 0.5179455  0.51791924 0.51796293 0.51795554 0.5179394\n",
            " 0.51791793 0.5180004  0.5179494  0.51802576 0.5179457  0.51794845\n",
            " 0.51789516 0.5180019  0.5179278  0.5178895  0.5179431  0.5179403 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.3859188988571987e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48606616 0.4860827  0.486095   0.4861064  0.48607945 0.48609203\n",
            " 0.48606515 0.48607704 0.48611936 0.48605406 0.48607588 0.48609507\n",
            " 0.48607218 0.48608324 0.4861014  0.4860847  0.48608968 0.48610142\n",
            " 0.48608884 0.48608074 0.48607874 0.48607257 0.48613474 0.48609084\n",
            " 0.48606876 0.48607594 0.48607108 0.4860664  0.48607075 0.48610213\n",
            " 0.48606893 0.48606977 0.48608583 0.48607817 0.48605177 0.48608992\n",
            " 0.48607767 0.48609114 0.48610246 0.48605293 0.48607326 0.48607212\n",
            " 0.486082   0.48610938 0.48606995 0.4860917  0.48609942 0.4860594\n",
            " 0.48609114 0.48604172 0.48607633 0.4860579  0.4860729  0.48607028\n",
            " 0.48608693 0.486066   0.48607013 0.4860683  0.48606348 0.4860798 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.6743764717830345e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48620132 0.48623848 0.48625803 0.48625308 0.48624897 0.48624894\n",
            " 0.48616084 0.48619905 0.4863152  0.48612633 0.4862651  0.4863182\n",
            " 0.48616782 0.4863436  0.48628154 0.48621514 0.4862155  0.48624828\n",
            " 0.4861665  0.48626718 0.48617244 0.48623496 0.48633406 0.4862397\n",
            " 0.48614278 0.48630095 0.48613706 0.4861973  0.48621863 0.48627037\n",
            " 0.48621103 0.48615336 0.4862522  0.48623884 0.48615122 0.4861318\n",
            " 0.4861405  0.48628944 0.4862259  0.48615998 0.48620287 0.48633507\n",
            " 0.48612642 0.48622823 0.4862237  0.4862428  0.4862936  0.48624113\n",
            " 0.48627558 0.4862196  0.48621708 0.48612934 0.48618227 0.48616514\n",
            " 0.48634142 0.48609942 0.48627138 0.48636186 0.48624197 0.48623192]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.22464795014821e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4819359  0.4818794  0.48196504 0.4819488  0.48197377 0.4819608\n",
            " 0.48179904 0.48197138 0.48195136 0.4818101  0.4819451  0.48192957\n",
            " 0.48191038 0.48192942 0.48194027 0.48191026 0.4819452  0.481927\n",
            " 0.48189145 0.48193604 0.4819192  0.48191732 0.4819872  0.48194417\n",
            " 0.4818952  0.4820092  0.4818726  0.48191348 0.48191124 0.48195308\n",
            " 0.48193908 0.48191425 0.48195273 0.4818984  0.48180345 0.48188016\n",
            " 0.4818946  0.48198667 0.48197877 0.48186445 0.4819367  0.48204902\n",
            " 0.48181245 0.481936   0.48195282 0.48193145 0.48192823 0.48201528\n",
            " 0.48200026 0.48185137 0.48196334 0.4818446  0.48192376 0.48191077\n",
            " 0.48192936 0.48184842 0.48195922 0.48199576 0.48195508 0.48196122]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.153514939593151e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50606084 0.5061135  0.50608665 0.50610006 0.5060934  0.5060439\n",
            " 0.506096   0.5060595  0.5061186  0.50607044 0.5060906  0.50610447\n",
            " 0.5060528  0.5060962  0.50610524 0.5060657  0.50605035 0.506103\n",
            " 0.5060692  0.5060809  0.5060438  0.5060655  0.5061073  0.5060792\n",
            " 0.506014   0.50611234 0.5059985  0.5060569  0.506091   0.5061137\n",
            " 0.50605613 0.5060196  0.506071   0.50607634 0.50610906 0.50600207\n",
            " 0.5060197  0.50611943 0.5060643  0.5060698  0.50607675 0.50613344\n",
            " 0.50605994 0.50608855 0.5060768  0.50607836 0.5061084  0.5060812\n",
            " 0.506092   0.50611746 0.50606745 0.50600857 0.50605106 0.50604016\n",
            " 0.50610703 0.50599444 0.5060711  0.5061091  0.5060581  0.5060637 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.2538289815420285e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5179738  0.51796937 0.51793957 0.51794255 0.5179233  0.51794666\n",
            " 0.5180123  0.51795715 0.51794547 0.5180373  0.5179324  0.5179108\n",
            " 0.51793975 0.51789737 0.51796055 0.5179813  0.5179247  0.517962\n",
            " 0.51798326 0.5179275  0.5179676  0.5179552  0.5179742  0.5179485\n",
            " 0.5179896  0.51790637 0.51800156 0.51794654 0.51798016 0.51794964\n",
            " 0.5179317  0.5179687  0.51794267 0.51797956 0.518018   0.5180091\n",
            " 0.51799    0.51793694 0.5179198  0.5179978  0.51795363 0.5179016\n",
            " 0.51801026 0.5179455  0.51791924 0.51796293 0.51795554 0.5179394\n",
            " 0.51791793 0.5180004  0.5179494  0.51802576 0.5179457  0.51794845\n",
            " 0.51789516 0.5180019  0.5179278  0.5178895  0.5179431  0.5179403 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.3859188988571987e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48606616 0.4860827  0.486095   0.4861064  0.48607945 0.48609203\n",
            " 0.48606515 0.48607704 0.48611936 0.48605406 0.48607588 0.48609507\n",
            " 0.48607218 0.48608324 0.4861014  0.4860847  0.48608968 0.48610142\n",
            " 0.48608884 0.48608074 0.48607874 0.48607257 0.48613474 0.48609084\n",
            " 0.48606876 0.48607594 0.48607108 0.4860664  0.48607075 0.48610213\n",
            " 0.48606893 0.48606977 0.48608583 0.48607817 0.48605177 0.48608992\n",
            " 0.48607767 0.48609114 0.48610246 0.48605293 0.48607326 0.48607212\n",
            " 0.486082   0.48610938 0.48606995 0.4860917  0.48609942 0.4860594\n",
            " 0.48609114 0.48604172 0.48607633 0.4860579  0.4860729  0.48607028\n",
            " 0.48608693 0.486066   0.48607013 0.4860683  0.48606348 0.4860798 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.6743764717830345e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48620132 0.48623848 0.48625803 0.48625308 0.48624897 0.48624894\n",
            " 0.48616084 0.48619905 0.4863152  0.48612633 0.4862651  0.4863182\n",
            " 0.48616782 0.4863436  0.48628154 0.48621514 0.4862155  0.48624828\n",
            " 0.4861665  0.48626718 0.48617244 0.48623496 0.48633406 0.4862397\n",
            " 0.48614278 0.48630095 0.48613706 0.4861973  0.48621863 0.48627037\n",
            " 0.48621103 0.48615336 0.4862522  0.48623884 0.48615122 0.4861318\n",
            " 0.4861405  0.48628944 0.4862259  0.48615998 0.48620287 0.48633507\n",
            " 0.48612642 0.48622823 0.4862237  0.4862428  0.4862936  0.48624113\n",
            " 0.48627558 0.4862196  0.48621708 0.48612934 0.48618227 0.48616514\n",
            " 0.48634142 0.48609942 0.48627138 0.48636186 0.48624197 0.48623192]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.22464795014821e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4819359  0.4818794  0.48196504 0.4819488  0.48197377 0.4819608\n",
            " 0.48179904 0.48197138 0.48195136 0.4818101  0.4819451  0.48192957\n",
            " 0.48191038 0.48192942 0.48194027 0.48191026 0.4819452  0.481927\n",
            " 0.48189145 0.48193604 0.4819192  0.48191732 0.4819872  0.48194417\n",
            " 0.4818952  0.4820092  0.4818726  0.48191348 0.48191124 0.48195308\n",
            " 0.48193908 0.48191425 0.48195273 0.4818984  0.48180345 0.48188016\n",
            " 0.4818946  0.48198667 0.48197877 0.48186445 0.4819367  0.48204902\n",
            " 0.48181245 0.481936   0.48195282 0.48193145 0.48192823 0.48201528\n",
            " 0.48200026 0.48185137 0.48196334 0.4818446  0.48192376 0.48191077\n",
            " 0.48192936 0.48184842 0.48195922 0.48199576 0.48195508 0.48196122]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.153514939593151e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50606084 0.5061135  0.50608665 0.50610006 0.5060934  0.5060439\n",
            " 0.506096   0.5060595  0.5061186  0.50607044 0.5060906  0.50610447\n",
            " 0.5060528  0.5060962  0.50610524 0.5060657  0.50605035 0.506103\n",
            " 0.5060692  0.5060809  0.5060438  0.5060655  0.5061073  0.5060792\n",
            " 0.506014   0.50611234 0.5059985  0.5060569  0.506091   0.5061137\n",
            " 0.50605613 0.5060196  0.506071   0.50607634 0.50610906 0.50600207\n",
            " 0.5060197  0.50611943 0.5060643  0.5060698  0.50607675 0.50613344\n",
            " 0.50605994 0.50608855 0.5060768  0.50607836 0.5061084  0.5060812\n",
            " 0.506092   0.50611746 0.50606745 0.50600857 0.50605106 0.50604016\n",
            " 0.50610703 0.50599444 0.5060711  0.5061091  0.5060581  0.5060637 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.2538289815420285e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5179738  0.51796937 0.51793957 0.51794255 0.5179233  0.51794666\n",
            " 0.5180123  0.51795715 0.51794547 0.5180373  0.5179324  0.5179108\n",
            " 0.51793975 0.51789737 0.51796055 0.5179813  0.5179247  0.517962\n",
            " 0.51798326 0.5179275  0.5179676  0.5179552  0.5179742  0.5179485\n",
            " 0.5179896  0.51790637 0.51800156 0.51794654 0.51798016 0.51794964\n",
            " 0.5179317  0.5179687  0.51794267 0.51797956 0.518018   0.5180091\n",
            " 0.51799    0.51793694 0.5179198  0.5179978  0.51795363 0.5179016\n",
            " 0.51801026 0.5179455  0.51791924 0.51796293 0.51795554 0.5179394\n",
            " 0.51791793 0.5180004  0.5179494  0.51802576 0.5179457  0.51794845\n",
            " 0.51789516 0.5180019  0.5179278  0.5178895  0.5179431  0.5179403 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.3859188988571987e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48606616 0.4860827  0.486095   0.4861064  0.48607945 0.48609203\n",
            " 0.48606515 0.48607704 0.48611936 0.48605406 0.48607588 0.48609507\n",
            " 0.48607218 0.48608324 0.4861014  0.4860847  0.48608968 0.48610142\n",
            " 0.48608884 0.48608074 0.48607874 0.48607257 0.48613474 0.48609084\n",
            " 0.48606876 0.48607594 0.48607108 0.4860664  0.48607075 0.48610213\n",
            " 0.48606893 0.48606977 0.48608583 0.48607817 0.48605177 0.48608992\n",
            " 0.48607767 0.48609114 0.48610246 0.48605293 0.48607326 0.48607212\n",
            " 0.486082   0.48610938 0.48606995 0.4860917  0.48609942 0.4860594\n",
            " 0.48609114 0.48604172 0.48607633 0.4860579  0.4860729  0.48607028\n",
            " 0.48608693 0.486066   0.48607013 0.4860683  0.48606348 0.4860798 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.6743764717830345e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48620132 0.48623848 0.48625803 0.48625308 0.48624897 0.48624894\n",
            " 0.48616084 0.48619905 0.4863152  0.48612633 0.4862651  0.4863182\n",
            " 0.48616782 0.4863436  0.48628154 0.48621514 0.4862155  0.48624828\n",
            " 0.4861665  0.48626718 0.48617244 0.48623496 0.48633406 0.4862397\n",
            " 0.48614278 0.48630095 0.48613706 0.4861973  0.48621863 0.48627037\n",
            " 0.48621103 0.48615336 0.4862522  0.48623884 0.48615122 0.4861318\n",
            " 0.4861405  0.48628944 0.4862259  0.48615998 0.48620287 0.48633507\n",
            " 0.48612642 0.48622823 0.4862237  0.4862428  0.4862936  0.48624113\n",
            " 0.48627558 0.4862196  0.48621708 0.48612934 0.48618227 0.48616514\n",
            " 0.48634142 0.48609942 0.48627138 0.48636186 0.48624197 0.48623192]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.22464795014821e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4819359  0.4818794  0.48196504 0.4819488  0.48197377 0.4819608\n",
            " 0.48179904 0.48197138 0.48195136 0.4818101  0.4819451  0.48192957\n",
            " 0.48191038 0.48192942 0.48194027 0.48191026 0.4819452  0.481927\n",
            " 0.48189145 0.48193604 0.4819192  0.48191732 0.4819872  0.48194417\n",
            " 0.4818952  0.4820092  0.4818726  0.48191348 0.48191124 0.48195308\n",
            " 0.48193908 0.48191425 0.48195273 0.4818984  0.48180345 0.48188016\n",
            " 0.4818946  0.48198667 0.48197877 0.48186445 0.4819367  0.48204902\n",
            " 0.48181245 0.481936   0.48195282 0.48193145 0.48192823 0.48201528\n",
            " 0.48200026 0.48185137 0.48196334 0.4818446  0.48192376 0.48191077\n",
            " 0.48192936 0.48184842 0.48195922 0.48199576 0.48195508 0.48196122]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.153514939593151e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50606084 0.5061135  0.50608665 0.50610006 0.5060934  0.5060439\n",
            " 0.506096   0.5060595  0.5061186  0.50607044 0.5060906  0.50610447\n",
            " 0.5060528  0.5060962  0.50610524 0.5060657  0.50605035 0.506103\n",
            " 0.5060692  0.5060809  0.5060438  0.5060655  0.5061073  0.5060792\n",
            " 0.506014   0.50611234 0.5059985  0.5060569  0.506091   0.5061137\n",
            " 0.50605613 0.5060196  0.506071   0.50607634 0.50610906 0.50600207\n",
            " 0.5060197  0.50611943 0.5060643  0.5060698  0.50607675 0.50613344\n",
            " 0.50605994 0.50608855 0.5060768  0.50607836 0.5061084  0.5060812\n",
            " 0.506092   0.50611746 0.50606745 0.50600857 0.50605106 0.50604016\n",
            " 0.50610703 0.50599444 0.5060711  0.5061091  0.5060581  0.5060637 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.2538289815420285e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5179738  0.51796937 0.51793957 0.51794255 0.5179233  0.51794666\n",
            " 0.5180123  0.51795715 0.51794547 0.5180373  0.5179324  0.5179108\n",
            " 0.51793975 0.51789737 0.51796055 0.5179813  0.5179247  0.517962\n",
            " 0.51798326 0.5179275  0.5179676  0.5179552  0.5179742  0.5179485\n",
            " 0.5179896  0.51790637 0.51800156 0.51794654 0.51798016 0.51794964\n",
            " 0.5179317  0.5179687  0.51794267 0.51797956 0.518018   0.5180091\n",
            " 0.51799    0.51793694 0.5179198  0.5179978  0.51795363 0.5179016\n",
            " 0.51801026 0.5179455  0.51791924 0.51796293 0.51795554 0.5179394\n",
            " 0.51791793 0.5180004  0.5179494  0.51802576 0.5179457  0.51794845\n",
            " 0.51789516 0.5180019  0.5179278  0.5178895  0.5179431  0.5179403 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.3859188988571987e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48606616 0.4860827  0.486095   0.4861064  0.48607945 0.48609203\n",
            " 0.48606515 0.48607704 0.48611936 0.48605406 0.48607588 0.48609507\n",
            " 0.48607218 0.48608324 0.4861014  0.4860847  0.48608968 0.48610142\n",
            " 0.48608884 0.48608074 0.48607874 0.48607257 0.48613474 0.48609084\n",
            " 0.48606876 0.48607594 0.48607108 0.4860664  0.48607075 0.48610213\n",
            " 0.48606893 0.48606977 0.48608583 0.48607817 0.48605177 0.48608992\n",
            " 0.48607767 0.48609114 0.48610246 0.48605293 0.48607326 0.48607212\n",
            " 0.486082   0.48610938 0.48606995 0.4860917  0.48609942 0.4860594\n",
            " 0.48609114 0.48604172 0.48607633 0.4860579  0.4860729  0.48607028\n",
            " 0.48608693 0.486066   0.48607013 0.4860683  0.48606348 0.4860798 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.6743764717830345e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48620132 0.48623848 0.48625803 0.48625308 0.48624897 0.48624894\n",
            " 0.48616084 0.48619905 0.4863152  0.48612633 0.4862651  0.4863182\n",
            " 0.48616782 0.4863436  0.48628154 0.48621514 0.4862155  0.48624828\n",
            " 0.4861665  0.48626718 0.48617244 0.48623496 0.48633406 0.4862397\n",
            " 0.48614278 0.48630095 0.48613706 0.4861973  0.48621863 0.48627037\n",
            " 0.48621103 0.48615336 0.4862522  0.48623884 0.48615122 0.4861318\n",
            " 0.4861405  0.48628944 0.4862259  0.48615998 0.48620287 0.48633507\n",
            " 0.48612642 0.48622823 0.4862237  0.4862428  0.4862936  0.48624113\n",
            " 0.48627558 0.4862196  0.48621708 0.48612934 0.48618227 0.48616514\n",
            " 0.48634142 0.48609942 0.48627138 0.48636186 0.48624197 0.48623192]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.22464795014821e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48190895 0.50606954 0.5179904  0.48607823 0.48620373]\n",
            " [0.48187828 0.5060304  0.5180136  0.48609075 0.48613685]\n",
            " [0.4818534  0.5060105  0.51800144 0.4860755  0.48613828]\n",
            " [0.4818683  0.506098   0.51799196 0.4860837  0.4861794 ]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48189586 0.5060477  0.5179585  0.48607576 0.4861541 ]\n",
            " [0.4819443  0.50605965 0.51796216 0.48608798 0.4862778 ]\n",
            " [0.4819834  0.5060934  0.51792556 0.48605993 0.48630264]\n",
            " [0.48187578 0.5060209  0.5179839  0.48608845 0.48612186]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48197627 0.5060719  0.5179483  0.48606306 0.4862455 ]\n",
            " [0.4819574  0.5060838  0.5179276  0.48607883 0.4862221 ]\n",
            " [0.48198295 0.506093   0.51791954 0.48607156 0.48624912]\n",
            " [0.48193938 0.5060452  0.5179555  0.48608696 0.48621565]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48191544 0.5061467  0.517954   0.4860851  0.48626894]\n",
            " [0.48193228 0.5060789  0.5179666  0.4860812  0.48629954]\n",
            " [0.48193732 0.5060417  0.51794946 0.48608568 0.48616114]\n",
            " [0.4819364  0.5060476  0.51796174 0.4860645  0.48619992]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48192245 0.5060638  0.5179598  0.4860768  0.48619795]\n",
            " [0.48200342 0.50612956 0.5178896  0.48609823 0.48634908]\n",
            " [0.48196143 0.50609285 0.51789725 0.48608136 0.4862752 ]\n",
            " [0.48191157 0.5060344  0.5179695  0.4860676  0.48618272]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48190895 0.48187828 0.4818534  0.4818683  0.48189586 0.4819443\n",
            " 0.4819834  0.48187578 0.48197627 0.4819574  0.48198295 0.48193938\n",
            " 0.48191544 0.48193228 0.48193732 0.4819364  0.48192245 0.48200342\n",
            " 0.48196143 0.48191157]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.050438292324543e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50606954 0.5060304  0.5060105  0.506098   0.5060477  0.50605965\n",
            " 0.5060934  0.5060209  0.5060719  0.5060838  0.506093   0.5060452\n",
            " 0.5061467  0.5060789  0.5060417  0.5060476  0.5060638  0.50612956\n",
            " 0.50609285 0.5060344 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.417460175114684e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5179904  0.5180136  0.51800144 0.51799196 0.5179585  0.51796216\n",
            " 0.51792556 0.5179839  0.5179483  0.5179276  0.51791954 0.5179555\n",
            " 0.517954   0.5179666  0.51794946 0.51796174 0.5179598  0.5178896\n",
            " 0.51789725 0.5179695 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.166218812111765e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48607823 0.48609075 0.4860755  0.4860837  0.48607576 0.48608798\n",
            " 0.48605993 0.48608845 0.48606306 0.48607883 0.48607156 0.48608696\n",
            " 0.4860851  0.4860812  0.48608568 0.4860645  0.4860768  0.48609823\n",
            " 0.48608136 0.4860676 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.739310371514875e-06\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48620373 0.48613685 0.48613828 0.4861794  0.4861541  0.4862778\n",
            " 0.48630264 0.48612186 0.4862455  0.4862221  0.48624912 0.48621565\n",
            " 0.48626894 0.48629954 0.48616114 0.48619992 0.48619795 0.48634908\n",
            " 0.4862752  0.48618272]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.136903539299965e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48190895 0.48187828 0.4818534  0.4818683  0.48189586 0.4819443\n",
            " 0.4819834  0.48187578 0.48197627 0.4819574  0.48198295 0.48193938\n",
            " 0.48191544 0.48193228 0.48193732 0.4819364  0.48192245 0.48200342\n",
            " 0.48196143 0.48191157]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.050438292324543e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50606954 0.5060304  0.5060105  0.506098   0.5060477  0.50605965\n",
            " 0.5060934  0.5060209  0.5060719  0.5060838  0.506093   0.5060452\n",
            " 0.5061467  0.5060789  0.5060417  0.5060476  0.5060638  0.50612956\n",
            " 0.50609285 0.5060344 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.417460175114684e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5179904  0.5180136  0.51800144 0.51799196 0.5179585  0.51796216\n",
            " 0.51792556 0.5179839  0.5179483  0.5179276  0.51791954 0.5179555\n",
            " 0.517954   0.5179666  0.51794946 0.51796174 0.5179598  0.5178896\n",
            " 0.51789725 0.5179695 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.166218812111765e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48607823 0.48609075 0.4860755  0.4860837  0.48607576 0.48608798\n",
            " 0.48605993 0.48608845 0.48606306 0.48607883 0.48607156 0.48608696\n",
            " 0.4860851  0.4860812  0.48608568 0.4860645  0.4860768  0.48609823\n",
            " 0.48608136 0.4860676 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.739310371514875e-06\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48620373 0.48613685 0.48613828 0.4861794  0.4861541  0.4862778\n",
            " 0.48630264 0.48612186 0.4862455  0.4862221  0.48624912 0.48621565\n",
            " 0.48626894 0.48629954 0.48616114 0.48619992 0.48619795 0.48634908\n",
            " 0.4862752  0.48618272]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.136903539299965e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48190895 0.48187828 0.4818534  0.4818683  0.48189586 0.4819443\n",
            " 0.4819834  0.48187578 0.48197627 0.4819574  0.48198295 0.48193938\n",
            " 0.48191544 0.48193228 0.48193732 0.4819364  0.48192245 0.48200342\n",
            " 0.48196143 0.48191157]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.050438292324543e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50606954 0.5060304  0.5060105  0.506098   0.5060477  0.50605965\n",
            " 0.5060934  0.5060209  0.5060719  0.5060838  0.506093   0.5060452\n",
            " 0.5061467  0.5060789  0.5060417  0.5060476  0.5060638  0.50612956\n",
            " 0.50609285 0.5060344 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.417460175114684e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5179904  0.5180136  0.51800144 0.51799196 0.5179585  0.51796216\n",
            " 0.51792556 0.5179839  0.5179483  0.5179276  0.51791954 0.5179555\n",
            " 0.517954   0.5179666  0.51794946 0.51796174 0.5179598  0.5178896\n",
            " 0.51789725 0.5179695 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.166218812111765e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48607823 0.48609075 0.4860755  0.4860837  0.48607576 0.48608798\n",
            " 0.48605993 0.48608845 0.48606306 0.48607883 0.48607156 0.48608696\n",
            " 0.4860851  0.4860812  0.48608568 0.4860645  0.4860768  0.48609823\n",
            " 0.48608136 0.4860676 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.739310371514875e-06\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48620373 0.48613685 0.48613828 0.4861794  0.4861541  0.4862778\n",
            " 0.48630264 0.48612186 0.4862455  0.4862221  0.48624912 0.48621565\n",
            " 0.48626894 0.48629954 0.48616114 0.48619992 0.48619795 0.48634908\n",
            " 0.4862752  0.48618272]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.136903539299965e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48190895 0.48187828 0.4818534  0.4818683  0.48189586 0.4819443\n",
            " 0.4819834  0.48187578 0.48197627 0.4819574  0.48198295 0.48193938\n",
            " 0.48191544 0.48193228 0.48193732 0.4819364  0.48192245 0.48200342\n",
            " 0.48196143 0.48191157]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.050438292324543e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50606954 0.5060304  0.5060105  0.506098   0.5060477  0.50605965\n",
            " 0.5060934  0.5060209  0.5060719  0.5060838  0.506093   0.5060452\n",
            " 0.5061467  0.5060789  0.5060417  0.5060476  0.5060638  0.50612956\n",
            " 0.50609285 0.5060344 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.417460175114684e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5179904  0.5180136  0.51800144 0.51799196 0.5179585  0.51796216\n",
            " 0.51792556 0.5179839  0.5179483  0.5179276  0.51791954 0.5179555\n",
            " 0.517954   0.5179666  0.51794946 0.51796174 0.5179598  0.5178896\n",
            " 0.51789725 0.5179695 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.166218812111765e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48607823 0.48609075 0.4860755  0.4860837  0.48607576 0.48608798\n",
            " 0.48605993 0.48608845 0.48606306 0.48607883 0.48607156 0.48608696\n",
            " 0.4860851  0.4860812  0.48608568 0.4860645  0.4860768  0.48609823\n",
            " 0.48608136 0.4860676 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.739310371514875e-06\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48620373 0.48613685 0.48613828 0.4861794  0.4861541  0.4862778\n",
            " 0.48630264 0.48612186 0.4862455  0.4862221  0.48624912 0.48621565\n",
            " 0.48626894 0.48629954 0.48616114 0.48619992 0.48619795 0.48634908\n",
            " 0.4862752  0.48618272]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.136903539299965e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4819655  0.5060861  0.51795274 0.48609546 0.48622686]\n",
            " [0.4819758  0.5060925  0.51791906 0.48606685 0.4862677 ]\n",
            " [0.4819743  0.5061027  0.5179235  0.48606804 0.486273  ]\n",
            " [0.48192787 0.50606686 0.51793975 0.48608682 0.4862043 ]\n",
            " [0.48199585 0.50610507 0.51791114 0.48604968 0.4862952 ]\n",
            " [0.48189676 0.506045   0.5180099  0.4860807  0.48616895]\n",
            " [0.48188877 0.5060443  0.51797795 0.48608974 0.48617995]\n",
            " [0.48188955 0.5060159  0.51796556 0.48607656 0.48614872]\n",
            " [0.48190746 0.50603354 0.5179863  0.48610282 0.48615557]\n",
            " [0.48191044 0.50608206 0.51794714 0.48609212 0.48626417]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48189044 0.50607765 0.5179778  0.48609456 0.486242  ]\n",
            " [0.481913   0.5060573  0.51798046 0.48608986 0.48619145]\n",
            " [0.48193684 0.50605536 0.5179579  0.4860935  0.48622456]\n",
            " [0.48198578 0.5061075  0.5179202  0.4861141  0.48632973]\n",
            " [0.48191732 0.5060617  0.517948   0.4860842  0.48619825]\n",
            " [0.4819628  0.5060691  0.51793796 0.48607555 0.48625466]\n",
            " [0.4819749  0.5060909  0.5179323  0.4860901  0.4863157 ]\n",
            " [0.48190942 0.50601476 0.5179721  0.48606595 0.48614022]\n",
            " [0.48195374 0.50611037 0.51792705 0.4860816  0.48624334]\n",
            " [0.4818776  0.50609744 0.51797736 0.4860722  0.48622158]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4819655  0.4819758  0.4819743  0.48192787 0.48199585 0.48189676\n",
            " 0.48188877 0.48188955 0.48190746 0.48191044 0.48189044 0.481913\n",
            " 0.48193684 0.48198578 0.48191732 0.4819628  0.4819749  0.48190942\n",
            " 0.48195374 0.4818776 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.6636927688959986e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5060861  0.5060925  0.5061027  0.50606686 0.50610507 0.506045\n",
            " 0.5060443  0.5060159  0.50603354 0.50608206 0.50607765 0.5060573\n",
            " 0.50605536 0.5061075  0.5060617  0.5060691  0.5060909  0.50601476\n",
            " 0.50611037 0.50609744]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.8746128009515814e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51795274 0.51791906 0.5179235  0.51793975 0.51791114 0.5180099\n",
            " 0.51797795 0.51796556 0.5179863  0.51794714 0.5179778  0.51798046\n",
            " 0.5179579  0.5179202  0.517948   0.51793796 0.5179323  0.5179721\n",
            " 0.51792705 0.51797736]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.6355352019891143e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48609546 0.48606685 0.48606804 0.48608682 0.48604968 0.4860807\n",
            " 0.48608974 0.48607656 0.48610282 0.48609212 0.48609456 0.48608986\n",
            " 0.4860935  0.4861141  0.4860842  0.48607555 0.4860901  0.48606595\n",
            " 0.4860816  0.4860722 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.432171484339051e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48622686 0.4862677  0.486273   0.4862043  0.4862952  0.48616895\n",
            " 0.48617995 0.48614872 0.48615557 0.48626417 0.486242   0.48619145\n",
            " 0.48622456 0.48632973 0.48619825 0.48625466 0.4863157  0.48614022\n",
            " 0.48624334 0.48622158]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.3134484915062785e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4819655  0.4819758  0.4819743  0.48192787 0.48199585 0.48189676\n",
            " 0.48188877 0.48188955 0.48190746 0.48191044 0.48189044 0.481913\n",
            " 0.48193684 0.48198578 0.48191732 0.4819628  0.4819749  0.48190942\n",
            " 0.48195374 0.4818776 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.6636927688959986e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5060861  0.5060925  0.5061027  0.50606686 0.50610507 0.506045\n",
            " 0.5060443  0.5060159  0.50603354 0.50608206 0.50607765 0.5060573\n",
            " 0.50605536 0.5061075  0.5060617  0.5060691  0.5060909  0.50601476\n",
            " 0.50611037 0.50609744]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.8746128009515814e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51795274 0.51791906 0.5179235  0.51793975 0.51791114 0.5180099\n",
            " 0.51797795 0.51796556 0.5179863  0.51794714 0.5179778  0.51798046\n",
            " 0.5179579  0.5179202  0.517948   0.51793796 0.5179323  0.5179721\n",
            " 0.51792705 0.51797736]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.6355352019891143e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48609546 0.48606685 0.48606804 0.48608682 0.48604968 0.4860807\n",
            " 0.48608974 0.48607656 0.48610282 0.48609212 0.48609456 0.48608986\n",
            " 0.4860935  0.4861141  0.4860842  0.48607555 0.4860901  0.48606595\n",
            " 0.4860816  0.4860722 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.432171484339051e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48622686 0.4862677  0.486273   0.4862043  0.4862952  0.48616895\n",
            " 0.48617995 0.48614872 0.48615557 0.48626417 0.486242   0.48619145\n",
            " 0.48622456 0.48632973 0.48619825 0.48625466 0.4863157  0.48614022\n",
            " 0.48624334 0.48622158]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.3134484915062785e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4819655  0.4819758  0.4819743  0.48192787 0.48199585 0.48189676\n",
            " 0.48188877 0.48188955 0.48190746 0.48191044 0.48189044 0.481913\n",
            " 0.48193684 0.48198578 0.48191732 0.4819628  0.4819749  0.48190942\n",
            " 0.48195374 0.4818776 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.6636927688959986e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5060861  0.5060925  0.5061027  0.50606686 0.50610507 0.506045\n",
            " 0.5060443  0.5060159  0.50603354 0.50608206 0.50607765 0.5060573\n",
            " 0.50605536 0.5061075  0.5060617  0.5060691  0.5060909  0.50601476\n",
            " 0.50611037 0.50609744]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.8746128009515814e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51795274 0.51791906 0.5179235  0.51793975 0.51791114 0.5180099\n",
            " 0.51797795 0.51796556 0.5179863  0.51794714 0.5179778  0.51798046\n",
            " 0.5179579  0.5179202  0.517948   0.51793796 0.5179323  0.5179721\n",
            " 0.51792705 0.51797736]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.6355352019891143e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48609546 0.48606685 0.48606804 0.48608682 0.48604968 0.4860807\n",
            " 0.48608974 0.48607656 0.48610282 0.48609212 0.48609456 0.48608986\n",
            " 0.4860935  0.4861141  0.4860842  0.48607555 0.4860901  0.48606595\n",
            " 0.4860816  0.4860722 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.432171484339051e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48622686 0.4862677  0.486273   0.4862043  0.4862952  0.48616895\n",
            " 0.48617995 0.48614872 0.48615557 0.48626417 0.486242   0.48619145\n",
            " 0.48622456 0.48632973 0.48619825 0.48625466 0.4863157  0.48614022\n",
            " 0.48624334 0.48622158]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.3134484915062785e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4819655  0.4819758  0.4819743  0.48192787 0.48199585 0.48189676\n",
            " 0.48188877 0.48188955 0.48190746 0.48191044 0.48189044 0.481913\n",
            " 0.48193684 0.48198578 0.48191732 0.4819628  0.4819749  0.48190942\n",
            " 0.48195374 0.4818776 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.6636927688959986e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5060861  0.5060925  0.5061027  0.50606686 0.50610507 0.506045\n",
            " 0.5060443  0.5060159  0.50603354 0.50608206 0.50607765 0.5060573\n",
            " 0.50605536 0.5061075  0.5060617  0.5060691  0.5060909  0.50601476\n",
            " 0.50611037 0.50609744]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 2.8746128009515814e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51795274 0.51791906 0.5179235  0.51793975 0.51791114 0.5180099\n",
            " 0.51797795 0.51796556 0.5179863  0.51794714 0.5179778  0.51798046\n",
            " 0.5179579  0.5179202  0.517948   0.51793796 0.5179323  0.5179721\n",
            " 0.51792705 0.51797736]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.6355352019891143e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48609546 0.48606685 0.48606804 0.48608682 0.48604968 0.4860807\n",
            " 0.48608974 0.48607656 0.48610282 0.48609212 0.48609456 0.48608986\n",
            " 0.4860935  0.4861141  0.4860842  0.48607555 0.4860901  0.48606595\n",
            " 0.4860816  0.4860722 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.432171484339051e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48622686 0.4862677  0.486273   0.4862043  0.4862952  0.48616895\n",
            " 0.48617995 0.48614872 0.48615557 0.48626417 0.486242   0.48619145\n",
            " 0.48622456 0.48632973 0.48619825 0.48625466 0.4863157  0.48614022\n",
            " 0.48624334 0.48622158]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.3134484915062785e-05\n",
            "Epoch 5/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819359  0.50606084 0.5179738  0.48606616 0.48620132]\n",
            " [0.4818794  0.5061135  0.51796937 0.4860827  0.48623848]\n",
            " [0.48196504 0.50608665 0.51793957 0.486095   0.48625803]\n",
            " [0.4819488  0.50610006 0.51794255 0.4861064  0.48625308]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48200008 0.5061232  0.5179588  0.48612085 0.4862972 ]\n",
            " [0.48198712 0.50607353 0.517982   0.48613334 0.48629707]\n",
            " [0.48182496 0.5061251  0.5180471  0.48610565 0.48620796]\n",
            " [0.48199725 0.5060889  0.5179925  0.48611802 0.4862468 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48200414 0.5061606  0.51798713 0.48615077 0.4864202 ]\n",
            " [0.48186114 0.5061111  0.5180782  0.48608416 0.4862286 ]\n",
            " [0.48199746 0.50613266 0.51797426 0.4861069  0.48636973]\n",
            " [0.4819824  0.50614685 0.51795256 0.48612636 0.48642367]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4819767  0.5061132  0.51800984 0.4861317  0.48630846]\n",
            " [0.48199615 0.5061577  0.5179685  0.48614347 0.4864867 ]\n",
            " [0.4820063  0.5061663  0.51803154 0.48616084 0.48642284]\n",
            " [0.48197627 0.5061264  0.51805186 0.48614404 0.48635596]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48204866 0.5061264  0.5180194  0.4861601  0.48641446]\n",
            " [0.48203182 0.5061798  0.51805645 0.48617274 0.48644805]\n",
            " [0.48199472 0.5061449  0.5180774  0.48615885 0.4863639 ]\n",
            " [0.4820402  0.50615764 0.5180224  0.48615178 0.48646736]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48202717 0.50611866 0.51805246 0.48614383 0.48641396]\n",
            " [0.48202583 0.506141   0.51804054 0.48613805 0.4864776 ]\n",
            " [0.4820956  0.5061836  0.51806045 0.4862004  0.48657876]\n",
            " [0.4820526  0.5061546  0.51803374 0.48615655 0.48648334]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4820328  0.50613034 0.51810086 0.48617366 0.48641774]\n",
            " [0.48214942 0.5062319  0.51801896 0.4861839  0.48658276]\n",
            " [0.48200992 0.5061145  0.5181124  0.48617557 0.48641118]\n",
            " [0.48205194 0.50617445 0.5180581  0.4861724  0.48647475]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48202747 0.506184   0.5180727  0.48619235 0.48651996]\n",
            " [0.4820704  0.50620854 0.5180432  0.48622587 0.4865756 ]\n",
            " [0.48205653 0.5061501  0.51802415 0.48619273 0.48651597]\n",
            " [0.48203    0.5061118  0.5180611  0.48619115 0.48645398]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4820823  0.50617534 0.5180453  0.48622373 0.48657358]\n",
            " [0.48202848 0.50618076 0.51808214 0.48621616 0.48656008]\n",
            " [0.48193067 0.50621045 0.51811934 0.48618597 0.48646554]\n",
            " [0.48200864 0.50610435 0.5181106  0.4862258  0.48644856]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48200905 0.50609976 0.518085   0.4862067  0.48645133]\n",
            " [0.4821023  0.50620246 0.5180335  0.48622292 0.48660636]\n",
            " [0.4820934  0.50614583 0.51801574 0.48623294 0.4865404 ]\n",
            " [0.48197818 0.50614953 0.5180929  0.48618123 0.4864702 ]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48212436 0.506224   0.5181024  0.48625785 0.4865925 ]\n",
            " [0.48223835 0.506283   0.5180527  0.48625892 0.48673052]\n",
            " [0.48199785 0.5062036  0.51815724 0.4862623  0.48650807]\n",
            " [0.4821238  0.50623584 0.5180953  0.48629367 0.4866181 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48214218 0.5062502  0.51807916 0.48629573 0.48663694]\n",
            " [0.4821208  0.50625175 0.51812226 0.48631662 0.48665425]\n",
            " [0.48211515 0.5062812  0.5181159  0.48632267 0.48670334]\n",
            " [0.4822033  0.5062541  0.51810044 0.486284   0.48665294]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48220515 0.50629085 0.51811355 0.4863557  0.48672912]\n",
            " [0.48205328 0.50631225 0.5181941  0.48630038 0.48666453]\n",
            " [0.48216563 0.50626385 0.5181446  0.4863378  0.48666626]\n",
            " [0.4820454  0.5062011  0.51821804 0.48631477 0.4865709 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48213616 0.50627005 0.51816285 0.486365   0.48665234]\n",
            " [0.48212168 0.5062582  0.51816577 0.48636115 0.48663378]\n",
            " [0.48214382 0.5063297  0.51811385 0.4863837  0.48681948]\n",
            " [0.4820586  0.5062096  0.51821643 0.48635307 0.48656183]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48216256 0.506263   0.5181269  0.48633638 0.48675546]\n",
            " [0.48220062 0.5063031  0.5180896  0.48633596 0.48684764]\n",
            " [0.48215717 0.506249   0.51814234 0.48632768 0.4867223 ]\n",
            " [0.48216543 0.50625545 0.51813906 0.4863455  0.48671398]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48216975 0.506292   0.51820207 0.48636883 0.4867363 ]\n",
            " [0.4821125  0.50634426 0.5181977  0.4863834  0.48677123]\n",
            " [0.48219946 0.50632054 0.5181699  0.48639938 0.48679653]\n",
            " [0.48218337 0.5063328  0.51817226 0.48641056 0.48679125]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48220792 0.5063271  0.51815337 0.48638344 0.48678723]\n",
            " [0.48219573 0.50627685 0.5181757  0.48639625 0.48678637]\n",
            " [0.48202887 0.506322   0.5182382  0.48636028 0.48668507]\n",
            " [0.4822041  0.5062904  0.5181863  0.48637903 0.4867343 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48218673 0.5063518  0.51817566 0.48642397 0.4868533 ]\n",
            " [0.48204008 0.50629675 0.51826334 0.4863493  0.48665056]\n",
            " [0.48217824 0.50632405 0.51816356 0.48637864 0.48680156]\n",
            " [0.482164   0.5063377  0.51814    0.48639992 0.48685902]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4821446  0.50628334 0.5181672  0.4863741  0.48670143]\n",
            " [0.48216483 0.50633043 0.51812726 0.48638943 0.48688665]\n",
            " [0.48217362 0.5063384  0.51819074 0.4864036  0.48681712]\n",
            " [0.48214358 0.5062974  0.5182103  0.48638612 0.48674893]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48217756 0.5062811  0.51815337 0.48639134 0.48675016]\n",
            " [0.48216254 0.5063355  0.5181902  0.4864046  0.4867841 ]\n",
            " [0.48212305 0.5062978  0.51821095 0.48638722 0.48669556]\n",
            " [0.4821703  0.50631374 0.5181565  0.48638475 0.48680532]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48215303 0.50627434 0.51819533 0.48638025 0.4867059 ]\n",
            " [0.482152   0.5062979  0.5181842  0.48637545 0.48677072]\n",
            " [0.4822219  0.50634265 0.51820517 0.48644048 0.48687503]\n",
            " [0.48217943 0.50631213 0.51817715 0.48639572 0.48677847]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48212767 0.50624263 0.51821697 0.4863682  0.48667288]\n",
            " [0.48224598 0.5063473  0.5181366  0.48638338 0.4868446 ]\n",
            " [0.48210484 0.5062265  0.5182281  0.48636958 0.48666567]\n",
            " [0.4821475  0.506288   0.51817465 0.48636886 0.4867325 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48214328 0.5063211  0.5182079  0.48637027 0.4867497 ]\n",
            " [0.48218688 0.50634784 0.5181801  0.486406   0.48680818]\n",
            " [0.4821736  0.5062884  0.5181598  0.4863729  0.48674875]\n",
            " [0.48214597 0.5062485  0.518196   0.48636895 0.48668367]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48218653 0.50630337 0.518172   0.48638868 0.48678824]\n",
            " [0.48213318 0.5063089  0.51820815 0.48638117 0.4867748 ]\n",
            " [0.4820333  0.5063351  0.5182437  0.48634693 0.48667532]\n",
            " [0.48211253 0.50623024 0.51823545 0.48638868 0.48666027]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4821281  0.5062489  0.518217   0.48637792 0.48667142]\n",
            " [0.4822219  0.5063552  0.51816756 0.4863969  0.48683032]\n",
            " [0.48221266 0.5062973  0.51814926 0.48640594 0.48676303]\n",
            " [0.4820965  0.5062986  0.51822484 0.4863517  0.48668963]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4821703  0.5063085  0.5181817  0.48637635 0.4867384 ]\n",
            " [0.4822845  0.5063691  0.5181333  0.4863789  0.4868785 ]\n",
            " [0.48204353 0.50628644 0.5182356  0.4863779  0.48665068]\n",
            " [0.48216993 0.5063206  0.5181751  0.48641226 0.48676413]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48218787 0.5063096  0.5181484  0.48637435 0.48676232]\n",
            " [0.4821665  0.5063112  0.51819134 0.4863949  0.4867788 ]\n",
            " [0.48215988 0.50634056 0.51818526 0.48640049 0.4868273 ]\n",
            " [0.48224884 0.5063137  0.5181699  0.48636255 0.48677796]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48223543 0.506326   0.5181478  0.48639643 0.4868155 ]\n",
            " [0.4820835  0.506347   0.5182282  0.48634043 0.48674956]\n",
            " [0.48219582 0.50629866 0.5181787  0.48637825 0.48675206]\n",
            " [0.4820755  0.5062355  0.5182517  0.48635456 0.48665527]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48215732 0.5062819  0.51817393 0.48637483 0.48671654]\n",
            " [0.4821428  0.5062699  0.5181768  0.48637092 0.48669782]\n",
            " [0.48216483 0.50634134 0.518125   0.48639333 0.48688453]\n",
            " [0.48207933 0.50622123 0.5182272  0.4863626  0.4866247 ]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48219445 0.50630486 0.51815724 0.48637554 0.4868122 ]\n",
            " [0.48223224 0.5063451  0.51811993 0.48637506 0.48690423]\n",
            " [0.48218837 0.5062903  0.5181726  0.48636624 0.48677817]\n",
            " [0.4821969  0.5062968  0.5181693  0.4863843  0.4867701 ]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48216975 0.4821125  0.48219946 0.48218337 0.48220792 0.48219573\n",
            " 0.48202887 0.4822041  0.48218673 0.48204008 0.48217824 0.482164\n",
            " 0.4821446  0.48216483 0.48217362 0.48214358 0.48217756 0.48216254\n",
            " 0.48212305 0.4821703  0.48215303 0.482152   0.4822219  0.48217943\n",
            " 0.48212767 0.48224598 0.48210484 0.4821475  0.48214328 0.48218688\n",
            " 0.4821736  0.48214597 0.48218653 0.48213318 0.4820333  0.48211253\n",
            " 0.4821281  0.4822219  0.48221266 0.4820965  0.4821703  0.4822845\n",
            " 0.48204353 0.48216993 0.48218787 0.4821665  0.48215988 0.48224884\n",
            " 0.48223543 0.4820835  0.48219582 0.4820755  0.48215732 0.4821428\n",
            " 0.48216483 0.48207933 0.48219445 0.48223224 0.48218837 0.4821969 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.278650132822804e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.506292   0.50634426 0.50632054 0.5063328  0.5063271  0.50627685\n",
            " 0.506322   0.5062904  0.5063518  0.50629675 0.50632405 0.5063377\n",
            " 0.50628334 0.50633043 0.5063384  0.5062974  0.5062811  0.5063355\n",
            " 0.5062978  0.50631374 0.50627434 0.5062979  0.50634265 0.50631213\n",
            " 0.50624263 0.5063473  0.5062265  0.506288   0.5063211  0.50634784\n",
            " 0.5062884  0.5062485  0.50630337 0.5063089  0.5063351  0.50623024\n",
            " 0.5062489  0.5063552  0.5062973  0.5062986  0.5063085  0.5063691\n",
            " 0.50628644 0.5063206  0.5063096  0.5063112  0.50634056 0.5063137\n",
            " 0.506326   0.506347   0.50629866 0.5062355  0.5062819  0.5062699\n",
            " 0.50634134 0.50622123 0.50630486 0.5063451  0.5062903  0.5062968 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.4091684938175604e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51820207 0.5181977  0.5181699  0.51817226 0.51815337 0.5181757\n",
            " 0.5182382  0.5181863  0.51817566 0.51826334 0.51816356 0.51814\n",
            " 0.5181672  0.51812726 0.51819074 0.5182103  0.51815337 0.5181902\n",
            " 0.51821095 0.5181565  0.51819533 0.5181842  0.51820517 0.51817715\n",
            " 0.51821697 0.5181366  0.5182281  0.51817465 0.5182079  0.5181801\n",
            " 0.5181598  0.518196   0.518172   0.51820815 0.5182437  0.51823545\n",
            " 0.518217   0.51816756 0.51814926 0.51822484 0.5181817  0.5181333\n",
            " 0.5182356  0.5181751  0.5181484  0.51819134 0.51818526 0.5181699\n",
            " 0.5181478  0.5182282  0.5181787  0.5182517  0.51817393 0.5181768\n",
            " 0.518125   0.5182272  0.51815724 0.51811993 0.5181726  0.5181693 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.267310603405349e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48636883 0.4863834  0.48639938 0.48641056 0.48638344 0.48639625\n",
            " 0.48636028 0.48637903 0.48642397 0.4863493  0.48637864 0.48639992\n",
            " 0.4863741  0.48638943 0.4864036  0.48638612 0.48639134 0.4864046\n",
            " 0.48638722 0.48638475 0.48638025 0.48637545 0.48644048 0.48639572\n",
            " 0.4863682  0.48638338 0.48636958 0.48636886 0.48637027 0.486406\n",
            " 0.4863729  0.48636895 0.48638868 0.48638117 0.48634693 0.48638868\n",
            " 0.48637792 0.4863969  0.48640594 0.4863517  0.48637635 0.4863789\n",
            " 0.4863779  0.48641226 0.48637435 0.4863949  0.48640049 0.48636255\n",
            " 0.48639643 0.48634043 0.48637825 0.48635456 0.48637483 0.48637092\n",
            " 0.48639333 0.4863626  0.48637554 0.48637506 0.48636624 0.4863843 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.8348977391724475e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4867363  0.48677123 0.48679653 0.48679125 0.48678723 0.48678637\n",
            " 0.48668507 0.4867343  0.4868533  0.48665056 0.48680156 0.48685902\n",
            " 0.48670143 0.48688665 0.48681712 0.48674893 0.48675016 0.4867841\n",
            " 0.48669556 0.48680532 0.4867059  0.48677072 0.48687503 0.48677847\n",
            " 0.48667288 0.4868446  0.48666567 0.4867325  0.4867497  0.48680818\n",
            " 0.48674875 0.48668367 0.48678824 0.4867748  0.48667532 0.48666027\n",
            " 0.48667142 0.48683032 0.48676303 0.48668963 0.4867384  0.4868785\n",
            " 0.48665068 0.48676413 0.48676232 0.4867788  0.4868273  0.48677796\n",
            " 0.4868155  0.48674956 0.48675206 0.48665527 0.48671654 0.48669782\n",
            " 0.48688453 0.4866247  0.4868122  0.48690423 0.48677817 0.4867701 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.674815813312307e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48216975 0.4821125  0.48219946 0.48218337 0.48220792 0.48219573\n",
            " 0.48202887 0.4822041  0.48218673 0.48204008 0.48217824 0.482164\n",
            " 0.4821446  0.48216483 0.48217362 0.48214358 0.48217756 0.48216254\n",
            " 0.48212305 0.4821703  0.48215303 0.482152   0.4822219  0.48217943\n",
            " 0.48212767 0.48224598 0.48210484 0.4821475  0.48214328 0.48218688\n",
            " 0.4821736  0.48214597 0.48218653 0.48213318 0.4820333  0.48211253\n",
            " 0.4821281  0.4822219  0.48221266 0.4820965  0.4821703  0.4822845\n",
            " 0.48204353 0.48216993 0.48218787 0.4821665  0.48215988 0.48224884\n",
            " 0.48223543 0.4820835  0.48219582 0.4820755  0.48215732 0.4821428\n",
            " 0.48216483 0.48207933 0.48219445 0.48223224 0.48218837 0.4821969 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.278650132822804e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.506292   0.50634426 0.50632054 0.5063328  0.5063271  0.50627685\n",
            " 0.506322   0.5062904  0.5063518  0.50629675 0.50632405 0.5063377\n",
            " 0.50628334 0.50633043 0.5063384  0.5062974  0.5062811  0.5063355\n",
            " 0.5062978  0.50631374 0.50627434 0.5062979  0.50634265 0.50631213\n",
            " 0.50624263 0.5063473  0.5062265  0.506288   0.5063211  0.50634784\n",
            " 0.5062884  0.5062485  0.50630337 0.5063089  0.5063351  0.50623024\n",
            " 0.5062489  0.5063552  0.5062973  0.5062986  0.5063085  0.5063691\n",
            " 0.50628644 0.5063206  0.5063096  0.5063112  0.50634056 0.5063137\n",
            " 0.506326   0.506347   0.50629866 0.5062355  0.5062819  0.5062699\n",
            " 0.50634134 0.50622123 0.50630486 0.5063451  0.5062903  0.5062968 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.4091684938175604e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51820207 0.5181977  0.5181699  0.51817226 0.51815337 0.5181757\n",
            " 0.5182382  0.5181863  0.51817566 0.51826334 0.51816356 0.51814\n",
            " 0.5181672  0.51812726 0.51819074 0.5182103  0.51815337 0.5181902\n",
            " 0.51821095 0.5181565  0.51819533 0.5181842  0.51820517 0.51817715\n",
            " 0.51821697 0.5181366  0.5182281  0.51817465 0.5182079  0.5181801\n",
            " 0.5181598  0.518196   0.518172   0.51820815 0.5182437  0.51823545\n",
            " 0.518217   0.51816756 0.51814926 0.51822484 0.5181817  0.5181333\n",
            " 0.5182356  0.5181751  0.5181484  0.51819134 0.51818526 0.5181699\n",
            " 0.5181478  0.5182282  0.5181787  0.5182517  0.51817393 0.5181768\n",
            " 0.518125   0.5182272  0.51815724 0.51811993 0.5181726  0.5181693 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.267310603405349e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48636883 0.4863834  0.48639938 0.48641056 0.48638344 0.48639625\n",
            " 0.48636028 0.48637903 0.48642397 0.4863493  0.48637864 0.48639992\n",
            " 0.4863741  0.48638943 0.4864036  0.48638612 0.48639134 0.4864046\n",
            " 0.48638722 0.48638475 0.48638025 0.48637545 0.48644048 0.48639572\n",
            " 0.4863682  0.48638338 0.48636958 0.48636886 0.48637027 0.486406\n",
            " 0.4863729  0.48636895 0.48638868 0.48638117 0.48634693 0.48638868\n",
            " 0.48637792 0.4863969  0.48640594 0.4863517  0.48637635 0.4863789\n",
            " 0.4863779  0.48641226 0.48637435 0.4863949  0.48640049 0.48636255\n",
            " 0.48639643 0.48634043 0.48637825 0.48635456 0.48637483 0.48637092\n",
            " 0.48639333 0.4863626  0.48637554 0.48637506 0.48636624 0.4863843 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.8348977391724475e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4867363  0.48677123 0.48679653 0.48679125 0.48678723 0.48678637\n",
            " 0.48668507 0.4867343  0.4868533  0.48665056 0.48680156 0.48685902\n",
            " 0.48670143 0.48688665 0.48681712 0.48674893 0.48675016 0.4867841\n",
            " 0.48669556 0.48680532 0.4867059  0.48677072 0.48687503 0.48677847\n",
            " 0.48667288 0.4868446  0.48666567 0.4867325  0.4867497  0.48680818\n",
            " 0.48674875 0.48668367 0.48678824 0.4867748  0.48667532 0.48666027\n",
            " 0.48667142 0.48683032 0.48676303 0.48668963 0.4867384  0.4868785\n",
            " 0.48665068 0.48676413 0.48676232 0.4867788  0.4868273  0.48677796\n",
            " 0.4868155  0.48674956 0.48675206 0.48665527 0.48671654 0.48669782\n",
            " 0.48688453 0.4866247  0.4868122  0.48690423 0.48677817 0.4867701 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.674815813312307e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48216975 0.4821125  0.48219946 0.48218337 0.48220792 0.48219573\n",
            " 0.48202887 0.4822041  0.48218673 0.48204008 0.48217824 0.482164\n",
            " 0.4821446  0.48216483 0.48217362 0.48214358 0.48217756 0.48216254\n",
            " 0.48212305 0.4821703  0.48215303 0.482152   0.4822219  0.48217943\n",
            " 0.48212767 0.48224598 0.48210484 0.4821475  0.48214328 0.48218688\n",
            " 0.4821736  0.48214597 0.48218653 0.48213318 0.4820333  0.48211253\n",
            " 0.4821281  0.4822219  0.48221266 0.4820965  0.4821703  0.4822845\n",
            " 0.48204353 0.48216993 0.48218787 0.4821665  0.48215988 0.48224884\n",
            " 0.48223543 0.4820835  0.48219582 0.4820755  0.48215732 0.4821428\n",
            " 0.48216483 0.48207933 0.48219445 0.48223224 0.48218837 0.4821969 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.278650132822804e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.506292   0.50634426 0.50632054 0.5063328  0.5063271  0.50627685\n",
            " 0.506322   0.5062904  0.5063518  0.50629675 0.50632405 0.5063377\n",
            " 0.50628334 0.50633043 0.5063384  0.5062974  0.5062811  0.5063355\n",
            " 0.5062978  0.50631374 0.50627434 0.5062979  0.50634265 0.50631213\n",
            " 0.50624263 0.5063473  0.5062265  0.506288   0.5063211  0.50634784\n",
            " 0.5062884  0.5062485  0.50630337 0.5063089  0.5063351  0.50623024\n",
            " 0.5062489  0.5063552  0.5062973  0.5062986  0.5063085  0.5063691\n",
            " 0.50628644 0.5063206  0.5063096  0.5063112  0.50634056 0.5063137\n",
            " 0.506326   0.506347   0.50629866 0.5062355  0.5062819  0.5062699\n",
            " 0.50634134 0.50622123 0.50630486 0.5063451  0.5062903  0.5062968 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.4091684938175604e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51820207 0.5181977  0.5181699  0.51817226 0.51815337 0.5181757\n",
            " 0.5182382  0.5181863  0.51817566 0.51826334 0.51816356 0.51814\n",
            " 0.5181672  0.51812726 0.51819074 0.5182103  0.51815337 0.5181902\n",
            " 0.51821095 0.5181565  0.51819533 0.5181842  0.51820517 0.51817715\n",
            " 0.51821697 0.5181366  0.5182281  0.51817465 0.5182079  0.5181801\n",
            " 0.5181598  0.518196   0.518172   0.51820815 0.5182437  0.51823545\n",
            " 0.518217   0.51816756 0.51814926 0.51822484 0.5181817  0.5181333\n",
            " 0.5182356  0.5181751  0.5181484  0.51819134 0.51818526 0.5181699\n",
            " 0.5181478  0.5182282  0.5181787  0.5182517  0.51817393 0.5181768\n",
            " 0.518125   0.5182272  0.51815724 0.51811993 0.5181726  0.5181693 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.267310603405349e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48636883 0.4863834  0.48639938 0.48641056 0.48638344 0.48639625\n",
            " 0.48636028 0.48637903 0.48642397 0.4863493  0.48637864 0.48639992\n",
            " 0.4863741  0.48638943 0.4864036  0.48638612 0.48639134 0.4864046\n",
            " 0.48638722 0.48638475 0.48638025 0.48637545 0.48644048 0.48639572\n",
            " 0.4863682  0.48638338 0.48636958 0.48636886 0.48637027 0.486406\n",
            " 0.4863729  0.48636895 0.48638868 0.48638117 0.48634693 0.48638868\n",
            " 0.48637792 0.4863969  0.48640594 0.4863517  0.48637635 0.4863789\n",
            " 0.4863779  0.48641226 0.48637435 0.4863949  0.48640049 0.48636255\n",
            " 0.48639643 0.48634043 0.48637825 0.48635456 0.48637483 0.48637092\n",
            " 0.48639333 0.4863626  0.48637554 0.48637506 0.48636624 0.4863843 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.8348977391724475e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4867363  0.48677123 0.48679653 0.48679125 0.48678723 0.48678637\n",
            " 0.48668507 0.4867343  0.4868533  0.48665056 0.48680156 0.48685902\n",
            " 0.48670143 0.48688665 0.48681712 0.48674893 0.48675016 0.4867841\n",
            " 0.48669556 0.48680532 0.4867059  0.48677072 0.48687503 0.48677847\n",
            " 0.48667288 0.4868446  0.48666567 0.4867325  0.4867497  0.48680818\n",
            " 0.48674875 0.48668367 0.48678824 0.4867748  0.48667532 0.48666027\n",
            " 0.48667142 0.48683032 0.48676303 0.48668963 0.4867384  0.4868785\n",
            " 0.48665068 0.48676413 0.48676232 0.4867788  0.4868273  0.48677796\n",
            " 0.4868155  0.48674956 0.48675206 0.48665527 0.48671654 0.48669782\n",
            " 0.48688453 0.4866247  0.4868122  0.48690423 0.48677817 0.4867701 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.674815813312307e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48216975 0.4821125  0.48219946 0.48218337 0.48220792 0.48219573\n",
            " 0.48202887 0.4822041  0.48218673 0.48204008 0.48217824 0.482164\n",
            " 0.4821446  0.48216483 0.48217362 0.48214358 0.48217756 0.48216254\n",
            " 0.48212305 0.4821703  0.48215303 0.482152   0.4822219  0.48217943\n",
            " 0.48212767 0.48224598 0.48210484 0.4821475  0.48214328 0.48218688\n",
            " 0.4821736  0.48214597 0.48218653 0.48213318 0.4820333  0.48211253\n",
            " 0.4821281  0.4822219  0.48221266 0.4820965  0.4821703  0.4822845\n",
            " 0.48204353 0.48216993 0.48218787 0.4821665  0.48215988 0.48224884\n",
            " 0.48223543 0.4820835  0.48219582 0.4820755  0.48215732 0.4821428\n",
            " 0.48216483 0.48207933 0.48219445 0.48223224 0.48218837 0.4821969 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.278650132822804e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.506292   0.50634426 0.50632054 0.5063328  0.5063271  0.50627685\n",
            " 0.506322   0.5062904  0.5063518  0.50629675 0.50632405 0.5063377\n",
            " 0.50628334 0.50633043 0.5063384  0.5062974  0.5062811  0.5063355\n",
            " 0.5062978  0.50631374 0.50627434 0.5062979  0.50634265 0.50631213\n",
            " 0.50624263 0.5063473  0.5062265  0.506288   0.5063211  0.50634784\n",
            " 0.5062884  0.5062485  0.50630337 0.5063089  0.5063351  0.50623024\n",
            " 0.5062489  0.5063552  0.5062973  0.5062986  0.5063085  0.5063691\n",
            " 0.50628644 0.5063206  0.5063096  0.5063112  0.50634056 0.5063137\n",
            " 0.506326   0.506347   0.50629866 0.5062355  0.5062819  0.5062699\n",
            " 0.50634134 0.50622123 0.50630486 0.5063451  0.5062903  0.5062968 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.4091684938175604e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51820207 0.5181977  0.5181699  0.51817226 0.51815337 0.5181757\n",
            " 0.5182382  0.5181863  0.51817566 0.51826334 0.51816356 0.51814\n",
            " 0.5181672  0.51812726 0.51819074 0.5182103  0.51815337 0.5181902\n",
            " 0.51821095 0.5181565  0.51819533 0.5181842  0.51820517 0.51817715\n",
            " 0.51821697 0.5181366  0.5182281  0.51817465 0.5182079  0.5181801\n",
            " 0.5181598  0.518196   0.518172   0.51820815 0.5182437  0.51823545\n",
            " 0.518217   0.51816756 0.51814926 0.51822484 0.5181817  0.5181333\n",
            " 0.5182356  0.5181751  0.5181484  0.51819134 0.51818526 0.5181699\n",
            " 0.5181478  0.5182282  0.5181787  0.5182517  0.51817393 0.5181768\n",
            " 0.518125   0.5182272  0.51815724 0.51811993 0.5181726  0.5181693 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.267310603405349e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48636883 0.4863834  0.48639938 0.48641056 0.48638344 0.48639625\n",
            " 0.48636028 0.48637903 0.48642397 0.4863493  0.48637864 0.48639992\n",
            " 0.4863741  0.48638943 0.4864036  0.48638612 0.48639134 0.4864046\n",
            " 0.48638722 0.48638475 0.48638025 0.48637545 0.48644048 0.48639572\n",
            " 0.4863682  0.48638338 0.48636958 0.48636886 0.48637027 0.486406\n",
            " 0.4863729  0.48636895 0.48638868 0.48638117 0.48634693 0.48638868\n",
            " 0.48637792 0.4863969  0.48640594 0.4863517  0.48637635 0.4863789\n",
            " 0.4863779  0.48641226 0.48637435 0.4863949  0.48640049 0.48636255\n",
            " 0.48639643 0.48634043 0.48637825 0.48635456 0.48637483 0.48637092\n",
            " 0.48639333 0.4863626  0.48637554 0.48637506 0.48636624 0.4863843 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 1.8348977391724475e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4867363  0.48677123 0.48679653 0.48679125 0.48678723 0.48678637\n",
            " 0.48668507 0.4867343  0.4868533  0.48665056 0.48680156 0.48685902\n",
            " 0.48670143 0.48688665 0.48681712 0.48674893 0.48675016 0.4867841\n",
            " 0.48669556 0.48680532 0.4867059  0.48677072 0.48687503 0.48677847\n",
            " 0.48667288 0.4868446  0.48666567 0.4867325  0.4867497  0.48680818\n",
            " 0.48674875 0.48668367 0.48678824 0.4867748  0.48667532 0.48666027\n",
            " 0.48667142 0.48683032 0.48676303 0.48668963 0.4867384  0.4868785\n",
            " 0.48665068 0.48676413 0.48676232 0.4867788  0.4868273  0.48677796\n",
            " 0.4868155  0.48674956 0.48675206 0.48665527 0.48671654 0.48669782\n",
            " 0.48688453 0.4866247  0.4868122  0.48690423 0.48677817 0.4867701 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 6.674815813312307e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4821427  0.50629985 0.518218   0.48637912 0.48673612]\n",
            " [0.48210952 0.5062579  0.5182401  0.48638842 0.48666424]\n",
            " [0.48208463 0.50623816 0.5182279  0.48637313 0.48666573]\n",
            " [0.4820988  0.5063262  0.5182194  0.4863813  0.4867074 ]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48212668 0.506276   0.5181863  0.4863737  0.48668268]\n",
            " [0.48217973 0.5062932  0.5181906  0.48639208 0.48681572]\n",
            " [0.4822202  0.506328   0.51815486 0.48636654 0.48684517]\n",
            " [0.48210663 0.5062485  0.5182104  0.48638612 0.48664942]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4822129  0.5063062  0.5181774  0.4863688  0.48678595]\n",
            " [0.4821925  0.5063167  0.5181562  0.48638305 0.48676023]\n",
            " [0.48221773 0.50632596 0.51814914 0.48637608 0.48678824]\n",
            " [0.48217362 0.5062774  0.5181837  0.48639014 0.4867515 ]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48214853 0.50638    0.51818407 0.48638716 0.48680496]\n",
            " [0.48216668 0.50631255 0.5181958  0.48638502 0.48683736]\n",
            " [0.48216942 0.506271   0.5181776  0.48638597 0.48669314]\n",
            " [0.48217067 0.5062798  0.51818925 0.48636758 0.48673564]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48215735 0.50629556 0.51818776 0.4863796  0.48673326]\n",
            " [0.4822404  0.50636464 0.51811963 0.48640636 0.48689413]\n",
            " [0.4821974  0.506327   0.5181267  0.4863873  0.4868165 ]\n",
            " [0.48214287 0.50626314 0.51819783 0.4863669  0.48671377]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.4821427  0.48210952 0.48208463 0.4820988  0.48212668 0.48217973\n",
            " 0.4822202  0.48210663 0.4822129  0.4821925  0.48221773 0.48217362\n",
            " 0.48214853 0.48216668 0.48216942 0.48217067 0.48215735 0.4822404\n",
            " 0.4821974  0.48214287]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.242081558913924e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50629985 0.5062579  0.50623816 0.5063262  0.506276   0.5062932\n",
            " 0.506328   0.5062485  0.5063062  0.5063167  0.50632596 0.5062774\n",
            " 0.50638    0.50631255 0.506271   0.5062798  0.50629556 0.50636464\n",
            " 0.506327   0.50626314]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.600885975174606e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.518218   0.5182401  0.5182279  0.5182194  0.5181863  0.5181906\n",
            " 0.51815486 0.5182104  0.5181774  0.5181562  0.51814914 0.5181837\n",
            " 0.51818407 0.5181958  0.5181776  0.51818925 0.51818776 0.51811963\n",
            " 0.5181267  0.51819783]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.077187648159452e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48637912 0.48638842 0.48637313 0.4863813  0.4863737  0.48639208\n",
            " 0.48636654 0.48638612 0.4863688  0.48638305 0.48637608 0.48639014\n",
            " 0.48638716 0.48638502 0.48638597 0.48636758 0.4863796  0.48640636\n",
            " 0.4863873  0.4863669 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.834599040914327e-06\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48673612 0.48666424 0.48666573 0.4867074  0.48668268 0.48681572\n",
            " 0.48684517 0.48664942 0.48678595 0.48676023 0.48678824 0.4867515\n",
            " 0.48680496 0.48683736 0.48669314 0.48673564 0.48673326 0.48689413\n",
            " 0.4868165  0.48671377]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.629508425248787e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.4821427  0.48210952 0.48208463 0.4820988  0.48212668 0.48217973\n",
            " 0.4822202  0.48210663 0.4822129  0.4821925  0.48221773 0.48217362\n",
            " 0.48214853 0.48216668 0.48216942 0.48217067 0.48215735 0.4822404\n",
            " 0.4821974  0.48214287]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.242081558913924e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50629985 0.5062579  0.50623816 0.5063262  0.506276   0.5062932\n",
            " 0.506328   0.5062485  0.5063062  0.5063167  0.50632596 0.5062774\n",
            " 0.50638    0.50631255 0.506271   0.5062798  0.50629556 0.50636464\n",
            " 0.506327   0.50626314]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.600885975174606e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.518218   0.5182401  0.5182279  0.5182194  0.5181863  0.5181906\n",
            " 0.51815486 0.5182104  0.5181774  0.5181562  0.51814914 0.5181837\n",
            " 0.51818407 0.5181958  0.5181776  0.51818925 0.51818776 0.51811963\n",
            " 0.5181267  0.51819783]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.077187648159452e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48637912 0.48638842 0.48637313 0.4863813  0.4863737  0.48639208\n",
            " 0.48636654 0.48638612 0.4863688  0.48638305 0.48637608 0.48639014\n",
            " 0.48638716 0.48638502 0.48638597 0.48636758 0.4863796  0.48640636\n",
            " 0.4863873  0.4863669 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.834599040914327e-06\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48673612 0.48666424 0.48666573 0.4867074  0.48668268 0.48681572\n",
            " 0.48684517 0.48664942 0.48678595 0.48676023 0.48678824 0.4867515\n",
            " 0.48680496 0.48683736 0.48669314 0.48673564 0.48673326 0.48689413\n",
            " 0.4868165  0.48671377]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.629508425248787e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.4821427  0.48210952 0.48208463 0.4820988  0.48212668 0.48217973\n",
            " 0.4822202  0.48210663 0.4822129  0.4821925  0.48221773 0.48217362\n",
            " 0.48214853 0.48216668 0.48216942 0.48217067 0.48215735 0.4822404\n",
            " 0.4821974  0.48214287]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.242081558913924e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50629985 0.5062579  0.50623816 0.5063262  0.506276   0.5062932\n",
            " 0.506328   0.5062485  0.5063062  0.5063167  0.50632596 0.5062774\n",
            " 0.50638    0.50631255 0.506271   0.5062798  0.50629556 0.50636464\n",
            " 0.506327   0.50626314]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.600885975174606e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.518218   0.5182401  0.5182279  0.5182194  0.5181863  0.5181906\n",
            " 0.51815486 0.5182104  0.5181774  0.5181562  0.51814914 0.5181837\n",
            " 0.51818407 0.5181958  0.5181776  0.51818925 0.51818776 0.51811963\n",
            " 0.5181267  0.51819783]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.077187648159452e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48637912 0.48638842 0.48637313 0.4863813  0.4863737  0.48639208\n",
            " 0.48636654 0.48638612 0.4863688  0.48638305 0.48637608 0.48639014\n",
            " 0.48638716 0.48638502 0.48638597 0.48636758 0.4863796  0.48640636\n",
            " 0.4863873  0.4863669 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.834599040914327e-06\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48673612 0.48666424 0.48666573 0.4867074  0.48668268 0.48681572\n",
            " 0.48684517 0.48664942 0.48678595 0.48676023 0.48678824 0.4867515\n",
            " 0.48680496 0.48683736 0.48669314 0.48673564 0.48673326 0.48689413\n",
            " 0.4868165  0.48671377]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.629508425248787e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.4821427  0.48210952 0.48208463 0.4820988  0.48212668 0.48217973\n",
            " 0.4822202  0.48210663 0.4822129  0.4821925  0.48221773 0.48217362\n",
            " 0.48214853 0.48216668 0.48216942 0.48217067 0.48215735 0.4822404\n",
            " 0.4821974  0.48214287]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.242081558913924e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50629985 0.5062579  0.50623816 0.5063262  0.506276   0.5062932\n",
            " 0.506328   0.5062485  0.5063062  0.5063167  0.50632596 0.5062774\n",
            " 0.50638    0.50631255 0.506271   0.5062798  0.50629556 0.50636464\n",
            " 0.506327   0.50626314]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.600885975174606e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.518218   0.5182401  0.5182279  0.5182194  0.5181863  0.5181906\n",
            " 0.51815486 0.5182104  0.5181774  0.5181562  0.51814914 0.5181837\n",
            " 0.51818407 0.5181958  0.5181776  0.51818925 0.51818776 0.51811963\n",
            " 0.5181267  0.51819783]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 3.077187648159452e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48637912 0.48638842 0.48637313 0.4863813  0.4863737  0.48639208\n",
            " 0.48636654 0.48638612 0.4863688  0.48638305 0.48637608 0.48639014\n",
            " 0.48638716 0.48638502 0.48638597 0.48636758 0.4863796  0.48640636\n",
            " 0.4863873  0.4863669 ]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 9.834599040914327e-06\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48673612 0.48666424 0.48666573 0.4867074  0.48668268 0.48681572\n",
            " 0.48684517 0.48664942 0.48678595 0.48676023 0.48678824 0.4867515\n",
            " 0.48680496 0.48683736 0.48669314 0.48673564 0.48673326 0.48689413\n",
            " 0.4868165  0.48671377]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 6.629508425248787e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4821988  0.50631785 0.5181823  0.48639783 0.4867626 ]\n",
            " [0.48221102 0.50632566 0.5181481  0.4863717  0.48680753]\n",
            " [0.48220772 0.5063351  0.5181532  0.48637187 0.48681194]\n",
            " [0.48215958 0.50629705 0.5181685  0.48638728 0.48673645]\n",
            " [0.48223117 0.5063395  0.51814157 0.4863558  0.4868374 ]\n",
            " [0.48212805 0.50627345 0.5182372  0.4863792  0.48669803]\n",
            " [0.48211965 0.50627303 0.5182056  0.48638824 0.4867095 ]\n",
            " [0.48212168 0.50624526 0.5181923  0.48637626 0.4866798 ]\n",
            " [0.4821386  0.5062619  0.518214   0.48640108 0.48668435]\n",
            " [0.48214355 0.5063146  0.51817715 0.48639485 0.48679972]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48212272 0.5063095  0.51820594 0.4863956  0.48677582]\n",
            " [0.4821459  0.50628823 0.5182086  0.48639053 0.48672408]\n",
            " [0.48216993 0.5062866  0.51818657 0.48639554 0.48675928]\n",
            " [0.48222032 0.5063433  0.5181516  0.48642004 0.48687148]\n",
            " [0.48215008 0.5062927  0.51817626 0.48638633 0.48673356]\n",
            " [0.48219717 0.50630206 0.5181672  0.48637953 0.48679277]\n",
            " [0.48221254 0.50632614 0.5181621  0.48639718 0.48685744]\n",
            " [0.48214296 0.50624436 0.51819956 0.4863668  0.4866721 ]\n",
            " [0.4821879  0.50634193 0.51815665 0.48638543 0.4867812 ]\n",
            " [0.48211017 0.50632703 0.5182053  0.4863714  0.4867523 ]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4821988  0.48221102 0.48220772 0.48215958 0.48223117 0.48212805\n",
            " 0.48211965 0.48212168 0.4821386  0.48214355 0.48212272 0.4821459\n",
            " 0.48216993 0.48222032 0.48215008 0.48219717 0.48221254 0.48214296\n",
            " 0.4821879  0.48211017]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.788186950259842e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50631785 0.50632566 0.5063351  0.50629705 0.5063395  0.50627345\n",
            " 0.50627303 0.50624526 0.5062619  0.5063146  0.5063095  0.50628823\n",
            " 0.5062866  0.5063433  0.5062927  0.50630206 0.50632614 0.50624436\n",
            " 0.50634193 0.50632703]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.0312721719383262e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5181823  0.5181481  0.5181532  0.5181685  0.51814157 0.5182372\n",
            " 0.5182056  0.5181923  0.518214   0.51817715 0.51820594 0.5182086\n",
            " 0.51818657 0.5181516  0.51817626 0.5181672  0.5181621  0.51819956\n",
            " 0.51815665 0.5182053 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.5414647097932175e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48639783 0.4863717  0.48637187 0.48638728 0.4863558  0.4863792\n",
            " 0.48638824 0.48637626 0.48640108 0.48639485 0.4863956  0.48639053\n",
            " 0.48639554 0.48642004 0.48638633 0.48637953 0.48639718 0.4863668\n",
            " 0.48638543 0.4863714 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.417209659848595e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4867626  0.48680753 0.48681194 0.48673645 0.4868374  0.48669803\n",
            " 0.4867095  0.4866798  0.48668435 0.48679972 0.48677582 0.48672408\n",
            " 0.48675928 0.48687148 0.48673356 0.48679277 0.48685744 0.4866721\n",
            " 0.4867812  0.4867523 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.70043885090854e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4821988  0.48221102 0.48220772 0.48215958 0.48223117 0.48212805\n",
            " 0.48211965 0.48212168 0.4821386  0.48214355 0.48212272 0.4821459\n",
            " 0.48216993 0.48222032 0.48215008 0.48219717 0.48221254 0.48214296\n",
            " 0.4821879  0.48211017]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.788186950259842e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50631785 0.50632566 0.5063351  0.50629705 0.5063395  0.50627345\n",
            " 0.50627303 0.50624526 0.5062619  0.5063146  0.5063095  0.50628823\n",
            " 0.5062866  0.5063433  0.5062927  0.50630206 0.50632614 0.50624436\n",
            " 0.50634193 0.50632703]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.0312721719383262e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5181823  0.5181481  0.5181532  0.5181685  0.51814157 0.5182372\n",
            " 0.5182056  0.5181923  0.518214   0.51817715 0.51820594 0.5182086\n",
            " 0.51818657 0.5181516  0.51817626 0.5181672  0.5181621  0.51819956\n",
            " 0.51815665 0.5182053 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.5414647097932175e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48639783 0.4863717  0.48637187 0.48638728 0.4863558  0.4863792\n",
            " 0.48638824 0.48637626 0.48640108 0.48639485 0.4863956  0.48639053\n",
            " 0.48639554 0.48642004 0.48638633 0.48637953 0.48639718 0.4863668\n",
            " 0.48638543 0.4863714 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.417209659848595e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4867626  0.48680753 0.48681194 0.48673645 0.4868374  0.48669803\n",
            " 0.4867095  0.4866798  0.48668435 0.48679972 0.48677582 0.48672408\n",
            " 0.48675928 0.48687148 0.48673356 0.48679277 0.48685744 0.4866721\n",
            " 0.4867812  0.4867523 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.70043885090854e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4821988  0.48221102 0.48220772 0.48215958 0.48223117 0.48212805\n",
            " 0.48211965 0.48212168 0.4821386  0.48214355 0.48212272 0.4821459\n",
            " 0.48216993 0.48222032 0.48215008 0.48219717 0.48221254 0.48214296\n",
            " 0.4821879  0.48211017]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.788186950259842e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50631785 0.50632566 0.5063351  0.50629705 0.5063395  0.50627345\n",
            " 0.50627303 0.50624526 0.5062619  0.5063146  0.5063095  0.50628823\n",
            " 0.5062866  0.5063433  0.5062927  0.50630206 0.50632614 0.50624436\n",
            " 0.50634193 0.50632703]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.0312721719383262e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5181823  0.5181481  0.5181532  0.5181685  0.51814157 0.5182372\n",
            " 0.5182056  0.5181923  0.518214   0.51817715 0.51820594 0.5182086\n",
            " 0.51818657 0.5181516  0.51817626 0.5181672  0.5181621  0.51819956\n",
            " 0.51815665 0.5182053 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.5414647097932175e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48639783 0.4863717  0.48637187 0.48638728 0.4863558  0.4863792\n",
            " 0.48638824 0.48637626 0.48640108 0.48639485 0.4863956  0.48639053\n",
            " 0.48639554 0.48642004 0.48638633 0.48637953 0.48639718 0.4863668\n",
            " 0.48638543 0.4863714 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.417209659848595e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4867626  0.48680753 0.48681194 0.48673645 0.4868374  0.48669803\n",
            " 0.4867095  0.4866798  0.48668435 0.48679972 0.48677582 0.48672408\n",
            " 0.48675928 0.48687148 0.48673356 0.48679277 0.48685744 0.4866721\n",
            " 0.4867812  0.4867523 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.70043885090854e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4821988  0.48221102 0.48220772 0.48215958 0.48223117 0.48212805\n",
            " 0.48211965 0.48212168 0.4821386  0.48214355 0.48212272 0.4821459\n",
            " 0.48216993 0.48222032 0.48215008 0.48219717 0.48221254 0.48214296\n",
            " 0.4821879  0.48211017]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.788186950259842e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50631785 0.50632566 0.5063351  0.50629705 0.5063395  0.50627345\n",
            " 0.50627303 0.50624526 0.5062619  0.5063146  0.5063095  0.50628823\n",
            " 0.5062866  0.5063433  0.5062927  0.50630206 0.50632614 0.50624436\n",
            " 0.50634193 0.50632703]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.0312721719383262e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5181823  0.5181481  0.5181532  0.5181685  0.51814157 0.5182372\n",
            " 0.5182056  0.5181923  0.518214   0.51817715 0.51820594 0.5182086\n",
            " 0.51818657 0.5181516  0.51817626 0.5181672  0.5181621  0.51819956\n",
            " 0.51815665 0.5182053 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.5414647097932175e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48639783 0.4863717  0.48637187 0.48638728 0.4863558  0.4863792\n",
            " 0.48638824 0.48637626 0.48640108 0.48639485 0.4863956  0.48639053\n",
            " 0.48639554 0.48642004 0.48638633 0.48637953 0.48639718 0.4863668\n",
            " 0.48638543 0.4863714 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.417209659848595e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4867626  0.48680753 0.48681194 0.48673645 0.4868374  0.48669803\n",
            " 0.4867095  0.4866798  0.48668435 0.48679972 0.48677582 0.48672408\n",
            " 0.48675928 0.48687148 0.48673356 0.48679277 0.48685744 0.4866721\n",
            " 0.4867812  0.4867523 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 5.70043885090854e-05\n",
            "Epoch 6/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48216975 0.506292   0.51820207 0.48636883 0.4867363 ]\n",
            " [0.4821125  0.50634426 0.5181977  0.4863834  0.48677123]\n",
            " [0.48219946 0.50632054 0.5181699  0.48639938 0.48679653]\n",
            " [0.48218337 0.5063328  0.51817226 0.48641056 0.48679125]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4822335  0.5063566  0.5181891  0.48642418 0.48683473]\n",
            " [0.48222142 0.50630623 0.5182112  0.48643705 0.48683387]\n",
            " [0.48205438 0.50635093 0.51827306 0.48640043 0.48673168]\n",
            " [0.48222977 0.50631964 0.5182216  0.48641974 0.4867817 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48223823 0.5063934  0.5182175  0.48645443 0.48695722]\n",
            " [0.48209044 0.50633717 0.51830417 0.48637882 0.48675206]\n",
            " [0.48222953 0.5063657  0.5182055  0.4864089  0.48690525]\n",
            " [0.48221612 0.5063796  0.51818186 0.48643062 0.48696375]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48220944 0.5063431  0.51823753 0.4864325  0.48684072]\n",
            " [0.4822306  0.5063912  0.5181985  0.48644888 0.48702866]\n",
            " [0.48223865 0.50639886 0.51826173 0.4864622  0.48695725]\n",
            " [0.48220828 0.5063575  0.5182811  0.48644438 0.48688844]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4822796  0.50635654 0.51824796 0.4864607  0.48694763]\n",
            " [0.48226526 0.50641143 0.5182849  0.4864743  0.48698184]\n",
            " [0.48222464 0.50637287 0.5183051  0.48645595 0.4868913 ]\n",
            " [0.48227286 0.5063894  0.5182516  0.48645452 0.48700383]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4822587  0.5063483  0.5182804  0.48644358 0.48694512]\n",
            " [0.48225832 0.5063724  0.5182698  0.4864392  0.4870111 ]\n",
            " [0.48232836 0.5064179  0.51829165 0.48650464 0.48711774]\n",
            " [0.48228586 0.5063864  0.5182626  0.48645973 0.48702   ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48226297 0.5063579  0.5183281  0.48647138 0.4869455 ]\n",
            " [0.48238385 0.5064654  0.5182494  0.4864895  0.48712397]\n",
            " [0.48224002 0.5063416  0.51833886 0.4864724  0.48693764]\n",
            " [0.48228404 0.5064044  0.5182862  0.48647326 0.48700783]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48225704 0.5064128  0.5183006  0.48648995 0.4870484 ]\n",
            " [0.4823013  0.50644135 0.5182742  0.4865274  0.48711038]\n",
            " [0.48228866 0.5063809  0.5182525  0.48649472 0.4870512 ]\n",
            " [0.48225966 0.5063398  0.5182883  0.4864887  0.48698205]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48231292 0.5064064  0.518275   0.48652416 0.4871064 ]\n",
            " [0.48226047 0.506412   0.5183108  0.48651695 0.487093  ]\n",
            " [0.48215854 0.5064356  0.51834476 0.48647952 0.48698738]\n",
            " [0.48223865 0.50633144 0.5183366  0.4865227  0.4869745 ]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48224    0.50632757 0.5183118  0.4865049  0.4869794 ]\n",
            " [0.48233443 0.50643635 0.5182643  0.48652622 0.48714393]\n",
            " [0.48232448 0.5063776  0.51824546 0.4865342  0.48707446]\n",
            " [0.48220778 0.5063772  0.51831967 0.486478   0.48699707]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48235476 0.5064539  0.51833045 0.48655856 0.48712465]\n",
            " [0.4824705  0.5065172  0.5182846  0.486563   0.48727033]\n",
            " [0.4822249  0.506429   0.51838255 0.486555   0.4870281 ]\n",
            " [0.482355   0.5064664  0.51832485 0.48659435 0.4871509 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48237377 0.5064811  0.51830846 0.4865972  0.48717177]\n",
            " [0.48235202 0.5064825  0.51835084 0.48661664 0.48718607]\n",
            " [0.48234227 0.5065119  0.51834625 0.48662025 0.4872325 ]\n",
            " [0.48243383 0.5064851  0.5183309  0.48658457 0.48718637]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48243582 0.506523   0.518344   0.48665744 0.4872644 ]\n",
            " [0.48228177 0.5065403  0.5184218  0.48659602 0.48719046]\n",
            " [0.48239556 0.5064937  0.51837355 0.48663753 0.48719808]\n",
            " [0.48227304 0.50642645 0.5184436  0.48660862 0.487093  ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48236647 0.50649923 0.51839066 0.4866642  0.48718283]\n",
            " [0.4823511  0.50648636 0.5183937  0.48665953 0.48716307]\n",
            " [0.48237646 0.5065619  0.5183438  0.48668748 0.48735896]\n",
            " [0.48228595 0.50643474 0.5184415  0.48664662 0.48708302]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4823943  0.5064945  0.5183563  0.4866387  0.48729205]\n",
            " [0.48243204 0.50653684 0.5183206  0.4866386  0.48738462]\n",
            " [0.48238695 0.5064795  0.51837146 0.4866275  0.48725438]\n",
            " [0.48239553 0.5064866  0.5183687  0.48664552 0.48724633]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48239905 0.5065212  0.5184302  0.48666778 0.4872663 ]\n",
            " [0.48234078 0.5065734  0.5184264  0.48668024 0.48729873]\n",
            " [0.48242766 0.5065524  0.518401   0.48669901 0.48732892]\n",
            " [0.4824125  0.5065634  0.5184025  0.48671046 0.48732373]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824367  0.5065586  0.5183838  0.48668304 0.48731977]\n",
            " [0.48242542 0.50650746 0.5184052  0.48669618 0.4873183 ]\n",
            " [0.48225445 0.50654674 0.51846397 0.48665196 0.48720455]\n",
            " [0.48243386 0.5065197  0.51841486 0.48667824 0.48726568]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48241612 0.506583   0.51840615 0.486724   0.48738545]\n",
            " [0.48226634 0.5065216  0.5184887  0.48664147 0.48717058]\n",
            " [0.48240614 0.50655544 0.5183946  0.48667708 0.48733217]\n",
            " [0.48239508 0.5065687  0.51836914 0.48670176 0.48739564]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48237392 0.5065117  0.51839477 0.48667204 0.4872298 ]\n",
            " [0.48239672 0.50656223 0.51835716 0.4866925  0.48742527]\n",
            " [0.48240298 0.50656945 0.51842064 0.48670247 0.48734802]\n",
            " [0.482372   0.5065271  0.5184396  0.4866835  0.48727754]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824062  0.5065102  0.5183817  0.48668978 0.4872804 ]\n",
            " [0.48239228 0.5065657  0.5184189  0.4867032  0.48731393]\n",
            " [0.48235056 0.5065249  0.5184382  0.48668215 0.48721984]\n",
            " [0.48240066 0.50654405 0.5183855  0.4866854  0.4873388 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48238146 0.5065029  0.51842326 0.48667753 0.48723376]\n",
            " [0.48238155 0.50652814 0.5184134  0.48667425 0.48730096]\n",
            " [0.48245183 0.5065755  0.5184367  0.4867424  0.4874106 ]\n",
            " [0.4824102  0.50654256 0.51840603 0.4866968  0.48731214]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48235598 0.50646955 0.5184438  0.4866643  0.48719832]\n",
            " [0.48247778 0.50657976 0.5183671  0.48668674 0.48738283]\n",
            " [0.4823329  0.5064528  0.5184543  0.4866646  0.48718965]\n",
            " [0.48237756 0.50651693 0.5184026  0.48666793 0.48726308]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48237076 0.5065492  0.5184357  0.48666614 0.48727572]\n",
            " [0.48241565 0.5065798  0.51841116 0.4867057  0.48734048]\n",
            " [0.48240396 0.50651824 0.5183881  0.48667327 0.48728168]\n",
            " [0.48237392 0.50647587 0.51842296 0.48666504 0.4872096 ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48241475 0.50653374 0.51840204 0.48668712 0.48731852]\n",
            " [0.48236296 0.5065393  0.51843685 0.4866801  0.48730525]\n",
            " [0.48225957 0.50655967 0.51846886 0.48663905 0.48719504]\n",
            " [0.4823406  0.50645655 0.5184614  0.48668393 0.48718405]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48235703 0.5064761  0.5184439  0.48667446 0.48719734]\n",
            " [0.48245215 0.5065882  0.5183987  0.48669857 0.48736563]\n",
            " [0.4824416  0.5065282  0.51837915 0.48670548 0.48729485]\n",
            " [0.4823244  0.5065258  0.5184516  0.4866472  0.48721468]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48239952 0.506538   0.5184099  0.486676   0.48726904]\n",
            " [0.48251513 0.50660276 0.5183653  0.48668176 0.48741668]\n",
            " [0.48226926 0.50651157 0.518461   0.48666945 0.4871691 ]\n",
            " [0.48239976 0.50655067 0.5184047  0.48671186 0.48729542]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48241842 0.5065401  0.5183778  0.48667496 0.48729587]\n",
            " [0.48239648 0.5065413  0.51841986 0.48669398 0.48730925]\n",
            " [0.48238605 0.506571   0.5184157  0.48669723 0.48735532]\n",
            " [0.48247838 0.50654435 0.5184002  0.48666233 0.48731032]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.482465   0.5065579  0.51837844 0.48669732 0.48734966]\n",
            " [0.48231107 0.5065749  0.5184558  0.48663536 0.48727438]\n",
            " [0.48242494 0.5065283  0.51840764 0.48667735 0.48728302]\n",
            " [0.4823024  0.50646055 0.51847726 0.48664775 0.48717657]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4823871  0.506511   0.51840174 0.4866736  0.4872464 ]\n",
            " [0.48237175 0.50649804 0.51840466 0.48666894 0.48722664]\n",
            " [0.48239684 0.5065732  0.518355   0.48669654 0.4874233 ]\n",
            " [0.48230618 0.5064462  0.51845217 0.4866557  0.4871453 ]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824256  0.5065362  0.51838684 0.48667744 0.4873483 ]\n",
            " [0.4824629  0.5065787  0.5183513  0.48667714 0.48744053]\n",
            " [0.48241767 0.5065206  0.51840186 0.4866657  0.48730984]\n",
            " [0.48242617 0.50652784 0.51839936 0.48668373 0.48730177]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48239905 0.48234078 0.48242766 0.4824125  0.4824367  0.48242542\n",
            " 0.48225445 0.48243386 0.48241612 0.48226634 0.48240614 0.48239508\n",
            " 0.48237392 0.48239672 0.48240298 0.482372   0.4824062  0.48239228\n",
            " 0.48235056 0.48240066 0.48238146 0.48238155 0.48245183 0.4824102\n",
            " 0.48235598 0.48247778 0.4823329  0.48237756 0.48237076 0.48241565\n",
            " 0.48240396 0.48237392 0.48241475 0.48236296 0.48225957 0.4823406\n",
            " 0.48235703 0.48245215 0.4824416  0.4823244  0.48239952 0.48251513\n",
            " 0.48226926 0.48239976 0.48241842 0.48239648 0.48238605 0.48247838\n",
            " 0.482465   0.48231107 0.48242494 0.4823024  0.4823871  0.48237175\n",
            " 0.48239684 0.48230618 0.4824256  0.4824629  0.48241767 0.48242617]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.383499228628352e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5065212  0.5065734  0.5065524  0.5065634  0.5065586  0.50650746\n",
            " 0.50654674 0.5065197  0.506583   0.5065216  0.50655544 0.5065687\n",
            " 0.5065117  0.50656223 0.50656945 0.5065271  0.5065102  0.5065657\n",
            " 0.5065249  0.50654405 0.5065029  0.50652814 0.5065755  0.50654256\n",
            " 0.50646955 0.50657976 0.5064528  0.50651693 0.5065492  0.5065798\n",
            " 0.50651824 0.50647587 0.50653374 0.5065393  0.50655967 0.50645655\n",
            " 0.5064761  0.5065882  0.5065282  0.5065258  0.506538   0.50660276\n",
            " 0.50651157 0.50655067 0.5065401  0.5065413  0.506571   0.50654435\n",
            " 0.5065579  0.5065749  0.5065283  0.50646055 0.506511   0.50649804\n",
            " 0.5065732  0.5064462  0.5065362  0.5065787  0.5065206  0.50652784]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.5619421396404505e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5184302  0.5184264  0.518401   0.5184025  0.5183838  0.5184052\n",
            " 0.51846397 0.51841486 0.51840615 0.5184887  0.5183946  0.51836914\n",
            " 0.51839477 0.51835716 0.51842064 0.5184396  0.5183817  0.5184189\n",
            " 0.5184382  0.5183855  0.51842326 0.5184134  0.5184367  0.51840603\n",
            " 0.5184438  0.5183671  0.5184543  0.5184026  0.5184357  0.51841116\n",
            " 0.5183881  0.51842296 0.51840204 0.51843685 0.51846886 0.5184614\n",
            " 0.5184439  0.5183987  0.51837915 0.5184516  0.5184099  0.5183653\n",
            " 0.518461   0.5184047  0.5183778  0.51841986 0.5184157  0.5184002\n",
            " 0.51837844 0.5184558  0.51840764 0.51847726 0.51840174 0.51840466\n",
            " 0.518355   0.51845217 0.51838684 0.5183513  0.51840186 0.51839936]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.132031633867882e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48666778 0.48668024 0.48669901 0.48671046 0.48668304 0.48669618\n",
            " 0.48665196 0.48667824 0.486724   0.48664147 0.48667708 0.48670176\n",
            " 0.48667204 0.4866925  0.48670247 0.4866835  0.48668978 0.4867032\n",
            " 0.48668215 0.4866854  0.48667753 0.48667425 0.4867424  0.4866968\n",
            " 0.4866643  0.48668674 0.4866646  0.48666793 0.48666614 0.4867057\n",
            " 0.48667327 0.48666504 0.48668712 0.4866801  0.48663905 0.48668393\n",
            " 0.48667446 0.48669857 0.48670548 0.4866472  0.486676   0.48668176\n",
            " 0.48666945 0.48671186 0.48667496 0.48669398 0.48669723 0.48666233\n",
            " 0.48669732 0.48663536 0.48667735 0.48664775 0.4866736  0.48666894\n",
            " 0.48669654 0.4866557  0.48667744 0.48667714 0.4866657  0.48668373]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.008291812671814e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4872663  0.48729873 0.48732892 0.48732373 0.48731977 0.4873183\n",
            " 0.48720455 0.48726568 0.48738545 0.48717058 0.48733217 0.48739564\n",
            " 0.4872298  0.48742527 0.48734802 0.48727754 0.4872804  0.48731393\n",
            " 0.48721984 0.4873388  0.48723376 0.48730096 0.4874106  0.48731214\n",
            " 0.48719832 0.48738283 0.48718965 0.48726308 0.48727572 0.48734048\n",
            " 0.48728168 0.4872096  0.48731852 0.48730525 0.48719504 0.48718405\n",
            " 0.48719734 0.48736563 0.48729485 0.48721468 0.48726904 0.48741668\n",
            " 0.4871691  0.48729542 0.48729587 0.48730925 0.48735532 0.48731032\n",
            " 0.48734966 0.48727438 0.48728302 0.48717657 0.4872464  0.48722664\n",
            " 0.4874233  0.4871453  0.4873483  0.48744053 0.48730984 0.48730177]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.110922160791233e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48239905 0.48234078 0.48242766 0.4824125  0.4824367  0.48242542\n",
            " 0.48225445 0.48243386 0.48241612 0.48226634 0.48240614 0.48239508\n",
            " 0.48237392 0.48239672 0.48240298 0.482372   0.4824062  0.48239228\n",
            " 0.48235056 0.48240066 0.48238146 0.48238155 0.48245183 0.4824102\n",
            " 0.48235598 0.48247778 0.4823329  0.48237756 0.48237076 0.48241565\n",
            " 0.48240396 0.48237392 0.48241475 0.48236296 0.48225957 0.4823406\n",
            " 0.48235703 0.48245215 0.4824416  0.4823244  0.48239952 0.48251513\n",
            " 0.48226926 0.48239976 0.48241842 0.48239648 0.48238605 0.48247838\n",
            " 0.482465   0.48231107 0.48242494 0.4823024  0.4823871  0.48237175\n",
            " 0.48239684 0.48230618 0.4824256  0.4824629  0.48241767 0.48242617]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.383499228628352e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5065212  0.5065734  0.5065524  0.5065634  0.5065586  0.50650746\n",
            " 0.50654674 0.5065197  0.506583   0.5065216  0.50655544 0.5065687\n",
            " 0.5065117  0.50656223 0.50656945 0.5065271  0.5065102  0.5065657\n",
            " 0.5065249  0.50654405 0.5065029  0.50652814 0.5065755  0.50654256\n",
            " 0.50646955 0.50657976 0.5064528  0.50651693 0.5065492  0.5065798\n",
            " 0.50651824 0.50647587 0.50653374 0.5065393  0.50655967 0.50645655\n",
            " 0.5064761  0.5065882  0.5065282  0.5065258  0.506538   0.50660276\n",
            " 0.50651157 0.50655067 0.5065401  0.5065413  0.506571   0.50654435\n",
            " 0.5065579  0.5065749  0.5065283  0.50646055 0.506511   0.50649804\n",
            " 0.5065732  0.5064462  0.5065362  0.5065787  0.5065206  0.50652784]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.5619421396404505e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5184302  0.5184264  0.518401   0.5184025  0.5183838  0.5184052\n",
            " 0.51846397 0.51841486 0.51840615 0.5184887  0.5183946  0.51836914\n",
            " 0.51839477 0.51835716 0.51842064 0.5184396  0.5183817  0.5184189\n",
            " 0.5184382  0.5183855  0.51842326 0.5184134  0.5184367  0.51840603\n",
            " 0.5184438  0.5183671  0.5184543  0.5184026  0.5184357  0.51841116\n",
            " 0.5183881  0.51842296 0.51840204 0.51843685 0.51846886 0.5184614\n",
            " 0.5184439  0.5183987  0.51837915 0.5184516  0.5184099  0.5183653\n",
            " 0.518461   0.5184047  0.5183778  0.51841986 0.5184157  0.5184002\n",
            " 0.51837844 0.5184558  0.51840764 0.51847726 0.51840174 0.51840466\n",
            " 0.518355   0.51845217 0.51838684 0.5183513  0.51840186 0.51839936]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.132031633867882e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48666778 0.48668024 0.48669901 0.48671046 0.48668304 0.48669618\n",
            " 0.48665196 0.48667824 0.486724   0.48664147 0.48667708 0.48670176\n",
            " 0.48667204 0.4866925  0.48670247 0.4866835  0.48668978 0.4867032\n",
            " 0.48668215 0.4866854  0.48667753 0.48667425 0.4867424  0.4866968\n",
            " 0.4866643  0.48668674 0.4866646  0.48666793 0.48666614 0.4867057\n",
            " 0.48667327 0.48666504 0.48668712 0.4866801  0.48663905 0.48668393\n",
            " 0.48667446 0.48669857 0.48670548 0.4866472  0.486676   0.48668176\n",
            " 0.48666945 0.48671186 0.48667496 0.48669398 0.48669723 0.48666233\n",
            " 0.48669732 0.48663536 0.48667735 0.48664775 0.4866736  0.48666894\n",
            " 0.48669654 0.4866557  0.48667744 0.48667714 0.4866657  0.48668373]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.008291812671814e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4872663  0.48729873 0.48732892 0.48732373 0.48731977 0.4873183\n",
            " 0.48720455 0.48726568 0.48738545 0.48717058 0.48733217 0.48739564\n",
            " 0.4872298  0.48742527 0.48734802 0.48727754 0.4872804  0.48731393\n",
            " 0.48721984 0.4873388  0.48723376 0.48730096 0.4874106  0.48731214\n",
            " 0.48719832 0.48738283 0.48718965 0.48726308 0.48727572 0.48734048\n",
            " 0.48728168 0.4872096  0.48731852 0.48730525 0.48719504 0.48718405\n",
            " 0.48719734 0.48736563 0.48729485 0.48721468 0.48726904 0.48741668\n",
            " 0.4871691  0.48729542 0.48729587 0.48730925 0.48735532 0.48731032\n",
            " 0.48734966 0.48727438 0.48728302 0.48717657 0.4872464  0.48722664\n",
            " 0.4874233  0.4871453  0.4873483  0.48744053 0.48730984 0.48730177]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.110922160791233e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48239905 0.48234078 0.48242766 0.4824125  0.4824367  0.48242542\n",
            " 0.48225445 0.48243386 0.48241612 0.48226634 0.48240614 0.48239508\n",
            " 0.48237392 0.48239672 0.48240298 0.482372   0.4824062  0.48239228\n",
            " 0.48235056 0.48240066 0.48238146 0.48238155 0.48245183 0.4824102\n",
            " 0.48235598 0.48247778 0.4823329  0.48237756 0.48237076 0.48241565\n",
            " 0.48240396 0.48237392 0.48241475 0.48236296 0.48225957 0.4823406\n",
            " 0.48235703 0.48245215 0.4824416  0.4823244  0.48239952 0.48251513\n",
            " 0.48226926 0.48239976 0.48241842 0.48239648 0.48238605 0.48247838\n",
            " 0.482465   0.48231107 0.48242494 0.4823024  0.4823871  0.48237175\n",
            " 0.48239684 0.48230618 0.4824256  0.4824629  0.48241767 0.48242617]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.383499228628352e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5065212  0.5065734  0.5065524  0.5065634  0.5065586  0.50650746\n",
            " 0.50654674 0.5065197  0.506583   0.5065216  0.50655544 0.5065687\n",
            " 0.5065117  0.50656223 0.50656945 0.5065271  0.5065102  0.5065657\n",
            " 0.5065249  0.50654405 0.5065029  0.50652814 0.5065755  0.50654256\n",
            " 0.50646955 0.50657976 0.5064528  0.50651693 0.5065492  0.5065798\n",
            " 0.50651824 0.50647587 0.50653374 0.5065393  0.50655967 0.50645655\n",
            " 0.5064761  0.5065882  0.5065282  0.5065258  0.506538   0.50660276\n",
            " 0.50651157 0.50655067 0.5065401  0.5065413  0.506571   0.50654435\n",
            " 0.5065579  0.5065749  0.5065283  0.50646055 0.506511   0.50649804\n",
            " 0.5065732  0.5064462  0.5065362  0.5065787  0.5065206  0.50652784]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.5619421396404505e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5184302  0.5184264  0.518401   0.5184025  0.5183838  0.5184052\n",
            " 0.51846397 0.51841486 0.51840615 0.5184887  0.5183946  0.51836914\n",
            " 0.51839477 0.51835716 0.51842064 0.5184396  0.5183817  0.5184189\n",
            " 0.5184382  0.5183855  0.51842326 0.5184134  0.5184367  0.51840603\n",
            " 0.5184438  0.5183671  0.5184543  0.5184026  0.5184357  0.51841116\n",
            " 0.5183881  0.51842296 0.51840204 0.51843685 0.51846886 0.5184614\n",
            " 0.5184439  0.5183987  0.51837915 0.5184516  0.5184099  0.5183653\n",
            " 0.518461   0.5184047  0.5183778  0.51841986 0.5184157  0.5184002\n",
            " 0.51837844 0.5184558  0.51840764 0.51847726 0.51840174 0.51840466\n",
            " 0.518355   0.51845217 0.51838684 0.5183513  0.51840186 0.51839936]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.132031633867882e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48666778 0.48668024 0.48669901 0.48671046 0.48668304 0.48669618\n",
            " 0.48665196 0.48667824 0.486724   0.48664147 0.48667708 0.48670176\n",
            " 0.48667204 0.4866925  0.48670247 0.4866835  0.48668978 0.4867032\n",
            " 0.48668215 0.4866854  0.48667753 0.48667425 0.4867424  0.4866968\n",
            " 0.4866643  0.48668674 0.4866646  0.48666793 0.48666614 0.4867057\n",
            " 0.48667327 0.48666504 0.48668712 0.4866801  0.48663905 0.48668393\n",
            " 0.48667446 0.48669857 0.48670548 0.4866472  0.486676   0.48668176\n",
            " 0.48666945 0.48671186 0.48667496 0.48669398 0.48669723 0.48666233\n",
            " 0.48669732 0.48663536 0.48667735 0.48664775 0.4866736  0.48666894\n",
            " 0.48669654 0.4866557  0.48667744 0.48667714 0.4866657  0.48668373]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.008291812671814e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4872663  0.48729873 0.48732892 0.48732373 0.48731977 0.4873183\n",
            " 0.48720455 0.48726568 0.48738545 0.48717058 0.48733217 0.48739564\n",
            " 0.4872298  0.48742527 0.48734802 0.48727754 0.4872804  0.48731393\n",
            " 0.48721984 0.4873388  0.48723376 0.48730096 0.4874106  0.48731214\n",
            " 0.48719832 0.48738283 0.48718965 0.48726308 0.48727572 0.48734048\n",
            " 0.48728168 0.4872096  0.48731852 0.48730525 0.48719504 0.48718405\n",
            " 0.48719734 0.48736563 0.48729485 0.48721468 0.48726904 0.48741668\n",
            " 0.4871691  0.48729542 0.48729587 0.48730925 0.48735532 0.48731032\n",
            " 0.48734966 0.48727438 0.48728302 0.48717657 0.4872464  0.48722664\n",
            " 0.4874233  0.4871453  0.4873483  0.48744053 0.48730984 0.48730177]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.110922160791233e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48239905 0.48234078 0.48242766 0.4824125  0.4824367  0.48242542\n",
            " 0.48225445 0.48243386 0.48241612 0.48226634 0.48240614 0.48239508\n",
            " 0.48237392 0.48239672 0.48240298 0.482372   0.4824062  0.48239228\n",
            " 0.48235056 0.48240066 0.48238146 0.48238155 0.48245183 0.4824102\n",
            " 0.48235598 0.48247778 0.4823329  0.48237756 0.48237076 0.48241565\n",
            " 0.48240396 0.48237392 0.48241475 0.48236296 0.48225957 0.4823406\n",
            " 0.48235703 0.48245215 0.4824416  0.4823244  0.48239952 0.48251513\n",
            " 0.48226926 0.48239976 0.48241842 0.48239648 0.48238605 0.48247838\n",
            " 0.482465   0.48231107 0.48242494 0.4823024  0.4823871  0.48237175\n",
            " 0.48239684 0.48230618 0.4824256  0.4824629  0.48241767 0.48242617]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.383499228628352e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5065212  0.5065734  0.5065524  0.5065634  0.5065586  0.50650746\n",
            " 0.50654674 0.5065197  0.506583   0.5065216  0.50655544 0.5065687\n",
            " 0.5065117  0.50656223 0.50656945 0.5065271  0.5065102  0.5065657\n",
            " 0.5065249  0.50654405 0.5065029  0.50652814 0.5065755  0.50654256\n",
            " 0.50646955 0.50657976 0.5064528  0.50651693 0.5065492  0.5065798\n",
            " 0.50651824 0.50647587 0.50653374 0.5065393  0.50655967 0.50645655\n",
            " 0.5064761  0.5065882  0.5065282  0.5065258  0.506538   0.50660276\n",
            " 0.50651157 0.50655067 0.5065401  0.5065413  0.506571   0.50654435\n",
            " 0.5065579  0.5065749  0.5065283  0.50646055 0.506511   0.50649804\n",
            " 0.5065732  0.5064462  0.5065362  0.5065787  0.5065206  0.50652784]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.5619421396404505e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5184302  0.5184264  0.518401   0.5184025  0.5183838  0.5184052\n",
            " 0.51846397 0.51841486 0.51840615 0.5184887  0.5183946  0.51836914\n",
            " 0.51839477 0.51835716 0.51842064 0.5184396  0.5183817  0.5184189\n",
            " 0.5184382  0.5183855  0.51842326 0.5184134  0.5184367  0.51840603\n",
            " 0.5184438  0.5183671  0.5184543  0.5184026  0.5184357  0.51841116\n",
            " 0.5183881  0.51842296 0.51840204 0.51843685 0.51846886 0.5184614\n",
            " 0.5184439  0.5183987  0.51837915 0.5184516  0.5184099  0.5183653\n",
            " 0.518461   0.5184047  0.5183778  0.51841986 0.5184157  0.5184002\n",
            " 0.51837844 0.5184558  0.51840764 0.51847726 0.51840174 0.51840466\n",
            " 0.518355   0.51845217 0.51838684 0.5183513  0.51840186 0.51839936]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 3.132031633867882e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48666778 0.48668024 0.48669901 0.48671046 0.48668304 0.48669618\n",
            " 0.48665196 0.48667824 0.486724   0.48664147 0.48667708 0.48670176\n",
            " 0.48667204 0.4866925  0.48670247 0.4866835  0.48668978 0.4867032\n",
            " 0.48668215 0.4866854  0.48667753 0.48667425 0.4867424  0.4866968\n",
            " 0.4866643  0.48668674 0.4866646  0.48666793 0.48666614 0.4867057\n",
            " 0.48667327 0.48666504 0.48668712 0.4866801  0.48663905 0.48668393\n",
            " 0.48667446 0.48669857 0.48670548 0.4866472  0.486676   0.48668176\n",
            " 0.48666945 0.48671186 0.48667496 0.48669398 0.48669723 0.48666233\n",
            " 0.48669732 0.48663536 0.48667735 0.48664775 0.4866736  0.48666894\n",
            " 0.48669654 0.4866557  0.48667744 0.48667714 0.4866657  0.48668373]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.008291812671814e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4872663  0.48729873 0.48732892 0.48732373 0.48731977 0.4873183\n",
            " 0.48720455 0.48726568 0.48738545 0.48717058 0.48733217 0.48739564\n",
            " 0.4872298  0.48742527 0.48734802 0.48727754 0.4872804  0.48731393\n",
            " 0.48721984 0.4873388  0.48723376 0.48730096 0.4874106  0.48731214\n",
            " 0.48719832 0.48738283 0.48718965 0.48726308 0.48727572 0.48734048\n",
            " 0.48728168 0.4872096  0.48731852 0.48730525 0.48719504 0.48718405\n",
            " 0.48719734 0.48736563 0.48729485 0.48721468 0.48726904 0.48741668\n",
            " 0.4871691  0.48729542 0.48729587 0.48730925 0.48735532 0.48731032\n",
            " 0.48734966 0.48727438 0.48728302 0.48717657 0.4872464  0.48722664\n",
            " 0.4874233  0.4871453  0.4873483  0.48744053 0.48730984 0.48730177]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.110922160791233e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48237112 0.50652826 0.5184458  0.48667577 0.487263  ]\n",
            " [0.48233652 0.50648373 0.51846623 0.48668253 0.4871869 ]\n",
            " [0.48231202 0.5064643  0.5184537  0.4866676  0.4871887 ]\n",
            " [0.48232552 0.5065531  0.5184465  0.48667574 0.48723108]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48235404 0.5065031  0.5184132  0.48666874 0.4872071 ]\n",
            " [0.48241046 0.5065242  0.51841927 0.48669234 0.48734844]\n",
            " [0.4824509  0.50656015 0.5183851  0.48666832 0.48738143]\n",
            " [0.48233423 0.5064747  0.5184363  0.48668107 0.48717305]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48244417 0.506538   0.5184071  0.48667026 0.48732078]\n",
            " [0.4824219  0.5065474  0.5183855  0.4866828  0.48729247]\n",
            " [0.48244765 0.5065568  0.5183792  0.48667675 0.48732212]\n",
            " [0.48240286 0.5065072  0.5184122  0.4866892  0.48728198]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48237702 0.50661117 0.5184143  0.48668548 0.48733577]\n",
            " [0.48239648 0.50654393 0.5184252  0.486685   0.48736978]\n",
            " [0.48239833 0.5064987  0.5184053  0.4866835  0.48722124]\n",
            " [0.48239958 0.5065093  0.5184176  0.4866662  0.48726562]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48238668 0.50652504 0.51841617 0.48667794 0.48726287]\n",
            " [0.48247173 0.5065972  0.5183508  0.48670986 0.48743314]\n",
            " [0.48242903 0.50655854 0.5183562  0.48668954 0.4873528 ]\n",
            " [0.4823711  0.50649047 0.5184256  0.48666364 0.48724103]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48237112 0.48233652 0.48231202 0.48232552 0.48235404 0.48241046\n",
            " 0.4824509  0.48233423 0.48244417 0.4824219  0.48244765 0.48240286\n",
            " 0.48237702 0.48239648 0.48239833 0.48239958 0.48238668 0.48247173\n",
            " 0.48242903 0.4823711 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.3752013880293816e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50652826 0.50648373 0.5064643  0.5065531  0.5065031  0.5065242\n",
            " 0.50656015 0.5064747  0.506538   0.5065474  0.5065568  0.5065072\n",
            " 0.50661117 0.50654393 0.5064987  0.5065093  0.50652504 0.5065972\n",
            " 0.50655854 0.50649047]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.7686346331611276e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5184458  0.51846623 0.5184537  0.5184465  0.5184132  0.51841927\n",
            " 0.5183851  0.5184363  0.5184071  0.5183855  0.5183792  0.5184122\n",
            " 0.5184143  0.5184252  0.5184053  0.5184176  0.51841617 0.5183508\n",
            " 0.5183562  0.5184256 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.956222670036368e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48667577 0.48668253 0.4866676  0.48667574 0.48666874 0.48669234\n",
            " 0.48666832 0.48668107 0.48667026 0.4866828  0.48667675 0.4866892\n",
            " 0.48668548 0.486685   0.4866835  0.4866662  0.48667794 0.48670986\n",
            " 0.48668954 0.48666364]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.07714076875709e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.487263   0.4871869  0.4871887  0.48723108 0.4872071  0.48734844\n",
            " 0.48738143 0.48717305 0.48732078 0.48729247 0.48732212 0.48728198\n",
            " 0.48733577 0.48736978 0.48722124 0.48726562 0.48726287 0.48743314\n",
            " 0.4873528  0.48724103]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.073876622598618e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48237112 0.48233652 0.48231202 0.48232552 0.48235404 0.48241046\n",
            " 0.4824509  0.48233423 0.48244417 0.4824219  0.48244765 0.48240286\n",
            " 0.48237702 0.48239648 0.48239833 0.48239958 0.48238668 0.48247173\n",
            " 0.48242903 0.4823711 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.3752013880293816e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50652826 0.50648373 0.5064643  0.5065531  0.5065031  0.5065242\n",
            " 0.50656015 0.5064747  0.506538   0.5065474  0.5065568  0.5065072\n",
            " 0.50661117 0.50654393 0.5064987  0.5065093  0.50652504 0.5065972\n",
            " 0.50655854 0.50649047]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.7686346331611276e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5184458  0.51846623 0.5184537  0.5184465  0.5184132  0.51841927\n",
            " 0.5183851  0.5184363  0.5184071  0.5183855  0.5183792  0.5184122\n",
            " 0.5184143  0.5184252  0.5184053  0.5184176  0.51841617 0.5183508\n",
            " 0.5183562  0.5184256 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.956222670036368e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48667577 0.48668253 0.4866676  0.48667574 0.48666874 0.48669234\n",
            " 0.48666832 0.48668107 0.48667026 0.4866828  0.48667675 0.4866892\n",
            " 0.48668548 0.486685   0.4866835  0.4866662  0.48667794 0.48670986\n",
            " 0.48668954 0.48666364]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.07714076875709e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.487263   0.4871869  0.4871887  0.48723108 0.4872071  0.48734844\n",
            " 0.48738143 0.48717305 0.48732078 0.48729247 0.48732212 0.48728198\n",
            " 0.48733577 0.48736978 0.48722124 0.48726562 0.48726287 0.48743314\n",
            " 0.4873528  0.48724103]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.073876622598618e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48237112 0.48233652 0.48231202 0.48232552 0.48235404 0.48241046\n",
            " 0.4824509  0.48233423 0.48244417 0.4824219  0.48244765 0.48240286\n",
            " 0.48237702 0.48239648 0.48239833 0.48239958 0.48238668 0.48247173\n",
            " 0.48242903 0.4823711 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.3752013880293816e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50652826 0.50648373 0.5064643  0.5065531  0.5065031  0.5065242\n",
            " 0.50656015 0.5064747  0.506538   0.5065474  0.5065568  0.5065072\n",
            " 0.50661117 0.50654393 0.5064987  0.5065093  0.50652504 0.5065972\n",
            " 0.50655854 0.50649047]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.7686346331611276e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5184458  0.51846623 0.5184537  0.5184465  0.5184132  0.51841927\n",
            " 0.5183851  0.5184363  0.5184071  0.5183855  0.5183792  0.5184122\n",
            " 0.5184143  0.5184252  0.5184053  0.5184176  0.51841617 0.5183508\n",
            " 0.5183562  0.5184256 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.956222670036368e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48667577 0.48668253 0.4866676  0.48667574 0.48666874 0.48669234\n",
            " 0.48666832 0.48668107 0.48667026 0.4866828  0.48667675 0.4866892\n",
            " 0.48668548 0.486685   0.4866835  0.4866662  0.48667794 0.48670986\n",
            " 0.48668954 0.48666364]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.07714076875709e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.487263   0.4871869  0.4871887  0.48723108 0.4872071  0.48734844\n",
            " 0.48738143 0.48717305 0.48732078 0.48729247 0.48732212 0.48728198\n",
            " 0.48733577 0.48736978 0.48722124 0.48726562 0.48726287 0.48743314\n",
            " 0.4873528  0.48724103]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.073876622598618e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48237112 0.48233652 0.48231202 0.48232552 0.48235404 0.48241046\n",
            " 0.4824509  0.48233423 0.48244417 0.4824219  0.48244765 0.48240286\n",
            " 0.48237702 0.48239648 0.48239833 0.48239958 0.48238668 0.48247173\n",
            " 0.48242903 0.4823711 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.3752013880293816e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50652826 0.50648373 0.5064643  0.5065531  0.5065031  0.5065242\n",
            " 0.50656015 0.5064747  0.506538   0.5065474  0.5065568  0.5065072\n",
            " 0.50661117 0.50654393 0.5064987  0.5065093  0.50652504 0.5065972\n",
            " 0.50655854 0.50649047]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.7686346331611276e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5184458  0.51846623 0.5184537  0.5184465  0.5184132  0.51841927\n",
            " 0.5183851  0.5184363  0.5184071  0.5183855  0.5183792  0.5184122\n",
            " 0.5184143  0.5184252  0.5184053  0.5184176  0.51841617 0.5183508\n",
            " 0.5183562  0.5184256 ]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.956222670036368e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48667577 0.48668253 0.4866676  0.48667574 0.48666874 0.48669234\n",
            " 0.48666832 0.48668107 0.48667026 0.4866828  0.48667675 0.4866892\n",
            " 0.48668548 0.486685   0.4866835  0.4866662  0.48667794 0.48670986\n",
            " 0.48668954 0.48666364]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.07714076875709e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.487263   0.4871869  0.4871887  0.48723108 0.4872071  0.48734844\n",
            " 0.48738143 0.48717305 0.48732078 0.48729247 0.48732212 0.48728198\n",
            " 0.48733577 0.48736978 0.48722124 0.48726562 0.48726287 0.48743314\n",
            " 0.4873528  0.48724103]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.073876622598618e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4824283  0.50654763 0.5184115  0.4866969  0.48729372]\n",
            " [0.48244217 0.50655645 0.5183772  0.48667306 0.48734266]\n",
            " [0.4824382  0.5065656  0.5183828  0.48667306 0.487347  ]\n",
            " [0.48238784 0.5065256  0.51839685 0.48668483 0.48726445]\n",
            " [0.48246285 0.50657165 0.51837206 0.4866587  0.48737502]\n",
            " [0.48235512 0.50650036 0.5184644  0.4866742  0.48722237]\n",
            " [0.48234573 0.50650024 0.5184333  0.4866829  0.48723394]\n",
            " [0.48235005 0.5064729  0.5184188  0.48667276 0.48720643]\n",
            " [0.4823661  0.506489   0.51844114 0.48669627 0.48720887]\n",
            " [0.4823721  0.50654495 0.5184071  0.48669386 0.48733026]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4823511  0.5065394  0.5184341  0.48669335 0.4873049 ]\n",
            " [0.482374   0.50651693 0.518437   0.48668718 0.4872514 ]\n",
            " [0.48239854 0.5065161  0.51841545 0.48669392 0.487289  ]\n",
            " [0.4824494  0.50657684 0.51838386 0.4867215  0.4874076 ]\n",
            " [0.48237923 0.50652146 0.51840466 0.48668528 0.48726445]\n",
            " [0.48242813 0.5065328  0.5183962  0.4866805  0.4873267 ]\n",
            " [0.4824436  0.5065587  0.5183931  0.48669907 0.48739257]\n",
            " [0.48237175 0.5064718  0.5184269  0.4866638  0.48719877]\n",
            " [0.48241857 0.5065718  0.5183857  0.48668647 0.48731494]\n",
            " [0.48233855 0.506555   0.5184326  0.48666713 0.48727816]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4824283  0.48244217 0.4824382  0.48238784 0.48246285 0.48235512\n",
            " 0.48234573 0.48235005 0.4823661  0.4823721  0.4823511  0.482374\n",
            " 0.48239854 0.4824494  0.48237923 0.48242813 0.4824436  0.48237175\n",
            " 0.48241857 0.48233855]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.9106769690988585e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50654763 0.50655645 0.5065656  0.5065256  0.50657165 0.50650036\n",
            " 0.50650024 0.5064729  0.506489   0.50654495 0.5065394  0.50651693\n",
            " 0.5065161  0.50657684 0.50652146 0.5065328  0.5065587  0.5064718\n",
            " 0.5065718  0.506555  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.179068153258413e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5184115  0.5183772  0.5183828  0.51839685 0.51837206 0.5184644\n",
            " 0.5184333  0.5184188  0.51844114 0.5184071  0.5184341  0.518437\n",
            " 0.51841545 0.51838386 0.51840466 0.5183962  0.5183931  0.5184269\n",
            " 0.5183857  0.5184326 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.438484261801932e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4866969  0.48667306 0.48667306 0.48668483 0.4866587  0.4866742\n",
            " 0.4866829  0.48667276 0.48669627 0.48669386 0.48669335 0.48668718\n",
            " 0.48669392 0.4867215  0.48668528 0.4866805  0.48669907 0.4866638\n",
            " 0.48668647 0.48666713]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4246322280087043e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48729372 0.48734266 0.487347   0.48726445 0.48737502 0.48722237\n",
            " 0.48723394 0.48720643 0.48720887 0.48733026 0.4873049  0.4872514\n",
            " 0.487289   0.4874076  0.48726445 0.4873267  0.48739257 0.48719877\n",
            " 0.48731494 0.48727816]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.075630517443642e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4824283  0.48244217 0.4824382  0.48238784 0.48246285 0.48235512\n",
            " 0.48234573 0.48235005 0.4823661  0.4823721  0.4823511  0.482374\n",
            " 0.48239854 0.4824494  0.48237923 0.48242813 0.4824436  0.48237175\n",
            " 0.48241857 0.48233855]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.9106769690988585e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50654763 0.50655645 0.5065656  0.5065256  0.50657165 0.50650036\n",
            " 0.50650024 0.5064729  0.506489   0.50654495 0.5065394  0.50651693\n",
            " 0.5065161  0.50657684 0.50652146 0.5065328  0.5065587  0.5064718\n",
            " 0.5065718  0.506555  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.179068153258413e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5184115  0.5183772  0.5183828  0.51839685 0.51837206 0.5184644\n",
            " 0.5184333  0.5184188  0.51844114 0.5184071  0.5184341  0.518437\n",
            " 0.51841545 0.51838386 0.51840466 0.5183962  0.5183931  0.5184269\n",
            " 0.5183857  0.5184326 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.438484261801932e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4866969  0.48667306 0.48667306 0.48668483 0.4866587  0.4866742\n",
            " 0.4866829  0.48667276 0.48669627 0.48669386 0.48669335 0.48668718\n",
            " 0.48669392 0.4867215  0.48668528 0.4866805  0.48669907 0.4866638\n",
            " 0.48668647 0.48666713]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4246322280087043e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48729372 0.48734266 0.487347   0.48726445 0.48737502 0.48722237\n",
            " 0.48723394 0.48720643 0.48720887 0.48733026 0.4873049  0.4872514\n",
            " 0.487289   0.4874076  0.48726445 0.4873267  0.48739257 0.48719877\n",
            " 0.48731494 0.48727816]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.075630517443642e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4824283  0.48244217 0.4824382  0.48238784 0.48246285 0.48235512\n",
            " 0.48234573 0.48235005 0.4823661  0.4823721  0.4823511  0.482374\n",
            " 0.48239854 0.4824494  0.48237923 0.48242813 0.4824436  0.48237175\n",
            " 0.48241857 0.48233855]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.9106769690988585e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50654763 0.50655645 0.5065656  0.5065256  0.50657165 0.50650036\n",
            " 0.50650024 0.5064729  0.506489   0.50654495 0.5065394  0.50651693\n",
            " 0.5065161  0.50657684 0.50652146 0.5065328  0.5065587  0.5064718\n",
            " 0.5065718  0.506555  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.179068153258413e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5184115  0.5183772  0.5183828  0.51839685 0.51837206 0.5184644\n",
            " 0.5184333  0.5184188  0.51844114 0.5184071  0.5184341  0.518437\n",
            " 0.51841545 0.51838386 0.51840466 0.5183962  0.5183931  0.5184269\n",
            " 0.5183857  0.5184326 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.438484261801932e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4866969  0.48667306 0.48667306 0.48668483 0.4866587  0.4866742\n",
            " 0.4866829  0.48667276 0.48669627 0.48669386 0.48669335 0.48668718\n",
            " 0.48669392 0.4867215  0.48668528 0.4866805  0.48669907 0.4866638\n",
            " 0.48668647 0.48666713]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4246322280087043e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48729372 0.48734266 0.487347   0.48726445 0.48737502 0.48722237\n",
            " 0.48723394 0.48720643 0.48720887 0.48733026 0.4873049  0.4872514\n",
            " 0.487289   0.4874076  0.48726445 0.4873267  0.48739257 0.48719877\n",
            " 0.48731494 0.48727816]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.075630517443642e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.4824283  0.48244217 0.4824382  0.48238784 0.48246285 0.48235512\n",
            " 0.48234573 0.48235005 0.4823661  0.4823721  0.4823511  0.482374\n",
            " 0.48239854 0.4824494  0.48237923 0.48242813 0.4824436  0.48237175\n",
            " 0.48241857 0.48233855]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.9106769690988585e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50654763 0.50655645 0.5065656  0.5065256  0.50657165 0.50650036\n",
            " 0.50650024 0.5064729  0.506489   0.50654495 0.5065394  0.50651693\n",
            " 0.5065161  0.50657684 0.50652146 0.5065328  0.5065587  0.5064718\n",
            " 0.5065718  0.506555  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.179068153258413e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5184115  0.5183772  0.5183828  0.51839685 0.51837206 0.5184644\n",
            " 0.5184333  0.5184188  0.51844114 0.5184071  0.5184341  0.518437\n",
            " 0.51841545 0.51838386 0.51840466 0.5183962  0.5183931  0.5184269\n",
            " 0.5183857  0.5184326 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.438484261801932e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4866969  0.48667306 0.48667306 0.48668483 0.4866587  0.4866742\n",
            " 0.4866829  0.48667276 0.48669627 0.48669386 0.48669335 0.48668718\n",
            " 0.48669392 0.4867215  0.48668528 0.4866805  0.48669907 0.4866638\n",
            " 0.48668647 0.48666713]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4246322280087043e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48729372 0.48734266 0.487347   0.48726445 0.48737502 0.48722237\n",
            " 0.48723394 0.48720643 0.48720887 0.48733026 0.4873049  0.4872514\n",
            " 0.487289   0.4874076  0.48726445 0.4873267  0.48739257 0.48719877\n",
            " 0.48731494 0.48727816]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.075630517443642e-05\n",
            "Epoch 7/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48239905 0.5065212  0.5184302  0.48666778 0.4872663 ]\n",
            " [0.48234078 0.5065734  0.5184264  0.48668024 0.48729873]\n",
            " [0.48242766 0.5065524  0.518401   0.48669901 0.48732892]\n",
            " [0.4824125  0.5065634  0.5184025  0.48671046 0.48732373]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48246196 0.5065879  0.51841944 0.48672363 0.48736706]\n",
            " [0.48245072 0.50653684 0.51844066 0.48673677 0.48736542]\n",
            " [0.48227948 0.5065757  0.51849896 0.48669183 0.4872508 ]\n",
            " [0.4824592  0.5065488  0.5184503  0.48671874 0.4873128 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824669  0.50662434 0.5184481  0.4867539  0.48748863]\n",
            " [0.48231617 0.50656193 0.51852953 0.48667052 0.48727146]\n",
            " [0.48245686 0.50659686 0.51843643 0.48670685 0.48743513]\n",
            " [0.48244682 0.5066104  0.5184109  0.48673218 0.48749986]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824381  0.50657105 0.51846504 0.48672983 0.48736823]\n",
            " [0.48246193 0.50662273 0.51842827 0.48675147 0.48756653]\n",
            " [0.48246711 0.50662965 0.51849157 0.48676032 0.4874872 ]\n",
            " [0.48243588 0.50658697 0.51851016 0.48674113 0.487416  ]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48250705 0.5065853  0.51847637 0.48675823 0.48747662]\n",
            " [0.48249343 0.5066412  0.5185138  0.48677173 0.48751011]\n",
            " [0.4824514  0.5065998  0.5185321  0.48675013 0.4874143 ]\n",
            " [0.4825022  0.5066192  0.5184806  0.48675424 0.4875361 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48248568 0.5065764  0.5185082  0.48673978 0.48747152]\n",
            " [0.48248643 0.5066021  0.51849896 0.4867368  0.48753983]\n",
            " [0.48255706 0.50665027 0.5185231  0.48680544 0.48765174]\n",
            " [0.4825149  0.50661635 0.5184915  0.48675966 0.48755193]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48248997 0.50658447 0.5185547  0.4867664  0.48746943]\n",
            " [0.48261344 0.50669724 0.5184802  0.4867912  0.48766   ]\n",
            " [0.4824665  0.50656736 0.5185649  0.48676625 0.48745984]\n",
            " [0.48251238 0.50663275 0.5185141  0.48677105 0.48753652]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824827  0.50664043 0.5185283  0.4867842  0.4875721 ]\n",
            " [0.4825284  0.5066726  0.5185052  0.4868257  0.48764077]\n",
            " [0.48251736 0.50661004 0.5184807  0.4867937  0.48758212]\n",
            " [0.48248613 0.50656676 0.51851505 0.48678353 0.48750627]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4825387  0.5066361  0.5185052  0.48682067 0.4876341 ]\n",
            " [0.48248804 0.5066417  0.5185394  0.48681408 0.487621  ]\n",
            " [0.48238343 0.50665987 0.5185692  0.48677003 0.48750442]\n",
            " [0.4824649  0.5065571  0.51856226 0.4868164  0.48749608]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4824664  0.50655395 0.5185385  0.48679936 0.48750257]\n",
            " [0.48256266 0.5066685  0.51849544 0.48682597 0.48767632]\n",
            " [0.48255137 0.5066075  0.51847523 0.48683202 0.48760384]\n",
            " [0.48243353 0.5066039  0.51854634 0.48677167 0.4875197 ]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4825815  0.50668263 0.51855856 0.4868561  0.4876521 ]\n",
            " [0.48269764 0.50675    0.5185175  0.48686323 0.4878049 ]\n",
            " [0.4824486  0.5066535  0.51860744 0.48684454 0.4875436 ]\n",
            " [0.48258176 0.50669575 0.5185546  0.4868915  0.487679  ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48260134 0.5067107  0.5185379  0.48689547 0.48770207]\n",
            " [0.48257792 0.5067114  0.5185799  0.48691264 0.48771238]\n",
            " [0.48256654 0.5067413  0.51857615 0.4869153  0.48775795]\n",
            " [0.48266116 0.50671506 0.5185608  0.48688233 0.48771545]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826617  0.5067538  0.518575   0.4869553  0.48779458]\n",
            " [0.48250625 0.50676745 0.5186492  0.48688817 0.48771113]\n",
            " [0.48262203 0.50672257 0.5186022  0.4869343  0.4877254 ]\n",
            " [0.48249757 0.5066508  0.51866853 0.48689976 0.4876111 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48259303 0.50672716 0.5186183  0.48696035 0.48770893]\n",
            " [0.48257735 0.5067136  0.5186212  0.48695526 0.48768854]\n",
            " [0.4826055  0.5067924  0.5185737  0.48698822 0.48789403]\n",
            " [0.48250985 0.5066587  0.51866597 0.48693728 0.48760003]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48262256 0.5067246  0.5185857  0.4869381  0.4878244 ]\n",
            " [0.4826585  0.5067692  0.51855236 0.48693717 0.4879159 ]\n",
            " [0.48261335 0.50670874 0.51860017 0.48692444 0.48778215]\n",
            " [0.482621   0.5067165  0.5185989  0.486942   0.48777372]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826254  0.5067495  0.5186576  0.4869638  0.4877918 ]\n",
            " [0.4825657  0.5068014  0.51865476 0.4869743  0.48782218]\n",
            " [0.4826529  0.50678277 0.5186317  0.48699594 0.4878573 ]\n",
            " [0.4826386  0.50679284 0.51863235 0.48700768 0.48785233]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48266178 0.50678855 0.51861393 0.48697978 0.4878481 ]\n",
            " [0.48265123 0.5067368  0.5186346  0.48699293 0.48784572]\n",
            " [0.482476   0.50677085 0.5186898  0.4869403  0.48771918]\n",
            " [0.48266003 0.5067479  0.5186434  0.48697463 0.48779288]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48264113 0.5068132  0.5186368  0.48702022 0.48791224]\n",
            " [0.48248973 0.50674576 0.51871336 0.48693067 0.48768595]\n",
            " [0.48263136 0.50678563 0.51862484 0.486973   0.48785874]\n",
            " [0.482623   0.50679827 0.51859814 0.48700088 0.4879282 ]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48259953 0.5067387  0.51862234 0.4869669  0.48775378]\n",
            " [0.48262542 0.5067925  0.51858693 0.4869928  0.48795977]\n",
            " [0.4826293  0.5067995  0.51864946 0.48699808 0.48787364]\n",
            " [0.48259723 0.50675577 0.518668   0.48697788 0.48780125]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48263088 0.5067382  0.5186102  0.48698515 0.48780626]\n",
            " [0.48261765 0.50679463 0.51864785 0.4869983  0.48783892]\n",
            " [0.48257563 0.5067512  0.51866466 0.48697463 0.48773992]\n",
            " [0.48262745 0.506773   0.51861453 0.48698306 0.487868  ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826062  0.5067303  0.5186508  0.48697188 0.48775738]\n",
            " [0.4826078  0.50675696 0.5186423  0.48697007 0.487827  ]\n",
            " [0.48267835 0.5068073  0.5186681  0.48704106 0.48794127]\n",
            " [0.4826366  0.5067717  0.5186348  0.48699448 0.48784107]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4825813  0.50669557 0.5186701  0.48695776 0.48771992]\n",
            " [0.48270532 0.506811   0.51859784 0.48698676 0.48791635]\n",
            " [0.48255765 0.506678   0.51868004 0.4869569  0.48770934]\n",
            " [0.48260412 0.5067447  0.51863027 0.4869641  0.4877894 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48259515 0.50677633 0.5186629  0.4869591  0.4877973 ]\n",
            " [0.4826417  0.5068104  0.5186419  0.4870029  0.48786902]\n",
            " [0.4826311  0.50674677 0.5186162  0.4869708  0.48781052]\n",
            " [0.48259884 0.50670224 0.5186495  0.48695856 0.4877318 ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48263922 0.50676286 0.51863205 0.48698246 0.48784435]\n",
            " [0.48258886 0.5067683  0.5186655  0.48697582 0.4878312 ]\n",
            " [0.48248395 0.50678384 0.5186922  0.48692828 0.48770958]\n",
            " [0.4825658  0.5066818  0.51868665 0.48697644 0.48770368]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48258212 0.506702   0.51867044 0.48696792 0.48771885]\n",
            " [0.4826788  0.5068201  0.5186301  0.48699686 0.4878959 ]\n",
            " [0.48266727 0.50675756 0.5186087  0.48700228 0.4878226 ]\n",
            " [0.4825487  0.50675213 0.51867807 0.4869395  0.48773527]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48262516 0.50676644 0.5186378  0.48697257 0.48779497]\n",
            " [0.4827414  0.50683534 0.51859814 0.48698112 0.48794985]\n",
            " [0.48249248 0.50673586 0.51868534 0.48695818 0.48768312]\n",
            " [0.48262566 0.5067797  0.51863426 0.48700812 0.4878222 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48264518 0.50676936 0.5186071  0.4869725  0.4878251 ]\n",
            " [0.48262146 0.5067701  0.51864886 0.4869891  0.48783445]\n",
            " [0.4826099  0.50680006 0.5186453  0.4869918  0.48787996]\n",
            " [0.4827051  0.5067741  0.5186299  0.48695943 0.48783827]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826904  0.5067885  0.51860934 0.4869947  0.48787916]\n",
            " [0.48253533 0.50680184 0.51868296 0.48692712 0.48779434]\n",
            " [0.482651   0.5067571  0.518636   0.48697367 0.48780957]\n",
            " [0.48252675 0.50668484 0.5187018  0.4869385  0.48769382]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48261335 0.5067388  0.5186293  0.4869694  0.48777202]\n",
            " [0.48259762 0.50672513 0.5186322  0.48696437 0.4877516 ]\n",
            " [0.48262548 0.5068035  0.5185849  0.4869969  0.48795778]\n",
            " [0.48252994 0.50666994 0.5186766  0.4869462  0.4876619 ]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48265353 0.5067661  0.51861614 0.48697656 0.4878803 ]\n",
            " [0.48268914 0.50681096 0.51858306 0.48697546 0.48797145]\n",
            " [0.4826438  0.5067498  0.5186305  0.4869624  0.48783726]\n",
            " [0.4826513  0.5067576  0.51862955 0.48697987 0.4878288 ]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4826254  0.4825657  0.4826529  0.4826386  0.48266178 0.48265123\n",
            " 0.482476   0.48266003 0.48264113 0.48248973 0.48263136 0.482623\n",
            " 0.48259953 0.48262542 0.4826293  0.48259723 0.48263088 0.48261765\n",
            " 0.48257563 0.48262745 0.4826062  0.4826078  0.48267835 0.4826366\n",
            " 0.4825813  0.48270532 0.48255765 0.48260412 0.48259515 0.4826417\n",
            " 0.4826311  0.48259884 0.48263922 0.48258886 0.48248395 0.4825658\n",
            " 0.48258212 0.4826788  0.48266727 0.4825487  0.48262516 0.4827414\n",
            " 0.48249248 0.48262566 0.48264518 0.48262146 0.4826099  0.4827051\n",
            " 0.4826904  0.48253533 0.482651   0.48252675 0.48261335 0.48259762\n",
            " 0.48262548 0.48252994 0.48265353 0.48268914 0.4826438  0.4826513 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.464918285724707e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5067495  0.5068014  0.50678277 0.50679284 0.50678855 0.5067368\n",
            " 0.50677085 0.5067479  0.5068132  0.50674576 0.50678563 0.50679827\n",
            " 0.5067387  0.5067925  0.5067995  0.50675577 0.5067382  0.50679463\n",
            " 0.5067512  0.506773   0.5067303  0.50675696 0.5068073  0.5067717\n",
            " 0.50669557 0.506811   0.506678   0.5067447  0.50677633 0.5068104\n",
            " 0.50674677 0.50670224 0.50676286 0.5067683  0.50678384 0.5066818\n",
            " 0.506702   0.5068201  0.50675756 0.50675213 0.50676644 0.50683534\n",
            " 0.50673586 0.5067797  0.50676936 0.5067701  0.50680006 0.5067741\n",
            " 0.5067885  0.50680184 0.5067571  0.50668484 0.5067388  0.50672513\n",
            " 0.5068035  0.50666994 0.5067661  0.50681096 0.5067498  0.5067576 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.718130392371677e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5186576  0.51865476 0.5186317  0.51863235 0.51861393 0.5186346\n",
            " 0.5186898  0.5186434  0.5186368  0.51871336 0.51862484 0.51859814\n",
            " 0.51862234 0.51858693 0.51864946 0.518668   0.5186102  0.51864785\n",
            " 0.51866466 0.51861453 0.5186508  0.5186423  0.5186681  0.5186348\n",
            " 0.5186701  0.51859784 0.51868004 0.51863027 0.5186629  0.5186419\n",
            " 0.5186162  0.5186495  0.51863205 0.5186655  0.5186922  0.51868665\n",
            " 0.51867044 0.5186301  0.5186087  0.51867807 0.5186378  0.51859814\n",
            " 0.51868534 0.51863426 0.5186071  0.51864886 0.5186453  0.5186299\n",
            " 0.51860934 0.51868296 0.518636   0.5187018  0.5186293  0.5186322\n",
            " 0.5185849  0.5186766  0.51861614 0.51858306 0.5186305  0.51862955]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.9764281862298958e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.4869638  0.4869743  0.48699594 0.48700768 0.48697978 0.48699293\n",
            " 0.4869403  0.48697463 0.48702022 0.48693067 0.486973   0.48700088\n",
            " 0.4869669  0.4869928  0.48699808 0.48697788 0.48698515 0.4869983\n",
            " 0.48697463 0.48698306 0.48697188 0.48697007 0.48704106 0.48699448\n",
            " 0.48695776 0.48698676 0.4869569  0.4869641  0.4869591  0.4870029\n",
            " 0.4869708  0.48695856 0.48698246 0.48697582 0.48692828 0.48697644\n",
            " 0.48696792 0.48699686 0.48700228 0.4869395  0.48697257 0.48698112\n",
            " 0.48695818 0.48700812 0.4869725  0.4869891  0.4869918  0.48695943\n",
            " 0.4869947  0.48692712 0.48697367 0.4869385  0.4869694  0.48696437\n",
            " 0.4869969  0.4869462  0.48697656 0.48697546 0.4869624  0.48697987]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.1973040929879062e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4877918  0.48782218 0.4878573  0.48785233 0.4878481  0.48784572\n",
            " 0.48771918 0.48779288 0.48791224 0.48768595 0.48785874 0.4879282\n",
            " 0.48775378 0.48795977 0.48787364 0.48780125 0.48780626 0.48783892\n",
            " 0.48773992 0.487868   0.48775738 0.487827   0.48794127 0.48784107\n",
            " 0.48771992 0.48791635 0.48770934 0.4877894  0.4877973  0.48786902\n",
            " 0.48781052 0.4877318  0.48784435 0.4878312  0.48770958 0.48770368\n",
            " 0.48771885 0.4878959  0.4878226  0.48773527 0.48779497 0.48794985\n",
            " 0.48768312 0.4878222  0.4878251  0.48783445 0.48787996 0.48783827\n",
            " 0.48787916 0.48779434 0.48780957 0.48769382 0.48777202 0.4877516\n",
            " 0.48795778 0.4876619  0.4878803  0.48797145 0.48783726 0.4878288 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.544078107457608e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4826254  0.4825657  0.4826529  0.4826386  0.48266178 0.48265123\n",
            " 0.482476   0.48266003 0.48264113 0.48248973 0.48263136 0.482623\n",
            " 0.48259953 0.48262542 0.4826293  0.48259723 0.48263088 0.48261765\n",
            " 0.48257563 0.48262745 0.4826062  0.4826078  0.48267835 0.4826366\n",
            " 0.4825813  0.48270532 0.48255765 0.48260412 0.48259515 0.4826417\n",
            " 0.4826311  0.48259884 0.48263922 0.48258886 0.48248395 0.4825658\n",
            " 0.48258212 0.4826788  0.48266727 0.4825487  0.48262516 0.4827414\n",
            " 0.48249248 0.48262566 0.48264518 0.48262146 0.4826099  0.4827051\n",
            " 0.4826904  0.48253533 0.482651   0.48252675 0.48261335 0.48259762\n",
            " 0.48262548 0.48252994 0.48265353 0.48268914 0.4826438  0.4826513 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.464918285724707e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5067495  0.5068014  0.50678277 0.50679284 0.50678855 0.5067368\n",
            " 0.50677085 0.5067479  0.5068132  0.50674576 0.50678563 0.50679827\n",
            " 0.5067387  0.5067925  0.5067995  0.50675577 0.5067382  0.50679463\n",
            " 0.5067512  0.506773   0.5067303  0.50675696 0.5068073  0.5067717\n",
            " 0.50669557 0.506811   0.506678   0.5067447  0.50677633 0.5068104\n",
            " 0.50674677 0.50670224 0.50676286 0.5067683  0.50678384 0.5066818\n",
            " 0.506702   0.5068201  0.50675756 0.50675213 0.50676644 0.50683534\n",
            " 0.50673586 0.5067797  0.50676936 0.5067701  0.50680006 0.5067741\n",
            " 0.5067885  0.50680184 0.5067571  0.50668484 0.5067388  0.50672513\n",
            " 0.5068035  0.50666994 0.5067661  0.50681096 0.5067498  0.5067576 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.718130392371677e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5186576  0.51865476 0.5186317  0.51863235 0.51861393 0.5186346\n",
            " 0.5186898  0.5186434  0.5186368  0.51871336 0.51862484 0.51859814\n",
            " 0.51862234 0.51858693 0.51864946 0.518668   0.5186102  0.51864785\n",
            " 0.51866466 0.51861453 0.5186508  0.5186423  0.5186681  0.5186348\n",
            " 0.5186701  0.51859784 0.51868004 0.51863027 0.5186629  0.5186419\n",
            " 0.5186162  0.5186495  0.51863205 0.5186655  0.5186922  0.51868665\n",
            " 0.51867044 0.5186301  0.5186087  0.51867807 0.5186378  0.51859814\n",
            " 0.51868534 0.51863426 0.5186071  0.51864886 0.5186453  0.5186299\n",
            " 0.51860934 0.51868296 0.518636   0.5187018  0.5186293  0.5186322\n",
            " 0.5185849  0.5186766  0.51861614 0.51858306 0.5186305  0.51862955]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.9764281862298958e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.4869638  0.4869743  0.48699594 0.48700768 0.48697978 0.48699293\n",
            " 0.4869403  0.48697463 0.48702022 0.48693067 0.486973   0.48700088\n",
            " 0.4869669  0.4869928  0.48699808 0.48697788 0.48698515 0.4869983\n",
            " 0.48697463 0.48698306 0.48697188 0.48697007 0.48704106 0.48699448\n",
            " 0.48695776 0.48698676 0.4869569  0.4869641  0.4869591  0.4870029\n",
            " 0.4869708  0.48695856 0.48698246 0.48697582 0.48692828 0.48697644\n",
            " 0.48696792 0.48699686 0.48700228 0.4869395  0.48697257 0.48698112\n",
            " 0.48695818 0.48700812 0.4869725  0.4869891  0.4869918  0.48695943\n",
            " 0.4869947  0.48692712 0.48697367 0.4869385  0.4869694  0.48696437\n",
            " 0.4869969  0.4869462  0.48697656 0.48697546 0.4869624  0.48697987]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.1973040929879062e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4877918  0.48782218 0.4878573  0.48785233 0.4878481  0.48784572\n",
            " 0.48771918 0.48779288 0.48791224 0.48768595 0.48785874 0.4879282\n",
            " 0.48775378 0.48795977 0.48787364 0.48780125 0.48780626 0.48783892\n",
            " 0.48773992 0.487868   0.48775738 0.487827   0.48794127 0.48784107\n",
            " 0.48771992 0.48791635 0.48770934 0.4877894  0.4877973  0.48786902\n",
            " 0.48781052 0.4877318  0.48784435 0.4878312  0.48770958 0.48770368\n",
            " 0.48771885 0.4878959  0.4878226  0.48773527 0.48779497 0.48794985\n",
            " 0.48768312 0.4878222  0.4878251  0.48783445 0.48787996 0.48783827\n",
            " 0.48787916 0.48779434 0.48780957 0.48769382 0.48777202 0.4877516\n",
            " 0.48795778 0.4876619  0.4878803  0.48797145 0.48783726 0.4878288 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.544078107457608e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4826254  0.4825657  0.4826529  0.4826386  0.48266178 0.48265123\n",
            " 0.482476   0.48266003 0.48264113 0.48248973 0.48263136 0.482623\n",
            " 0.48259953 0.48262542 0.4826293  0.48259723 0.48263088 0.48261765\n",
            " 0.48257563 0.48262745 0.4826062  0.4826078  0.48267835 0.4826366\n",
            " 0.4825813  0.48270532 0.48255765 0.48260412 0.48259515 0.4826417\n",
            " 0.4826311  0.48259884 0.48263922 0.48258886 0.48248395 0.4825658\n",
            " 0.48258212 0.4826788  0.48266727 0.4825487  0.48262516 0.4827414\n",
            " 0.48249248 0.48262566 0.48264518 0.48262146 0.4826099  0.4827051\n",
            " 0.4826904  0.48253533 0.482651   0.48252675 0.48261335 0.48259762\n",
            " 0.48262548 0.48252994 0.48265353 0.48268914 0.4826438  0.4826513 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.464918285724707e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5067495  0.5068014  0.50678277 0.50679284 0.50678855 0.5067368\n",
            " 0.50677085 0.5067479  0.5068132  0.50674576 0.50678563 0.50679827\n",
            " 0.5067387  0.5067925  0.5067995  0.50675577 0.5067382  0.50679463\n",
            " 0.5067512  0.506773   0.5067303  0.50675696 0.5068073  0.5067717\n",
            " 0.50669557 0.506811   0.506678   0.5067447  0.50677633 0.5068104\n",
            " 0.50674677 0.50670224 0.50676286 0.5067683  0.50678384 0.5066818\n",
            " 0.506702   0.5068201  0.50675756 0.50675213 0.50676644 0.50683534\n",
            " 0.50673586 0.5067797  0.50676936 0.5067701  0.50680006 0.5067741\n",
            " 0.5067885  0.50680184 0.5067571  0.50668484 0.5067388  0.50672513\n",
            " 0.5068035  0.50666994 0.5067661  0.50681096 0.5067498  0.5067576 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.718130392371677e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5186576  0.51865476 0.5186317  0.51863235 0.51861393 0.5186346\n",
            " 0.5186898  0.5186434  0.5186368  0.51871336 0.51862484 0.51859814\n",
            " 0.51862234 0.51858693 0.51864946 0.518668   0.5186102  0.51864785\n",
            " 0.51866466 0.51861453 0.5186508  0.5186423  0.5186681  0.5186348\n",
            " 0.5186701  0.51859784 0.51868004 0.51863027 0.5186629  0.5186419\n",
            " 0.5186162  0.5186495  0.51863205 0.5186655  0.5186922  0.51868665\n",
            " 0.51867044 0.5186301  0.5186087  0.51867807 0.5186378  0.51859814\n",
            " 0.51868534 0.51863426 0.5186071  0.51864886 0.5186453  0.5186299\n",
            " 0.51860934 0.51868296 0.518636   0.5187018  0.5186293  0.5186322\n",
            " 0.5185849  0.5186766  0.51861614 0.51858306 0.5186305  0.51862955]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.9764281862298958e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.4869638  0.4869743  0.48699594 0.48700768 0.48697978 0.48699293\n",
            " 0.4869403  0.48697463 0.48702022 0.48693067 0.486973   0.48700088\n",
            " 0.4869669  0.4869928  0.48699808 0.48697788 0.48698515 0.4869983\n",
            " 0.48697463 0.48698306 0.48697188 0.48697007 0.48704106 0.48699448\n",
            " 0.48695776 0.48698676 0.4869569  0.4869641  0.4869591  0.4870029\n",
            " 0.4869708  0.48695856 0.48698246 0.48697582 0.48692828 0.48697644\n",
            " 0.48696792 0.48699686 0.48700228 0.4869395  0.48697257 0.48698112\n",
            " 0.48695818 0.48700812 0.4869725  0.4869891  0.4869918  0.48695943\n",
            " 0.4869947  0.48692712 0.48697367 0.4869385  0.4869694  0.48696437\n",
            " 0.4869969  0.4869462  0.48697656 0.48697546 0.4869624  0.48697987]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.1973040929879062e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4877918  0.48782218 0.4878573  0.48785233 0.4878481  0.48784572\n",
            " 0.48771918 0.48779288 0.48791224 0.48768595 0.48785874 0.4879282\n",
            " 0.48775378 0.48795977 0.48787364 0.48780125 0.48780626 0.48783892\n",
            " 0.48773992 0.487868   0.48775738 0.487827   0.48794127 0.48784107\n",
            " 0.48771992 0.48791635 0.48770934 0.4877894  0.4877973  0.48786902\n",
            " 0.48781052 0.4877318  0.48784435 0.4878312  0.48770958 0.48770368\n",
            " 0.48771885 0.4878959  0.4878226  0.48773527 0.48779497 0.48794985\n",
            " 0.48768312 0.4878222  0.4878251  0.48783445 0.48787996 0.48783827\n",
            " 0.48787916 0.48779434 0.48780957 0.48769382 0.48777202 0.4877516\n",
            " 0.48795778 0.4876619  0.4878803  0.48797145 0.48783726 0.4878288 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.544078107457608e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.4826254  0.4825657  0.4826529  0.4826386  0.48266178 0.48265123\n",
            " 0.482476   0.48266003 0.48264113 0.48248973 0.48263136 0.482623\n",
            " 0.48259953 0.48262542 0.4826293  0.48259723 0.48263088 0.48261765\n",
            " 0.48257563 0.48262745 0.4826062  0.4826078  0.48267835 0.4826366\n",
            " 0.4825813  0.48270532 0.48255765 0.48260412 0.48259515 0.4826417\n",
            " 0.4826311  0.48259884 0.48263922 0.48258886 0.48248395 0.4825658\n",
            " 0.48258212 0.4826788  0.48266727 0.4825487  0.48262516 0.4827414\n",
            " 0.48249248 0.48262566 0.48264518 0.48262146 0.4826099  0.4827051\n",
            " 0.4826904  0.48253533 0.482651   0.48252675 0.48261335 0.48259762\n",
            " 0.48262548 0.48252994 0.48265353 0.48268914 0.4826438  0.4826513 ]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.464918285724707e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5067495  0.5068014  0.50678277 0.50679284 0.50678855 0.5067368\n",
            " 0.50677085 0.5067479  0.5068132  0.50674576 0.50678563 0.50679827\n",
            " 0.5067387  0.5067925  0.5067995  0.50675577 0.5067382  0.50679463\n",
            " 0.5067512  0.506773   0.5067303  0.50675696 0.5068073  0.5067717\n",
            " 0.50669557 0.506811   0.506678   0.5067447  0.50677633 0.5068104\n",
            " 0.50674677 0.50670224 0.50676286 0.5067683  0.50678384 0.5066818\n",
            " 0.506702   0.5068201  0.50675756 0.50675213 0.50676644 0.50683534\n",
            " 0.50673586 0.5067797  0.50676936 0.5067701  0.50680006 0.5067741\n",
            " 0.5067885  0.50680184 0.5067571  0.50668484 0.5067388  0.50672513\n",
            " 0.5068035  0.50666994 0.5067661  0.50681096 0.5067498  0.5067576 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.718130392371677e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5186576  0.51865476 0.5186317  0.51863235 0.51861393 0.5186346\n",
            " 0.5186898  0.5186434  0.5186368  0.51871336 0.51862484 0.51859814\n",
            " 0.51862234 0.51858693 0.51864946 0.518668   0.5186102  0.51864785\n",
            " 0.51866466 0.51861453 0.5186508  0.5186423  0.5186681  0.5186348\n",
            " 0.5186701  0.51859784 0.51868004 0.51863027 0.5186629  0.5186419\n",
            " 0.5186162  0.5186495  0.51863205 0.5186655  0.5186922  0.51868665\n",
            " 0.51867044 0.5186301  0.5186087  0.51867807 0.5186378  0.51859814\n",
            " 0.51868534 0.51863426 0.5186071  0.51864886 0.5186453  0.5186299\n",
            " 0.51860934 0.51868296 0.518636   0.5187018  0.5186293  0.5186322\n",
            " 0.5185849  0.5186766  0.51861614 0.51858306 0.5186305  0.51862955]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.9764281862298958e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.4869638  0.4869743  0.48699594 0.48700768 0.48697978 0.48699293\n",
            " 0.4869403  0.48697463 0.48702022 0.48693067 0.486973   0.48700088\n",
            " 0.4869669  0.4869928  0.48699808 0.48697788 0.48698515 0.4869983\n",
            " 0.48697463 0.48698306 0.48697188 0.48697007 0.48704106 0.48699448\n",
            " 0.48695776 0.48698676 0.4869569  0.4869641  0.4869591  0.4870029\n",
            " 0.4869708  0.48695856 0.48698246 0.48697582 0.48692828 0.48697644\n",
            " 0.48696792 0.48699686 0.48700228 0.4869395  0.48697257 0.48698112\n",
            " 0.48695818 0.48700812 0.4869725  0.4869891  0.4869918  0.48695943\n",
            " 0.4869947  0.48692712 0.48697367 0.4869385  0.4869694  0.48696437\n",
            " 0.4869969  0.4869462  0.48697656 0.48697546 0.4869624  0.48697987]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.1973040929879062e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4877918  0.48782218 0.4878573  0.48785233 0.4878481  0.48784572\n",
            " 0.48771918 0.48779288 0.48791224 0.48768595 0.48785874 0.4879282\n",
            " 0.48775378 0.48795977 0.48787364 0.48780125 0.48780626 0.48783892\n",
            " 0.48773992 0.487868   0.48775738 0.487827   0.48794127 0.48784107\n",
            " 0.48771992 0.48791635 0.48770934 0.4877894  0.4877973  0.48786902\n",
            " 0.48781052 0.4877318  0.48784435 0.4878312  0.48770958 0.48770368\n",
            " 0.48771885 0.4878959  0.4878226  0.48773527 0.48779497 0.48794985\n",
            " 0.48768312 0.4878222  0.4878251  0.48783445 0.48787996 0.48783827\n",
            " 0.48787916 0.48779434 0.48780957 0.48769382 0.48777202 0.4877516\n",
            " 0.48795778 0.4876619  0.4878803  0.48797145 0.48783726 0.4878288 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.544078107457608e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48259565 0.5067555  0.51867354 0.48696914 0.4877853 ]\n",
            " [0.4825604  0.5067086  0.5186918  0.4869739  0.48770547]\n",
            " [0.48253673 0.5066895  0.5186787  0.48695943 0.48770756]\n",
            " [0.48254922 0.50677925 0.51867324 0.4869676  0.48775095]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48257786 0.5067293  0.51863956 0.4869607  0.4877268 ]\n",
            " [0.4826368  0.5067538  0.5186482  0.4869891  0.4878763 ]\n",
            " [0.48267722 0.50679106 0.51861584 0.48696664 0.4879129 ]\n",
            " [0.4825588  0.5067     0.51866156 0.48697323 0.48769242]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.482671   0.5067682  0.5186371  0.4869683  0.48785076]\n",
            " [0.48264754 0.5067769  0.5186147  0.48697945 0.48782027]\n",
            " [0.48267296 0.50678676 0.51860976 0.48697385 0.48785117]\n",
            " [0.48262826 0.50673574 0.5186402  0.48698497 0.48780742]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48260283 0.5068411  0.5186437  0.48698115 0.4878622 ]\n",
            " [0.48262265 0.50677395 0.5186542  0.48698166 0.48789722]\n",
            " [0.48262465 0.50672555 0.51863223 0.4869785  0.48774543]\n",
            " [0.4826246  0.50673753 0.5186458  0.48696163 0.48779103]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48261192 0.50675315 0.51864433 0.4869729  0.48778763]\n",
            " [0.48269826 0.5068286  0.5185826  0.48700958 0.48796707]\n",
            " [0.48265675 0.5067887  0.5185859  0.4869885  0.48788452]\n",
            " [0.4825962  0.506717   0.51865286 0.48695773 0.48776454]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48259565 0.4825604  0.48253673 0.48254922 0.48257786 0.4826368\n",
            " 0.48267722 0.4825588  0.482671   0.48264754 0.48267296 0.48262826\n",
            " 0.48260283 0.48262265 0.48262465 0.4826246  0.48261192 0.48269826\n",
            " 0.48265675 0.4825962 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.456896931515075e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5067555  0.5067086  0.5066895  0.50677925 0.5067293  0.5067538\n",
            " 0.50679106 0.5067     0.5067682  0.5067769  0.50678676 0.50673574\n",
            " 0.5068411  0.50677395 0.50672555 0.50673753 0.50675315 0.5068286\n",
            " 0.5067887  0.506717  ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.931953324354254e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51867354 0.5186918  0.5186787  0.51867324 0.51863956 0.5186482\n",
            " 0.51861584 0.51866156 0.5186371  0.5186147  0.51860976 0.5186402\n",
            " 0.5186437  0.5186542  0.51863223 0.5186458  0.51864433 0.5185826\n",
            " 0.5185859  0.51865286]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.8080894480808638e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48696914 0.4869739  0.48695943 0.4869676  0.4869607  0.4869891\n",
            " 0.48696664 0.48697323 0.4869683  0.48697945 0.48697385 0.48698497\n",
            " 0.48698115 0.48698166 0.4869785  0.48696163 0.4869729  0.48700958\n",
            " 0.4869885  0.48695773]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.2101574611733668e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.4877853  0.48770547 0.48770756 0.48775095 0.4877268  0.4878763\n",
            " 0.4879129  0.48769242 0.48785076 0.48782027 0.48785117 0.48780742\n",
            " 0.4878622  0.48789722 0.48774543 0.48779103 0.48778763 0.48796707\n",
            " 0.48788452 0.48776454]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.49534519854933e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48259565 0.4825604  0.48253673 0.48254922 0.48257786 0.4826368\n",
            " 0.48267722 0.4825588  0.482671   0.48264754 0.48267296 0.48262826\n",
            " 0.48260283 0.48262265 0.48262465 0.4826246  0.48261192 0.48269826\n",
            " 0.48265675 0.4825962 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.456896931515075e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5067555  0.5067086  0.5066895  0.50677925 0.5067293  0.5067538\n",
            " 0.50679106 0.5067     0.5067682  0.5067769  0.50678676 0.50673574\n",
            " 0.5068411  0.50677395 0.50672555 0.50673753 0.50675315 0.5068286\n",
            " 0.5067887  0.506717  ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.931953324354254e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51867354 0.5186918  0.5186787  0.51867324 0.51863956 0.5186482\n",
            " 0.51861584 0.51866156 0.5186371  0.5186147  0.51860976 0.5186402\n",
            " 0.5186437  0.5186542  0.51863223 0.5186458  0.51864433 0.5185826\n",
            " 0.5185859  0.51865286]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.8080894480808638e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48696914 0.4869739  0.48695943 0.4869676  0.4869607  0.4869891\n",
            " 0.48696664 0.48697323 0.4869683  0.48697945 0.48697385 0.48698497\n",
            " 0.48698115 0.48698166 0.4869785  0.48696163 0.4869729  0.48700958\n",
            " 0.4869885  0.48695773]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.2101574611733668e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.4877853  0.48770547 0.48770756 0.48775095 0.4877268  0.4878763\n",
            " 0.4879129  0.48769242 0.48785076 0.48782027 0.48785117 0.48780742\n",
            " 0.4878622  0.48789722 0.48774543 0.48779103 0.48778763 0.48796707\n",
            " 0.48788452 0.48776454]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.49534519854933e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48259565 0.4825604  0.48253673 0.48254922 0.48257786 0.4826368\n",
            " 0.48267722 0.4825588  0.482671   0.48264754 0.48267296 0.48262826\n",
            " 0.48260283 0.48262265 0.48262465 0.4826246  0.48261192 0.48269826\n",
            " 0.48265675 0.4825962 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.456896931515075e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5067555  0.5067086  0.5066895  0.50677925 0.5067293  0.5067538\n",
            " 0.50679106 0.5067     0.5067682  0.5067769  0.50678676 0.50673574\n",
            " 0.5068411  0.50677395 0.50672555 0.50673753 0.50675315 0.5068286\n",
            " 0.5067887  0.506717  ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.931953324354254e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51867354 0.5186918  0.5186787  0.51867324 0.51863956 0.5186482\n",
            " 0.51861584 0.51866156 0.5186371  0.5186147  0.51860976 0.5186402\n",
            " 0.5186437  0.5186542  0.51863223 0.5186458  0.51864433 0.5185826\n",
            " 0.5185859  0.51865286]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.8080894480808638e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48696914 0.4869739  0.48695943 0.4869676  0.4869607  0.4869891\n",
            " 0.48696664 0.48697323 0.4869683  0.48697945 0.48697385 0.48698497\n",
            " 0.48698115 0.48698166 0.4869785  0.48696163 0.4869729  0.48700958\n",
            " 0.4869885  0.48695773]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.2101574611733668e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.4877853  0.48770547 0.48770756 0.48775095 0.4877268  0.4878763\n",
            " 0.4879129  0.48769242 0.48785076 0.48782027 0.48785117 0.48780742\n",
            " 0.4878622  0.48789722 0.48774543 0.48779103 0.48778763 0.48796707\n",
            " 0.48788452 0.48776454]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.49534519854933e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48259565 0.4825604  0.48253673 0.48254922 0.48257786 0.4826368\n",
            " 0.48267722 0.4825588  0.482671   0.48264754 0.48267296 0.48262826\n",
            " 0.48260283 0.48262265 0.48262465 0.4826246  0.48261192 0.48269826\n",
            " 0.48265675 0.4825962 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.456896931515075e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5067555  0.5067086  0.5066895  0.50677925 0.5067293  0.5067538\n",
            " 0.50679106 0.5067     0.5067682  0.5067769  0.50678676 0.50673574\n",
            " 0.5068411  0.50677395 0.50672555 0.50673753 0.50675315 0.5068286\n",
            " 0.5067887  0.506717  ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 3.931953324354254e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51867354 0.5186918  0.5186787  0.51867324 0.51863956 0.5186482\n",
            " 0.51861584 0.51866156 0.5186371  0.5186147  0.51860976 0.5186402\n",
            " 0.5186437  0.5186542  0.51863223 0.5186458  0.51864433 0.5185826\n",
            " 0.5185859  0.51865286]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.8080894480808638e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48696914 0.4869739  0.48695943 0.4869676  0.4869607  0.4869891\n",
            " 0.48696664 0.48697323 0.4869683  0.48697945 0.48697385 0.48698497\n",
            " 0.48698115 0.48698166 0.4869785  0.48696163 0.4869729  0.48700958\n",
            " 0.4869885  0.48695773]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.2101574611733668e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.4877853  0.48770547 0.48770756 0.48775095 0.4877268  0.4878763\n",
            " 0.4879129  0.48769242 0.48785076 0.48782027 0.48785117 0.48780742\n",
            " 0.4878622  0.48789722 0.48774543 0.48779103 0.48778763 0.48796707\n",
            " 0.48788452 0.48776454]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.49534519854933e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48265374 0.50677663 0.51864094 0.48699254 0.4878199 ]\n",
            " [0.48266897 0.506786   0.5186064  0.48697096 0.48787305]\n",
            " [0.48266527 0.5067949  0.51861215 0.48697138 0.48787794]\n",
            " [0.48261285 0.5067531  0.5186248  0.48697963 0.48778847]\n",
            " [0.48269063 0.5068025  0.518603   0.48695827 0.48790807]\n",
            " [0.48257884 0.5067261  0.5186913  0.48696637 0.48774257]\n",
            " [0.4825691  0.5067265  0.51866037 0.4869751  0.48775464]\n",
            " [0.4825755  0.50669926 0.5186448  0.48696664 0.48772928]\n",
            " [0.48259023 0.50671524 0.518668   0.48698866 0.48772934]\n",
            " [0.482598   0.5067743  0.5186362  0.48699018 0.4878567 ]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48257726 0.506768   0.5186611  0.48698837 0.48782927]\n",
            " [0.48259896 0.50674474 0.5186648  0.48698086 0.48777395]\n",
            " [0.48262355 0.5067441  0.5186443  0.48698932 0.48781446]\n",
            " [0.48267475 0.5068091  0.51861656 0.48701984 0.48793915]\n",
            " [0.4826056  0.506749   0.51863253 0.48698166 0.48779166]\n",
            " [0.48265514 0.5067625  0.51862544 0.4869783  0.4878562 ]\n",
            " [0.4826702  0.50679016 0.51862425 0.4869971  0.4879221 ]\n",
            " [0.48259705 0.5066984  0.5186541  0.48695785 0.48772135]\n",
            " [0.4826458  0.5068004  0.5186144  0.48698473 0.48784456]\n",
            " [0.48256367 0.50678235 0.51865923 0.48695967 0.48779884]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48265374 0.48266897 0.48266527 0.48261285 0.48269063 0.48257884\n",
            " 0.4825691  0.4825755  0.48259023 0.482598   0.48257726 0.48259896\n",
            " 0.48262355 0.48267475 0.4826056  0.48265514 0.4826702  0.48259705\n",
            " 0.4826458  0.48256367]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.990823097410612e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50677663 0.506786   0.5067949  0.5067531  0.5068025  0.5067261\n",
            " 0.5067265  0.50669926 0.50671524 0.5067743  0.506768   0.50674474\n",
            " 0.5067441  0.5068091  0.506749   0.5067625  0.50679016 0.5066984\n",
            " 0.5068004  0.50678235]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.325532088638283e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51864094 0.5186064  0.51861215 0.5186248  0.518603   0.5186913\n",
            " 0.51866037 0.5186448  0.518668   0.5186362  0.5186611  0.5186648\n",
            " 0.5186443  0.51861656 0.51863253 0.51862544 0.51862425 0.5186541\n",
            " 0.5186144  0.51865923]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.315665733476635e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48699254 0.48697096 0.48697138 0.48697963 0.48695827 0.48696637\n",
            " 0.4869751  0.48696664 0.48698866 0.48699018 0.48698837 0.48698086\n",
            " 0.48698932 0.48701984 0.48698166 0.4869783  0.4869971  0.48695785\n",
            " 0.48698473 0.48695967]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4699490748171229e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4878199  0.48787305 0.48787794 0.48778847 0.48790807 0.48774257\n",
            " 0.48775464 0.48772928 0.48772934 0.4878567  0.48782927 0.48777395\n",
            " 0.48781446 0.48793915 0.48779166 0.4878562  0.4879221  0.48772135\n",
            " 0.48784456 0.48779884]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.43021849100478e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48265374 0.48266897 0.48266527 0.48261285 0.48269063 0.48257884\n",
            " 0.4825691  0.4825755  0.48259023 0.482598   0.48257726 0.48259896\n",
            " 0.48262355 0.48267475 0.4826056  0.48265514 0.4826702  0.48259705\n",
            " 0.4826458  0.48256367]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.990823097410612e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50677663 0.506786   0.5067949  0.5067531  0.5068025  0.5067261\n",
            " 0.5067265  0.50669926 0.50671524 0.5067743  0.506768   0.50674474\n",
            " 0.5067441  0.5068091  0.506749   0.5067625  0.50679016 0.5066984\n",
            " 0.5068004  0.50678235]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.325532088638283e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51864094 0.5186064  0.51861215 0.5186248  0.518603   0.5186913\n",
            " 0.51866037 0.5186448  0.518668   0.5186362  0.5186611  0.5186648\n",
            " 0.5186443  0.51861656 0.51863253 0.51862544 0.51862425 0.5186541\n",
            " 0.5186144  0.51865923]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.315665733476635e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48699254 0.48697096 0.48697138 0.48697963 0.48695827 0.48696637\n",
            " 0.4869751  0.48696664 0.48698866 0.48699018 0.48698837 0.48698086\n",
            " 0.48698932 0.48701984 0.48698166 0.4869783  0.4869971  0.48695785\n",
            " 0.48698473 0.48695967]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4699490748171229e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4878199  0.48787305 0.48787794 0.48778847 0.48790807 0.48774257\n",
            " 0.48775464 0.48772928 0.48772934 0.4878567  0.48782927 0.48777395\n",
            " 0.48781446 0.48793915 0.48779166 0.4878562  0.4879221  0.48772135\n",
            " 0.48784456 0.48779884]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.43021849100478e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48265374 0.48266897 0.48266527 0.48261285 0.48269063 0.48257884\n",
            " 0.4825691  0.4825755  0.48259023 0.482598   0.48257726 0.48259896\n",
            " 0.48262355 0.48267475 0.4826056  0.48265514 0.4826702  0.48259705\n",
            " 0.4826458  0.48256367]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.990823097410612e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50677663 0.506786   0.5067949  0.5067531  0.5068025  0.5067261\n",
            " 0.5067265  0.50669926 0.50671524 0.5067743  0.506768   0.50674474\n",
            " 0.5067441  0.5068091  0.506749   0.5067625  0.50679016 0.5066984\n",
            " 0.5068004  0.50678235]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.325532088638283e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51864094 0.5186064  0.51861215 0.5186248  0.518603   0.5186913\n",
            " 0.51866037 0.5186448  0.518668   0.5186362  0.5186611  0.5186648\n",
            " 0.5186443  0.51861656 0.51863253 0.51862544 0.51862425 0.5186541\n",
            " 0.5186144  0.51865923]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.315665733476635e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48699254 0.48697096 0.48697138 0.48697963 0.48695827 0.48696637\n",
            " 0.4869751  0.48696664 0.48698866 0.48699018 0.48698837 0.48698086\n",
            " 0.48698932 0.48701984 0.48698166 0.4869783  0.4869971  0.48695785\n",
            " 0.48698473 0.48695967]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4699490748171229e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4878199  0.48787305 0.48787794 0.48778847 0.48790807 0.48774257\n",
            " 0.48775464 0.48772928 0.48772934 0.4878567  0.48782927 0.48777395\n",
            " 0.48781446 0.48793915 0.48779166 0.4878562  0.4879221  0.48772135\n",
            " 0.48784456 0.48779884]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.43021849100478e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48265374 0.48266897 0.48266527 0.48261285 0.48269063 0.48257884\n",
            " 0.4825691  0.4825755  0.48259023 0.482598   0.48257726 0.48259896\n",
            " 0.48262355 0.48267475 0.4826056  0.48265514 0.4826702  0.48259705\n",
            " 0.4826458  0.48256367]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.990823097410612e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.50677663 0.506786   0.5067949  0.5067531  0.5068025  0.5067261\n",
            " 0.5067265  0.50669926 0.50671524 0.5067743  0.506768   0.50674474\n",
            " 0.5067441  0.5068091  0.506749   0.5067625  0.50679016 0.5066984\n",
            " 0.5068004  0.50678235]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.325532088638283e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51864094 0.5186064  0.51861215 0.5186248  0.518603   0.5186913\n",
            " 0.51866037 0.5186448  0.518668   0.5186362  0.5186611  0.5186648\n",
            " 0.5186443  0.51861656 0.51863253 0.51862544 0.51862425 0.5186541\n",
            " 0.5186144  0.51865923]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.315665733476635e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48699254 0.48697096 0.48697138 0.48697963 0.48695827 0.48696637\n",
            " 0.4869751  0.48696664 0.48698866 0.48699018 0.48698837 0.48698086\n",
            " 0.48698932 0.48701984 0.48698166 0.4869783  0.4869971  0.48695785\n",
            " 0.48698473 0.48695967]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.4699490748171229e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.4878199  0.48787305 0.48787794 0.48778847 0.48790807 0.48774257\n",
            " 0.48775464 0.48772928 0.48772934 0.4878567  0.48782927 0.48777395\n",
            " 0.48781446 0.48793915 0.48779166 0.4878562  0.4879221  0.48772135\n",
            " 0.48784456 0.48779884]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.43021849100478e-05\n",
            "Epoch 8/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826254  0.5067495  0.5186576  0.4869638  0.4877918 ]\n",
            " [0.4825657  0.5068014  0.51865476 0.4869743  0.48782218]\n",
            " [0.4826529  0.50678277 0.5186317  0.48699594 0.4878573 ]\n",
            " [0.4826386  0.50679284 0.51863235 0.48700768 0.48785233]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826868  0.50681794 0.5186496  0.4870202  0.487895  ]\n",
            " [0.4826763  0.50676614 0.51867014 0.48703328 0.4878926 ]\n",
            " [0.4825008  0.5067997  0.5187247  0.48697984 0.487765  ]\n",
            " [0.48268512 0.50677705 0.51867884 0.48701486 0.48783964]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48269138 0.50685453 0.51867867 0.4870497  0.4880147 ]\n",
            " [0.48253933 0.50678605 0.51875377 0.4869594  0.4877861 ]\n",
            " [0.48268175 0.50682694 0.51866657 0.48700243 0.48796108]\n",
            " [0.48267412 0.5068399  0.51864    0.4870308  0.48803177]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826628  0.50679797 0.5186926  0.48702395 0.48789117]\n",
            " [0.48268998 0.5068528  0.5186579  0.48705104 0.48810014]\n",
            " [0.48269314 0.50685954 0.5187199  0.48705536 0.48801166]\n",
            " [0.48266074 0.5068154  0.51873815 0.48703495 0.48793867]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48273098 0.5068132  0.5187046  0.48705274 0.4880013 ]\n",
            " [0.4827178  0.5068699  0.51874256 0.48706594 0.4880338 ]\n",
            " [0.48267564 0.50682586 0.51875824 0.48704174 0.48793307]\n",
            " [0.48272797 0.506848   0.5187094  0.48705104 0.48806396]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48270932 0.5068035  0.5187355  0.4870331  0.48799366]\n",
            " [0.48271155 0.5068307  0.5187276  0.4870316  0.4880644 ]\n",
            " [0.48278236 0.50688195 0.5187545  0.48710278 0.4881803 ]\n",
            " [0.4827402  0.5068452  0.51872015 0.48705634 0.48807943]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48271397 0.5068102  0.51878065 0.4870586  0.48798907]\n",
            " [0.48283932 0.50692815 0.5187111  0.48708966 0.48819152]\n",
            " [0.48268995 0.50679237 0.51879007 0.4870573  0.4879775 ]\n",
            " [0.48273742 0.5068601  0.5187416  0.48706582 0.488061  ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48270598 0.5068673  0.5187551  0.48707598 0.48809174]\n",
            " [0.48275328 0.5069026  0.5187354  0.48712173 0.4881674 ]\n",
            " [0.48274288 0.50683796 0.5187087  0.4870898  0.48810887]\n",
            " [0.48270953 0.5067927  0.51874125 0.48707587 0.48802644]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48276183 0.5068644  0.51873475 0.48711467 0.48815787]\n",
            " [0.482712   0.5068701  0.5187679  0.4871081  0.48814452]\n",
            " [0.4826075  0.50688404 0.5187907  0.4870577  0.48801544]\n",
            " [0.4826887  0.50678205 0.5187868  0.48710737 0.48801303]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4826901  0.5067795  0.5187642  0.48709127 0.4880213 ]\n",
            " [0.48278686 0.50689983 0.5187271  0.48712206 0.4882034 ]\n",
            " [0.4827752  0.5068362  0.5187044  0.4871272  0.4881291 ]\n",
            " [0.48265627 0.5068297  0.5187723  0.48706248 0.48803768]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48280442 0.5069106  0.5187867  0.4871503  0.4881747 ]\n",
            " [0.48292166 0.50698197 0.5187503  0.48716068 0.4883351 ]\n",
            " [0.48267025 0.50687736 0.5188309  0.4871314  0.4880542 ]\n",
            " [0.48280507 0.50692403 0.51878417 0.48718563 0.48820257]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48282582 0.5069392  0.5187668  0.4871909  0.4882282 ]\n",
            " [0.4828012  0.50693953 0.518808   0.48720568 0.48823404]\n",
            " [0.48278877 0.50696963 0.51880527 0.48720807 0.4882797 ]\n",
            " [0.48288563 0.50694424 0.5187901  0.48717737 0.4882403 ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4828845  0.5069838  0.5188061  0.48725036 0.4883205 ]\n",
            " [0.48272845 0.5069935  0.5188756  0.48717785 0.48822764]\n",
            " [0.48284578 0.50695056 0.51883006 0.4872283  0.48824856]\n",
            " [0.48272043 0.50687486 0.5188916  0.48718816 0.48812398]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48281685 0.5069544  0.51884526 0.48725373 0.48823076]\n",
            " [0.48280084 0.5069403  0.518848   0.4872484  0.48820984]\n",
            " [0.48283082 0.5070219  0.51880354 0.48728567 0.4884245 ]\n",
            " [0.48273137 0.50688183 0.5188891  0.48722562 0.48811263]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48284742 0.50695366 0.5188148  0.48723438 0.4883523 ]\n",
            " [0.48288232 0.50700045 0.51878375 0.48723266 0.48844212]\n",
            " [0.48283738 0.50693697 0.51882803 0.48721883 0.48830578]\n",
            " [0.48284376 0.5069453  0.5188286  0.48723575 0.48829716]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48284915 0.5069769  0.5188841  0.48725724 0.4883134 ]\n",
            " [0.48278862 0.5070286  0.5188818  0.48726556 0.4883409 ]\n",
            " [0.48287672 0.50701225 0.518861   0.48729074 0.48838186]\n",
            " [0.48286223 0.5070213  0.5188616  0.48730236 0.48837715]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48288468 0.5070175  0.5188434  0.48727423 0.48837268]\n",
            " [0.48287496 0.50696534 0.518863   0.48728722 0.4883692 ]\n",
            " [0.4826965  0.5069945  0.5189131  0.48722607 0.48822862]\n",
            " [0.48288336 0.5069753  0.51887125 0.48726845 0.4883161 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48286358 0.50704265 0.5188667  0.4873139  0.48843494]\n",
            " [0.48271167 0.5069694  0.5189359  0.4872175  0.4881964 ]\n",
            " [0.4828545  0.50701475 0.5188536  0.48726678 0.48838133]\n",
            " [0.48284703 0.5070269  0.5188271  0.48729673 0.48845607]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48282197 0.5069649  0.51884955 0.48725888 0.48827353]\n",
            " [0.48285067 0.50702167 0.5188165  0.48728994 0.48848978]\n",
            " [0.4828538  0.50702846 0.51887685 0.48729122 0.48839483]\n",
            " [0.48282078 0.5069836  0.51889473 0.48726976 0.48832017]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4828533  0.50696546 0.51883763 0.487278   0.48832846]\n",
            " [0.48284036 0.5070225  0.518876   0.4872906  0.48835957]\n",
            " [0.4827982  0.5069767  0.51889014 0.48726434 0.4882557 ]\n",
            " [0.48285106 0.50700104 0.51884305 0.4872778  0.48839286]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48282862 0.5069569  0.5188774  0.4872638  0.4882769 ]\n",
            " [0.48283136 0.5069849  0.51887035 0.48726323 0.488349  ]\n",
            " [0.48290193 0.5070386  0.51889884 0.4873364  0.4884665 ]\n",
            " [0.48286003 0.5069998  0.5188632  0.48728937 0.4883658 ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4828043  0.5069209  0.51889527 0.48724854 0.48823702]\n",
            " [0.48292875 0.50704163 0.51882935 0.48728305 0.48844483]\n",
            " [0.48277998 0.5069026  0.5189044  0.48724657 0.48822454]\n",
            " [0.4828278  0.50697136 0.5188574  0.4872575  0.4883117 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48281753 0.50700295 0.51888883 0.48724952 0.48831454]\n",
            " [0.48286575 0.50703996 0.5188712  0.48729777 0.48839355]\n",
            " [0.48285538 0.5069743  0.51884365 0.48726568 0.48833537]\n",
            " [0.48282105 0.5069278  0.5188753  0.48724976 0.48825014]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4828617  0.5069908  0.51886094 0.4872755  0.4883664 ]\n",
            " [0.48281163 0.50699633 0.5188937  0.4872686  0.48835292]\n",
            " [0.48270795 0.507008   0.5189122  0.48721477 0.48821786]\n",
            " [0.4827886  0.50690645 0.51891065 0.4872663  0.48821872]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48280513 0.5069275  0.51889515 0.48725864 0.48823527]\n",
            " [0.48290184 0.5070511  0.5188616  0.4872917  0.4884209 ]\n",
            " [0.4828899  0.506986   0.51883763 0.4872963  0.48834616]\n",
            " [0.48277068 0.50697756 0.5189037  0.48722935 0.48825172]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48284742 0.5069942  0.5188658  0.48726606 0.48831636]\n",
            " [0.48296466 0.5070671  0.51883084 0.4872777  0.48847878]\n",
            " [0.4827139  0.50695956 0.5189079  0.4872443  0.48819202]\n",
            " [0.48284832 0.50700784 0.51886356 0.4873014  0.4883446 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48286924 0.5069976  0.5188357  0.48726746 0.4883504 ]\n",
            " [0.48284462 0.506998   0.5188763  0.48728162 0.48835498]\n",
            " [0.48283193 0.5070281  0.51887393 0.48728412 0.48840064]\n",
            " [0.48292923 0.507003   0.5188591  0.48725396 0.4883623 ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48291284 0.50701827 0.5188403  0.48728925 0.48840436]\n",
            " [0.4827572  0.5070276  0.51890916 0.4872164  0.48831022]\n",
            " [0.4828745  0.5069849  0.5188636  0.48726723 0.48833194]\n",
            " [0.4827494  0.5069088  0.5189245  0.48722655 0.4882059 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48283693 0.50696576 0.518856   0.4872625  0.4882934 ]\n",
            " [0.48282105 0.5069517  0.51885873 0.48725718 0.48827243]\n",
            " [0.4828505  0.507033   0.51881474 0.48729402 0.48848778]\n",
            " [0.4827513  0.5068931  0.5188995  0.4872342  0.488174  ]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48287794 0.50699514 0.5188454  0.48727256 0.4884078 ]\n",
            " [0.48291266 0.50704217 0.5188145  0.48727056 0.48849717]\n",
            " [0.4828676  0.506978   0.51885843 0.48725656 0.48836058]\n",
            " [0.48287374 0.5069864  0.5188592  0.48727345 0.4883519 ]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48284915 0.48278862 0.48287672 0.48286223 0.48288468 0.48287496\n",
            " 0.4826965  0.48288336 0.48286358 0.48271167 0.4828545  0.48284703\n",
            " 0.48282197 0.48285067 0.4828538  0.48282078 0.4828533  0.48284036\n",
            " 0.4827982  0.48285106 0.48282862 0.48283136 0.48290193 0.48286003\n",
            " 0.4828043  0.48292875 0.48277998 0.4828278  0.48281753 0.48286575\n",
            " 0.48285538 0.48282105 0.4828617  0.48281163 0.48270795 0.4827886\n",
            " 0.48280513 0.48290184 0.4828899  0.48277068 0.48284742 0.48296466\n",
            " 0.4827139  0.48284832 0.48286924 0.48284462 0.48283193 0.48292923\n",
            " 0.48291284 0.4827572  0.4828745  0.4827494  0.48283693 0.48282105\n",
            " 0.4828505  0.4827513  0.48287794 0.48291266 0.4828676  0.48287374]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.509454422281124e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5069769  0.5070286  0.50701225 0.5070213  0.5070175  0.50696534\n",
            " 0.5069945  0.5069753  0.50704265 0.5069694  0.50701475 0.5070269\n",
            " 0.5069649  0.50702167 0.50702846 0.5069836  0.50696546 0.5070225\n",
            " 0.5069767  0.50700104 0.5069569  0.5069849  0.5070386  0.5069998\n",
            " 0.5069209  0.50704163 0.5069026  0.50697136 0.50700295 0.50703996\n",
            " 0.5069743  0.5069278  0.5069908  0.50699633 0.507008   0.50690645\n",
            " 0.5069275  0.5070511  0.506986   0.50697756 0.5069942  0.5070671\n",
            " 0.50695956 0.50700784 0.5069976  0.506998   0.5070281  0.507003\n",
            " 0.50701827 0.5070276  0.5069849  0.5069088  0.50696576 0.5069517\n",
            " 0.507033   0.5068931  0.50699514 0.50704217 0.506978   0.5069864 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.870947693940252e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5188841  0.5188818  0.518861   0.5188616  0.5188434  0.518863\n",
            " 0.5189131  0.51887125 0.5188667  0.5189359  0.5188536  0.5188271\n",
            " 0.51884955 0.5188165  0.51887685 0.51889473 0.51883763 0.518876\n",
            " 0.51889014 0.51884305 0.5188774  0.51887035 0.51889884 0.5188632\n",
            " 0.51889527 0.51882935 0.5189044  0.5188574  0.51888883 0.5188712\n",
            " 0.51884365 0.5188753  0.51886094 0.5188937  0.5189122  0.51891065\n",
            " 0.51889515 0.5188616  0.51883763 0.5189037  0.5188658  0.51883084\n",
            " 0.5189079  0.51886356 0.5188357  0.5188763  0.51887393 0.5188591\n",
            " 0.5188403  0.51890916 0.5188636  0.5189245  0.518856   0.51885873\n",
            " 0.51881474 0.5188995  0.5188454  0.5188145  0.51885843 0.5188592 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.7774593036156148e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48725724 0.48726556 0.48729074 0.48730236 0.48727423 0.48728722\n",
            " 0.48722607 0.48726845 0.4873139  0.4872175  0.48726678 0.48729673\n",
            " 0.48725888 0.48728994 0.48729122 0.48726976 0.487278   0.4872906\n",
            " 0.48726434 0.4872778  0.4872638  0.48726323 0.4873364  0.48728937\n",
            " 0.48724854 0.48728305 0.48724657 0.4872575  0.48724952 0.48729777\n",
            " 0.48726568 0.48724976 0.4872755  0.4872686  0.48721477 0.4872663\n",
            " 0.48725864 0.4872917  0.4872963  0.48722935 0.48726606 0.4872777\n",
            " 0.4872443  0.4873014  0.48726746 0.48728162 0.48728412 0.48725396\n",
            " 0.48728925 0.4872164  0.48726723 0.48722655 0.4872625  0.48725718\n",
            " 0.48729402 0.4872342  0.48727256 0.48727056 0.48725656 0.48727345]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.394482544332277e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4883134  0.4883409  0.48838186 0.48837715 0.48837268 0.4883692\n",
            " 0.48822862 0.4883161  0.48843494 0.4881964  0.48838133 0.48845607\n",
            " 0.48827353 0.48848978 0.48839483 0.48832017 0.48832846 0.48835957\n",
            " 0.4882557  0.48839286 0.4882769  0.488349   0.4884665  0.4883658\n",
            " 0.48823702 0.48844483 0.48822454 0.4883117  0.48831454 0.48839355\n",
            " 0.48833537 0.48825014 0.4883664  0.48835292 0.48821786 0.48821872\n",
            " 0.48823527 0.4884209  0.48834616 0.48825172 0.48831636 0.48847878\n",
            " 0.48819202 0.4883446  0.4883504  0.48835498 0.48840064 0.4883623\n",
            " 0.48840436 0.48831022 0.48833194 0.4882059  0.4882934  0.48827243\n",
            " 0.48848778 0.488174   0.4884078  0.48849717 0.48836058 0.4883519 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.990825542947277e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48284915 0.48278862 0.48287672 0.48286223 0.48288468 0.48287496\n",
            " 0.4826965  0.48288336 0.48286358 0.48271167 0.4828545  0.48284703\n",
            " 0.48282197 0.48285067 0.4828538  0.48282078 0.4828533  0.48284036\n",
            " 0.4827982  0.48285106 0.48282862 0.48283136 0.48290193 0.48286003\n",
            " 0.4828043  0.48292875 0.48277998 0.4828278  0.48281753 0.48286575\n",
            " 0.48285538 0.48282105 0.4828617  0.48281163 0.48270795 0.4827886\n",
            " 0.48280513 0.48290184 0.4828899  0.48277068 0.48284742 0.48296466\n",
            " 0.4827139  0.48284832 0.48286924 0.48284462 0.48283193 0.48292923\n",
            " 0.48291284 0.4827572  0.4828745  0.4827494  0.48283693 0.48282105\n",
            " 0.4828505  0.4827513  0.48287794 0.48291266 0.4828676  0.48287374]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.509454422281124e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5069769  0.5070286  0.50701225 0.5070213  0.5070175  0.50696534\n",
            " 0.5069945  0.5069753  0.50704265 0.5069694  0.50701475 0.5070269\n",
            " 0.5069649  0.50702167 0.50702846 0.5069836  0.50696546 0.5070225\n",
            " 0.5069767  0.50700104 0.5069569  0.5069849  0.5070386  0.5069998\n",
            " 0.5069209  0.50704163 0.5069026  0.50697136 0.50700295 0.50703996\n",
            " 0.5069743  0.5069278  0.5069908  0.50699633 0.507008   0.50690645\n",
            " 0.5069275  0.5070511  0.506986   0.50697756 0.5069942  0.5070671\n",
            " 0.50695956 0.50700784 0.5069976  0.506998   0.5070281  0.507003\n",
            " 0.50701827 0.5070276  0.5069849  0.5069088  0.50696576 0.5069517\n",
            " 0.507033   0.5068931  0.50699514 0.50704217 0.506978   0.5069864 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.870947693940252e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5188841  0.5188818  0.518861   0.5188616  0.5188434  0.518863\n",
            " 0.5189131  0.51887125 0.5188667  0.5189359  0.5188536  0.5188271\n",
            " 0.51884955 0.5188165  0.51887685 0.51889473 0.51883763 0.518876\n",
            " 0.51889014 0.51884305 0.5188774  0.51887035 0.51889884 0.5188632\n",
            " 0.51889527 0.51882935 0.5189044  0.5188574  0.51888883 0.5188712\n",
            " 0.51884365 0.5188753  0.51886094 0.5188937  0.5189122  0.51891065\n",
            " 0.51889515 0.5188616  0.51883763 0.5189037  0.5188658  0.51883084\n",
            " 0.5189079  0.51886356 0.5188357  0.5188763  0.51887393 0.5188591\n",
            " 0.5188403  0.51890916 0.5188636  0.5189245  0.518856   0.51885873\n",
            " 0.51881474 0.5188995  0.5188454  0.5188145  0.51885843 0.5188592 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.7774593036156148e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48725724 0.48726556 0.48729074 0.48730236 0.48727423 0.48728722\n",
            " 0.48722607 0.48726845 0.4873139  0.4872175  0.48726678 0.48729673\n",
            " 0.48725888 0.48728994 0.48729122 0.48726976 0.487278   0.4872906\n",
            " 0.48726434 0.4872778  0.4872638  0.48726323 0.4873364  0.48728937\n",
            " 0.48724854 0.48728305 0.48724657 0.4872575  0.48724952 0.48729777\n",
            " 0.48726568 0.48724976 0.4872755  0.4872686  0.48721477 0.4872663\n",
            " 0.48725864 0.4872917  0.4872963  0.48722935 0.48726606 0.4872777\n",
            " 0.4872443  0.4873014  0.48726746 0.48728162 0.48728412 0.48725396\n",
            " 0.48728925 0.4872164  0.48726723 0.48722655 0.4872625  0.48725718\n",
            " 0.48729402 0.4872342  0.48727256 0.48727056 0.48725656 0.48727345]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.394482544332277e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4883134  0.4883409  0.48838186 0.48837715 0.48837268 0.4883692\n",
            " 0.48822862 0.4883161  0.48843494 0.4881964  0.48838133 0.48845607\n",
            " 0.48827353 0.48848978 0.48839483 0.48832017 0.48832846 0.48835957\n",
            " 0.4882557  0.48839286 0.4882769  0.488349   0.4884665  0.4883658\n",
            " 0.48823702 0.48844483 0.48822454 0.4883117  0.48831454 0.48839355\n",
            " 0.48833537 0.48825014 0.4883664  0.48835292 0.48821786 0.48821872\n",
            " 0.48823527 0.4884209  0.48834616 0.48825172 0.48831636 0.48847878\n",
            " 0.48819202 0.4883446  0.4883504  0.48835498 0.48840064 0.4883623\n",
            " 0.48840436 0.48831022 0.48833194 0.4882059  0.4882934  0.48827243\n",
            " 0.48848778 0.488174   0.4884078  0.48849717 0.48836058 0.4883519 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.990825542947277e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48284915 0.48278862 0.48287672 0.48286223 0.48288468 0.48287496\n",
            " 0.4826965  0.48288336 0.48286358 0.48271167 0.4828545  0.48284703\n",
            " 0.48282197 0.48285067 0.4828538  0.48282078 0.4828533  0.48284036\n",
            " 0.4827982  0.48285106 0.48282862 0.48283136 0.48290193 0.48286003\n",
            " 0.4828043  0.48292875 0.48277998 0.4828278  0.48281753 0.48286575\n",
            " 0.48285538 0.48282105 0.4828617  0.48281163 0.48270795 0.4827886\n",
            " 0.48280513 0.48290184 0.4828899  0.48277068 0.48284742 0.48296466\n",
            " 0.4827139  0.48284832 0.48286924 0.48284462 0.48283193 0.48292923\n",
            " 0.48291284 0.4827572  0.4828745  0.4827494  0.48283693 0.48282105\n",
            " 0.4828505  0.4827513  0.48287794 0.48291266 0.4828676  0.48287374]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.509454422281124e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5069769  0.5070286  0.50701225 0.5070213  0.5070175  0.50696534\n",
            " 0.5069945  0.5069753  0.50704265 0.5069694  0.50701475 0.5070269\n",
            " 0.5069649  0.50702167 0.50702846 0.5069836  0.50696546 0.5070225\n",
            " 0.5069767  0.50700104 0.5069569  0.5069849  0.5070386  0.5069998\n",
            " 0.5069209  0.50704163 0.5069026  0.50697136 0.50700295 0.50703996\n",
            " 0.5069743  0.5069278  0.5069908  0.50699633 0.507008   0.50690645\n",
            " 0.5069275  0.5070511  0.506986   0.50697756 0.5069942  0.5070671\n",
            " 0.50695956 0.50700784 0.5069976  0.506998   0.5070281  0.507003\n",
            " 0.50701827 0.5070276  0.5069849  0.5069088  0.50696576 0.5069517\n",
            " 0.507033   0.5068931  0.50699514 0.50704217 0.506978   0.5069864 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.870947693940252e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5188841  0.5188818  0.518861   0.5188616  0.5188434  0.518863\n",
            " 0.5189131  0.51887125 0.5188667  0.5189359  0.5188536  0.5188271\n",
            " 0.51884955 0.5188165  0.51887685 0.51889473 0.51883763 0.518876\n",
            " 0.51889014 0.51884305 0.5188774  0.51887035 0.51889884 0.5188632\n",
            " 0.51889527 0.51882935 0.5189044  0.5188574  0.51888883 0.5188712\n",
            " 0.51884365 0.5188753  0.51886094 0.5188937  0.5189122  0.51891065\n",
            " 0.51889515 0.5188616  0.51883763 0.5189037  0.5188658  0.51883084\n",
            " 0.5189079  0.51886356 0.5188357  0.5188763  0.51887393 0.5188591\n",
            " 0.5188403  0.51890916 0.5188636  0.5189245  0.518856   0.51885873\n",
            " 0.51881474 0.5188995  0.5188454  0.5188145  0.51885843 0.5188592 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.7774593036156148e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48725724 0.48726556 0.48729074 0.48730236 0.48727423 0.48728722\n",
            " 0.48722607 0.48726845 0.4873139  0.4872175  0.48726678 0.48729673\n",
            " 0.48725888 0.48728994 0.48729122 0.48726976 0.487278   0.4872906\n",
            " 0.48726434 0.4872778  0.4872638  0.48726323 0.4873364  0.48728937\n",
            " 0.48724854 0.48728305 0.48724657 0.4872575  0.48724952 0.48729777\n",
            " 0.48726568 0.48724976 0.4872755  0.4872686  0.48721477 0.4872663\n",
            " 0.48725864 0.4872917  0.4872963  0.48722935 0.48726606 0.4872777\n",
            " 0.4872443  0.4873014  0.48726746 0.48728162 0.48728412 0.48725396\n",
            " 0.48728925 0.4872164  0.48726723 0.48722655 0.4872625  0.48725718\n",
            " 0.48729402 0.4872342  0.48727256 0.48727056 0.48725656 0.48727345]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.394482544332277e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4883134  0.4883409  0.48838186 0.48837715 0.48837268 0.4883692\n",
            " 0.48822862 0.4883161  0.48843494 0.4881964  0.48838133 0.48845607\n",
            " 0.48827353 0.48848978 0.48839483 0.48832017 0.48832846 0.48835957\n",
            " 0.4882557  0.48839286 0.4882769  0.488349   0.4884665  0.4883658\n",
            " 0.48823702 0.48844483 0.48822454 0.4883117  0.48831454 0.48839355\n",
            " 0.48833537 0.48825014 0.4883664  0.48835292 0.48821786 0.48821872\n",
            " 0.48823527 0.4884209  0.48834616 0.48825172 0.48831636 0.48847878\n",
            " 0.48819202 0.4883446  0.4883504  0.48835498 0.48840064 0.4883623\n",
            " 0.48840436 0.48831022 0.48833194 0.4882059  0.4882934  0.48827243\n",
            " 0.48848778 0.488174   0.4884078  0.48849717 0.48836058 0.4883519 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.990825542947277e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48284915 0.48278862 0.48287672 0.48286223 0.48288468 0.48287496\n",
            " 0.4826965  0.48288336 0.48286358 0.48271167 0.4828545  0.48284703\n",
            " 0.48282197 0.48285067 0.4828538  0.48282078 0.4828533  0.48284036\n",
            " 0.4827982  0.48285106 0.48282862 0.48283136 0.48290193 0.48286003\n",
            " 0.4828043  0.48292875 0.48277998 0.4828278  0.48281753 0.48286575\n",
            " 0.48285538 0.48282105 0.4828617  0.48281163 0.48270795 0.4827886\n",
            " 0.48280513 0.48290184 0.4828899  0.48277068 0.48284742 0.48296466\n",
            " 0.4827139  0.48284832 0.48286924 0.48284462 0.48283193 0.48292923\n",
            " 0.48291284 0.4827572  0.4828745  0.4827494  0.48283693 0.48282105\n",
            " 0.4828505  0.4827513  0.48287794 0.48291266 0.4828676  0.48287374]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.509454422281124e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.5069769  0.5070286  0.50701225 0.5070213  0.5070175  0.50696534\n",
            " 0.5069945  0.5069753  0.50704265 0.5069694  0.50701475 0.5070269\n",
            " 0.5069649  0.50702167 0.50702846 0.5069836  0.50696546 0.5070225\n",
            " 0.5069767  0.50700104 0.5069569  0.5069849  0.5070386  0.5069998\n",
            " 0.5069209  0.50704163 0.5069026  0.50697136 0.50700295 0.50703996\n",
            " 0.5069743  0.5069278  0.5069908  0.50699633 0.507008   0.50690645\n",
            " 0.5069275  0.5070511  0.506986   0.50697756 0.5069942  0.5070671\n",
            " 0.50695956 0.50700784 0.5069976  0.506998   0.5070281  0.507003\n",
            " 0.50701827 0.5070276  0.5069849  0.5069088  0.50696576 0.5069517\n",
            " 0.507033   0.5068931  0.50699514 0.50704217 0.506978   0.5069864 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 3.870947693940252e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5188841  0.5188818  0.518861   0.5188616  0.5188434  0.518863\n",
            " 0.5189131  0.51887125 0.5188667  0.5189359  0.5188536  0.5188271\n",
            " 0.51884955 0.5188165  0.51887685 0.51889473 0.51883763 0.518876\n",
            " 0.51889014 0.51884305 0.5188774  0.51887035 0.51889884 0.5188632\n",
            " 0.51889527 0.51882935 0.5189044  0.5188574  0.51888883 0.5188712\n",
            " 0.51884365 0.5188753  0.51886094 0.5188937  0.5189122  0.51891065\n",
            " 0.51889515 0.5188616  0.51883763 0.5189037  0.5188658  0.51883084\n",
            " 0.5189079  0.51886356 0.5188357  0.5188763  0.51887393 0.5188591\n",
            " 0.5188403  0.51890916 0.5188636  0.5189245  0.518856   0.51885873\n",
            " 0.51881474 0.5188995  0.5188454  0.5188145  0.51885843 0.5188592 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.7774593036156148e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48725724 0.48726556 0.48729074 0.48730236 0.48727423 0.48728722\n",
            " 0.48722607 0.48726845 0.4873139  0.4872175  0.48726678 0.48729673\n",
            " 0.48725888 0.48728994 0.48729122 0.48726976 0.487278   0.4872906\n",
            " 0.48726434 0.4872778  0.4872638  0.48726323 0.4873364  0.48728937\n",
            " 0.48724854 0.48728305 0.48724657 0.4872575  0.48724952 0.48729777\n",
            " 0.48726568 0.48724976 0.4872755  0.4872686  0.48721477 0.4872663\n",
            " 0.48725864 0.4872917  0.4872963  0.48722935 0.48726606 0.4872777\n",
            " 0.4872443  0.4873014  0.48726746 0.48728162 0.48728412 0.48725396\n",
            " 0.48728925 0.4872164  0.48726723 0.48722655 0.4872625  0.48725718\n",
            " 0.48729402 0.4872342  0.48727256 0.48727056 0.48725656 0.48727345]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.394482544332277e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.4883134  0.4883409  0.48838186 0.48837715 0.48837268 0.4883692\n",
            " 0.48822862 0.4883161  0.48843494 0.4881964  0.48838133 0.48845607\n",
            " 0.48827353 0.48848978 0.48839483 0.48832017 0.48832846 0.48835957\n",
            " 0.4882557  0.48839286 0.4882769  0.488349   0.4884665  0.4883658\n",
            " 0.48823702 0.48844483 0.48822454 0.4883117  0.48831454 0.48839355\n",
            " 0.48833537 0.48825014 0.4883664  0.48835292 0.48821786 0.48821872\n",
            " 0.48823527 0.4884209  0.48834616 0.48825172 0.48831636 0.48847878\n",
            " 0.48819202 0.4883446  0.4883504  0.48835498 0.48840064 0.4883623\n",
            " 0.48840436 0.48831022 0.48833194 0.4882059  0.4882934  0.48827243\n",
            " 0.48848778 0.488174   0.4884078  0.48849717 0.48836058 0.4883519 ]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 7.990825542947277e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48281807 0.5069818  0.51890016 0.48726013 0.48830357]\n",
            " [0.48278278 0.5069331  0.5189155  0.4872627  0.48821887]\n",
            " [0.48275945 0.5069141  0.5189024  0.48724884 0.4882222 ]\n",
            " [0.4827709  0.50700486 0.5188986  0.48725688 0.48826638]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4827993  0.5069546  0.51886505 0.48725048 0.488243  ]\n",
            " [0.48286062 0.50698245 0.5188766  0.48728323 0.4883999 ]\n",
            " [0.48290074 0.50702095 0.51884604 0.48726222 0.48844025]\n",
            " [0.4827817  0.50692487 0.51888496 0.48726273 0.48820674]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48289478 0.5069976  0.5188664  0.48726356 0.48837632]\n",
            " [0.4828706  0.50700545 0.5188432  0.48727375 0.48834437]\n",
            " [0.4828954  0.5070157  0.51883996 0.4872682  0.48837617]\n",
            " [0.48285106 0.5069634  0.5188675  0.487278   0.4883288 ]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48282638 0.50707006 0.5188725  0.4872744  0.48838478]\n",
            " [0.48284703 0.5070031  0.518882   0.48727584 0.4884202 ]\n",
            " [0.4828482  0.5069517  0.51885843 0.4872709  0.48826542]\n",
            " [0.48284727 0.50696474 0.51887333 0.4872548  0.48831275]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48283494 0.50698036 0.5188713  0.4872654  0.48830804]\n",
            " [0.48292035 0.50705934 0.51881546 0.48730555 0.48849574]\n",
            " [0.48288077 0.50701785 0.5188157  0.4872843  0.4884116 ]\n",
            " [0.4828189  0.5069427  0.51887935 0.48724955 0.48828435]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48281807 0.48278278 0.48275945 0.4827709  0.4827993  0.48286062\n",
            " 0.48290074 0.4827817  0.48289478 0.4828706  0.4828954  0.48285106\n",
            " 0.48282638 0.48284703 0.4828482  0.48284727 0.48283494 0.48292035\n",
            " 0.48288077 0.4828189 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.4865955715067685e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5069818  0.5069331  0.5069141  0.50700486 0.5069546  0.50698245\n",
            " 0.50702095 0.50692487 0.5069976  0.50700545 0.5070157  0.5069634\n",
            " 0.50707006 0.5070031  0.5069517  0.50696474 0.50698036 0.50705934\n",
            " 0.50701785 0.5069427 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.089571302756667e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51890016 0.5189155  0.5189024  0.5188986  0.51886505 0.5188766\n",
            " 0.51884604 0.51888496 0.5188664  0.5188432  0.51883996 0.5188675\n",
            " 0.5188725  0.518882   0.51885843 0.51887333 0.5188713  0.51881546\n",
            " 0.5188157  0.51887935]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.6104860808118246e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48726013 0.4872627  0.48724884 0.48725688 0.48725048 0.48728323\n",
            " 0.48726222 0.48726273 0.48726356 0.48727375 0.4872682  0.487278\n",
            " 0.4872744  0.48727584 0.4872709  0.4872548  0.4872654  0.48730555\n",
            " 0.4872843  0.48724955]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.348812111245934e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48830357 0.48821887 0.4882222  0.48826638 0.488243   0.4883999\n",
            " 0.48844025 0.48820674 0.48837632 0.48834437 0.48837617 0.4883288\n",
            " 0.48838478 0.4884202  0.48826542 0.48831275 0.48830804 0.48849574\n",
            " 0.4884116  0.48828435]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.914824527688324e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48281807 0.48278278 0.48275945 0.4827709  0.4827993  0.48286062\n",
            " 0.48290074 0.4827817  0.48289478 0.4828706  0.4828954  0.48285106\n",
            " 0.48282638 0.48284703 0.4828482  0.48284727 0.48283494 0.48292035\n",
            " 0.48288077 0.4828189 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.4865955715067685e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5069818  0.5069331  0.5069141  0.50700486 0.5069546  0.50698245\n",
            " 0.50702095 0.50692487 0.5069976  0.50700545 0.5070157  0.5069634\n",
            " 0.50707006 0.5070031  0.5069517  0.50696474 0.50698036 0.50705934\n",
            " 0.50701785 0.5069427 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.089571302756667e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51890016 0.5189155  0.5189024  0.5188986  0.51886505 0.5188766\n",
            " 0.51884604 0.51888496 0.5188664  0.5188432  0.51883996 0.5188675\n",
            " 0.5188725  0.518882   0.51885843 0.51887333 0.5188713  0.51881546\n",
            " 0.5188157  0.51887935]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.6104860808118246e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48726013 0.4872627  0.48724884 0.48725688 0.48725048 0.48728323\n",
            " 0.48726222 0.48726273 0.48726356 0.48727375 0.4872682  0.487278\n",
            " 0.4872744  0.48727584 0.4872709  0.4872548  0.4872654  0.48730555\n",
            " 0.4872843  0.48724955]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.348812111245934e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48830357 0.48821887 0.4882222  0.48826638 0.488243   0.4883999\n",
            " 0.48844025 0.48820674 0.48837632 0.48834437 0.48837617 0.4883288\n",
            " 0.48838478 0.4884202  0.48826542 0.48831275 0.48830804 0.48849574\n",
            " 0.4884116  0.48828435]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.914824527688324e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48281807 0.48278278 0.48275945 0.4827709  0.4827993  0.48286062\n",
            " 0.48290074 0.4827817  0.48289478 0.4828706  0.4828954  0.48285106\n",
            " 0.48282638 0.48284703 0.4828482  0.48284727 0.48283494 0.48292035\n",
            " 0.48288077 0.4828189 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.4865955715067685e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5069818  0.5069331  0.5069141  0.50700486 0.5069546  0.50698245\n",
            " 0.50702095 0.50692487 0.5069976  0.50700545 0.5070157  0.5069634\n",
            " 0.50707006 0.5070031  0.5069517  0.50696474 0.50698036 0.50705934\n",
            " 0.50701785 0.5069427 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.089571302756667e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51890016 0.5189155  0.5189024  0.5188986  0.51886505 0.5188766\n",
            " 0.51884604 0.51888496 0.5188664  0.5188432  0.51883996 0.5188675\n",
            " 0.5188725  0.518882   0.51885843 0.51887333 0.5188713  0.51881546\n",
            " 0.5188157  0.51887935]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.6104860808118246e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48726013 0.4872627  0.48724884 0.48725688 0.48725048 0.48728323\n",
            " 0.48726222 0.48726273 0.48726356 0.48727375 0.4872682  0.487278\n",
            " 0.4872744  0.48727584 0.4872709  0.4872548  0.4872654  0.48730555\n",
            " 0.4872843  0.48724955]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.348812111245934e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48830357 0.48821887 0.4882222  0.48826638 0.488243   0.4883999\n",
            " 0.48844025 0.48820674 0.48837632 0.48834437 0.48837617 0.4883288\n",
            " 0.48838478 0.4884202  0.48826542 0.48831275 0.48830804 0.48849574\n",
            " 0.4884116  0.48828435]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.914824527688324e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48281807 0.48278278 0.48275945 0.4827709  0.4827993  0.48286062\n",
            " 0.48290074 0.4827817  0.48289478 0.4828706  0.4828954  0.48285106\n",
            " 0.48282638 0.48284703 0.4828482  0.48284727 0.48283494 0.48292035\n",
            " 0.48288077 0.4828189 ]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.4865955715067685e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5069818  0.5069331  0.5069141  0.50700486 0.5069546  0.50698245\n",
            " 0.50702095 0.50692487 0.5069976  0.50700545 0.5070157  0.5069634\n",
            " 0.50707006 0.5070031  0.5069517  0.50696474 0.50698036 0.50705934\n",
            " 0.50701785 0.5069427 ]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.089571302756667e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.51890016 0.5189155  0.5189024  0.5188986  0.51886505 0.5188766\n",
            " 0.51884604 0.51888496 0.5188664  0.5188432  0.51883996 0.5188675\n",
            " 0.5188725  0.518882   0.51885843 0.51887333 0.5188713  0.51881546\n",
            " 0.5188157  0.51887935]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.6104860808118246e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48726013 0.4872627  0.48724884 0.48725688 0.48725048 0.48728323\n",
            " 0.48726222 0.48726273 0.48726356 0.48727375 0.4872682  0.487278\n",
            " 0.4872744  0.48727584 0.4872709  0.4872548  0.4872654  0.48730555\n",
            " 0.4872843  0.48724955]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.348812111245934e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48830357 0.48821887 0.4882222  0.48826638 0.488243   0.4883999\n",
            " 0.48844025 0.48820674 0.48837632 0.48834437 0.48837617 0.4883288\n",
            " 0.48838478 0.4884202  0.48826542 0.48831275 0.48830804 0.48849574\n",
            " 0.4884116  0.48828435]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 7.914824527688324e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48287705 0.5070047  0.51886934 0.48728576 0.48834231]\n",
            " [0.48289317 0.5070144  0.51883507 0.48726636 0.48839957]\n",
            " [0.48288915 0.5070236  0.5188412  0.48726678 0.48840463]\n",
            " [0.48283502 0.5069796  0.5188522  0.48727188 0.4883085 ]\n",
            " [0.4829146  0.5070326  0.5188345  0.4872544  0.48843628]\n",
            " [0.48280063 0.5069513  0.5189166  0.48725617 0.48825827]\n",
            " [0.48279116 0.50695217 0.5188856  0.48726517 0.48827118]\n",
            " [0.48279828 0.5069249  0.51887006 0.48725793 0.48824802]\n",
            " [0.48281214 0.5069409  0.5188937  0.48727855 0.48824576]\n",
            " [0.48282143 0.50700295 0.51886433 0.4872838  0.4883785 ]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.4828023  0.506996   0.5188859  0.48728088 0.4883483 ]\n",
            " [0.48282185 0.5069716  0.5188913  0.48727202 0.48829234]\n",
            " [0.48284593 0.50697124 0.5188725  0.48728216 0.48833597]\n",
            " [0.48289707 0.5070404  0.51884925 0.4873153  0.48846635]\n",
            " [0.4828295  0.50697577 0.5188598  0.48727572 0.4883151 ]\n",
            " [0.4828789  0.50699115 0.5188543  0.48727313 0.48838145]\n",
            " [0.48289347 0.5070206  0.5188553  0.487292   0.488447  ]\n",
            " [0.4828199  0.50692433 0.5188803  0.48724934 0.48823968]\n",
            " [0.48286903 0.50702834 0.51884335 0.48727947 0.48836938]\n",
            " [0.48278666 0.50700897 0.51888466 0.48724955 0.4883149 ]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48287705 0.48289317 0.48288915 0.48283502 0.4829146  0.48280063\n",
            " 0.48279116 0.48279828 0.48281214 0.48282143 0.4828023  0.48282185\n",
            " 0.48284593 0.48289707 0.4828295  0.4828789  0.48289347 0.4828199\n",
            " 0.48286903 0.48278666]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.01990873797331e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5070047  0.5070144  0.5070236  0.5069796  0.5070326  0.5069513\n",
            " 0.50695217 0.5069249  0.5069409  0.50700295 0.506996   0.5069716\n",
            " 0.50697124 0.5070404  0.50697577 0.50699115 0.5070206  0.50692433\n",
            " 0.50702834 0.50700897]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.4676853829296306e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51886934 0.51883507 0.5188412  0.5188522  0.5188345  0.5189166\n",
            " 0.5188856  0.51887006 0.5188937  0.51886433 0.5188859  0.5188913\n",
            " 0.5188725  0.51884925 0.5188598  0.5188543  0.5188553  0.5188803\n",
            " 0.51884335 0.51888466]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.1443114746944048e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48728576 0.48726636 0.48726678 0.48727188 0.4872544  0.48725617\n",
            " 0.48726517 0.48725793 0.48727855 0.4872838  0.48728088 0.48727202\n",
            " 0.48728216 0.4873153  0.48727572 0.48727313 0.487292   0.48724934\n",
            " 0.48727947 0.48724955]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.5437250112881884e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48834231 0.48839957 0.48840463 0.4883085  0.48843628 0.48825827\n",
            " 0.48827118 0.48824802 0.48824576 0.4883785  0.4883483  0.48829234\n",
            " 0.48833597 0.48846635 0.4883151  0.48838145 0.488447   0.48823968\n",
            " 0.48836938 0.4883149 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.778715760447085e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48287705 0.48289317 0.48288915 0.48283502 0.4829146  0.48280063\n",
            " 0.48279116 0.48279828 0.48281214 0.48282143 0.4828023  0.48282185\n",
            " 0.48284593 0.48289707 0.4828295  0.4828789  0.48289347 0.4828199\n",
            " 0.48286903 0.48278666]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.01990873797331e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5070047  0.5070144  0.5070236  0.5069796  0.5070326  0.5069513\n",
            " 0.50695217 0.5069249  0.5069409  0.50700295 0.506996   0.5069716\n",
            " 0.50697124 0.5070404  0.50697577 0.50699115 0.5070206  0.50692433\n",
            " 0.50702834 0.50700897]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.4676853829296306e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51886934 0.51883507 0.5188412  0.5188522  0.5188345  0.5189166\n",
            " 0.5188856  0.51887006 0.5188937  0.51886433 0.5188859  0.5188913\n",
            " 0.5188725  0.51884925 0.5188598  0.5188543  0.5188553  0.5188803\n",
            " 0.51884335 0.51888466]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.1443114746944048e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48728576 0.48726636 0.48726678 0.48727188 0.4872544  0.48725617\n",
            " 0.48726517 0.48725793 0.48727855 0.4872838  0.48728088 0.48727202\n",
            " 0.48728216 0.4873153  0.48727572 0.48727313 0.487292   0.48724934\n",
            " 0.48727947 0.48724955]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.5437250112881884e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48834231 0.48839957 0.48840463 0.4883085  0.48843628 0.48825827\n",
            " 0.48827118 0.48824802 0.48824576 0.4883785  0.4883483  0.48829234\n",
            " 0.48833597 0.48846635 0.4883151  0.48838145 0.488447   0.48823968\n",
            " 0.48836938 0.4883149 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.778715760447085e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48287705 0.48289317 0.48288915 0.48283502 0.4829146  0.48280063\n",
            " 0.48279116 0.48279828 0.48281214 0.48282143 0.4828023  0.48282185\n",
            " 0.48284593 0.48289707 0.4828295  0.4828789  0.48289347 0.4828199\n",
            " 0.48286903 0.48278666]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.01990873797331e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5070047  0.5070144  0.5070236  0.5069796  0.5070326  0.5069513\n",
            " 0.50695217 0.5069249  0.5069409  0.50700295 0.506996   0.5069716\n",
            " 0.50697124 0.5070404  0.50697577 0.50699115 0.5070206  0.50692433\n",
            " 0.50702834 0.50700897]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.4676853829296306e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51886934 0.51883507 0.5188412  0.5188522  0.5188345  0.5189166\n",
            " 0.5188856  0.51887006 0.5188937  0.51886433 0.5188859  0.5188913\n",
            " 0.5188725  0.51884925 0.5188598  0.5188543  0.5188553  0.5188803\n",
            " 0.51884335 0.51888466]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.1443114746944048e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48728576 0.48726636 0.48726678 0.48727188 0.4872544  0.48725617\n",
            " 0.48726517 0.48725793 0.48727855 0.4872838  0.48728088 0.48727202\n",
            " 0.48728216 0.4873153  0.48727572 0.48727313 0.487292   0.48724934\n",
            " 0.48727947 0.48724955]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.5437250112881884e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48834231 0.48839957 0.48840463 0.4883085  0.48843628 0.48825827\n",
            " 0.48827118 0.48824802 0.48824576 0.4883785  0.4883483  0.48829234\n",
            " 0.48833597 0.48846635 0.4883151  0.48838145 0.488447   0.48823968\n",
            " 0.48836938 0.4883149 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.778715760447085e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48287705 0.48289317 0.48288915 0.48283502 0.4829146  0.48280063\n",
            " 0.48279116 0.48279828 0.48281214 0.48282143 0.4828023  0.48282185\n",
            " 0.48284593 0.48289707 0.4828295  0.4828789  0.48289347 0.4828199\n",
            " 0.48286903 0.48278666]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.01990873797331e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5070047  0.5070144  0.5070236  0.5069796  0.5070326  0.5069513\n",
            " 0.50695217 0.5069249  0.5069409  0.50700295 0.506996   0.5069716\n",
            " 0.50697124 0.5070404  0.50697577 0.50699115 0.5070206  0.50692433\n",
            " 0.50702834 0.50700897]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.4676853829296306e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51886934 0.51883507 0.5188412  0.5188522  0.5188345  0.5189166\n",
            " 0.5188856  0.51887006 0.5188937  0.51886433 0.5188859  0.5188913\n",
            " 0.5188725  0.51884925 0.5188598  0.5188543  0.5188553  0.5188803\n",
            " 0.51884335 0.51888466]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 2.1443114746944048e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48728576 0.48726636 0.48726678 0.48727188 0.4872544  0.48725617\n",
            " 0.48726517 0.48725793 0.48727855 0.4872838  0.48728088 0.48727202\n",
            " 0.48728216 0.4873153  0.48727572 0.48727313 0.487292   0.48724934\n",
            " 0.48727947 0.48724955]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.5437250112881884e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48834231 0.48839957 0.48840463 0.4883085  0.48843628 0.48825827\n",
            " 0.48827118 0.48824802 0.48824576 0.4883785  0.4883483  0.48829234\n",
            " 0.48833597 0.48846635 0.4883151  0.48838145 0.488447   0.48823968\n",
            " 0.48836938 0.4883149 ]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 6.778715760447085e-05\n",
            "Epoch 9/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48284915 0.5069769  0.5188841  0.48725724 0.4883134 ]\n",
            " [0.48278862 0.5070286  0.5188818  0.48726556 0.4883409 ]\n",
            " [0.48287672 0.50701225 0.518861   0.48729074 0.48838186]\n",
            " [0.48286223 0.5070213  0.5188616  0.48730236 0.48837715]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48290947 0.5070468  0.51887894 0.4873144  0.4884193 ]\n",
            " [0.4828999  0.50699455 0.5188985  0.4873275  0.48841575]\n",
            " [0.4827214  0.5070234  0.51894766 0.4872655  0.488274  ]\n",
            " [0.48290828 0.50700444 0.5189066  0.4873086  0.48836258]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48291364 0.5070838  0.5189083  0.48734304 0.4885368 ]\n",
            " [0.48276126 0.50700974 0.518976   0.48724583 0.4882958 ]\n",
            " [0.48290458 0.507056   0.51889527 0.487296   0.48848313]\n",
            " [0.48289758 0.50706834 0.51886904 0.48732615 0.48855886]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48288482 0.50702405 0.5189194  0.48731554 0.4884101 ]\n",
            " [0.48291445 0.5070818  0.51888746 0.4873476  0.4886291 ]\n",
            " [0.48291725 0.50708836 0.5189471  0.487348   0.48853183]\n",
            " [0.4828841  0.5070431  0.5189646  0.48732632 0.48845667]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4829529  0.50704014 0.51893175 0.48734513 0.4885225 ]\n",
            " [0.4829403  0.5070976  0.5189701  0.48735756 0.488553  ]\n",
            " [0.48289815 0.50705135 0.5189831  0.4873309  0.48844755]\n",
            " [0.48295125 0.5070759  0.5189375  0.4873451  0.48858738]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4829315  0.50702995 0.51896125 0.4873245  0.48851168]\n",
            " [0.48293468 0.5070584  0.518955   0.48732388 0.48858452]\n",
            " [0.48300484 0.5071129  0.5189852  0.487397   0.48870367]\n",
            " [0.48296285 0.50707304 0.5189483  0.48735037 0.4886028 ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4829366  0.50703543 0.5190048  0.48734844 0.488504  ]\n",
            " [0.48306048 0.5071586  0.5189434  0.48738423 0.4887173 ]\n",
            " [0.482912   0.50701684 0.51901364 0.48734617 0.48849082]\n",
            " [0.48296052 0.50708646 0.5189683  0.48735836 0.48858166]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48292798 0.5070937  0.51897985 0.48736525 0.48860648]\n",
            " [0.48297668 0.5071318  0.51896393 0.48741552 0.48868954]\n",
            " [0.4829663  0.50706506 0.5189357  0.48738354 0.48863178]\n",
            " [0.48293072 0.50701785 0.51896656 0.48736596 0.4885429 ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4829835  0.50709194 0.5189631  0.48740643 0.48867765]\n",
            " [0.4829337  0.50709766 0.51899564 0.4873994  0.48866364]\n",
            " [0.4828312  0.50710803 0.51900935 0.48734295 0.4885209 ]\n",
            " [0.48291075 0.50700635 0.51901007 0.48739603 0.488526  ]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48291263 0.50700474 0.51898754 0.48738068 0.4885346 ]\n",
            " [0.48300883 0.5071304  0.5189582  0.48741528 0.4887256 ]\n",
            " [0.4829967  0.5070641  0.51893294 0.4874199  0.48865044]\n",
            " [0.48287743 0.5070546  0.5189971  0.48735106 0.48855188]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48302475 0.507138   0.5190146  0.48744193 0.48869306]\n",
            " [0.483143   0.5072134  0.5189832  0.4874552  0.48886073]\n",
            " [0.48289213 0.50710106 0.5190509  0.48741597 0.48855886]\n",
            " [0.48302704 0.5071516  0.51901233 0.48747742 0.48872203]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48304835 0.50716674 0.518995   0.487484   0.48875037]\n",
            " [0.48302376 0.50716704 0.51903373 0.48749647 0.48875073]\n",
            " [0.48301032 0.5071973  0.51903236 0.48749876 0.48879665]\n",
            " [0.48310855 0.5071727  0.5190184  0.48747018 0.48876107]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48310506 0.50721323 0.5190367  0.4875424  0.48884127]\n",
            " [0.48294973 0.5072188  0.51910007 0.48746547 0.48874   ]\n",
            " [0.4830675  0.50717795 0.5190571  0.48751968 0.48876712]\n",
            " [0.48294234 0.5070985  0.51911247 0.48747444 0.48863217]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48303938 0.5071809  0.5190703  0.48754466 0.48874766]\n",
            " [0.48302335 0.5071663  0.51907307 0.48753938 0.48872688]\n",
            " [0.48305228 0.5072508  0.5190344  0.48757938 0.48894933]\n",
            " [0.4829526  0.50710493 0.51910937 0.48751172 0.48861963]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48306945 0.50718194 0.5190437  0.48752776 0.48887548]\n",
            " [0.4831041  0.507231   0.5190143  0.48752514 0.4889629 ]\n",
            " [0.4830594  0.5071644  0.519055   0.48751083 0.48882535]\n",
            " [0.48306525 0.50717336 0.51905656 0.4875273  0.48881605]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48307186 0.50720376 0.5191089  0.48754838 0.48883015]\n",
            " [0.48301107 0.5072552  0.5191065  0.48755494 0.48885524]\n",
            " [0.48309794 0.5072408  0.51909    0.48758274 0.48890188]\n",
            " [0.48308447 0.507249   0.5190892  0.4875948  0.48889774]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48310512 0.50724566 0.51907265 0.4875659  0.48889264]\n",
            " [0.48309717 0.5071929  0.5190902  0.48757944 0.4888887 ]\n",
            " [0.48291755 0.5072178  0.5191331  0.48751003 0.48873287]\n",
            " [0.48310557 0.50720197 0.5190974  0.4875603  0.4888353 ]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4830846  0.5072714  0.51909536 0.48760524 0.48895332]\n",
            " [0.48293328 0.5071927  0.5191556  0.48750237 0.48870203]\n",
            " [0.4830763  0.5072431  0.5190811  0.4875586  0.48889998]\n",
            " [0.48306805 0.5072547  0.519056   0.4875894  0.48897886]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48304337 0.5071905  0.51907474 0.48754886 0.48878914]\n",
            " [0.48307276 0.50725    0.51904607 0.48758388 0.48901466]\n",
            " [0.48307687 0.5072569  0.519103   0.48758173 0.48891097]\n",
            " [0.48304343 0.50721073 0.51911956 0.4875596  0.48883504]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48307434 0.5071918  0.5190637  0.487569   0.488847  ]\n",
            " [0.483062   0.5072497  0.5191021  0.48758045 0.48887515]\n",
            " [0.4830208  0.50720197 0.51911277 0.48755196 0.48876616]\n",
            " [0.48307344 0.5072285  0.51907    0.48756993 0.48891255]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4830501  0.50718284 0.51910186 0.4875537  0.48879194]\n",
            " [0.4830538  0.5072121  0.5190965  0.48755395 0.48886585]\n",
            " [0.48312256 0.50726914 0.5191296  0.48762876 0.48898667]\n",
            " [0.48308173 0.5072272  0.5190905  0.48758197 0.4888866 ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48302642 0.50714576 0.51911813 0.48753715 0.48874915]\n",
            " [0.48314866 0.5072716  0.5190613  0.48757607 0.48896787]\n",
            " [0.48300207 0.5071268  0.5191262  0.48753422 0.4887348 ]\n",
            " [0.48305055 0.5071974  0.51908267 0.4875488  0.48882952]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48303932 0.507229   0.5191125  0.4875379  0.48882732]\n",
            " [0.4830882  0.5072688  0.519099   0.4875902  0.4889131 ]\n",
            " [0.4830779  0.507201   0.51906985 0.48755816 0.48885584]\n",
            " [0.48304173 0.50715244 0.5190994  0.48753887 0.4887643 ]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48308298 0.5072178  0.51908845 0.4875664  0.48888454]\n",
            " [0.4830331  0.5072236  0.5191204  0.48755896 0.48886976]\n",
            " [0.48293108 0.50723165 0.51913005 0.4874992  0.48872152]\n",
            " [0.48301026 0.50713044 0.5191328  0.48755407 0.48872972]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4830275  0.5071527  0.5191173  0.48754734 0.48874664]\n",
            " [0.4831231  0.5072814  0.51909226 0.48758376 0.4889411 ]\n",
            " [0.48311052 0.50721383 0.519066   0.4875879  0.4888655 ]\n",
            " [0.48299164 0.5072024  0.5191273  0.48751706 0.48876396]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48306748 0.5072214  0.519093   0.48755696 0.48883325]\n",
            " [0.48318544 0.50729835 0.51906335 0.48757133 0.48900253]\n",
            " [0.482936   0.507183   0.51912683 0.48752832 0.48869517]\n",
            " [0.48307028 0.5072351  0.51909083 0.4875926  0.48886254]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4830915  0.5072249  0.5190634  0.48756006 0.4888716 ]\n",
            " [0.48306727 0.50722533 0.5191011  0.48757198 0.4888704 ]\n",
            " [0.48305362 0.5072558  0.5191001  0.48757428 0.48891637]\n",
            " [0.48315188 0.50723124 0.5190867  0.48754624 0.488882  ]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831331  0.5072476  0.51907057 0.48758084 0.4889241 ]\n",
            " [0.4829787  0.5072529  0.5191329  0.48750383 0.48882186]\n",
            " [0.48309624 0.50721204 0.5190901  0.48755836 0.4888498 ]\n",
            " [0.48297143 0.5071323  0.51914465 0.48751256 0.4887133 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48305956 0.5071923  0.51908064 0.4875533  0.4888098 ]\n",
            " [0.48304346 0.5071776  0.5190834  0.48754805 0.4887892 ]\n",
            " [0.4830714  0.5072618  0.5190457  0.48758724 0.48901188]\n",
            " [0.48297262 0.507116   0.51911914 0.48752022 0.48868042]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48309967 0.5072235  0.5190743  0.48756564 0.48893052]\n",
            " [0.4831343  0.5072726  0.519045   0.48756292 0.48901758]\n",
            " [0.48308936 0.5072054  0.5190854  0.48754832 0.48887974]\n",
            " [0.48309523 0.5072145  0.5190871  0.4875648  0.48887032]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48307186 0.48301107 0.48309794 0.48308447 0.48310512 0.48309717\n",
            " 0.48291755 0.48310557 0.4830846  0.48293328 0.4830763  0.48306805\n",
            " 0.48304337 0.48307276 0.48307687 0.48304343 0.48307434 0.483062\n",
            " 0.4830208  0.48307344 0.4830501  0.4830538  0.48312256 0.48308173\n",
            " 0.48302642 0.48314866 0.48300207 0.48305055 0.48303932 0.4830882\n",
            " 0.4830779  0.48304173 0.48308298 0.4830331  0.48293108 0.48301026\n",
            " 0.4830275  0.4831231  0.48311052 0.48299164 0.48306748 0.48318544\n",
            " 0.482936   0.48307028 0.4830915  0.48306727 0.48305362 0.48315188\n",
            " 0.4831331  0.4829787  0.48309624 0.48297143 0.48305956 0.48304346\n",
            " 0.4830714  0.48297262 0.48309967 0.4831343  0.48308936 0.48309523]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.4903885029489174e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50720376 0.5072552  0.5072408  0.507249   0.50724566 0.5071929\n",
            " 0.5072178  0.50720197 0.5072714  0.5071927  0.5072431  0.5072547\n",
            " 0.5071905  0.50725    0.5072569  0.50721073 0.5071918  0.5072497\n",
            " 0.50720197 0.5072285  0.50718284 0.5072121  0.50726914 0.5072272\n",
            " 0.50714576 0.5072716  0.5071268  0.5071974  0.507229   0.5072688\n",
            " 0.507201   0.50715244 0.5072178  0.5072236  0.50723165 0.50713044\n",
            " 0.5071527  0.5072814  0.50721383 0.5072024  0.5072214  0.50729835\n",
            " 0.507183   0.5072351  0.5072249  0.50722533 0.5072558  0.50723124\n",
            " 0.5072476  0.5072529  0.50721204 0.5071323  0.5071923  0.5071776\n",
            " 0.5072618  0.507116   0.5072235  0.5072726  0.5072054  0.5072145 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.022403300041333e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5191089  0.5191065  0.51909    0.5190892  0.51907265 0.5190902\n",
            " 0.5191331  0.5190974  0.51909536 0.5191556  0.5190811  0.519056\n",
            " 0.51907474 0.51904607 0.519103   0.51911956 0.5190637  0.5191021\n",
            " 0.51911277 0.51907    0.51910186 0.5190965  0.5191296  0.5190905\n",
            " 0.51911813 0.5190613  0.5191262  0.51908267 0.5191125  0.519099\n",
            " 0.51906985 0.5190994  0.51908845 0.5191204  0.51913005 0.5191328\n",
            " 0.5191173  0.51909226 0.519066   0.5191273  0.519093   0.51906335\n",
            " 0.51912683 0.51909083 0.5190634  0.5191011  0.5191001  0.5190867\n",
            " 0.51907057 0.5191329  0.5190901  0.51914465 0.51908064 0.5190834\n",
            " 0.5190457  0.51911914 0.5190743  0.519045   0.5190854  0.5190871 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.519341251172591e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48754838 0.48755494 0.48758274 0.4875948  0.4875659  0.48757944\n",
            " 0.48751003 0.4875603  0.48760524 0.48750237 0.4875586  0.4875894\n",
            " 0.48754886 0.48758388 0.48758173 0.4875596  0.487569   0.48758045\n",
            " 0.48755196 0.48756993 0.4875537  0.48755395 0.48762876 0.48758197\n",
            " 0.48753715 0.48757607 0.48753422 0.4875488  0.4875379  0.4875902\n",
            " 0.48755816 0.48753887 0.4875664  0.48755896 0.4874992  0.48755407\n",
            " 0.48754734 0.48758376 0.4875879  0.48751706 0.48755696 0.48757133\n",
            " 0.48752832 0.4875926  0.48756006 0.48757198 0.48757428 0.48754624\n",
            " 0.48758084 0.48750383 0.48755836 0.48751256 0.4875533  0.48754805\n",
            " 0.48758724 0.48752022 0.48756564 0.48756292 0.48754832 0.4875648 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.580697400844656e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48883015 0.48885524 0.48890188 0.48889774 0.48889264 0.4888887\n",
            " 0.48873287 0.4888353  0.48895332 0.48870203 0.48889998 0.48897886\n",
            " 0.48878914 0.48901466 0.48891097 0.48883504 0.488847   0.48887515\n",
            " 0.48876616 0.48891255 0.48879194 0.48886585 0.48898667 0.4888866\n",
            " 0.48874915 0.48896787 0.4887348  0.48882952 0.48882732 0.4889131\n",
            " 0.48885584 0.4887643  0.48888454 0.48886976 0.48872152 0.48872972\n",
            " 0.48874664 0.4889411  0.4888655  0.48876396 0.48883325 0.48900253\n",
            " 0.48869517 0.48886254 0.4888716  0.4888704  0.48891637 0.488882\n",
            " 0.4889241  0.48882186 0.4888498  0.4887133  0.4888098  0.4887892\n",
            " 0.48901188 0.48868042 0.48893052 0.48901758 0.48887974 0.48887032]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.437837823294103e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48307186 0.48301107 0.48309794 0.48308447 0.48310512 0.48309717\n",
            " 0.48291755 0.48310557 0.4830846  0.48293328 0.4830763  0.48306805\n",
            " 0.48304337 0.48307276 0.48307687 0.48304343 0.48307434 0.483062\n",
            " 0.4830208  0.48307344 0.4830501  0.4830538  0.48312256 0.48308173\n",
            " 0.48302642 0.48314866 0.48300207 0.48305055 0.48303932 0.4830882\n",
            " 0.4830779  0.48304173 0.48308298 0.4830331  0.48293108 0.48301026\n",
            " 0.4830275  0.4831231  0.48311052 0.48299164 0.48306748 0.48318544\n",
            " 0.482936   0.48307028 0.4830915  0.48306727 0.48305362 0.48315188\n",
            " 0.4831331  0.4829787  0.48309624 0.48297143 0.48305956 0.48304346\n",
            " 0.4830714  0.48297262 0.48309967 0.4831343  0.48308936 0.48309523]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.4903885029489174e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50720376 0.5072552  0.5072408  0.507249   0.50724566 0.5071929\n",
            " 0.5072178  0.50720197 0.5072714  0.5071927  0.5072431  0.5072547\n",
            " 0.5071905  0.50725    0.5072569  0.50721073 0.5071918  0.5072497\n",
            " 0.50720197 0.5072285  0.50718284 0.5072121  0.50726914 0.5072272\n",
            " 0.50714576 0.5072716  0.5071268  0.5071974  0.507229   0.5072688\n",
            " 0.507201   0.50715244 0.5072178  0.5072236  0.50723165 0.50713044\n",
            " 0.5071527  0.5072814  0.50721383 0.5072024  0.5072214  0.50729835\n",
            " 0.507183   0.5072351  0.5072249  0.50722533 0.5072558  0.50723124\n",
            " 0.5072476  0.5072529  0.50721204 0.5071323  0.5071923  0.5071776\n",
            " 0.5072618  0.507116   0.5072235  0.5072726  0.5072054  0.5072145 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.022403300041333e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5191089  0.5191065  0.51909    0.5190892  0.51907265 0.5190902\n",
            " 0.5191331  0.5190974  0.51909536 0.5191556  0.5190811  0.519056\n",
            " 0.51907474 0.51904607 0.519103   0.51911956 0.5190637  0.5191021\n",
            " 0.51911277 0.51907    0.51910186 0.5190965  0.5191296  0.5190905\n",
            " 0.51911813 0.5190613  0.5191262  0.51908267 0.5191125  0.519099\n",
            " 0.51906985 0.5190994  0.51908845 0.5191204  0.51913005 0.5191328\n",
            " 0.5191173  0.51909226 0.519066   0.5191273  0.519093   0.51906335\n",
            " 0.51912683 0.51909083 0.5190634  0.5191011  0.5191001  0.5190867\n",
            " 0.51907057 0.5191329  0.5190901  0.51914465 0.51908064 0.5190834\n",
            " 0.5190457  0.51911914 0.5190743  0.519045   0.5190854  0.5190871 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.519341251172591e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48754838 0.48755494 0.48758274 0.4875948  0.4875659  0.48757944\n",
            " 0.48751003 0.4875603  0.48760524 0.48750237 0.4875586  0.4875894\n",
            " 0.48754886 0.48758388 0.48758173 0.4875596  0.487569   0.48758045\n",
            " 0.48755196 0.48756993 0.4875537  0.48755395 0.48762876 0.48758197\n",
            " 0.48753715 0.48757607 0.48753422 0.4875488  0.4875379  0.4875902\n",
            " 0.48755816 0.48753887 0.4875664  0.48755896 0.4874992  0.48755407\n",
            " 0.48754734 0.48758376 0.4875879  0.48751706 0.48755696 0.48757133\n",
            " 0.48752832 0.4875926  0.48756006 0.48757198 0.48757428 0.48754624\n",
            " 0.48758084 0.48750383 0.48755836 0.48751256 0.4875533  0.48754805\n",
            " 0.48758724 0.48752022 0.48756564 0.48756292 0.48754832 0.4875648 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.580697400844656e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48883015 0.48885524 0.48890188 0.48889774 0.48889264 0.4888887\n",
            " 0.48873287 0.4888353  0.48895332 0.48870203 0.48889998 0.48897886\n",
            " 0.48878914 0.48901466 0.48891097 0.48883504 0.488847   0.48887515\n",
            " 0.48876616 0.48891255 0.48879194 0.48886585 0.48898667 0.4888866\n",
            " 0.48874915 0.48896787 0.4887348  0.48882952 0.48882732 0.4889131\n",
            " 0.48885584 0.4887643  0.48888454 0.48886976 0.48872152 0.48872972\n",
            " 0.48874664 0.4889411  0.4888655  0.48876396 0.48883325 0.48900253\n",
            " 0.48869517 0.48886254 0.4888716  0.4888704  0.48891637 0.488882\n",
            " 0.4889241  0.48882186 0.4888498  0.4887133  0.4888098  0.4887892\n",
            " 0.48901188 0.48868042 0.48893052 0.48901758 0.48887974 0.48887032]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.437837823294103e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48307186 0.48301107 0.48309794 0.48308447 0.48310512 0.48309717\n",
            " 0.48291755 0.48310557 0.4830846  0.48293328 0.4830763  0.48306805\n",
            " 0.48304337 0.48307276 0.48307687 0.48304343 0.48307434 0.483062\n",
            " 0.4830208  0.48307344 0.4830501  0.4830538  0.48312256 0.48308173\n",
            " 0.48302642 0.48314866 0.48300207 0.48305055 0.48303932 0.4830882\n",
            " 0.4830779  0.48304173 0.48308298 0.4830331  0.48293108 0.48301026\n",
            " 0.4830275  0.4831231  0.48311052 0.48299164 0.48306748 0.48318544\n",
            " 0.482936   0.48307028 0.4830915  0.48306727 0.48305362 0.48315188\n",
            " 0.4831331  0.4829787  0.48309624 0.48297143 0.48305956 0.48304346\n",
            " 0.4830714  0.48297262 0.48309967 0.4831343  0.48308936 0.48309523]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.4903885029489174e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50720376 0.5072552  0.5072408  0.507249   0.50724566 0.5071929\n",
            " 0.5072178  0.50720197 0.5072714  0.5071927  0.5072431  0.5072547\n",
            " 0.5071905  0.50725    0.5072569  0.50721073 0.5071918  0.5072497\n",
            " 0.50720197 0.5072285  0.50718284 0.5072121  0.50726914 0.5072272\n",
            " 0.50714576 0.5072716  0.5071268  0.5071974  0.507229   0.5072688\n",
            " 0.507201   0.50715244 0.5072178  0.5072236  0.50723165 0.50713044\n",
            " 0.5071527  0.5072814  0.50721383 0.5072024  0.5072214  0.50729835\n",
            " 0.507183   0.5072351  0.5072249  0.50722533 0.5072558  0.50723124\n",
            " 0.5072476  0.5072529  0.50721204 0.5071323  0.5071923  0.5071776\n",
            " 0.5072618  0.507116   0.5072235  0.5072726  0.5072054  0.5072145 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.022403300041333e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5191089  0.5191065  0.51909    0.5190892  0.51907265 0.5190902\n",
            " 0.5191331  0.5190974  0.51909536 0.5191556  0.5190811  0.519056\n",
            " 0.51907474 0.51904607 0.519103   0.51911956 0.5190637  0.5191021\n",
            " 0.51911277 0.51907    0.51910186 0.5190965  0.5191296  0.5190905\n",
            " 0.51911813 0.5190613  0.5191262  0.51908267 0.5191125  0.519099\n",
            " 0.51906985 0.5190994  0.51908845 0.5191204  0.51913005 0.5191328\n",
            " 0.5191173  0.51909226 0.519066   0.5191273  0.519093   0.51906335\n",
            " 0.51912683 0.51909083 0.5190634  0.5191011  0.5191001  0.5190867\n",
            " 0.51907057 0.5191329  0.5190901  0.51914465 0.51908064 0.5190834\n",
            " 0.5190457  0.51911914 0.5190743  0.519045   0.5190854  0.5190871 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.519341251172591e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48754838 0.48755494 0.48758274 0.4875948  0.4875659  0.48757944\n",
            " 0.48751003 0.4875603  0.48760524 0.48750237 0.4875586  0.4875894\n",
            " 0.48754886 0.48758388 0.48758173 0.4875596  0.487569   0.48758045\n",
            " 0.48755196 0.48756993 0.4875537  0.48755395 0.48762876 0.48758197\n",
            " 0.48753715 0.48757607 0.48753422 0.4875488  0.4875379  0.4875902\n",
            " 0.48755816 0.48753887 0.4875664  0.48755896 0.4874992  0.48755407\n",
            " 0.48754734 0.48758376 0.4875879  0.48751706 0.48755696 0.48757133\n",
            " 0.48752832 0.4875926  0.48756006 0.48757198 0.48757428 0.48754624\n",
            " 0.48758084 0.48750383 0.48755836 0.48751256 0.4875533  0.48754805\n",
            " 0.48758724 0.48752022 0.48756564 0.48756292 0.48754832 0.4875648 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.580697400844656e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48883015 0.48885524 0.48890188 0.48889774 0.48889264 0.4888887\n",
            " 0.48873287 0.4888353  0.48895332 0.48870203 0.48889998 0.48897886\n",
            " 0.48878914 0.48901466 0.48891097 0.48883504 0.488847   0.48887515\n",
            " 0.48876616 0.48891255 0.48879194 0.48886585 0.48898667 0.4888866\n",
            " 0.48874915 0.48896787 0.4887348  0.48882952 0.48882732 0.4889131\n",
            " 0.48885584 0.4887643  0.48888454 0.48886976 0.48872152 0.48872972\n",
            " 0.48874664 0.4889411  0.4888655  0.48876396 0.48883325 0.48900253\n",
            " 0.48869517 0.48886254 0.4888716  0.4888704  0.48891637 0.488882\n",
            " 0.4889241  0.48882186 0.4888498  0.4887133  0.4888098  0.4887892\n",
            " 0.48901188 0.48868042 0.48893052 0.48901758 0.48887974 0.48887032]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.437837823294103e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48307186 0.48301107 0.48309794 0.48308447 0.48310512 0.48309717\n",
            " 0.48291755 0.48310557 0.4830846  0.48293328 0.4830763  0.48306805\n",
            " 0.48304337 0.48307276 0.48307687 0.48304343 0.48307434 0.483062\n",
            " 0.4830208  0.48307344 0.4830501  0.4830538  0.48312256 0.48308173\n",
            " 0.48302642 0.48314866 0.48300207 0.48305055 0.48303932 0.4830882\n",
            " 0.4830779  0.48304173 0.48308298 0.4830331  0.48293108 0.48301026\n",
            " 0.4830275  0.4831231  0.48311052 0.48299164 0.48306748 0.48318544\n",
            " 0.482936   0.48307028 0.4830915  0.48306727 0.48305362 0.48315188\n",
            " 0.4831331  0.4829787  0.48309624 0.48297143 0.48305956 0.48304346\n",
            " 0.4830714  0.48297262 0.48309967 0.4831343  0.48308936 0.48309523]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.4903885029489174e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50720376 0.5072552  0.5072408  0.507249   0.50724566 0.5071929\n",
            " 0.5072178  0.50720197 0.5072714  0.5071927  0.5072431  0.5072547\n",
            " 0.5071905  0.50725    0.5072569  0.50721073 0.5071918  0.5072497\n",
            " 0.50720197 0.5072285  0.50718284 0.5072121  0.50726914 0.5072272\n",
            " 0.50714576 0.5072716  0.5071268  0.5071974  0.507229   0.5072688\n",
            " 0.507201   0.50715244 0.5072178  0.5072236  0.50723165 0.50713044\n",
            " 0.5071527  0.5072814  0.50721383 0.5072024  0.5072214  0.50729835\n",
            " 0.507183   0.5072351  0.5072249  0.50722533 0.5072558  0.50723124\n",
            " 0.5072476  0.5072529  0.50721204 0.5071323  0.5071923  0.5071776\n",
            " 0.5072618  0.507116   0.5072235  0.5072726  0.5072054  0.5072145 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.022403300041333e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.5191089  0.5191065  0.51909    0.5190892  0.51907265 0.5190902\n",
            " 0.5191331  0.5190974  0.51909536 0.5191556  0.5190811  0.519056\n",
            " 0.51907474 0.51904607 0.519103   0.51911956 0.5190637  0.5191021\n",
            " 0.51911277 0.51907    0.51910186 0.5190965  0.5191296  0.5190905\n",
            " 0.51911813 0.5190613  0.5191262  0.51908267 0.5191125  0.519099\n",
            " 0.51906985 0.5190994  0.51908845 0.5191204  0.51913005 0.5191328\n",
            " 0.5191173  0.51909226 0.519066   0.5191273  0.519093   0.51906335\n",
            " 0.51912683 0.51909083 0.5190634  0.5191011  0.5191001  0.5190867\n",
            " 0.51907057 0.5191329  0.5190901  0.51914465 0.51908064 0.5190834\n",
            " 0.5190457  0.51911914 0.5190743  0.519045   0.5190854  0.5190871 ]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.519341251172591e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48754838 0.48755494 0.48758274 0.4875948  0.4875659  0.48757944\n",
            " 0.48751003 0.4875603  0.48760524 0.48750237 0.4875586  0.4875894\n",
            " 0.48754886 0.48758388 0.48758173 0.4875596  0.487569   0.48758045\n",
            " 0.48755196 0.48756993 0.4875537  0.48755395 0.48762876 0.48758197\n",
            " 0.48753715 0.48757607 0.48753422 0.4875488  0.4875379  0.4875902\n",
            " 0.48755816 0.48753887 0.4875664  0.48755896 0.4874992  0.48755407\n",
            " 0.48754734 0.48758376 0.4875879  0.48751706 0.48755696 0.48757133\n",
            " 0.48752832 0.4875926  0.48756006 0.48757198 0.48757428 0.48754624\n",
            " 0.48758084 0.48750383 0.48755836 0.48751256 0.4875533  0.48754805\n",
            " 0.48758724 0.48752022 0.48756564 0.48756292 0.48754832 0.4875648 ]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.580697400844656e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48883015 0.48885524 0.48890188 0.48889774 0.48889264 0.4888887\n",
            " 0.48873287 0.4888353  0.48895332 0.48870203 0.48889998 0.48897886\n",
            " 0.48878914 0.48901466 0.48891097 0.48883504 0.488847   0.48887515\n",
            " 0.48876616 0.48891255 0.48879194 0.48886585 0.48898667 0.4888866\n",
            " 0.48874915 0.48896787 0.4887348  0.48882952 0.48882732 0.4889131\n",
            " 0.48885584 0.4887643  0.48888454 0.48886976 0.48872152 0.48872972\n",
            " 0.48874664 0.4889411  0.4888655  0.48876396 0.48883325 0.48900253\n",
            " 0.48869517 0.48886254 0.4888716  0.4888704  0.48891637 0.488882\n",
            " 0.4889241  0.48882186 0.4888498  0.4887133  0.4888098  0.4887892\n",
            " 0.48901188 0.48868042 0.48893052 0.48901758 0.48887974 0.48887032]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.437837823294103e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48303968 0.5072076  0.5191247  0.48754904 0.48881736]\n",
            " [0.48300457 0.5071572  0.5191366  0.48754933 0.48872763]\n",
            " [0.48298168 0.50713825 0.5191238  0.4875362  0.48873225]\n",
            " [0.48299208 0.5072299  0.51912147 0.4875442  0.4887772 ]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48302013 0.50717926 0.5190884  0.48753846 0.4887551 ]\n",
            " [0.4830836  0.5072104  0.5191028  0.48757502 0.4889185 ]\n",
            " [0.4831214  0.5072502  0.51907635 0.48755464 0.48896262]\n",
            " [0.4830036  0.5071491  0.51910657 0.4875502  0.4887169 ]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831168  0.5072261  0.51909465 0.48755625 0.48889723]\n",
            " [0.48309204 0.50723326 0.5190705  0.48756564 0.48886386]\n",
            " [0.4831165  0.50724393 0.5190689  0.4875604  0.4888969 ]\n",
            " [0.48307282 0.50719047 0.5190931  0.48756868 0.48884526]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4830493  0.50729823 0.519099   0.48756576 0.4889031 ]\n",
            " [0.48307008 0.5072315  0.51910824 0.4875678  0.48893887]\n",
            " [0.4830696  0.5071772  0.51908374 0.48756087 0.48878118]\n",
            " [0.48306912 0.5071912  0.519099   0.48754594 0.48883054]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48305723 0.5072071  0.5190962  0.48755577 0.48882356]\n",
            " [0.4831397  0.50728935 0.5190483  0.4875984  0.48901936]\n",
            " [0.48310173 0.5072464  0.51904535 0.48757702 0.48893368]\n",
            " [0.48304024 0.50716794 0.51910424 0.48753908 0.48880014]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48303968 0.48300457 0.48298168 0.48299208 0.48302013 0.4830836\n",
            " 0.4831214  0.4830036  0.4831168  0.48309204 0.4831165  0.48307282\n",
            " 0.4830493  0.48307008 0.4830696  0.48306912 0.48305723 0.4831397\n",
            " 0.48310173 0.48304024]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.457318573258817e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5072076  0.5071572  0.50713825 0.5072299  0.50717926 0.5072104\n",
            " 0.5072502  0.5071491  0.5072261  0.50723326 0.50724393 0.50719047\n",
            " 0.50729823 0.5072315  0.5071772  0.5071912  0.5072071  0.50728935\n",
            " 0.5072464  0.50716794]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.2417890654178336e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5191247  0.5191366  0.5191238  0.51912147 0.5190884  0.5191028\n",
            " 0.51907635 0.51910657 0.51909465 0.5190705  0.5190689  0.5190931\n",
            " 0.519099   0.51910824 0.51908374 0.519099   0.5190962  0.5190483\n",
            " 0.51904535 0.51910424]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.3536522348877043e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48754904 0.48754933 0.4875362  0.4875442  0.48753846 0.48757502\n",
            " 0.48755464 0.4875502  0.48755625 0.48756564 0.4875604  0.48756868\n",
            " 0.48756576 0.4875678  0.48756087 0.48754594 0.48755577 0.4875984\n",
            " 0.48757702 0.48753908]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.485305529058678e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48881736 0.48872763 0.48873225 0.4887772  0.4887551  0.4889185\n",
            " 0.48896262 0.4887169  0.48889723 0.48886386 0.4888969  0.48884526\n",
            " 0.4889031  0.48893887 0.48878118 0.48883054 0.48882356 0.48901936\n",
            " 0.48893368 0.48880014]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.321102359332144e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48303968 0.48300457 0.48298168 0.48299208 0.48302013 0.4830836\n",
            " 0.4831214  0.4830036  0.4831168  0.48309204 0.4831165  0.48307282\n",
            " 0.4830493  0.48307008 0.4830696  0.48306912 0.48305723 0.4831397\n",
            " 0.48310173 0.48304024]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.457318573258817e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5072076  0.5071572  0.50713825 0.5072299  0.50717926 0.5072104\n",
            " 0.5072502  0.5071491  0.5072261  0.50723326 0.50724393 0.50719047\n",
            " 0.50729823 0.5072315  0.5071772  0.5071912  0.5072071  0.50728935\n",
            " 0.5072464  0.50716794]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.2417890654178336e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5191247  0.5191366  0.5191238  0.51912147 0.5190884  0.5191028\n",
            " 0.51907635 0.51910657 0.51909465 0.5190705  0.5190689  0.5190931\n",
            " 0.519099   0.51910824 0.51908374 0.519099   0.5190962  0.5190483\n",
            " 0.51904535 0.51910424]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.3536522348877043e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48754904 0.48754933 0.4875362  0.4875442  0.48753846 0.48757502\n",
            " 0.48755464 0.4875502  0.48755625 0.48756564 0.4875604  0.48756868\n",
            " 0.48756576 0.4875678  0.48756087 0.48754594 0.48755577 0.4875984\n",
            " 0.48757702 0.48753908]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.485305529058678e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48881736 0.48872763 0.48873225 0.4887772  0.4887551  0.4889185\n",
            " 0.48896262 0.4887169  0.48889723 0.48886386 0.4888969  0.48884526\n",
            " 0.4889031  0.48893887 0.48878118 0.48883054 0.48882356 0.48901936\n",
            " 0.48893368 0.48880014]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.321102359332144e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48303968 0.48300457 0.48298168 0.48299208 0.48302013 0.4830836\n",
            " 0.4831214  0.4830036  0.4831168  0.48309204 0.4831165  0.48307282\n",
            " 0.4830493  0.48307008 0.4830696  0.48306912 0.48305723 0.4831397\n",
            " 0.48310173 0.48304024]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.457318573258817e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5072076  0.5071572  0.50713825 0.5072299  0.50717926 0.5072104\n",
            " 0.5072502  0.5071491  0.5072261  0.50723326 0.50724393 0.50719047\n",
            " 0.50729823 0.5072315  0.5071772  0.5071912  0.5072071  0.50728935\n",
            " 0.5072464  0.50716794]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.2417890654178336e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5191247  0.5191366  0.5191238  0.51912147 0.5190884  0.5191028\n",
            " 0.51907635 0.51910657 0.51909465 0.5190705  0.5190689  0.5190931\n",
            " 0.519099   0.51910824 0.51908374 0.519099   0.5190962  0.5190483\n",
            " 0.51904535 0.51910424]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.3536522348877043e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48754904 0.48754933 0.4875362  0.4875442  0.48753846 0.48757502\n",
            " 0.48755464 0.4875502  0.48755625 0.48756564 0.4875604  0.48756868\n",
            " 0.48756576 0.4875678  0.48756087 0.48754594 0.48755577 0.4875984\n",
            " 0.48757702 0.48753908]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.485305529058678e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48881736 0.48872763 0.48873225 0.4887772  0.4887551  0.4889185\n",
            " 0.48896262 0.4887169  0.48889723 0.48886386 0.4888969  0.48884526\n",
            " 0.4889031  0.48893887 0.48878118 0.48883054 0.48882356 0.48901936\n",
            " 0.48893368 0.48880014]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.321102359332144e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48303968 0.48300457 0.48298168 0.48299208 0.48302013 0.4830836\n",
            " 0.4831214  0.4830036  0.4831168  0.48309204 0.4831165  0.48307282\n",
            " 0.4830493  0.48307008 0.4830696  0.48306912 0.48305723 0.4831397\n",
            " 0.48310173 0.48304024]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.457318573258817e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.5072076  0.5071572  0.50713825 0.5072299  0.50717926 0.5072104\n",
            " 0.5072502  0.5071491  0.5072261  0.50723326 0.50724393 0.50719047\n",
            " 0.50729823 0.5072315  0.5071772  0.5071912  0.5072071  0.50728935\n",
            " 0.5072464  0.50716794]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.2417890654178336e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5191247  0.5191366  0.5191238  0.51912147 0.5190884  0.5191028\n",
            " 0.51907635 0.51910657 0.51909465 0.5190705  0.5190689  0.5190931\n",
            " 0.519099   0.51910824 0.51908374 0.519099   0.5190962  0.5190483\n",
            " 0.51904535 0.51910424]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.3536522348877043e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48754904 0.48754933 0.4875362  0.4875442  0.48753846 0.48757502\n",
            " 0.48755464 0.4875502  0.48755625 0.48756564 0.4875604  0.48756868\n",
            " 0.48756576 0.4875678  0.48756087 0.48754594 0.48755577 0.4875984\n",
            " 0.48757702 0.48753908]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.485305529058678e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48881736 0.48872763 0.48873225 0.4887772  0.4887551  0.4889185\n",
            " 0.48896262 0.4887169  0.48889723 0.48886386 0.4888969  0.48884526\n",
            " 0.4889031  0.48893887 0.48878118 0.48883054 0.48882356 0.48901936\n",
            " 0.48893368 0.48880014]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.321102359332144e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48309898 0.507232   0.51909655 0.48757708 0.488861  ]\n",
            " [0.48311576 0.50724185 0.5190625  0.48755962 0.48892215]\n",
            " [0.4831104  0.5072515  0.51906997 0.48755932 0.48892665]\n",
            " [0.4830559  0.5072053  0.51907825 0.487562   0.48882467]\n",
            " [0.4831356  0.507262   0.5190657  0.48754746 0.48895952]\n",
            " [0.4830221  0.507176   0.5191396  0.4875441  0.48876962]\n",
            " [0.4830124  0.50717705 0.51910925 0.48755333 0.48878407]\n",
            " [0.48301992 0.50715    0.5190935  0.48754698 0.48876238]\n",
            " [0.48303294 0.5071658  0.5191176  0.48756653 0.48875818]\n",
            " [0.48304248 0.5072308  0.51909226 0.48757464 0.4888958 ]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48302576 0.507223   0.5191092  0.48757124 0.4888634 ]\n",
            " [0.48304394 0.5071976  0.51911587 0.48756132 0.4888067 ]\n",
            " [0.48306754 0.5071976  0.51909864 0.48757303 0.4888534 ]\n",
            " [0.4831177  0.5072709  0.51908094 0.48760808 0.48898852]\n",
            " [0.48305166 0.5072017  0.51908576 0.48756748 0.48883465]\n",
            " [0.48310098 0.5072191  0.519082   0.4875654  0.48890188]\n",
            " [0.48311424 0.5072503  0.5190857  0.4875839  0.48896694]\n",
            " [0.4830422  0.5071498  0.5191041  0.4875387  0.4887532 ]\n",
            " [0.48309052 0.50725573 0.51907116 0.48757175 0.48888966]\n",
            " [0.4830084  0.507235   0.51910865 0.48753735 0.48882675]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48309898 0.48311576 0.4831104  0.4830559  0.4831356  0.4830221\n",
            " 0.4830124  0.48301992 0.48303294 0.48304248 0.48302576 0.48304394\n",
            " 0.48306754 0.4831177  0.48305166 0.48310098 0.48311424 0.4830422\n",
            " 0.48309052 0.4830084 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.0042730688583106e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.507232   0.50724185 0.5072515  0.5072053  0.507262   0.507176\n",
            " 0.50717705 0.50715    0.5071658  0.5072308  0.507223   0.5071976\n",
            " 0.5071976  0.5072709  0.5072017  0.5072191  0.5072503  0.5071498\n",
            " 0.50725573 0.507235  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.608384577091783e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51909655 0.5190625  0.51906997 0.51907825 0.5190657  0.5191396\n",
            " 0.51910925 0.5190935  0.5191176  0.51909226 0.5191092  0.51911587\n",
            " 0.51909864 0.51908094 0.51908576 0.519082   0.5190857  0.5191041\n",
            " 0.51907116 0.51910865]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.93749710888369e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48757708 0.48755962 0.48755932 0.487562   0.48754746 0.4875441\n",
            " 0.48755333 0.48754698 0.48756653 0.48757464 0.48757124 0.48756132\n",
            " 0.48757303 0.48760808 0.48756748 0.4875654  0.4875839  0.4875387\n",
            " 0.48757175 0.48753735]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.629119651624933e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.488861   0.48892215 0.48892665 0.48882467 0.48895952 0.48876962\n",
            " 0.48878407 0.48876238 0.48875818 0.4888958  0.4888634  0.4888067\n",
            " 0.4888534  0.48898852 0.48883465 0.48890188 0.48896694 0.4887532\n",
            " 0.48888966 0.48882675]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.109186117304489e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48309898 0.48311576 0.4831104  0.4830559  0.4831356  0.4830221\n",
            " 0.4830124  0.48301992 0.48303294 0.48304248 0.48302576 0.48304394\n",
            " 0.48306754 0.4831177  0.48305166 0.48310098 0.48311424 0.4830422\n",
            " 0.48309052 0.4830084 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.0042730688583106e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.507232   0.50724185 0.5072515  0.5072053  0.507262   0.507176\n",
            " 0.50717705 0.50715    0.5071658  0.5072308  0.507223   0.5071976\n",
            " 0.5071976  0.5072709  0.5072017  0.5072191  0.5072503  0.5071498\n",
            " 0.50725573 0.507235  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.608384577091783e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51909655 0.5190625  0.51906997 0.51907825 0.5190657  0.5191396\n",
            " 0.51910925 0.5190935  0.5191176  0.51909226 0.5191092  0.51911587\n",
            " 0.51909864 0.51908094 0.51908576 0.519082   0.5190857  0.5191041\n",
            " 0.51907116 0.51910865]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.93749710888369e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48757708 0.48755962 0.48755932 0.487562   0.48754746 0.4875441\n",
            " 0.48755333 0.48754698 0.48756653 0.48757464 0.48757124 0.48756132\n",
            " 0.48757303 0.48760808 0.48756748 0.4875654  0.4875839  0.4875387\n",
            " 0.48757175 0.48753735]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.629119651624933e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.488861   0.48892215 0.48892665 0.48882467 0.48895952 0.48876962\n",
            " 0.48878407 0.48876238 0.48875818 0.4888958  0.4888634  0.4888067\n",
            " 0.4888534  0.48898852 0.48883465 0.48890188 0.48896694 0.4887532\n",
            " 0.48888966 0.48882675]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.109186117304489e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48309898 0.48311576 0.4831104  0.4830559  0.4831356  0.4830221\n",
            " 0.4830124  0.48301992 0.48303294 0.48304248 0.48302576 0.48304394\n",
            " 0.48306754 0.4831177  0.48305166 0.48310098 0.48311424 0.4830422\n",
            " 0.48309052 0.4830084 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.0042730688583106e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.507232   0.50724185 0.5072515  0.5072053  0.507262   0.507176\n",
            " 0.50717705 0.50715    0.5071658  0.5072308  0.507223   0.5071976\n",
            " 0.5071976  0.5072709  0.5072017  0.5072191  0.5072503  0.5071498\n",
            " 0.50725573 0.507235  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.608384577091783e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51909655 0.5190625  0.51906997 0.51907825 0.5190657  0.5191396\n",
            " 0.51910925 0.5190935  0.5191176  0.51909226 0.5191092  0.51911587\n",
            " 0.51909864 0.51908094 0.51908576 0.519082   0.5190857  0.5191041\n",
            " 0.51907116 0.51910865]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.93749710888369e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48757708 0.48755962 0.48755932 0.487562   0.48754746 0.4875441\n",
            " 0.48755333 0.48754698 0.48756653 0.48757464 0.48757124 0.48756132\n",
            " 0.48757303 0.48760808 0.48756748 0.4875654  0.4875839  0.4875387\n",
            " 0.48757175 0.48753735]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.629119651624933e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.488861   0.48892215 0.48892665 0.48882467 0.48895952 0.48876962\n",
            " 0.48878407 0.48876238 0.48875818 0.4888958  0.4888634  0.4888067\n",
            " 0.4888534  0.48898852 0.48883465 0.48890188 0.48896694 0.4887532\n",
            " 0.48888966 0.48882675]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.109186117304489e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48309898 0.48311576 0.4831104  0.4830559  0.4831356  0.4830221\n",
            " 0.4830124  0.48301992 0.48303294 0.48304248 0.48302576 0.48304394\n",
            " 0.48306754 0.4831177  0.48305166 0.48310098 0.48311424 0.4830422\n",
            " 0.48309052 0.4830084 ]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 4.0042730688583106e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.507232   0.50724185 0.5072515  0.5072053  0.507262   0.507176\n",
            " 0.50717705 0.50715    0.5071658  0.5072308  0.507223   0.5071976\n",
            " 0.5071976  0.5072709  0.5072017  0.5072191  0.5072503  0.5071498\n",
            " 0.50725573 0.507235  ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.608384577091783e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.51909655 0.5190625  0.51906997 0.51907825 0.5190657  0.5191396\n",
            " 0.51910925 0.5190935  0.5191176  0.51909226 0.5191092  0.51911587\n",
            " 0.51909864 0.51908094 0.51908576 0.519082   0.5190857  0.5191041\n",
            " 0.51907116 0.51910865]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.93749710888369e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.48757708 0.48755962 0.48755932 0.487562   0.48754746 0.4875441\n",
            " 0.48755333 0.48754698 0.48756653 0.48757464 0.48757124 0.48756132\n",
            " 0.48757303 0.48760808 0.48756748 0.4875654  0.4875839  0.4875387\n",
            " 0.48757175 0.48753735]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.629119651624933e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.488861   0.48892215 0.48892665 0.48882467 0.48895952 0.48876962\n",
            " 0.48878407 0.48876238 0.48875818 0.4888958  0.4888634  0.4888067\n",
            " 0.4888534  0.48898852 0.48883465 0.48890188 0.48896694 0.4887532\n",
            " 0.48888966 0.48882675]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.109186117304489e-05\n",
            "Epoch 10/10\n",
            "training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48307186 0.50720376 0.5191089  0.48754838 0.48883015]\n",
            " [0.48301107 0.5072552  0.5191065  0.48755494 0.48885524]\n",
            " [0.48309794 0.5072408  0.51909    0.48758274 0.48890188]\n",
            " [0.48308447 0.507249   0.5190892  0.4875948  0.48889774]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831298  0.50727487 0.51910824 0.48760596 0.48893893]\n",
            " [0.48312214 0.5072221  0.51912546 0.4876195  0.488935  ]\n",
            " [0.4829425  0.50724673 0.51916736 0.48754933 0.48877788]\n",
            " [0.48313048 0.5072311  0.51913255 0.48760033 0.48888147]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48313436 0.50731254 0.5191371  0.48763397 0.48905462]\n",
            " [0.48298275 0.50723284 0.5191954  0.48753053 0.48880076]\n",
            " [0.48312625 0.5072843  0.51912254 0.48758748 0.48900124]\n",
            " [0.48311788 0.5072961  0.5190983  0.48761815 0.48908082]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831062  0.50724953 0.51914424 0.487605   0.48892477]\n",
            " [0.48313537 0.50731015 0.51911783 0.4876405  0.48915255]\n",
            " [0.4831401  0.50731677 0.51917297 0.48763794 0.48904678]\n",
            " [0.48310667 0.5072702  0.5191889  0.48761576 0.48897046]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831736  0.5072663  0.5191573  0.4876357  0.48904008]\n",
            " [0.4831614  0.50732464 0.5191958  0.48764673 0.48906717]\n",
            " [0.4831209  0.50727654 0.51920474 0.48761803 0.4889565 ]\n",
            " [0.48317313 0.50730324 0.5191643  0.48763648 0.48910573]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48315248 0.5072558  0.5191853  0.48761362 0.48902524]\n",
            " [0.48315647 0.5072855  0.5191809  0.4876137  0.48909974]\n",
            " [0.48322478 0.5073434  0.51921576 0.4876885  0.48922226]\n",
            " [0.4831844  0.5073001  0.5191749  0.4876425  0.4891225 ]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48315847 0.5072601  0.5192267  0.48763627 0.48901445]\n",
            " [0.48327953 0.5073882  0.51917523 0.4876762  0.48923865]\n",
            " [0.4831343  0.50724095 0.5192338  0.4876332  0.4889989 ]\n",
            " [0.48318335 0.5073124  0.5191922  0.4876488  0.48909727]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831493  0.50731933 0.5192028  0.48765287 0.48911777]\n",
            " [0.48319826 0.5073606  0.5191913  0.48770648 0.4892063 ]\n",
            " [0.48318794 0.5072915  0.51916134 0.48767486 0.48915008]\n",
            " [0.48315135 0.5072423  0.5191894  0.48765433 0.48905498]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4832042  0.50731844 0.51918983 0.48769632 0.48919374]\n",
            " [0.48315457 0.50732464 0.5192215  0.48768863 0.48917818]\n",
            " [0.4830536  0.50733113 0.51922655 0.4876265  0.48902294]\n",
            " [0.4831323  0.50723016 0.51923054 0.4876831  0.48903462]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4831345  0.5072294  0.51920855 0.48766854 0.48904413]\n",
            " [0.4832291  0.5073601  0.5191883  0.48770615 0.48924348]\n",
            " [0.48321524 0.50729173 0.5191617  0.48770952 0.48916674]\n",
            " [0.483098   0.5072789  0.5192194  0.48763767 0.48906162]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48324442 0.50736505 0.5192403  0.48773137 0.48920643]\n",
            " [0.483362   0.5074445  0.51921576 0.4877466  0.4893801 ]\n",
            " [0.48311353 0.507324   0.5192687  0.48769882 0.4890596 ]\n",
            " [0.48324805 0.50737864 0.5192387  0.48776713 0.4892371 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4832691  0.50739366 0.5192224  0.48777467 0.48926812]\n",
            " [0.4832455  0.50739413 0.51925737 0.48778525 0.4892628 ]\n",
            " [0.48323137 0.50742453 0.5192571  0.48778746 0.48930913]\n",
            " [0.48332906 0.5074007  0.5192461  0.48776034 0.48927736]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48332393 0.5074423  0.51926607 0.4878318  0.4893569 ]\n",
            " [0.4831706  0.50744355 0.51932216 0.48775136 0.48924798]\n",
            " [0.48328847 0.507405   0.51928174 0.48780897 0.4892809 ]\n",
            " [0.48316374 0.5073216  0.5193308  0.48775887 0.4891359 ]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48326117 0.50740707 0.5192933  0.48783368 0.48926   ]\n",
            " [0.48324445 0.5073917  0.5192965  0.48782846 0.48924017]\n",
            " [0.48326966 0.5074795  0.51926655 0.48786935 0.4894684 ]\n",
            " [0.48317334 0.5073276  0.5193268  0.48779604 0.48912197]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48328835 0.50741    0.5192728  0.48781785 0.48939323]\n",
            " [0.4833237  0.5074606  0.5192441  0.48781556 0.48947954]\n",
            " [0.48327923 0.5073913  0.51928157 0.48780027 0.48934048]\n",
            " [0.48328605 0.507401   0.51928246 0.48781684 0.48933038]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "evaluating Training...\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48329335 0.50742996 0.51933193 0.48783752 0.48934275]\n",
            " [0.4832327  0.5074811  0.5193293  0.48784232 0.4893654 ]\n",
            " [0.4833178  0.5074688  0.51931775 0.4878726  0.48941764]\n",
            " [0.4833043  0.50747633 0.51931643 0.48788443 0.48941317]]\n",
            "True Labels: [[0.5420561  0.5625     0.46153846 0.5631068  0.46666667]\n",
            " [0.7943925  0.8645833  0.7582418  0.8252427  0.9222222 ]\n",
            " [0.45794392 0.42708334 0.64835167 0.5436893  0.6333333 ]\n",
            " [0.43925235 0.5104167  0.61538464 0.47572815 0.46666667]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48332414 0.50747323 0.5193007  0.48785535 0.4894084 ]\n",
            " [0.48331788 0.50741994 0.5193161  0.48786935 0.48940393]\n",
            " [0.4831376  0.50744045 0.5193514  0.48779216 0.4892334 ]\n",
            " [0.483326   0.5074284  0.5193225  0.48784944 0.48934942]]\n",
            "True Labels: [[0.5794392  0.65625    0.64835167 0.5339806  0.82222223]\n",
            " [0.6448598  0.5833333  0.61538464 0.5533981  0.62222224]\n",
            " [0.3271028  0.375      0.31868133 0.27184466 0.6111111 ]\n",
            " [0.6448598  0.5625     0.5714286  0.4563107  0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48330367 0.5074996  0.5193233  0.48789418 0.4894674 ]\n",
            " [0.48315388 0.50741524 0.5193736  0.48778543 0.48920363]\n",
            " [0.48329648 0.50747085 0.5193077  0.4878482  0.48941442]\n",
            " [0.48328415 0.5074824  0.5192871  0.4878776  0.48949528]]\n",
            "True Labels: [[0.49532712 0.6875     0.73626375 0.5825243  0.6333333 ]\n",
            " [0.6168224  0.4375     0.51648355 0.5145631  0.6333333 ]\n",
            " [0.5794392  0.6979167  0.7912088  0.70873785 0.5888889 ]\n",
            " [0.40186915 0.41666666 0.36263737 0.4563107  0.51111114]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48326397 0.50741553 0.5192981  0.48783684 0.48930055]\n",
            " [0.48329008 0.50747836 0.5192778  0.4878735  0.48953313]\n",
            " [0.48329827 0.50748485 0.5193281  0.48786974 0.48942226]\n",
            " [0.4832651  0.5074375  0.51934254 0.48784724 0.48934516]]\n",
            "True Labels: [[0.7757009  0.7083333  0.6813187  0.70873785 0.85555553]\n",
            " [0.23364486 0.21875    0.4065934  0.32038835 0.26666668]\n",
            " [0.62616825 0.6145833  0.6043956  0.47572815 0.75555557]\n",
            " [0.7196262  0.6770833  0.6703297  0.57281554 0.73333335]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4832935  0.50741744 0.5192888  0.4878579  0.48936158]\n",
            " [0.48328167 0.50747633 0.5193271  0.48786777 0.48938578]\n",
            " [0.48324224 0.50742686 0.5193336  0.4878375  0.48927224]\n",
            " [0.4832937  0.5074554  0.5192965  0.48785955 0.4894278 ]]\n",
            "True Labels: [[0.5607477  0.6145833  0.51648355 0.60194176 0.7222222 ]\n",
            " [0.49532712 0.5833333  0.6043956  0.5339806  0.73333335]\n",
            " [0.5420561  0.39583334 0.32967034 0.21359223 0.42222223]\n",
            " [0.35514018 0.42708334 0.52747256 0.5145631  0.5555556 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48327017 0.5074083  0.51932514 0.48784137 0.48930284]\n",
            " [0.4832741  0.5074392  0.51932204 0.4878417  0.48937726]\n",
            " [0.4833417  0.5074991  0.51935923 0.48791888 0.4895026 ]\n",
            " [0.48330233 0.5074538  0.51931614 0.4878727  0.48940355]]\n",
            "True Labels: [[0.37383178 0.40625    0.32967034 0.22330096 0.4888889 ]\n",
            " [0.76635516 0.7604167  0.8131868  0.7281553  0.6666667 ]\n",
            " [0.39252338 0.5520833  0.5714286  0.69902915 0.46666667]\n",
            " [0.74766356 0.7916667  0.6703297  0.74757284 0.7222222 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4832477  0.5073701  0.5193389  0.48782378 0.48925695]\n",
            " [0.4833665  0.5075008  0.51929253 0.48786658 0.48948658]\n",
            " [0.48322374 0.5073507  0.5193453  0.48782018 0.48924023]\n",
            " [0.48327285 0.50742316 0.5193052  0.48783797 0.4893423 ]]\n",
            "True Labels: [[0.34579438 0.40625    0.41758242 0.52427185 0.47777778]\n",
            " [0.45794392 0.53125    0.47252747 0.6407767  0.64444447]\n",
            " [0.55140185 0.48958334 0.5824176  0.4368932  0.56666666]\n",
            " [0.3271028  0.3125     0.3956044  0.52427185 0.54444444]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48325986 0.5074542  0.5193348  0.48782453 0.48933652]\n",
            " [0.48330903 0.5074973  0.5193256  0.48787987 0.4894271 ]\n",
            " [0.48329866 0.50742716 0.51929504 0.48784825 0.4893718 ]\n",
            " [0.48326182 0.5073767  0.5193212  0.48782626 0.48927414]]\n",
            "True Labels: [[0.55140185 0.5104167  0.52747256 0.6796116  0.6       ]\n",
            " [0.5420561  0.5520833  0.71428573 0.47572815 0.53333336]\n",
            " [0.2990654  0.34375    0.30769232 0.23300971 0.32222223]\n",
            " [0.682243   0.7395833  0.63736266 0.7281553  0.6888889 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48330268 0.50744426 0.5193149  0.487855   0.4893982 ]\n",
            " [0.4832531  0.50745034 0.5193459  0.48784706 0.4893822 ]\n",
            " [0.4831522  0.5074543  0.519347   0.4877818  0.48922205]\n",
            " [0.48323113 0.507354   0.51935226 0.4878403  0.4892361 ]]\n",
            "True Labels: [[0.44859812 0.41666666 0.5604396  0.4368932  0.45555556]\n",
            " [0.635514   0.6875     0.61538464 0.88349515 0.67777777]\n",
            " [0.28037384 0.23958333 0.2967033  0.24271844 0.32222223]\n",
            " [0.39252338 0.40625    0.51648355 0.29126215 0.4       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48324862 0.50737697 0.5193379  0.48783427 0.4892546 ]\n",
            " [0.4833429  0.5075109  0.5193217  0.48787385 0.4894575 ]\n",
            " [0.48332778 0.5074414  0.5192949  0.48787615 0.48937967]\n",
            " [0.4832115  0.5074265  0.5193493  0.4878027  0.48927185]]\n",
            "True Labels: [[0.76635516 0.84375    0.82417583 0.75728154 0.7888889 ]\n",
            " [0.6168224  0.65625    0.6923077  0.4563107  0.6333333 ]\n",
            " [0.6542056  0.5416667  0.5714286  0.6213592  0.64444447]\n",
            " [0.72897196 0.75       0.61538464 0.7281553  0.74444443]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48328668 0.50744843 0.51931834 0.48784533 0.48934454]\n",
            " [0.48340398 0.5075292  0.51929563 0.48786184 0.48952025]\n",
            " [0.48315692 0.50740576 0.5193442  0.48781055 0.48919484]\n",
            " [0.48329088 0.50746197 0.51931673 0.48788157 0.4893761 ]]\n",
            "True Labels: [[0.20560747 0.36458334 0.3956044  0.69902915 0.35555556]\n",
            " [0.6448598  0.6666667  0.63736266 0.5825243  0.6333333 ]\n",
            " [0.5607477  0.59375    0.63736266 0.49514562 0.6666667 ]\n",
            " [0.53271025 0.6875     0.52747256 0.61165047 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48331168 0.5074517  0.51929057 0.48784998 0.48938805]\n",
            " [0.4832886  0.5074523  0.5193246  0.4878602  0.4893813 ]\n",
            " [0.48327437 0.5074827  0.51932454 0.4878624  0.4894278 ]\n",
            " [0.48337182 0.5074593  0.5193143  0.48783553 0.48939654]]\n",
            "True Labels: [[0.5233645  0.59375    0.6813187  0.57281554 0.53333336]\n",
            " [0.5233645  0.53125    0.42857143 0.5145631  0.5555556 ]\n",
            " [0.40186915 0.47916666 0.64835167 0.5631068  0.45555556]\n",
            " [0.6635514  0.6979167  0.71428573 0.7184466  0.84444445]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48335192 0.50747657 0.51929957 0.48786986 0.48943883]\n",
            " [0.48319954 0.5074774  0.51935446 0.48778936 0.48932907]\n",
            " [0.48331702 0.507439   0.51931447 0.48784715 0.4893627 ]\n",
            " [0.48319265 0.5073552  0.51936257 0.4877967  0.48921645]]\n",
            "True Labels: [[0.44859812 0.5625     0.48351648 0.5631068  0.5       ]\n",
            " [0.74766356 0.71875    0.7802198  0.7378641  0.7111111 ]\n",
            " [0.2990654  0.4375     0.41758242 0.49514562 0.32222223]\n",
            " [0.55140185 0.5729167  0.6593407  0.49514562 0.6666667 ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48328125 0.5074183  0.5193033  0.48784208 0.4893216 ]\n",
            " [0.4832645  0.50740296 0.51930666 0.48783687 0.48930192]\n",
            " [0.48328847 0.5074904  0.5192779  0.4878768  0.48953035]\n",
            " [0.48319328 0.50733864 0.5193364  0.48780432 0.4891823 ]]\n",
            "True Labels: [[0.5794392  0.6458333  0.61538464 0.592233   0.7777778 ]\n",
            " [0.8037383  0.625      0.6593407  0.5631068  0.6333333 ]\n",
            " [0.10280374 0.15625    0.2747253  0.19417475 0.3       ]\n",
            " [0.317757   0.27083334 0.30769232 0.27184466 0.33333334]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.4833184  0.50745153 0.5193037  0.4878554  0.48944774]\n",
            " [0.48335364 0.50750226 0.51927483 0.48785314 0.48953387]\n",
            " [0.48330894 0.5074323  0.5193119  0.48783755 0.48939458]\n",
            " [0.48331594 0.5074421  0.51931286 0.48785412 0.48938432]]\n",
            "True Labels: [[0.6728972  0.65625    0.63736266 0.6213592  0.67777777]\n",
            " [0.42990655 0.46875    0.5934066  0.4854369  0.45555556]\n",
            " [0.42056075 0.48958334 0.48351648 0.49514562 0.5       ]\n",
            " [0.7570093  0.8854167  0.71428573 0.7669903  0.9444444 ]]\n",
            "for accuracy:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48329335 0.4832327  0.4833178  0.4833043  0.48332414 0.48331788\n",
            " 0.4831376  0.483326   0.48330367 0.48315388 0.48329648 0.48328415\n",
            " 0.48326397 0.48329008 0.48329827 0.4832651  0.4832935  0.48328167\n",
            " 0.48324224 0.4832937  0.48327017 0.4832741  0.4833417  0.48330233\n",
            " 0.4832477  0.4833665  0.48322374 0.48327285 0.48325986 0.48330903\n",
            " 0.48329866 0.48326182 0.48330268 0.4832531  0.4831522  0.48323113\n",
            " 0.48324862 0.4833429  0.48332778 0.4832115  0.48328668 0.48340398\n",
            " 0.48315692 0.48329088 0.48331168 0.4832886  0.48327437 0.48337182\n",
            " 0.48335192 0.48319954 0.48331702 0.48319265 0.48328125 0.4832645\n",
            " 0.48328847 0.48319328 0.4833184  0.48335364 0.48330894 0.48331594]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.437236177385785e-05\n",
            "for accuracy:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50742996 0.5074811  0.5074688  0.50747633 0.50747323 0.50741994\n",
            " 0.50744045 0.5074284  0.5074996  0.50741524 0.50747085 0.5074824\n",
            " 0.50741553 0.50747836 0.50748485 0.5074375  0.50741744 0.50747633\n",
            " 0.50742686 0.5074554  0.5074083  0.5074392  0.5074991  0.5074538\n",
            " 0.5073701  0.5075008  0.5073507  0.50742316 0.5074542  0.5074973\n",
            " 0.50742716 0.5073767  0.50744426 0.50745034 0.5074543  0.507354\n",
            " 0.50737697 0.5075109  0.5074414  0.5074265  0.50744843 0.5075292\n",
            " 0.50740576 0.50746197 0.5074517  0.5074523  0.5074827  0.5074593\n",
            " 0.50747657 0.5074774  0.507439   0.5073552  0.5074183  0.50740296\n",
            " 0.5074904  0.50733864 0.50745153 0.50750226 0.5074323  0.5074421 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.176376751274802e-05\n",
            "for accuracy:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51933193 0.5193293  0.51931775 0.51931643 0.5193007  0.5193161\n",
            " 0.5193514  0.5193225  0.5193233  0.5193736  0.5193077  0.5192871\n",
            " 0.5192981  0.5192778  0.5193281  0.51934254 0.5192888  0.5193271\n",
            " 0.5193336  0.5192965  0.51932514 0.51932204 0.51935923 0.51931614\n",
            " 0.5193389  0.51929253 0.5193453  0.5193052  0.5193348  0.5193256\n",
            " 0.51929504 0.5193212  0.5193149  0.5193459  0.519347   0.51935226\n",
            " 0.5193379  0.5193217  0.5192949  0.5193493  0.51931834 0.51929563\n",
            " 0.5193442  0.51931673 0.51929057 0.5193246  0.51932454 0.5193143\n",
            " 0.51929957 0.51935446 0.51931447 0.51936257 0.5193033  0.51930666\n",
            " 0.5192779  0.5193364  0.5193037  0.51927483 0.5193119  0.51931286]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.2192669348441996e-05\n",
            "for accuracy:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48783752 0.48784232 0.4878726  0.48788443 0.48785535 0.48786935\n",
            " 0.48779216 0.48784944 0.48789418 0.48778543 0.4878482  0.4878776\n",
            " 0.48783684 0.4878735  0.48786974 0.48784724 0.4878579  0.48786777\n",
            " 0.4878375  0.48785955 0.48784137 0.4878417  0.48791888 0.4878727\n",
            " 0.48782378 0.48786658 0.48782018 0.48783797 0.48782453 0.48787987\n",
            " 0.48784825 0.48782626 0.487855   0.48784706 0.4877818  0.4878403\n",
            " 0.48783427 0.48787385 0.48787615 0.4878027  0.48784533 0.48786184\n",
            " 0.48781055 0.48788157 0.48784998 0.4878602  0.4878624  0.48783553\n",
            " 0.48786986 0.48778936 0.48784715 0.4877967  0.48784208 0.48783687\n",
            " 0.4878768  0.48780432 0.4878554  0.48785314 0.48783755 0.48785412]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.74647227342939e-05\n",
            "for accuracy:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48934275 0.4893654  0.48941764 0.48941317 0.4894084  0.48940393\n",
            " 0.4892334  0.48934942 0.4894674  0.48920363 0.48941442 0.48949528\n",
            " 0.48930055 0.48953313 0.48942226 0.48934516 0.48936158 0.48938578\n",
            " 0.48927224 0.4894278  0.48930284 0.48937726 0.4895026  0.48940355\n",
            " 0.48925695 0.48948658 0.48924023 0.4893423  0.48933652 0.4894271\n",
            " 0.4893718  0.48927414 0.4893982  0.4893822  0.48922205 0.4892361\n",
            " 0.4892546  0.4894575  0.48937967 0.48927185 0.48934454 0.48952025\n",
            " 0.48919484 0.4893761  0.48938805 0.4893813  0.4894278  0.48939654\n",
            " 0.48943883 0.48932907 0.4893627  0.48921645 0.4893216  0.48930192\n",
            " 0.48953035 0.4891823  0.48944774 0.48953387 0.48939458 0.48938432]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.859039371600375e-05\n",
            "for r2:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48329335 0.4832327  0.4833178  0.4833043  0.48332414 0.48331788\n",
            " 0.4831376  0.483326   0.48330367 0.48315388 0.48329648 0.48328415\n",
            " 0.48326397 0.48329008 0.48329827 0.4832651  0.4832935  0.48328167\n",
            " 0.48324224 0.4832937  0.48327017 0.4832741  0.4833417  0.48330233\n",
            " 0.4832477  0.4833665  0.48322374 0.48327285 0.48325986 0.48330903\n",
            " 0.48329866 0.48326182 0.48330268 0.4832531  0.4831522  0.48323113\n",
            " 0.48324862 0.4833429  0.48332778 0.4832115  0.48328668 0.48340398\n",
            " 0.48315692 0.48329088 0.48331168 0.4832886  0.48327437 0.48337182\n",
            " 0.48335192 0.48319954 0.48331702 0.48319265 0.48328125 0.4832645\n",
            " 0.48328847 0.48319328 0.4833184  0.48335364 0.48330894 0.48331594]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.437236177385785e-05\n",
            "for r2:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50742996 0.5074811  0.5074688  0.50747633 0.50747323 0.50741994\n",
            " 0.50744045 0.5074284  0.5074996  0.50741524 0.50747085 0.5074824\n",
            " 0.50741553 0.50747836 0.50748485 0.5074375  0.50741744 0.50747633\n",
            " 0.50742686 0.5074554  0.5074083  0.5074392  0.5074991  0.5074538\n",
            " 0.5073701  0.5075008  0.5073507  0.50742316 0.5074542  0.5074973\n",
            " 0.50742716 0.5073767  0.50744426 0.50745034 0.5074543  0.507354\n",
            " 0.50737697 0.5075109  0.5074414  0.5074265  0.50744843 0.5075292\n",
            " 0.50740576 0.50746197 0.5074517  0.5074523  0.5074827  0.5074593\n",
            " 0.50747657 0.5074774  0.507439   0.5073552  0.5074183  0.50740296\n",
            " 0.5074904  0.50733864 0.50745153 0.50750226 0.5074323  0.5074421 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.176376751274802e-05\n",
            "for r2:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51933193 0.5193293  0.51931775 0.51931643 0.5193007  0.5193161\n",
            " 0.5193514  0.5193225  0.5193233  0.5193736  0.5193077  0.5192871\n",
            " 0.5192981  0.5192778  0.5193281  0.51934254 0.5192888  0.5193271\n",
            " 0.5193336  0.5192965  0.51932514 0.51932204 0.51935923 0.51931614\n",
            " 0.5193389  0.51929253 0.5193453  0.5193052  0.5193348  0.5193256\n",
            " 0.51929504 0.5193212  0.5193149  0.5193459  0.519347   0.51935226\n",
            " 0.5193379  0.5193217  0.5192949  0.5193493  0.51931834 0.51929563\n",
            " 0.5193442  0.51931673 0.51929057 0.5193246  0.51932454 0.5193143\n",
            " 0.51929957 0.51935446 0.51931447 0.51936257 0.5193033  0.51930666\n",
            " 0.5192779  0.5193364  0.5193037  0.51927483 0.5193119  0.51931286]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.2192669348441996e-05\n",
            "for r2:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48783752 0.48784232 0.4878726  0.48788443 0.48785535 0.48786935\n",
            " 0.48779216 0.48784944 0.48789418 0.48778543 0.4878482  0.4878776\n",
            " 0.48783684 0.4878735  0.48786974 0.48784724 0.4878579  0.48786777\n",
            " 0.4878375  0.48785955 0.48784137 0.4878417  0.48791888 0.4878727\n",
            " 0.48782378 0.48786658 0.48782018 0.48783797 0.48782453 0.48787987\n",
            " 0.48784825 0.48782626 0.487855   0.48784706 0.4877818  0.4878403\n",
            " 0.48783427 0.48787385 0.48787615 0.4878027  0.48784533 0.48786184\n",
            " 0.48781055 0.48788157 0.48784998 0.4878602  0.4878624  0.48783553\n",
            " 0.48786986 0.48778936 0.48784715 0.4877967  0.48784208 0.48783687\n",
            " 0.4878768  0.48780432 0.4878554  0.48785314 0.48783755 0.48785412]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.74647227342939e-05\n",
            "for r2:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48934275 0.4893654  0.48941764 0.48941317 0.4894084  0.48940393\n",
            " 0.4892334  0.48934942 0.4894674  0.48920363 0.48941442 0.48949528\n",
            " 0.48930055 0.48953313 0.48942226 0.48934516 0.48936158 0.48938578\n",
            " 0.48927224 0.4894278  0.48930284 0.48937726 0.4895026  0.48940355\n",
            " 0.48925695 0.48948658 0.48924023 0.4893423  0.48933652 0.4894271\n",
            " 0.4893718  0.48927414 0.4893982  0.4893822  0.48922205 0.4892361\n",
            " 0.4892546  0.4894575  0.48937967 0.48927185 0.48934454 0.48952025\n",
            " 0.48919484 0.4893761  0.48938805 0.4893813  0.4894278  0.48939654\n",
            " 0.48943883 0.48932907 0.4893627  0.48921645 0.4893216  0.48930192\n",
            " 0.48953035 0.4891823  0.48944774 0.48953387 0.48939458 0.48938432]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.859039371600375e-05\n",
            "for ccc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48329335 0.4832327  0.4833178  0.4833043  0.48332414 0.48331788\n",
            " 0.4831376  0.483326   0.48330367 0.48315388 0.48329648 0.48328415\n",
            " 0.48326397 0.48329008 0.48329827 0.4832651  0.4832935  0.48328167\n",
            " 0.48324224 0.4832937  0.48327017 0.4832741  0.4833417  0.48330233\n",
            " 0.4832477  0.4833665  0.48322374 0.48327285 0.48325986 0.48330903\n",
            " 0.48329866 0.48326182 0.48330268 0.4832531  0.4831522  0.48323113\n",
            " 0.48324862 0.4833429  0.48332778 0.4832115  0.48328668 0.48340398\n",
            " 0.48315692 0.48329088 0.48331168 0.4832886  0.48327437 0.48337182\n",
            " 0.48335192 0.48319954 0.48331702 0.48319265 0.48328125 0.4832645\n",
            " 0.48328847 0.48319328 0.4833184  0.48335364 0.48330894 0.48331594]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.437236177385785e-05\n",
            "for ccc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50742996 0.5074811  0.5074688  0.50747633 0.50747323 0.50741994\n",
            " 0.50744045 0.5074284  0.5074996  0.50741524 0.50747085 0.5074824\n",
            " 0.50741553 0.50747836 0.50748485 0.5074375  0.50741744 0.50747633\n",
            " 0.50742686 0.5074554  0.5074083  0.5074392  0.5074991  0.5074538\n",
            " 0.5073701  0.5075008  0.5073507  0.50742316 0.5074542  0.5074973\n",
            " 0.50742716 0.5073767  0.50744426 0.50745034 0.5074543  0.507354\n",
            " 0.50737697 0.5075109  0.5074414  0.5074265  0.50744843 0.5075292\n",
            " 0.50740576 0.50746197 0.5074517  0.5074523  0.5074827  0.5074593\n",
            " 0.50747657 0.5074774  0.507439   0.5073552  0.5074183  0.50740296\n",
            " 0.5074904  0.50733864 0.50745153 0.50750226 0.5074323  0.5074421 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.176376751274802e-05\n",
            "for ccc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51933193 0.5193293  0.51931775 0.51931643 0.5193007  0.5193161\n",
            " 0.5193514  0.5193225  0.5193233  0.5193736  0.5193077  0.5192871\n",
            " 0.5192981  0.5192778  0.5193281  0.51934254 0.5192888  0.5193271\n",
            " 0.5193336  0.5192965  0.51932514 0.51932204 0.51935923 0.51931614\n",
            " 0.5193389  0.51929253 0.5193453  0.5193052  0.5193348  0.5193256\n",
            " 0.51929504 0.5193212  0.5193149  0.5193459  0.519347   0.51935226\n",
            " 0.5193379  0.5193217  0.5192949  0.5193493  0.51931834 0.51929563\n",
            " 0.5193442  0.51931673 0.51929057 0.5193246  0.51932454 0.5193143\n",
            " 0.51929957 0.51935446 0.51931447 0.51936257 0.5193033  0.51930666\n",
            " 0.5192779  0.5193364  0.5193037  0.51927483 0.5193119  0.51931286]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.2192669348441996e-05\n",
            "for ccc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48783752 0.48784232 0.4878726  0.48788443 0.48785535 0.48786935\n",
            " 0.48779216 0.48784944 0.48789418 0.48778543 0.4878482  0.4878776\n",
            " 0.48783684 0.4878735  0.48786974 0.48784724 0.4878579  0.48786777\n",
            " 0.4878375  0.48785955 0.48784137 0.4878417  0.48791888 0.4878727\n",
            " 0.48782378 0.48786658 0.48782018 0.48783797 0.48782453 0.48787987\n",
            " 0.48784825 0.48782626 0.487855   0.48784706 0.4877818  0.4878403\n",
            " 0.48783427 0.48787385 0.48787615 0.4878027  0.48784533 0.48786184\n",
            " 0.48781055 0.48788157 0.48784998 0.4878602  0.4878624  0.48783553\n",
            " 0.48786986 0.48778936 0.48784715 0.4877967  0.48784208 0.48783687\n",
            " 0.4878768  0.48780432 0.4878554  0.48785314 0.48783755 0.48785412]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.74647227342939e-05\n",
            "for ccc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48934275 0.4893654  0.48941764 0.48941317 0.4894084  0.48940393\n",
            " 0.4892334  0.48934942 0.4894674  0.48920363 0.48941442 0.48949528\n",
            " 0.48930055 0.48953313 0.48942226 0.48934516 0.48936158 0.48938578\n",
            " 0.48927224 0.4894278  0.48930284 0.48937726 0.4895026  0.48940355\n",
            " 0.48925695 0.48948658 0.48924023 0.4893423  0.48933652 0.4894271\n",
            " 0.4893718  0.48927414 0.4893982  0.4893822  0.48922205 0.4892361\n",
            " 0.4892546  0.4894575  0.48937967 0.48927185 0.48934454 0.48952025\n",
            " 0.48919484 0.4893761  0.48938805 0.4893813  0.4894278  0.48939654\n",
            " 0.48943883 0.48932907 0.4893627  0.48921645 0.4893216  0.48930192\n",
            " 0.48953035 0.4891823  0.48944774 0.48953387 0.48939458 0.48938432]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.859039371600375e-05\n",
            "for pcc:\n",
            "y_true: [0.5420561  0.7943925  0.45794392 0.43925235 0.5794392  0.6448598\n",
            " 0.3271028  0.6448598  0.49532712 0.6168224  0.5794392  0.40186915\n",
            " 0.7757009  0.23364486 0.62616825 0.7196262  0.5607477  0.49532712\n",
            " 0.5420561  0.35514018 0.37383178 0.76635516 0.39252338 0.74766356\n",
            " 0.34579438 0.45794392 0.55140185 0.3271028  0.55140185 0.5420561\n",
            " 0.2990654  0.682243   0.44859812 0.635514   0.28037384 0.39252338\n",
            " 0.76635516 0.6168224  0.6542056  0.72897196 0.20560747 0.6448598\n",
            " 0.5607477  0.53271025 0.5233645  0.5233645  0.40186915 0.6635514\n",
            " 0.44859812 0.74766356 0.2990654  0.55140185 0.5794392  0.8037383\n",
            " 0.10280374 0.317757   0.6728972  0.42990655 0.42056075 0.7570093 ]\n",
            "y_pred: [0.48329335 0.4832327  0.4833178  0.4833043  0.48332414 0.48331788\n",
            " 0.4831376  0.483326   0.48330367 0.48315388 0.48329648 0.48328415\n",
            " 0.48326397 0.48329008 0.48329827 0.4832651  0.4832935  0.48328167\n",
            " 0.48324224 0.4832937  0.48327017 0.4832741  0.4833417  0.48330233\n",
            " 0.4832477  0.4833665  0.48322374 0.48327285 0.48325986 0.48330903\n",
            " 0.48329866 0.48326182 0.48330268 0.4832531  0.4831522  0.48323113\n",
            " 0.48324862 0.4833429  0.48332778 0.4832115  0.48328668 0.48340398\n",
            " 0.48315692 0.48329088 0.48331168 0.4832886  0.48327437 0.48337182\n",
            " 0.48335192 0.48319954 0.48331702 0.48319265 0.48328125 0.4832645\n",
            " 0.48328847 0.48319328 0.4833184  0.48335364 0.48330894 0.48331594]\n",
            "Stddev y_true: 0.1627214550971985\n",
            "Stddev y_pred: 5.437236177385785e-05\n",
            "for pcc:\n",
            "y_true: [0.5625     0.8645833  0.42708334 0.5104167  0.65625    0.5833333\n",
            " 0.375      0.5625     0.6875     0.4375     0.6979167  0.41666666\n",
            " 0.7083333  0.21875    0.6145833  0.6770833  0.6145833  0.5833333\n",
            " 0.39583334 0.42708334 0.40625    0.7604167  0.5520833  0.7916667\n",
            " 0.40625    0.53125    0.48958334 0.3125     0.5104167  0.5520833\n",
            " 0.34375    0.7395833  0.41666666 0.6875     0.23958333 0.40625\n",
            " 0.84375    0.65625    0.5416667  0.75       0.36458334 0.6666667\n",
            " 0.59375    0.6875     0.59375    0.53125    0.47916666 0.6979167\n",
            " 0.5625     0.71875    0.4375     0.5729167  0.6458333  0.625\n",
            " 0.15625    0.27083334 0.65625    0.46875    0.48958334 0.8854167 ]\n",
            "y_pred: [0.50742996 0.5074811  0.5074688  0.50747633 0.50747323 0.50741994\n",
            " 0.50744045 0.5074284  0.5074996  0.50741524 0.50747085 0.5074824\n",
            " 0.50741553 0.50747836 0.50748485 0.5074375  0.50741744 0.50747633\n",
            " 0.50742686 0.5074554  0.5074083  0.5074392  0.5074991  0.5074538\n",
            " 0.5073701  0.5075008  0.5073507  0.50742316 0.5074542  0.5074973\n",
            " 0.50742716 0.5073767  0.50744426 0.50745034 0.5074543  0.507354\n",
            " 0.50737697 0.5075109  0.5074414  0.5074265  0.50744843 0.5075292\n",
            " 0.50740576 0.50746197 0.5074517  0.5074523  0.5074827  0.5074593\n",
            " 0.50747657 0.5074774  0.507439   0.5073552  0.5074183  0.50740296\n",
            " 0.5074904  0.50733864 0.50745153 0.50750226 0.5074323  0.5074421 ]\n",
            "Stddev y_true: 0.15952244400978088\n",
            "Stddev y_pred: 4.176376751274802e-05\n",
            "for pcc:\n",
            "y_true: [0.46153846 0.7582418  0.64835167 0.61538464 0.64835167 0.61538464\n",
            " 0.31868133 0.5714286  0.73626375 0.51648355 0.7912088  0.36263737\n",
            " 0.6813187  0.4065934  0.6043956  0.6703297  0.51648355 0.6043956\n",
            " 0.32967034 0.52747256 0.32967034 0.8131868  0.5714286  0.6703297\n",
            " 0.41758242 0.47252747 0.5824176  0.3956044  0.52747256 0.71428573\n",
            " 0.30769232 0.63736266 0.5604396  0.61538464 0.2967033  0.51648355\n",
            " 0.82417583 0.6923077  0.5714286  0.61538464 0.3956044  0.63736266\n",
            " 0.63736266 0.52747256 0.6813187  0.42857143 0.64835167 0.71428573\n",
            " 0.48351648 0.7802198  0.41758242 0.6593407  0.61538464 0.6593407\n",
            " 0.2747253  0.30769232 0.63736266 0.5934066  0.48351648 0.71428573]\n",
            "y_pred: [0.51933193 0.5193293  0.51931775 0.51931643 0.5193007  0.5193161\n",
            " 0.5193514  0.5193225  0.5193233  0.5193736  0.5193077  0.5192871\n",
            " 0.5192981  0.5192778  0.5193281  0.51934254 0.5192888  0.5193271\n",
            " 0.5193336  0.5192965  0.51932514 0.51932204 0.51935923 0.51931614\n",
            " 0.5193389  0.51929253 0.5193453  0.5193052  0.5193348  0.5193256\n",
            " 0.51929504 0.5193212  0.5193149  0.5193459  0.519347   0.51935226\n",
            " 0.5193379  0.5193217  0.5192949  0.5193493  0.51931834 0.51929563\n",
            " 0.5193442  0.51931673 0.51929057 0.5193246  0.51932454 0.5193143\n",
            " 0.51929957 0.51935446 0.51931447 0.51936257 0.5193033  0.51930666\n",
            " 0.5192779  0.5193364  0.5193037  0.51927483 0.5193119  0.51931286]\n",
            "Stddev y_true: 0.14090083539485931\n",
            "Stddev y_pred: 2.2192669348441996e-05\n",
            "for pcc:\n",
            "y_true: [0.5631068  0.8252427  0.5436893  0.47572815 0.5339806  0.5533981\n",
            " 0.27184466 0.4563107  0.5825243  0.5145631  0.70873785 0.4563107\n",
            " 0.70873785 0.32038835 0.47572815 0.57281554 0.60194176 0.5339806\n",
            " 0.21359223 0.5145631  0.22330096 0.7281553  0.69902915 0.74757284\n",
            " 0.52427185 0.6407767  0.4368932  0.52427185 0.6796116  0.47572815\n",
            " 0.23300971 0.7281553  0.4368932  0.88349515 0.24271844 0.29126215\n",
            " 0.75728154 0.4563107  0.6213592  0.7281553  0.69902915 0.5825243\n",
            " 0.49514562 0.61165047 0.57281554 0.5145631  0.5631068  0.7184466\n",
            " 0.5631068  0.7378641  0.49514562 0.49514562 0.592233   0.5631068\n",
            " 0.19417475 0.27184466 0.6213592  0.4854369  0.49514562 0.7669903 ]\n",
            "y_pred: [0.48783752 0.48784232 0.4878726  0.48788443 0.48785535 0.48786935\n",
            " 0.48779216 0.48784944 0.48789418 0.48778543 0.4878482  0.4878776\n",
            " 0.48783684 0.4878735  0.48786974 0.48784724 0.4878579  0.48786777\n",
            " 0.4878375  0.48785955 0.48784137 0.4878417  0.48791888 0.4878727\n",
            " 0.48782378 0.48786658 0.48782018 0.48783797 0.48782453 0.48787987\n",
            " 0.48784825 0.48782626 0.487855   0.48784706 0.4877818  0.4878403\n",
            " 0.48783427 0.48787385 0.48787615 0.4878027  0.48784533 0.48786184\n",
            " 0.48781055 0.48788157 0.48784998 0.4878602  0.4878624  0.48783553\n",
            " 0.48786986 0.48778936 0.48784715 0.4877967  0.48784208 0.48783687\n",
            " 0.4878768  0.48780432 0.4878554  0.48785314 0.48783755 0.48785412]\n",
            "Stddev y_true: 0.15913809835910797\n",
            "Stddev y_pred: 2.74647227342939e-05\n",
            "for pcc:\n",
            "y_true: [0.46666667 0.9222222  0.6333333  0.46666667 0.82222223 0.62222224\n",
            " 0.6111111  0.53333336 0.6333333  0.6333333  0.5888889  0.51111114\n",
            " 0.85555553 0.26666668 0.75555557 0.73333335 0.7222222  0.73333335\n",
            " 0.42222223 0.5555556  0.4888889  0.6666667  0.46666667 0.7222222\n",
            " 0.47777778 0.64444447 0.56666666 0.54444444 0.6        0.53333336\n",
            " 0.32222223 0.6888889  0.45555556 0.67777777 0.32222223 0.4\n",
            " 0.7888889  0.6333333  0.64444447 0.74444443 0.35555556 0.6333333\n",
            " 0.6666667  0.53333336 0.53333336 0.5555556  0.45555556 0.84444445\n",
            " 0.5        0.7111111  0.32222223 0.6666667  0.7777778  0.6333333\n",
            " 0.3        0.33333334 0.67777777 0.45555556 0.5        0.9444444 ]\n",
            "y_pred: [0.48934275 0.4893654  0.48941764 0.48941317 0.4894084  0.48940393\n",
            " 0.4892334  0.48934942 0.4894674  0.48920363 0.48941442 0.48949528\n",
            " 0.48930055 0.48953313 0.48942226 0.48934516 0.48936158 0.48938578\n",
            " 0.48927224 0.4894278  0.48930284 0.48937726 0.4895026  0.48940355\n",
            " 0.48925695 0.48948658 0.48924023 0.4893423  0.48933652 0.4894271\n",
            " 0.4893718  0.48927414 0.4893982  0.4893822  0.48922205 0.4892361\n",
            " 0.4892546  0.4894575  0.48937967 0.48927185 0.48934454 0.48952025\n",
            " 0.48919484 0.4893761  0.48938805 0.4893813  0.4894278  0.48939654\n",
            " 0.48943883 0.48932907 0.4893627  0.48921645 0.4893216  0.48930192\n",
            " 0.48953035 0.4891823  0.48944774 0.48953387 0.48939458 0.48938432]\n",
            "Stddev y_true: 0.15573127567768097\n",
            "Stddev y_pred: 8.859039371600375e-05\n",
            "evaluating Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48325998 0.50743276 0.5193479  0.48783585 0.48932704]\n",
            " [0.4832255  0.5073808  0.51935565 0.48783392 0.48923203]\n",
            " [0.48320362 0.50736207 0.5193424  0.48782176 0.48923755]\n",
            " [0.48321265 0.5074543  0.5193424  0.48782972 0.48928404]]\n",
            "True Labels: [[0.6635514  0.5208333  0.3956044  0.6407767  0.67777777]\n",
            " [0.48598132 0.5833333  0.37362638 0.5339806  0.54444444]\n",
            " [0.35514018 0.4375     0.51648355 0.37864077 0.44444445]\n",
            " [0.43925235 0.375      0.43956044 0.41747573 0.7       ]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48324    0.5074034  0.5193097  0.4878248  0.48926327]\n",
            " [0.48330468 0.50743806 0.5193281  0.48786396 0.48943174]\n",
            " [0.48333967 0.507479   0.5193065  0.48784417 0.4894797 ]\n",
            " [0.48322457 0.507373   0.51932603 0.4878357  0.48922288]]\n",
            "True Labels: [[0.49532712 0.625      0.5604396  0.6407767  0.7777778 ]\n",
            " [0.44859812 0.48958334 0.47252747 0.5339806  0.53333336]\n",
            " [0.60747665 0.8125     0.72527474 0.9514563  0.67777777]\n",
            " [0.3271028  0.33333334 0.36263737 0.4563107  0.32222223]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48333716 0.50745404 0.51932174 0.4878466  0.48941335]\n",
            " [0.48331085 0.5074605  0.5192978  0.48785472 0.4893787 ]\n",
            " [0.48333514 0.5074717  0.5192975  0.48784974 0.48941278]\n",
            " [0.48329356 0.50741714 0.519317   0.48785707 0.48935676]]\n",
            "True Labels: [[0.635514   0.7604167  0.5934066  0.44660193 0.53333336]\n",
            " [0.6635514  0.6145833  0.7032967  0.6407767  0.7111111 ]\n",
            " [0.36448598 0.5416667  0.50549453 0.33009708 0.5555556 ]\n",
            " [0.45794392 0.45833334 0.45054945 0.3883495  0.64444447]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48327127 0.5075261  0.5193239  0.48785454 0.48941603]\n",
            " [0.48329234 0.5074594  0.5193325  0.48785758 0.48945236]\n",
            " [0.48328978 0.5074023  0.5193073  0.48784852 0.48929217]\n",
            " [0.4832908  0.50741726 0.519322   0.48783517 0.48934352]]\n",
            "True Labels: [[0.17757009 0.15625    0.25274727 0.16504854 0.18888889]\n",
            " [0.55140185 0.42708334 0.35164836 0.5339806  0.5555556 ]\n",
            " [0.45794392 0.5416667  0.53846157 0.5048544  0.5       ]\n",
            " [0.71028036 0.45833334 0.64835167 0.52427185 0.53333336]]\n",
            "input:  torch.Size([60, 1, 64, 96])\n",
            "after conv1:  torch.Size([60, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([60, 64, 32, 48])\n",
            "after conv2:  torch.Size([60, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([60, 128, 16, 24])\n",
            "after conv3:  torch.Size([60, 256, 16, 24])\n",
            "after conv4:  torch.Size([60, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([60, 256, 8, 12])\n",
            "after conv5:  torch.Size([60, 512, 8, 12])\n",
            "after conv6:  torch.Size([60, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([60, 512, 4, 6])\n",
            "after flatten:  torch.Size([60, 12288])\n",
            "after fc1:  torch.Size([60, 4096])\n",
            "after fc2:  torch.Size([60, 4096])\n",
            "after fc3:  torch.Size([60, 128])\n",
            "after fc3:  torch.Size([60, 5])\n",
            "Predicted Labels: [[0.48327836 0.5074334  0.51931924 0.48784393 0.4893343 ]\n",
            " [0.48335716 0.5075186  0.5192811  0.48788816 0.4895381 ]\n",
            " [0.48332006 0.50747436 0.51927507 0.48786694 0.48945105]\n",
            " [0.48326114 0.50739264 0.51932657 0.48782688 0.48931125]]\n",
            "True Labels: [[0.5794392  0.5208333  0.5714286  0.57281554 0.6333333 ]\n",
            " [0.39252338 0.45833334 0.53846157 0.6407767  0.3       ]\n",
            " [0.5794392  0.65625    0.5824176  0.5825243  0.64444447]\n",
            " [0.39252338 0.38541666 0.52747256 0.4368932  0.54444444]]\n",
            "for accuracy:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48325998 0.4832255  0.48320362 0.48321265 0.48324    0.48330468\n",
            " 0.48333967 0.48322457 0.48333716 0.48331085 0.48333514 0.48329356\n",
            " 0.48327127 0.48329234 0.48328978 0.4832908  0.48327836 0.48335716\n",
            " 0.48332006 0.48326114]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.374193667899817e-05\n",
            "for accuracy:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50743276 0.5073808  0.50736207 0.5074543  0.5074034  0.50743806\n",
            " 0.507479   0.507373   0.50745404 0.5074605  0.5074717  0.50741714\n",
            " 0.5075261  0.5074594  0.5074023  0.50741726 0.5074334  0.5075186\n",
            " 0.50747436 0.50739264]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.392473420011811e-05\n",
            "for accuracy:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5193479  0.51935565 0.5193424  0.5193424  0.5193097  0.5193281\n",
            " 0.5193065  0.51932603 0.51932174 0.5192978  0.5192975  0.519317\n",
            " 0.5193239  0.5193325  0.5193073  0.519322   0.51931924 0.5192811\n",
            " 0.51927507 0.51932657]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.0437637431314215e-05\n",
            "for accuracy:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48783585 0.48783392 0.48782176 0.48782972 0.4878248  0.48786396\n",
            " 0.48784417 0.4878357  0.4878466  0.48785472 0.48784974 0.48785707\n",
            " 0.48785454 0.48785758 0.48784852 0.48783517 0.48784393 0.48788816\n",
            " 0.48786694 0.48782688]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5988016457413323e-05\n",
            "for accuracy:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48932704 0.48923203 0.48923755 0.48928404 0.48926327 0.48943174\n",
            " 0.4894797  0.48922288 0.48941335 0.4893787  0.48941278 0.48935676\n",
            " 0.48941603 0.48945236 0.48929217 0.48934352 0.4893343  0.4895381\n",
            " 0.48945105 0.48931125]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.701084152562544e-05\n",
            "for r2:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48325998 0.4832255  0.48320362 0.48321265 0.48324    0.48330468\n",
            " 0.48333967 0.48322457 0.48333716 0.48331085 0.48333514 0.48329356\n",
            " 0.48327127 0.48329234 0.48328978 0.4832908  0.48327836 0.48335716\n",
            " 0.48332006 0.48326114]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.374193667899817e-05\n",
            "for r2:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50743276 0.5073808  0.50736207 0.5074543  0.5074034  0.50743806\n",
            " 0.507479   0.507373   0.50745404 0.5074605  0.5074717  0.50741714\n",
            " 0.5075261  0.5074594  0.5074023  0.50741726 0.5074334  0.5075186\n",
            " 0.50747436 0.50739264]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.392473420011811e-05\n",
            "for r2:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5193479  0.51935565 0.5193424  0.5193424  0.5193097  0.5193281\n",
            " 0.5193065  0.51932603 0.51932174 0.5192978  0.5192975  0.519317\n",
            " 0.5193239  0.5193325  0.5193073  0.519322   0.51931924 0.5192811\n",
            " 0.51927507 0.51932657]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.0437637431314215e-05\n",
            "for r2:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48783585 0.48783392 0.48782176 0.48782972 0.4878248  0.48786396\n",
            " 0.48784417 0.4878357  0.4878466  0.48785472 0.48784974 0.48785707\n",
            " 0.48785454 0.48785758 0.48784852 0.48783517 0.48784393 0.48788816\n",
            " 0.48786694 0.48782688]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5988016457413323e-05\n",
            "for r2:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48932704 0.48923203 0.48923755 0.48928404 0.48926327 0.48943174\n",
            " 0.4894797  0.48922288 0.48941335 0.4893787  0.48941278 0.48935676\n",
            " 0.48941603 0.48945236 0.48929217 0.48934352 0.4893343  0.4895381\n",
            " 0.48945105 0.48931125]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.701084152562544e-05\n",
            "for ccc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48325998 0.4832255  0.48320362 0.48321265 0.48324    0.48330468\n",
            " 0.48333967 0.48322457 0.48333716 0.48331085 0.48333514 0.48329356\n",
            " 0.48327127 0.48329234 0.48328978 0.4832908  0.48327836 0.48335716\n",
            " 0.48332006 0.48326114]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.374193667899817e-05\n",
            "for ccc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50743276 0.5073808  0.50736207 0.5074543  0.5074034  0.50743806\n",
            " 0.507479   0.507373   0.50745404 0.5074605  0.5074717  0.50741714\n",
            " 0.5075261  0.5074594  0.5074023  0.50741726 0.5074334  0.5075186\n",
            " 0.50747436 0.50739264]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.392473420011811e-05\n",
            "for ccc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5193479  0.51935565 0.5193424  0.5193424  0.5193097  0.5193281\n",
            " 0.5193065  0.51932603 0.51932174 0.5192978  0.5192975  0.519317\n",
            " 0.5193239  0.5193325  0.5193073  0.519322   0.51931924 0.5192811\n",
            " 0.51927507 0.51932657]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.0437637431314215e-05\n",
            "for ccc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48783585 0.48783392 0.48782176 0.48782972 0.4878248  0.48786396\n",
            " 0.48784417 0.4878357  0.4878466  0.48785472 0.48784974 0.48785707\n",
            " 0.48785454 0.48785758 0.48784852 0.48783517 0.48784393 0.48788816\n",
            " 0.48786694 0.48782688]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5988016457413323e-05\n",
            "for ccc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48932704 0.48923203 0.48923755 0.48928404 0.48926327 0.48943174\n",
            " 0.4894797  0.48922288 0.48941335 0.4893787  0.48941278 0.48935676\n",
            " 0.48941603 0.48945236 0.48929217 0.48934352 0.4893343  0.4895381\n",
            " 0.48945105 0.48931125]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.701084152562544e-05\n",
            "for pcc:\n",
            "y_true: [0.6635514  0.48598132 0.35514018 0.43925235 0.49532712 0.44859812\n",
            " 0.60747665 0.3271028  0.635514   0.6635514  0.36448598 0.45794392\n",
            " 0.17757009 0.55140185 0.45794392 0.71028036 0.5794392  0.39252338\n",
            " 0.5794392  0.39252338]\n",
            "y_pred: [0.48325998 0.4832255  0.48320362 0.48321265 0.48324    0.48330468\n",
            " 0.48333967 0.48322457 0.48333716 0.48331085 0.48333514 0.48329356\n",
            " 0.48327127 0.48329234 0.48328978 0.4832908  0.48327836 0.48335716\n",
            " 0.48332006 0.48326114]\n",
            "Stddev y_true: 0.13171519339084625\n",
            "Stddev y_pred: 4.374193667899817e-05\n",
            "for pcc:\n",
            "y_true: [0.5208333  0.5833333  0.4375     0.375      0.625      0.48958334\n",
            " 0.8125     0.33333334 0.7604167  0.6145833  0.5416667  0.45833334\n",
            " 0.15625    0.42708334 0.5416667  0.45833334 0.5208333  0.45833334\n",
            " 0.65625    0.38541666]\n",
            "y_pred: [0.50743276 0.5073808  0.50736207 0.5074543  0.5074034  0.50743806\n",
            " 0.507479   0.507373   0.50745404 0.5074605  0.5074717  0.50741714\n",
            " 0.5075261  0.5074594  0.5074023  0.50741726 0.5074334  0.5075186\n",
            " 0.50747436 0.50739264]\n",
            "Stddev y_true: 0.14455822110176086\n",
            "Stddev y_pred: 4.392473420011811e-05\n",
            "for pcc:\n",
            "y_true: [0.3956044  0.37362638 0.51648355 0.43956044 0.5604396  0.47252747\n",
            " 0.72527474 0.36263737 0.5934066  0.7032967  0.50549453 0.45054945\n",
            " 0.25274727 0.35164836 0.53846157 0.64835167 0.5714286  0.53846157\n",
            " 0.5824176  0.52747256]\n",
            "y_pred: [0.5193479  0.51935565 0.5193424  0.5193424  0.5193097  0.5193281\n",
            " 0.5193065  0.51932603 0.51932174 0.5192978  0.5192975  0.519317\n",
            " 0.5193239  0.5193325  0.5193073  0.519322   0.51931924 0.5192811\n",
            " 0.51927507 0.51932657]\n",
            "Stddev y_true: 0.1177927702665329\n",
            "Stddev y_pred: 2.0437637431314215e-05\n",
            "for pcc:\n",
            "y_true: [0.6407767  0.5339806  0.37864077 0.41747573 0.6407767  0.5339806\n",
            " 0.9514563  0.4563107  0.44660193 0.6407767  0.33009708 0.3883495\n",
            " 0.16504854 0.5339806  0.5048544  0.52427185 0.57281554 0.6407767\n",
            " 0.5825243  0.4368932 ]\n",
            "y_pred: [0.48783585 0.48783392 0.48782176 0.48782972 0.4878248  0.48786396\n",
            " 0.48784417 0.4878357  0.4878466  0.48785472 0.48784974 0.48785707\n",
            " 0.48785454 0.48785758 0.48784852 0.48783517 0.48784393 0.48788816\n",
            " 0.48786694 0.48782688]\n",
            "Stddev y_true: 0.15458783507347107\n",
            "Stddev y_pred: 1.5988016457413323e-05\n",
            "for pcc:\n",
            "y_true: [0.67777777 0.54444444 0.44444445 0.7        0.7777778  0.53333336\n",
            " 0.67777777 0.32222223 0.53333336 0.7111111  0.5555556  0.64444447\n",
            " 0.18888889 0.5555556  0.5        0.53333336 0.6333333  0.3\n",
            " 0.64444447 0.54444444]\n",
            "y_pred: [0.48932704 0.48923203 0.48923755 0.48928404 0.48926327 0.48943174\n",
            " 0.4894797  0.48922288 0.48941335 0.4893787  0.48941278 0.48935676\n",
            " 0.48941603 0.48945236 0.48929217 0.48934352 0.4893343  0.4895381\n",
            " 0.48945105 0.48931125]\n",
            "Stddev y_true: 0.14441880583763123\n",
            "Stddev y_pred: 8.701084152562544e-05\n",
            "evaluating Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48331916 0.5074587  0.5193225  0.4878661  0.48937494]\n",
            " [0.4833364  0.50746864 0.51928926 0.4878505  0.48944062]\n",
            " [0.48332846 0.5074793  0.51929915 0.48784876 0.48944366]\n",
            " [0.48327565 0.50743055 0.51930255 0.48785    0.48933616]\n",
            " [0.48335356 0.5074909  0.519297   0.48783743 0.48947787]\n",
            " [0.4832427  0.5074     0.51936066 0.4878302  0.48927703]\n",
            " [0.4832327  0.5074013  0.51933116 0.4878398  0.48929313]\n",
            " [0.48324028 0.50737447 0.5193152  0.48783407 0.4892728 ]\n",
            " [0.4832528  0.50738996 0.5193393  0.48785275 0.48926646]\n",
            " [0.48326218 0.50745845 0.51931846 0.4878628  0.48940772]]\n",
            "True Labels: [[0.69158876 0.6458333  0.73626375 0.5533981  0.7       ]\n",
            " [0.43925235 0.5        0.6813187  0.5631068  0.64444447]\n",
            " [0.38317758 0.38541666 0.3846154  0.32038835 0.5       ]\n",
            " [0.5233645  0.6770833  0.46153846 0.592233   0.6111111 ]\n",
            " [0.36448598 0.48958334 0.5714286  0.6213592  0.45555556]\n",
            " [0.44859812 0.6354167  0.5934066  0.592233   0.6111111 ]\n",
            " [0.48598132 0.5416667  0.61538464 0.5436893  0.53333336]\n",
            " [0.53271025 0.41666666 0.5494506  0.5631068  0.65555555]\n",
            " [0.57009345 0.5416667  0.61538464 0.36893204 0.73333335]\n",
            " [0.28037384 0.14583333 0.41758242 0.3106796  0.41111112]]\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n",
            "Predicted Labels: [[0.48324826 0.50744915 0.51933086 0.4878598  0.48937458]\n",
            " [0.48326507 0.50742304 0.5193383  0.48784888 0.48931703]\n",
            " [0.48328823 0.50742364 0.5193226  0.4878619  0.48936623]\n",
            " [0.48333704 0.5075009  0.5193111  0.4878987  0.4895063 ]\n",
            " [0.4832721  0.5074271  0.51931065 0.4878571  0.4893503 ]\n",
            " [0.48332122 0.5074468  0.5193088  0.48785472 0.48941666]\n",
            " [0.483333   0.5074792  0.51931536 0.48787335 0.48948237]\n",
            " [0.48326376 0.5073747  0.5193254  0.48782632 0.48926234]\n",
            " [0.4833098  0.50748247 0.5192984  0.48786145 0.4894056 ]\n",
            " [0.48322886 0.5074601  0.5193311  0.4878233  0.48933476]]\n",
            "True Labels: [[0.6635514  0.6041667  0.73626375 0.42718446 0.6       ]\n",
            " [0.47663552 0.6875     0.5494506  0.7378641  0.6888889 ]\n",
            " [0.47663552 0.5729167  0.5714286  0.4854369  0.45555556]\n",
            " [0.49532712 0.5833333  0.72527474 0.5533981  0.5222222 ]\n",
            " [0.3364486  0.25       0.37362638 0.41747573 0.62222224]\n",
            " [0.34579438 0.4375     0.37362638 0.66019416 0.41111112]\n",
            " [0.49532712 0.6458333  0.7912088  0.63106793 0.54444444]\n",
            " [0.43925235 0.5625     0.52747256 0.6893204  0.56666666]\n",
            " [0.27102804 0.20833333 0.4065934  0.30097088 0.33333334]\n",
            " [0.6635514  0.6041667  0.4945055  0.6699029  0.7888889 ]]\n",
            "for accuracy:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48331916 0.4833364  0.48332846 0.48327565 0.48335356 0.4832427\n",
            " 0.4832327  0.48324028 0.4832528  0.48326218 0.48324826 0.48326507\n",
            " 0.48328823 0.48333704 0.4832721  0.48332122 0.483333   0.48326376\n",
            " 0.4833098  0.48322886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.938625013688579e-05\n",
            "for accuracy:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5074587  0.50746864 0.5074793  0.50743055 0.5074909  0.5074\n",
            " 0.5074013  0.50737447 0.50738996 0.50745845 0.50744915 0.50742304\n",
            " 0.50742364 0.5075009  0.5074271  0.5074468  0.5074792  0.5073747\n",
            " 0.50748247 0.5074601 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.7536665331572294e-05\n",
            "for accuracy:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5193225  0.51928926 0.51929915 0.51930255 0.519297   0.51936066\n",
            " 0.51933116 0.5193152  0.5193393  0.51931846 0.51933086 0.5193383\n",
            " 0.5193226  0.5193111  0.51931065 0.5193088  0.51931536 0.5193254\n",
            " 0.5192984  0.5193311 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.693802551017143e-05\n",
            "for accuracy:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4878661  0.4878505  0.48784876 0.48785    0.48783743 0.4878302\n",
            " 0.4878398  0.48783407 0.48785275 0.4878628  0.4878598  0.48784888\n",
            " 0.4878619  0.4878987  0.4878571  0.48785472 0.48787335 0.48782632\n",
            " 0.48786145 0.4878233 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7179025235236622e-05\n",
            "for accuracy:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48937494 0.48944062 0.48944366 0.48933616 0.48947787 0.48927703\n",
            " 0.48929313 0.4892728  0.48926646 0.48940772 0.48937458 0.48931703\n",
            " 0.48936623 0.4895063  0.4893503  0.48941666 0.48948237 0.48926234\n",
            " 0.4894056  0.48933476]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.418636232614517e-05\n",
            "for r2:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48331916 0.4833364  0.48332846 0.48327565 0.48335356 0.4832427\n",
            " 0.4832327  0.48324028 0.4832528  0.48326218 0.48324826 0.48326507\n",
            " 0.48328823 0.48333704 0.4832721  0.48332122 0.483333   0.48326376\n",
            " 0.4833098  0.48322886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.938625013688579e-05\n",
            "for r2:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5074587  0.50746864 0.5074793  0.50743055 0.5074909  0.5074\n",
            " 0.5074013  0.50737447 0.50738996 0.50745845 0.50744915 0.50742304\n",
            " 0.50742364 0.5075009  0.5074271  0.5074468  0.5074792  0.5073747\n",
            " 0.50748247 0.5074601 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.7536665331572294e-05\n",
            "for r2:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5193225  0.51928926 0.51929915 0.51930255 0.519297   0.51936066\n",
            " 0.51933116 0.5193152  0.5193393  0.51931846 0.51933086 0.5193383\n",
            " 0.5193226  0.5193111  0.51931065 0.5193088  0.51931536 0.5193254\n",
            " 0.5192984  0.5193311 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.693802551017143e-05\n",
            "for r2:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4878661  0.4878505  0.48784876 0.48785    0.48783743 0.4878302\n",
            " 0.4878398  0.48783407 0.48785275 0.4878628  0.4878598  0.48784888\n",
            " 0.4878619  0.4878987  0.4878571  0.48785472 0.48787335 0.48782632\n",
            " 0.48786145 0.4878233 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7179025235236622e-05\n",
            "for r2:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48937494 0.48944062 0.48944366 0.48933616 0.48947787 0.48927703\n",
            " 0.48929313 0.4892728  0.48926646 0.48940772 0.48937458 0.48931703\n",
            " 0.48936623 0.4895063  0.4893503  0.48941666 0.48948237 0.48926234\n",
            " 0.4894056  0.48933476]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.418636232614517e-05\n",
            "for ccc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48331916 0.4833364  0.48332846 0.48327565 0.48335356 0.4832427\n",
            " 0.4832327  0.48324028 0.4832528  0.48326218 0.48324826 0.48326507\n",
            " 0.48328823 0.48333704 0.4832721  0.48332122 0.483333   0.48326376\n",
            " 0.4833098  0.48322886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.938625013688579e-05\n",
            "for ccc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5074587  0.50746864 0.5074793  0.50743055 0.5074909  0.5074\n",
            " 0.5074013  0.50737447 0.50738996 0.50745845 0.50744915 0.50742304\n",
            " 0.50742364 0.5075009  0.5074271  0.5074468  0.5074792  0.5073747\n",
            " 0.50748247 0.5074601 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.7536665331572294e-05\n",
            "for ccc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5193225  0.51928926 0.51929915 0.51930255 0.519297   0.51936066\n",
            " 0.51933116 0.5193152  0.5193393  0.51931846 0.51933086 0.5193383\n",
            " 0.5193226  0.5193111  0.51931065 0.5193088  0.51931536 0.5193254\n",
            " 0.5192984  0.5193311 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.693802551017143e-05\n",
            "for ccc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4878661  0.4878505  0.48784876 0.48785    0.48783743 0.4878302\n",
            " 0.4878398  0.48783407 0.48785275 0.4878628  0.4878598  0.48784888\n",
            " 0.4878619  0.4878987  0.4878571  0.48785472 0.48787335 0.48782632\n",
            " 0.48786145 0.4878233 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7179025235236622e-05\n",
            "for ccc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48937494 0.48944062 0.48944366 0.48933616 0.48947787 0.48927703\n",
            " 0.48929313 0.4892728  0.48926646 0.48940772 0.48937458 0.48931703\n",
            " 0.48936623 0.4895063  0.4893503  0.48941666 0.48948237 0.48926234\n",
            " 0.4894056  0.48933476]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.418636232614517e-05\n",
            "for pcc:\n",
            "y_true: [0.69158876 0.43925235 0.38317758 0.5233645  0.36448598 0.44859812\n",
            " 0.48598132 0.53271025 0.57009345 0.28037384 0.6635514  0.47663552\n",
            " 0.47663552 0.49532712 0.3364486  0.34579438 0.49532712 0.43925235\n",
            " 0.27102804 0.6635514 ]\n",
            "y_pred: [0.48331916 0.4833364  0.48332846 0.48327565 0.48335356 0.4832427\n",
            " 0.4832327  0.48324028 0.4832528  0.48326218 0.48324826 0.48326507\n",
            " 0.48328823 0.48333704 0.4832721  0.48332122 0.483333   0.48326376\n",
            " 0.4833098  0.48322886]\n",
            "Stddev y_true: 0.11667653918266296\n",
            "Stddev y_pred: 3.938625013688579e-05\n",
            "for pcc:\n",
            "y_true: [0.6458333  0.5        0.38541666 0.6770833  0.48958334 0.6354167\n",
            " 0.5416667  0.41666666 0.5416667  0.14583333 0.6041667  0.6875\n",
            " 0.5729167  0.5833333  0.25       0.4375     0.6458333  0.5625\n",
            " 0.20833333 0.6041667 ]\n",
            "y_pred: [0.5074587  0.50746864 0.5074793  0.50743055 0.5074909  0.5074\n",
            " 0.5074013  0.50737447 0.50738996 0.50745845 0.50744915 0.50742304\n",
            " 0.50742364 0.5075009  0.5074271  0.5074468  0.5074792  0.5073747\n",
            " 0.50748247 0.5074601 ]\n",
            "Stddev y_true: 0.15246368944644928\n",
            "Stddev y_pred: 3.7536665331572294e-05\n",
            "for pcc:\n",
            "y_true: [0.73626375 0.6813187  0.3846154  0.46153846 0.5714286  0.5934066\n",
            " 0.61538464 0.5494506  0.61538464 0.41758242 0.73626375 0.5494506\n",
            " 0.5714286  0.72527474 0.37362638 0.37362638 0.7912088  0.52747256\n",
            " 0.4065934  0.4945055 ]\n",
            "y_pred: [0.5193225  0.51928926 0.51929915 0.51930255 0.519297   0.51936066\n",
            " 0.51933116 0.5193152  0.5193393  0.51931846 0.51933086 0.5193383\n",
            " 0.5193226  0.5193111  0.51931065 0.5193088  0.51931536 0.5193254\n",
            " 0.5192984  0.5193311 ]\n",
            "Stddev y_true: 0.12736235558986664\n",
            "Stddev y_pred: 1.693802551017143e-05\n",
            "for pcc:\n",
            "y_true: [0.5533981  0.5631068  0.32038835 0.592233   0.6213592  0.592233\n",
            " 0.5436893  0.5631068  0.36893204 0.3106796  0.42718446 0.7378641\n",
            " 0.4854369  0.5533981  0.41747573 0.66019416 0.63106793 0.6893204\n",
            " 0.30097088 0.6699029 ]\n",
            "y_pred: [0.4878661  0.4878505  0.48784876 0.48785    0.48783743 0.4878302\n",
            " 0.4878398  0.48783407 0.48785275 0.4878628  0.4878598  0.48784888\n",
            " 0.4878619  0.4878987  0.4878571  0.48785472 0.48787335 0.48782632\n",
            " 0.48786145 0.4878233 ]\n",
            "Stddev y_true: 0.12855923175811768\n",
            "Stddev y_pred: 1.7179025235236622e-05\n",
            "for pcc:\n",
            "y_true: [0.7        0.64444447 0.5        0.6111111  0.45555556 0.6111111\n",
            " 0.53333336 0.65555555 0.73333335 0.41111112 0.6        0.6888889\n",
            " 0.45555556 0.5222222  0.62222224 0.41111112 0.54444444 0.56666666\n",
            " 0.33333334 0.7888889 ]\n",
            "y_pred: [0.48937494 0.48944062 0.48944366 0.48933616 0.48947787 0.48927703\n",
            " 0.48929313 0.4892728  0.48926646 0.48940772 0.48937458 0.48931703\n",
            " 0.48936623 0.4895063  0.4893503  0.48941666 0.48948237 0.48926234\n",
            " 0.4894056  0.48933476]\n",
            "Stddev y_true: 0.11562364548444748\n",
            "Stddev y_pred: 7.418636232614517e-05\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "modelsCsvPath = \"/content/vgg.csv\"\n",
        "best_accuracy = -1\n",
        "best_epoch = -1\n",
        "\n",
        "phases = [\"Training\", \"Validation\", \"Test\"]\n",
        "phases_dataloader = [train_dataloader, valid_dataloader, test_dataloader]\n",
        "\n",
        "\n",
        "metrics = [\"accuracy\", \"r2\", \"ccc\", \"pcc\"]\n",
        "wantedMetrics = {}\n",
        "for phase in phases:\n",
        "  wantedMetrics[phase] = {}\n",
        "  for metric in metrics:\n",
        "    wantedMetrics[phase][metric] = []\n",
        "\n",
        "\n",
        "t1 = datetime.datetime.utcnow()\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "    # Training\n",
        "    print(\"training...\")\n",
        "    training_losses = trainAudioModel(model, criterion2, optimizer, train_dataloader, device)\n",
        "\n",
        "    # Evaluation\n",
        "    for i in range(len(phases)):\n",
        "        print(f\"evaluating {phases[i]}...\")\n",
        "        losses, y_pred, y_true = evaluateAudioModel(model, criterion1, phases_dataloader[i], device)\n",
        "\n",
        "        if phases[i] == \"Test\":\n",
        "            test_predictions = y_pred\n",
        "            test_labels = y_true\n",
        "\n",
        "        if phases[i] == \"Validation\":\n",
        "            validation_predictions = y_pred\n",
        "            validation_labels = y_true\n",
        "\n",
        "        wantedMetrics = evaluationMetrics(y_true, y_pred, wantedMetrics, phases[i])\n",
        "\n",
        "        if phases[i] == \"Training\":\n",
        "            losses = training_losses\n",
        "\n",
        "        history = updateHistory(history, phases[i],\n",
        "                                    wantedMetrics[phases[i]][\"accuracy\"],\n",
        "                                    wantedMetrics[phases[i]][\"r2\"],\n",
        "                                    wantedMetrics[phases[i]][\"ccc\"],\n",
        "                                    wantedMetrics[phases[i]][\"pcc\"], losses)\n",
        "\n",
        "    # Check for best accuracy and save model\n",
        "    if history[\"meanAccuracyValidation\"][epoch] > best_accuracy:\n",
        "        best_accuracy = history[\"meanAccuracyValidation\"][epoch]\n",
        "        best_epoch = epoch\n",
        "\n",
        "        if not os.path.isfile(modelsCsvPath):\n",
        "                haveHeader = True\n",
        "\n",
        "        new_row = createRow(modelInfo = modelInfo, history = history,\n",
        "                            epoch = epoch, elapsedTime = None,\n",
        "                            torchInfo = torchInfo)\n",
        "\n",
        "t2 = datetime.datetime.utcnow()\n",
        "\n",
        "new_row[\"elapsedTime\"] = str(t2-t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot regression to the mean"
      ],
      "metadata": {
        "id": "-ssaNPlTPXT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "3hU8O6CPRkyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_mean = np.mean(test_predictions, axis=0)\n",
        "test_labels_mean = np.mean(test_labels, axis=0)\n",
        "\n",
        "test_prediction_differences = test_predictions - test_predictions_mean\n",
        "test_label_differences = test_labels - test_labels_mean"
      ],
      "metadata": {
        "id": "K8Wj4cbhPV8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(test_label_differences, test_prediction_differences)\n",
        "plt.xlabel(\"Difference between Test Labels and Label Mean\")\n",
        "plt.ylabel(\"Difference between Test Predictions and Prediction Mean\")\n",
        "plt.title(\"Regression to the Mean Check (Test Set)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "PIFrEsCcRiPa",
        "outputId": "f089c74a-bd5d-4af8-f4fd-e8d07318c9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validation"
      ],
      "metadata": {
        "id": "wVrgJ3yPRmw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_predictions_mean = np.mean(validation_predictions, axis=0)\n",
        "validation_labels_mean = np.mean(validation_labels, axis=0)\n",
        "\n",
        "validation_prediction_differences = validation_predictions - validation_predictions_mean\n",
        "validation_label_differences = validation_labels - validation_labels_mean"
      ],
      "metadata": {
        "id": "jY9th01bRt-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(validation_label_differences, validation_prediction_differences)\n",
        "plt.xlabel(\"Difference between validation Labels and Label Mean\")\n",
        "plt.ylabel(\"Difference between validation Predictions and Prediction Mean\")\n",
        "plt.title(\"Regression to the Mean Check (validation Set)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "p0yKVvZxRwrU",
        "outputId": "dc89fe74-5482-4f34-c9c3-38c255eaca7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shap"
      ],
      "metadata": {
        "id": "ljFez5F1SsYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybYbQR4lSu7S",
        "outputId": "396ff01c-4e21-45a7-d24e-30aca3ffe40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.46.0 slicer-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.Explainer(model, train_dataloader)"
      ],
      "metadata": {
        "id": "f9n0RmwRSxYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# از دیتالودر تست یک نمونه بگیرید\n",
        "data_iter = iter(test_dataloader)\n",
        "\n",
        "# فقط داده‌های صوتی را استخراج کنید (بدون لیبل)\n",
        "audios, _ = next(data_iter)  # audios شامل ویژگی‌ها (داده‌های صوتی) است، لیبل‌ها استفاده نمی‌شوند\n",
        "\n",
        "# reshape داده‌ها به شکل مناسب برای مدل\n",
        "Total = audios.size(0) * audioFrameNum  # بچ‌سایز * تعداد فریم‌ها\n",
        "audios_reshaped = audios.reshape(Total, audioChannelNum, audioWidth, audioHeight)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    audios_reshaped = audios_reshaped.cuda()\n",
        "\n",
        "# ایجاد explainer با مدل و داده‌های reshape شده\n",
        "explainer = shap.DeepExplainer(model, audios_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8jI8yn6a6jt",
        "outputId": "d163a4e0-ae75-431f-aee0-fb6ce023eee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0877262d7d23>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features).clone().detach().float()  # Safe tensor conversion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# محاسبه مقادیر SHAP برای داده‌ها\n",
        "shap_values = explainer.shap_values(audios_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7trihl2Tew7i",
        "outputId": "3590ebee-bd45-4904-e156-0bac3292a8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([300, 1, 64, 96])\n",
            "after conv1:  torch.Size([300, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([300, 64, 32, 48])\n",
            "after conv2:  torch.Size([300, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([300, 128, 16, 24])\n",
            "after conv3:  torch.Size([300, 256, 16, 24])\n",
            "after conv4:  torch.Size([300, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([300, 256, 8, 12])\n",
            "after conv5:  torch.Size([300, 512, 8, 12])\n",
            "after conv6:  torch.Size([300, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([300, 512, 4, 6])\n",
            "after flatten:  torch.Size([300, 12288])\n",
            "after fc1:  torch.Size([300, 4096])\n",
            "after fc2:  torch.Size([300, 4096])\n",
            "after fc3:  torch.Size([300, 128])\n",
            "after fc3:  torch.Size([300, 5])\n",
            "input:  torch.Size([150, 1, 64, 96])\n",
            "after conv1:  torch.Size([150, 64, 64, 96])\n",
            "after maxpool1:  torch.Size([150, 64, 32, 48])\n",
            "after conv2:  torch.Size([150, 128, 32, 48])\n",
            "after maxpool2:  torch.Size([150, 128, 16, 24])\n",
            "after conv3:  torch.Size([150, 256, 16, 24])\n",
            "after conv4:  torch.Size([150, 256, 16, 24])\n",
            "after maxpool3:  torch.Size([150, 256, 8, 12])\n",
            "after conv5:  torch.Size([150, 512, 8, 12])\n",
            "after conv6:  torch.Size([150, 512, 8, 12])\n",
            "after maxpool4:  torch.Size([150, 512, 4, 6])\n",
            "after flatten:  torch.Size([150, 12288])\n",
            "after fc1:  torch.Size([150, 4096])\n",
            "after fc2:  torch.Size([150, 4096])\n",
            "after fc3:  torch.Size([150, 128])\n",
            "after fc3:  torch.Size([150, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C8VczmotBfM",
        "outputId": "946f68d0-fd89-4bdd-be5e-81f3d0271054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 1, 64, 96, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values2 = np.array(shap_values)\n",
        "shap_values2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nv0JWCRvtjN",
        "outputId": "85b9fd82-72fe-4e49-f171-203aef5f7ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 1, 64, 96, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audios_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2q7ihuT00bG",
        "outputId": "0390bd89-df5e-4c3e-e557-ed5d3b93fd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 1, 64, 96])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = np.mean(shap_values, axis=1)\n",
        "shap_values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z43-KgS96QXq",
        "outputId": "46ac0bb5-e693-40d9-ab77-0762e4a876cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 64, 96, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "uSQQEomZS9Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save csv"
      ],
      "metadata": {
        "id": "pL0qX8sCTnjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezVmw0Xz6pk2"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns = new_row.keys())\n",
        "df.loc[0] = new_row\n",
        "df.to_csv(modelsCsvPath, mode=\"a\", header=haveHeader, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-hbtgzgwkuLC",
        "KZxcXDMYk56d",
        "fqpE4ztylqwz",
        "sOyQHdkhpF7U"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}